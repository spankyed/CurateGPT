[
    {
        "id": "2307.01548",
        "title": "Knowledge Graph for NLG in the context of conversational agents",
        "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
        "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
        "semantic_relevancy_score": 0.4531978964805603
    },
    {
        "id": "2307.01933",
        "title": "Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs",
        "abstract": "Knowledge graph embeddings (KGE) have been extensively studied to embed\nlarge-scale relational data for many real-world applications. Existing methods\nhave long ignored the fact many KGs contain two fundamentally different views:\nhigh-level ontology-view concepts and fine-grained instance-view entities. They\nusually embed all nodes as vectors in one latent space. However, a single\ngeometric representation fails to capture the structural differences between\ntwo views and lacks probabilistic semantics towards concepts' granularity. We\npropose Concept2Box, a novel approach that jointly embeds the two views of a KG\nusing dual geometric representations. We model concepts with box embeddings,\nwhich learn the hierarchy structure and complex relations such as overlap and\ndisjoint among them. Box volumes can be interpreted as concepts' granularity.\nDifferent from concepts, we model entities as vectors. To bridge the gap\nbetween concept box embeddings and entity vector embeddings, we propose a novel\nvector-to-box distance metric and learn both embeddings jointly. Experiments on\nboth the public DBpedia KG and a newly-created industrial KG showed the\neffectiveness of Concept2Box.",
        "pdfLink": "https://arxiv.org/pdf/2307.01933.pdf",
        "semantic_relevancy_score": 0.38993898034095764
    },
    {
        "id": "2307.10680",
        "title": "A Personalized Recommender System Based-on Knowledge Graph Embeddings",
        "abstract": "Knowledge graphs have proven to be effective for modeling entities and their\nrelationships through the use of ontologies. The recent emergence in interest\nfor using knowledge graphs as a form of information modeling has led to their\nincreased adoption in recommender systems. By incorporating users and items\ninto the knowledge graph, these systems can better capture the implicit\nconnections between them and provide more accurate recommendations. In this\npaper, we investigate and propose the construction of a personalized\nrecommender system via knowledge graphs embedding applied to the vehicle\npurchase/sale domain. The results of our experimentation demonstrate the\nefficacy of the proposed method in providing relevant recommendations that are\nconsistent with individual users.",
        "pdfLink": "https://arxiv.org/pdf/2307.10680.pdf",
        "semantic_relevancy_score": 0.38526344299316406
    },
    {
        "id": "2308.05481",
        "title": "LLM As DBA",
        "abstract": "Database administrators (DBAs) play a crucial role in managing, maintaining and optimizing a database system to ensure data availability, performance, and reliability. However, it is hard and tedious for DBAs to manage a large number of database instances (e.g., millions of instances on the cloud databases). Recently large language models (LLMs) have shown great potential to understand valuable documents and accordingly generate reasonable answers. Thus, we propose D-Bot, a LLM-based database administrator that can continuously acquire database maintenance experience from textual sources, and provide reasonable, well-founded, in-time diagnosis and optimization advice for target databases. This paper presents a revolutionary LLM-centric framework for database maintenance, including (i) database maintenance knowledge detection from documents and tools, (ii) tree of thought reasoning for root cause analysis, and (iii) collaborative diagnosis among multiple LLMs. Our preliminary experimental results that D-Bot can efficiently and effectively diagnose the root causes and our code is available at this http URL.",
        "pdfLink": "https://arxiv.org/pdf/2308.05481.pdf",
        "semantic_relevancy_score": 0.3641251027584076
    },
    {
        "id": "2307.06917",
        "title": "LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT",
        "abstract": "Knowledge Graphs (KG) provide us with a structured, flexible, transparent,\ncross-system, and collaborative way of organizing our knowledge and data across\nvarious domains in society and industrial as well as scientific disciplines.\nKGs surpass any other form of representation in terms of effectiveness.\nHowever, Knowledge Graph Engineering (KGE) requires in-depth experiences of\ngraph structures, web technologies, existing models and vocabularies, rule\nsets, logic, as well as best practices. It also demands a significant amount of\nwork. Considering the advancements in large language models (LLMs) and their\ninterfaces and applications in recent years, we have conducted comprehensive\nexperiments with ChatGPT to explore its potential in supporting KGE. In this\npaper, we present a selection of these experiments and their results to\ndemonstrate how ChatGPT can assist us in the development and management of KGs.",
        "pdfLink": "https://arxiv.org/pdf/2307.06917.pdf",
        "semantic_relevancy_score": 0.3409186005592346
    },
    {
        "id": "2206.08853",
        "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
        "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
        "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
        "semantic_relevancy_score": 0.3277594745159149
    },
    {
        "id": "2307.01204",
        "title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach",
        "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict\nmissing links for unseen entities with few-shot links observed. Previous\nmethods are limited to transductive scenarios, where entities exist in the\nknowledge graphs, so they are unable to handle unseen entities. Therefore,\nrecent inductive methods utilize the sub-graphs around unseen entities to\nobtain the semantics and predict links inductively. However, in the few-shot\nsetting, the sub-graphs are often sparse and cannot provide meaningful\ninductive patterns. In this paper, we propose a novel relational anonymous\nwalk-guided neural process for few-shot inductive link prediction on knowledge\ngraphs, denoted as RawNP. Specifically, we develop a neural process-based\nmethod to model a flexible distribution over link prediction functions. This\nenables the model to quickly adapt to new entities and estimate the uncertainty\nwhen making predictions. To capture general inductive patterns, we present a\nrelational anonymous walk to extract a series of relational motifs from\nfew-shot observations. These motifs reveal the distinctive semantic patterns on\nKGs that support inductive predictions. Extensive experiments on typical\nbenchmark datasets demonstrate that our model derives new state-of-the-art\nperformance.",
        "pdfLink": "https://arxiv.org/pdf/2307.01204.pdf",
        "semantic_relevancy_score": 0.31846317648887634
    },
    {
        "id": "2307.05082",
        "title": "OntoChatGPT Information System: Ontology-Driven Structured Prompts for ChatGPT Meta-Learning",
        "abstract": "This research presents a comprehensive methodology for utilizing an\nontology-driven structured prompts system in interplay with ChatGPT, a widely\nused large language model (LLM). The study develops formal models, both\ninformation and functional, and establishes the methodological foundations for\nintegrating ontology-driven prompts with ChatGPT's meta-learning capabilities.\nThe resulting productive triad comprises the methodological foundations,\nadvanced information technology, and the OntoChatGPT system, which collectively\nenhance the effectiveness and performance of chatbot systems. The\nimplementation of this technology is demonstrated using the Ukrainian language\nwithin the domain of rehabilitation. By applying the proposed methodology, the\nOntoChatGPT system effectively extracts entities from contexts, classifies\nthem, and generates relevant responses. The study highlights the versatility of\nthe methodology, emphasizing its applicability not only to ChatGPT but also to\nother chatbot systems based on LLMs, such as Google's Bard utilizing the PaLM 2\nLLM. The underlying principles of meta-learning, structured prompts, and\nontology-driven information retrieval form the core of the proposed\nmethodology, enabling their adaptation and utilization in various LLM-based\nsystems. This versatile approach opens up new possibilities for NLP and\ndialogue systems, empowering developers to enhance the performance and\nfunctionality of chatbot systems across different domains and languages.",
        "pdfLink": "https://arxiv.org/pdf/2307.05082.pdf",
        "semantic_relevancy_score": 0.31605207920074463
    },
    {
        "id": "2307.01928",
        "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
        "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities\n-- from step-by-step planning to commonsense reasoning -- that may provide\nutility for robots, but remain prone to confidently hallucinated predictions.\nIn this work, we present KnowNo, which is a framework for measuring and\naligning the uncertainty of LLM-based planners such that they know when they\ndon't know and ask for help when needed. KnowNo builds on the theory of\nconformal prediction to provide statistical guarantees on task completion while\nminimizing human help in complex multi-step planning settings. Experiments\nacross a variety of simulated and real robot setups that involve tasks with\ndifferent modes of ambiguity (e.g., from spatial to numeric uncertainties, from\nhuman preferences to Winograd schemas) show that KnowNo performs favorably over\nmodern baselines (which may involve ensembles or extensive prompt tuning) in\nterms of improving efficiency and autonomy, while providing formal assurances.\nKnowNo can be used with LLMs out of the box without model-finetuning, and\nsuggests a promising lightweight approach to modeling uncertainty that can\ncomplement and scale with the growing capabilities of foundation models.\nWebsite: this https URL",
        "pdfLink": "https://arxiv.org/pdf/2307.01928.pdf",
        "semantic_relevancy_score": 0.3117046356201172
    }
]