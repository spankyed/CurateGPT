[
  {
    "date": {
      "value": "2024-05-31",
      "status": "pending",
      "count": null,
      "createdAt": "2024-05-31 04:00:01.010 +00:00",
      "updatedAt": "2024-05-31 13:50:50.309 +00:00"
    },
    "papers": []
  },
  {
    "date": {
      "value": "2024-05-30",
      "status": "complete",
      "count": 118,
      "createdAt": "2024-05-31 00:09:48.114 +00:00",
      "updatedAt": "2024-05-31 04:58:28.953 +00:00"
    },
    "papers": [
      {
        "id": "2405.19686",
        "date": "2024-05-30",
        "title": "Knowledge Graph Tuning: Real-time Large Language Model Personalization\n  based on Human Feedback",
        "abstract": "  Large language models (LLMs) have demonstrated remarkable proficiency in a\nrange of natural language processing tasks. Once deployed, LLMs encounter users\nwith personalized factual knowledge, and such personalized knowledge is\nconsistently reflected through users' interactions with the LLMs. To enhance\nuser experience, real-time model personalization is essential, allowing LLMs to\nadapt user-specific knowledge based on user feedback during human-LLM\ninteractions. Existing methods mostly require back-propagation to finetune the\nmodel parameters, which incurs high computational and memory costs. In\naddition, these methods suffer from low interpretability, which will cause\nunforeseen impacts on model performance during long-term use, where the user's\npersonalized knowledge is accumulated extensively.To address these challenges,\nwe propose Knowledge Graph Tuning (KGT), a novel approach that leverages\nknowledge graphs (KGs) to personalize LLMs. KGT extracts personalized factual\nknowledge triples from users' queries and feedback and optimizes KGs without\nmodifying the LLM parameters. Our method improves computational and memory\nefficiency by avoiding back-propagation and ensures interpretability by making\nthe KG adjustments comprehensible to humans.Experiments with state-of-the-art\nLLMs, including GPT-2, Llama2, and Llama3, show that KGT significantly improves\npersonalization performance while reducing latency and GPU memory costs.\nUltimately, KGT offers a promising solution of effective, efficient, and\ninterpretable real-time LLM personalization during user interactions with the\nLLMs.\n",
        "authors": "Jingwei Sun; Zhixu Du; Yiran Chen",
        "status": 0,
        "relevancy": 0.6376084555961112,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20309",
        "date": "2024-05-30",
        "title": "Large Language Models Can Self-Improve At Web Agent Tasks",
        "abstract": "  Training models to act as agents that can effectively navigate and perform\nactions in a complex environment, such as a web browser, has typically been\nchallenging due to lack of training data. Large language models (LLMs) have\nrecently demonstrated some capability to navigate novel environments as agents\nin a zero-shot or few-shot fashion, purely guided by natural language\ninstructions as prompts. Recent research has also demonstrated LLMs have the\ncapability to exceed their base performance through self-improvement, i.e.\nfine-tuning on data generated by the model itself. In this work, we explore the\nextent to which LLMs can self-improve their performance as agents in\nlong-horizon tasks in a complex environment using the WebArena benchmark. In\nWebArena, an agent must autonomously navigate and perform actions on web pages\nto achieve a specified objective. We explore fine-tuning on three distinct\nsynthetic training data mixtures and achieve a 31\\% improvement in task\ncompletion rate over the base model on the WebArena benchmark through a\nself-improvement procedure. We additionally contribute novel evaluation metrics\nfor assessing the performance, robustness, capabilities, and quality of\ntrajectories of our fine-tuned agent models to a greater degree than simple,\naggregate-level benchmark scores currently used to measure self-improvement.\n",
        "authors": "Ajay Patel; Markus Hofmarcher; Claudiu Leoveanu-Condrei; Marius-Constantin Dinu; Chris Callison-Burch; Sepp Hochreiter",
        "status": 0,
        "relevancy": 0.6260053599812707,
        "isStarred": true,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T07:09:19.690Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19737",
        "date": "2024-05-30",
        "title": "Beyond Imitation: Learning Key Reasoning Steps from Dual\n  Chain-of-Thoughts in Reasoning Distillation",
        "abstract": "  As Large Language Models (LLMs) scale up and gain powerful Chain-of-Thoughts\n(CoTs) reasoning abilities, practical resource constraints drive efforts to\ndistill these capabilities into more compact Smaller Language Models (SLMs). We\nfind that CoTs consist mainly of simple reasoning forms, with a small\nproportion ($\\approx 4.7\\%$) of key reasoning steps that truly impact\nconclusions. However, previous distillation methods typically involve\nsupervised fine-tuning student SLMs only on correct CoTs data produced by\nteacher LLMs, resulting in students struggling to learn the key reasoning\nsteps, instead imitating the teacher's reasoning forms and making errors or\nomissions on these steps. To address these issues, drawing an analogy to human\nlearning, where analyzing mistakes according to correct solutions often reveals\nthe crucial steps leading to successes or failures, we propose\nmistak\\textbf{E}-\\textbf{D}riven key reason\\textbf{I}ng step\ndistilla\\textbf{T}ion (\\textbf{EDIT}), a novel method that further aids SLMs\nlearning key reasoning steps rather than mere simple fine-tuning. Firstly, to\nexpose these crucial steps in CoTs, we design specific prompts to generate dual\nCoTs data with similar reasoning paths but divergent conclusions. Then, we\napply the minimum edit distance algorithm on the dual CoTs data to locate these\nkey steps and optimize the likelihood of these steps. Extensive experiments\nvalidate the effectiveness of EDIT across both in-domain and out-of-domain\nbenchmark reasoning datasets. Further analysis shows that EDIT can generate\nhigh-quality CoTs with more correct key reasoning steps. Notably, we also\nexplore how different mistake patterns affect performance and find that EDIT\nbenefits more from logical errors than from knowledge or mathematical\ncalculation errors in dual CoTs\\footnote{Code can be found at\n\\url{https://github.com/C-W-D/EDIT}}.\n",
        "authors": "Chengwei Dai; Kun Li; Wei Zhou; Songlin Hu",
        "status": 0,
        "relevancy": 0.6101105980546383,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20315",
        "date": "2024-05-30",
        "title": "ANAH: Analytical Annotation of Hallucinations in Large Language Models",
        "abstract": "  Reducing the `$\\textit{hallucination}$' problem of Large Language Models\n(LLMs) is crucial for their wide applications. A comprehensive and fine-grained\nmeasurement of the hallucination is the first key step for the governance of\nthis issue but is under-explored in the community. Thus, we present\n$\\textbf{ANAH}$, a bilingual dataset that offers $\\textbf{AN}$alytical\n$\\textbf{A}$nnotation of $\\textbf{H}$allucinations in LLMs within Generative\nQuestion Answering. Each answer sentence in our dataset undergoes rigorous\nannotation, involving the retrieval of a reference fragment, the judgment of\nthe hallucination type, and the correction of hallucinated content. ANAH\nconsists of ~12k sentence-level annotations for ~4.3k LLM responses covering\nover 700 topics, constructed by a human-in-the-loop pipeline. Thanks to the\nfine granularity of the hallucination annotations, we can quantitatively\nconfirm that the hallucinations of LLMs progressively accumulate in the answer\nand use ANAH to train and evaluate hallucination annotators. We conduct\nextensive experiments on studying generative and discriminative annotators and\nshow that, although current open-source LLMs have difficulties in fine-grained\nhallucination annotation, the generative annotator trained with ANAH can\nsurpass all open-source LLMs and GPT-3.5, obtain performance competitive with\nGPT-4, and exhibits better generalization ability on unseen questions.\n",
        "authors": "Ziwei Ji; Yuzhe Gu; Wenwei Zhang; Chengqi Lyu; Dahua Lin; Kai Chen",
        "status": 0,
        "relevancy": 0.6035992069948193,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T07:09:34.075Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20179",
        "date": "2024-05-30",
        "title": "Robo-Instruct: Simulator-Augmented Instruction Alignment For Finetuning\n  CodeLLMs",
        "abstract": "  Large language models (LLMs) have shown great promise at generating robot\nprograms from natural language given domain-specific robot application\nprogramming interfaces (APIs). However, the performance gap between proprietary\nLLMs and smaller open-weight LLMs remains wide. This raises a question: Can we\nfine-tune smaller open-weight LLMs for generating domain-specific robot\nprograms to close the performance gap with proprietary LLMs? While\nSelf-Instruct is a promising solution by generating a diverse set of training\ndata, it cannot verify the correctness of these programs. In contrast, a robot\nsimulator with a well-defined world can identify execution errors but limits\nthe diversity of programs that it can verify. In this work, we introduce\nRobo-Instruct, which brings the best of both worlds -- it promotes the\ndiversity of Self-Instruct while providing the correctness of simulator-based\nchecking. Robo-Instruct introduces RoboSim to synthesize a consistent world\nstate on the fly by inferring properties relevant to the program being checked,\nand simulating actions accordingly. Furthermore, the instructions and programs\ngenerated by Self-Instruct may be subtly inconsistent -- such as the program\nmissing a step implied by the instruction. Robo-Instruct further addresses this\nwith InstAlign, an instruction-program alignment procedure that revises the\ntask instruction to reflect the actual results of the generated program. Given\na few seed task descriptions and the robot APIs, Robo-Instruct is capable of\ngenerating a training dataset using only a small open-weight model. This\ndataset can then be used to fine-tune small open-weight language models,\nenabling them to match or even exceed the performance of several proprietary\nLLMs, such as GPT-3.5-Turbo and Gemini-Pro.\n",
        "authors": "Zichao Hu; Junyi Jessy Li; Arjun Guha; Joydeep Biswas",
        "status": 0,
        "relevancy": 0.5998539735913091,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20163",
        "date": "2024-05-30",
        "title": "Reasoning about concepts with LLMs: Inconsistencies abound",
        "abstract": "  The ability to summarize and organize knowledge into abstract concepts is key\nto learning and reasoning. Many industrial applications rely on the consistent\nand systematic use of concepts, especially when dealing with decision-critical\nknowledge. However, we demonstrate that, when methodically questioned, large\nlanguage models (LLMs) often display and demonstrate significant\ninconsistencies in their knowledge. Computationally, the basic aspects of the\nconceptualization of a given domain can be represented as Is-A hierarchies in a\nknowledge graph (KG) or ontology, together with a few properties or axioms that\nenable straightforward reasoning. We show that even simple ontologies can be\nused to reveal conceptual inconsistencies across several LLMs. We also propose\nstrategies that domain experts can use to evaluate and improve the coverage of\nkey domain concepts in LLMs of various sizes. In particular, we have been able\nto significantly enhance the performance of LLMs of various sizes with openly\navailable weights using simple knowledge-graph (KG) based prompting strategies.\n",
        "authors": "Rosario Uceda-Sosa; Karthikeyan Natesan Ramamurthy; Maria Chang; Moninder Singh",
        "status": 0,
        "relevancy": 0.5992772276091419,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19616",
        "date": "2024-05-30",
        "title": "Easy Problems That LLMs Get Wrong",
        "abstract": "  We introduce a comprehensive Linguistic Benchmark designed to evaluate the\nlimitations of Large Language Models (LLMs) in domains such as logical\nreasoning, spatial intelligence, and linguistic understanding, among others.\nThrough a series of straightforward questions, it uncovers the significant\nlimitations of well-regarded models to perform tasks that humans manage with\nease. It also highlights the potential of prompt engineering to mitigate some\nerrors and underscores the necessity for better training methodologies. Our\nfindings stress the importance of grounding LLMs with human reasoning and\ncommon sense, emphasising the need for human-in-the-loop for enterprise\napplications. We hope this work paves the way for future research to enhance\nthe usefulness and reliability of new models.\n",
        "authors": "Sean Williams; James Huckle",
        "status": 0,
        "relevancy": 0.593759085090133,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19842",
        "date": "2024-05-30",
        "title": "Improve Student's Reasoning Generalizability through Cascading\n  Decomposed CoTs Distillation",
        "abstract": "  Large language models (LLMs) exhibit enhanced reasoning at larger scales,\ndriving efforts to distill these capabilities into smaller models via\nteacher-student learning. Previous works simply fine-tune student models on\nteachers' generated Chain-of-Thoughts (CoTs) data. Although these methods\nenhance in-domain (IND) reasoning performance, they struggle to generalize to\nout-of-domain (OOD) tasks. We believe that the widespread spurious correlations\nbetween questions and answers may lead the model to preset a specific answer\nwhich restricts the diversity and generalizability of its reasoning process. In\nthis paper, we propose Cascading Decomposed CoTs Distillation (CasCoD) to\naddress these issues by decomposing the traditional single-step learning\nprocess into two cascaded learning steps. Specifically, by restructuring the\ntraining objectives -- removing the answer from outputs and concatenating the\nquestion with the rationale as input -- CasCoD's two-step learning process\nensures that students focus on learning rationales without interference from\nthe preset answers, thus improving reasoning generalizability. Extensive\nexperiments demonstrate the effectiveness of CasCoD on both IND and OOD\nbenchmark reasoning datasets. Code can be found at\nhttps://github.com/C-W-D/CasCoD.\n",
        "authors": "Chengwei Dai; Kun Li; Wei Zhou; Songlin Hu",
        "status": 0,
        "relevancy": 0.5875590148206132,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19877",
        "date": "2024-05-30",
        "title": "KNOW: A Real-World Ontology for Knowledge Capture with Large Language\n  Models",
        "abstract": "  We present KNOW--the Knowledge Navigator Ontology for the World--the first\nontology designed to capture everyday knowledge to augment large language\nmodels (LLMs) in real-world generative AI use cases such as personal AI\nassistants. Our domain is human life, both its everyday concerns and its major\nmilestones. We have limited the initial scope of the modeled concepts to only\nestablished human universals: spacetime (places, events) plus social (people,\ngroups, organizations). The inclusion criteria for modeled concepts are\npragmatic, beginning with universality and utility. We compare and contrast\nprevious work such as Schema.org and Cyc--as well as attempts at a synthesis of\nknowledge graphs and language models--noting how LLMs already encode internally\nmuch of the commonsense tacit knowledge that took decades to capture in the Cyc\nproject. We also make available code-generated software libraries for the 12\nmost popular programming languages, enabling the direct use of ontology\nconcepts in software engineering. We emphasize simplicity and developer\nexperience in promoting AI interoperability.\n",
        "authors": "Arto Bendiken",
        "status": 0,
        "relevancy": 0.5819214765405173,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19988",
        "date": "2024-05-30",
        "title": "Video-Language Critic: Transferable Reward Functions for\n  Language-Conditioned Robotics",
        "abstract": "  Natural language is often the easiest and most convenient modality for humans\nto specify tasks for robots. However, learning to ground language to behavior\ntypically requires impractical amounts of diverse, language-annotated\ndemonstrations collected on each target robot. In this work, we aim to separate\nthe problem of what to accomplish from how to accomplish it, as the former can\nbenefit from substantial amounts of external observation-only data, and only\nthe latter depends on a specific robot embodiment. To this end, we propose\nVideo-Language Critic, a reward model that can be trained on readily available\ncross-embodiment data using contrastive learning and a temporal ranking\nobjective, and use it to score behavior traces from a separate reinforcement\nlearning actor. When trained on Open X-Embodiment data, our reward model\nenables 2x more sample-efficient policy training on Meta-World tasks than a\nsparse reward only, despite a significant domain gap. Using in-domain data but\nin a challenging task generalization setting on Meta-World, we further\ndemonstrate more sample-efficient training than is possible with prior\nlanguage-conditioned reward models that are either trained with binary\nclassification, use static images, or do not leverage the temporal information\npresent in video data.\n",
        "authors": "Minttu Alakuijala; Reginald McLean; Isaac Woungang; Nariman Farsad; Samuel Kaski; Pekka Marttinen; Kai Yuan",
        "status": 0,
        "relevancy": 0.5796007891930083,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20175",
        "date": "2024-05-30",
        "title": "InstructionCP: A fast approach to transfer Large Language Models into\n  target language",
        "abstract": "  The rapid development of large language models (LLMs) in recent years has\nlargely focused on English, resulting in models that respond exclusively in\nEnglish. To adapt these models to other languages, continual pre-training (CP)\nis often employed, followed by supervised fine-tuning (SFT) to maintain\nconversational abilities. However, CP and SFT can reduce a model's ability to\nfilter harmful content. We propose Instruction Continual Pre-training (InsCP),\nwhich integrates instruction tags into the CP process to prevent loss of\nconversational proficiency while acquiring new languages. Our experiments\ndemonstrate that InsCP retains conversational and Reinforcement Learning from\nHuman Feedback (RLHF) abilities. Empirical evaluations on language alignment,\nreliability, and knowledge benchmarks confirm the efficacy of InsCP. Notably,\nthis approach requires only 0.1 billion tokens of high-quality\ninstruction-following data, thereby reducing resource consumption.\n",
        "authors": "Kuang-Ming Chen; Hung-yi Lee",
        "status": 0,
        "relevancy": 0.5744896107983334,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20318",
        "date": "2024-05-30",
        "title": "CausalQuest: Collecting Natural Causal Questions for AI Agents",
        "abstract": "  Humans have an innate drive to seek out causality. Whether fuelled by\ncuriosity or specific goals, we constantly question why things happen, how they\nare interconnected, and many other related phenomena. To develop AI agents\ncapable of addressing this natural human quest for causality, we urgently need\na comprehensive dataset of natural causal questions. Unfortunately, existing\ndatasets either contain only artificially-crafted questions that do not reflect\nreal AI usage scenarios or have limited coverage of questions from specific\nsources. To address this gap, we present CausalQuest, a dataset of 13,500\nnaturally occurring questions sourced from social networks, search engines, and\nAI assistants. We formalize the definition of causal questions and establish a\ntaxonomy for finer-grained classification. Through a combined effort of human\nannotators and large language models (LLMs), we carefully label the dataset. We\nfind that 42% of the questions humans ask are indeed causal, with the majority\nseeking to understand the causes behind given effects. Using this dataset, we\ntrain efficient classifiers (up to 2.85B parameters) for the binary task of\nidentifying causal questions, achieving high performance with F1 scores of up\nto 0.877. We conclude with a rich set of future research directions that can\nbuild upon our data and models.\n",
        "authors": "Roberto Ceraolo; Dmitrii Kharlapenko; Amélie Reymond; Rada Mihalcea; Mrinmaya Sachan; Bernhard Schölkopf; Zhijing Jin",
        "status": 0,
        "relevancy": 0.5681685308949704,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20189",
        "date": "2024-05-30",
        "title": "Nadine: An LLM-driven Intelligent Social Robot with Affective\n  Capabilities and Human-like Memory",
        "abstract": "  In this work, we describe our approach to developing an intelligent and\nrobust social robotic system for the Nadine social robot platform. We achieve\nthis by integrating Large Language Models (LLMs) and skilfully leveraging the\npowerful reasoning and instruction-following capabilities of these types of\nmodels to achieve advanced human-like affective and cognitive capabilities.\nThis approach is novel compared to the current state-of-the-art LLM-based\nagents which do not implement human-like long-term memory or sophisticated\nemotional appraisal. The naturalness of social robots, consisting of multiple\nmodules, highly depends on the performance and capabilities of each component\nof the system and the seamless integration of the components. We built a social\nrobot system that enables generating appropriate behaviours through multimodal\ninput processing, bringing episodic memories accordingly to the recognised\nuser, and simulating the emotional states of the robot induced by the\ninteraction with the human partner. In particular, we introduce an LLM-agent\nframe for social robots, SoR-ReAct, serving as a core component for the\ninteraction module in our system. This design has brought forth the advancement\nof social robots and aims to increase the quality of human-robot interaction.\n",
        "authors": "Hangyeol Kang; Maher Ben Moussa; Nadia Magnenat-Thalmann",
        "status": 0,
        "relevancy": 0.5658114955122293,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20331",
        "date": "2024-05-30",
        "title": "CoSy: Evaluating Textual Explanations of Neurons",
        "abstract": "  A crucial aspect of understanding the complex nature of Deep Neural Networks\n(DNNs) is the ability to explain learned concepts within their latent\nrepresentations. While various methods exist to connect neurons to textual\ndescriptions of human-understandable concepts, evaluating the quality of these\nexplanation methods presents a major challenge in the field due to a lack of\nunified, general-purpose quantitative evaluation. In this work, we introduce\nCoSy (Concept Synthesis) -- a novel, architecture-agnostic framework to\nevaluate the quality of textual explanations for latent neurons. Given textual\nexplanations, our proposed framework leverages a generative model conditioned\non textual input to create data points representing the textual explanation.\nThen, the neuron's response to these explanation data points is compared with\nthe response to control data points, providing a quality estimate of the given\nexplanation. We ensure the reliability of our proposed framework in a series of\nmeta-evaluation experiments and demonstrate practical value through insights\nfrom benchmarking various concept-based textual explanation methods for\nComputer Vision tasks, showing that tested explanation methods significantly\ndiffer in quality.\n",
        "authors": "Laura Kopf; Philine Lou Bommer; Anna Hedström; Sebastian Lapuschkin; Marina M. -C. Höhne; Kirill Bykov",
        "status": 0,
        "relevancy": 0.5552265666100827,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19787",
        "date": "2024-05-30",
        "title": "From Symbolic Tasks to Code Generation: Diversification Yields Better\n  Task Performers",
        "abstract": "  Instruction tuning -- tuning large language models on instruction-output\npairs -- is a promising technique for making models better adapted to the real\nworld. Yet, the key factors driving the model's capability to understand and\nfollow instructions not seen during training remain under-explored. Our\ninvestigation begins with a series of synthetic experiments within the\ntheoretical framework of a Turing-complete algorithm called Markov algorithm,\nwhich allows fine-grained control over the instruction-tuning data.\nGeneralization and robustness with respect to the training distribution emerge\nonce a diverse enough set of tasks is provided, even though very few examples\nare provided for each task. We extend these initial results to a real-world\napplication scenario of code generation and find that a more diverse\ninstruction set, extending beyond code-related tasks, improves the performance\nof code generation. Our observations suggest that a more diverse semantic space\nfor instruction-tuning sets greatly improves the model's ability to follow\ninstructions and perform tasks.\n",
        "authors": "Dylan Zhang; Justin Wang; Francois Charton",
        "status": 0,
        "relevancy": 0.5487411096183784,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20131",
        "date": "2024-05-30",
        "title": "Language Models Need Inductive Biases to Count Inductively",
        "abstract": "  Counting is a fundamental example of generalization, whether viewed through\nthe mathematical lens of Peano's axioms defining the natural numbers or the\ncognitive science literature for children learning to count. The argument holds\nfor both cases that learning to count means learning to count infinitely. While\nfew papers have tried to distill transformer \"reasoning\" to the simplest case\nof counting, investigating length generalization does occur throughout the\nliterature. In the \"train short, test long\" paradigm of NLP, length refers to\nthe training sentence length. In formal language recognition, length refers to\nthe input sequence length, or the maximum stack size induced by a pushdown\nautomata. In general problem solving, length refers to the number of hops in a\ndeductive reasoning chain or the recursion depth. For all cases, counting is\ncentral to task success. And crucially, generalizing counting inductively is\ncentral to success on OOD instances. This work provides extensive empirical\nresults on training language models to count. We experiment with architectures\nranging from RNNs, Transformers, State-Space Models and RWKV. We present\ncarefully-designed task formats, auxiliary tasks and positional embeddings to\navoid limitations in generalization with OOD-position and OOD-vocabulary. We\nfind that while traditional RNNs trivially achieve inductive counting,\nTransformers have to rely on positional embeddings to count out-of-domain. As\ncounting is the basis for many arguments concerning the expressivity of\nTransformers, our finding calls for the community to reexamine the application\nscope of primitive functions defined in formal characterizations. Finally,\nmodern RNNs also largely underperform traditional RNNs in generalizing counting\ninductively. We discuss how design choices that enable parallelized training of\nmodern RNNs cause them to lose merits of a recurrent nature.\n",
        "authors": "Yingshan Chang; Yonatan Bisk",
        "status": 0,
        "relevancy": 0.5469786419539899,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20046",
        "date": "2024-05-30",
        "title": "Cross-Training with Multi-View Knowledge Fusion for Heterogenous\n  Federated Learning",
        "abstract": "  Federated learning benefits from cross-training strategies, which enables\nmodels to train on data from distinct sources to improve the generalization\ncapability. However, the data heterogeneity between sources may lead models to\ngradually forget previously acquired knowledge when undergoing cross-training\nto adapt to new tasks or data sources. We argue that integrating personalized\nand global knowledge to gather information from multiple perspectives could\npotentially improve performance. To achieve this goal, this paper presents a\nnovel approach that enhances federated learning through a cross-training scheme\nincorporating multi-view information. Specifically, the proposed method, termed\nFedCT, includes three main modules, where the consistency-aware knowledge\nbroadcasting module aims to optimize model assignment strategies, which\nenhances collaborative advantages between clients and achieves an efficient\nfederated learning process. The multi-view knowledge-guided representation\nlearning module leverages fused prototypical knowledge from both global and\nlocal views to enhance the preservation of local knowledge before and after\nmodel exchange, as well as to ensure consistency between local and global\nknowledge. The mixup-based feature augmentation module aggregates rich\ninformation to further increase the diversity of feature spaces, which enables\nthe model to better discriminate complex samples. Extensive experiments were\nconducted on four datasets in terms of performance comparison, ablation study,\nin-depth analysis and case study. The results demonstrated that FedCT\nalleviates knowledge forgetting from both local and global views, which enables\nit outperform state-of-the-art methods.\n",
        "authors": "Zhuang Qi; Lei Meng; Weihao He; Ruohan Zhang; Yu Wang; Xin Qi; Xiangxu Meng",
        "status": 0,
        "relevancy": 0.5465224352747082,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19740",
        "date": "2024-05-30",
        "title": "PertEval: Unveiling Real Knowledge Capacity of LLMs with\n  Knowledge-Invariant Perturbations",
        "abstract": "  Expert-designed close-ended benchmarks serve as vital tools in assessing the\nknowledge capacity of large language models (LLMs). Despite their widespread\nuse, concerns have mounted regarding their reliability due to limited test\nscenarios and an unavoidable risk of data contamination. To rectify this, we\npresent PertEval, a toolkit devised for in-depth probing of LLMs' knowledge\ncapacity through knowledge-invariant perturbations. These perturbations employ\nhuman-like restatement techniques to generate on-the-fly test samples from\nstatic benchmarks, meticulously retaining knowledge-critical content while\naltering irrelevant details. Our toolkit further includes a suite of transition\nanalyses that compare performance on raw vs. perturbed test sets to precisely\nassess LLMs' genuine knowledge capacity. Six state-of-the-art LLMs are\nre-evaluated using PertEval. Results reveal significantly inflated performance\nof the LLMs on raw benchmarks, including an absolute 21% overestimation for\nGPT-4. Additionally, through a nuanced response pattern analysis, we discover\nthat PertEval retains LLMs' uncertainty to specious knowledge, potentially\nbeing resolved through rote memorization and leading to inflated performance.\nWe also find that the detailed transition analyses by PertEval could illuminate\nweaknesses in existing LLMs' knowledge mastery and guide the development of\nrefinement. Given these insights, we posit that PertEval can act as an\nessential tool that, when applied alongside any close-ended benchmark, unveils\nthe true knowledge capacity of LLMs, marking a significant step toward more\ntrustworthy LLM evaluation.\n",
        "authors": "Jiatong Li; Renjun Hu; Kunzhe Huang; Yan Zhuang; Qi Liu; Mengxiao Zhu; Xing Shi; Wei Lin",
        "status": 0,
        "relevancy": 0.5391528916112052,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19846",
        "date": "2024-05-30",
        "title": "Quest: Query-centric Data Synthesis Approach for Long-context Scaling of\n  Large Language Model",
        "abstract": "  Large language models, initially pre-trained with a limited context length,\ncan better handle longer texts by continuing training on a corpus with extended\ncontexts. However, obtaining effective long-context data is challenging due to\nthe scarcity and uneven distribution of long documents across different\ndomains. To address this issue, we propose a Query-centric data synthesis\nmethod, abbreviated as Quest. Quest is an interpretable method based on the\nobservation that documents retrieved by similar queries are relevant but\nlow-redundant, thus well-suited for synthesizing long-context data. The method\nis also scalable and capable of constructing large amounts of long-context\ndata. Using Quest, we synthesize a long-context dataset up to 128k context\nlength, significantly outperforming other data synthesis methods on multiple\nlong-context benchmark datasets. In addition, we further verify that the Quest\nmethod is predictable through scaling law experiments, making it a reliable\nsolution for advancing long-context models.\n",
        "authors": "Chaochen Gao; Xing Wu; Qi Fu; Songlin Hu",
        "status": 0,
        "relevancy": 0.538267137522946,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19744",
        "date": "2024-05-30",
        "title": "X-Instruction: Aligning Language Model in Low-resource Languages with\n  Self-curated Cross-lingual Instructions",
        "abstract": "  Large language models respond well in high-resource languages like English\nbut struggle in low-resource languages. It may arise from the lack of\nhigh-quality instruction following data in these languages. Directly\ntranslating English samples into these languages can be a solution but\nunreliable, leading to responses with translation errors and lacking\nlanguage-specific or cultural knowledge. To address this issue, we propose a\nnovel method to construct cross-lingual instruction following samples with\ninstruction in English and response in low-resource languages. Specifically,\nthe language model first learns to generate appropriate English instructions\naccording to the natural web texts in other languages as responses. The\ncandidate cross-lingual instruction tuning samples are further refined and\ndiversified. We have employed this method to build a large-scale cross-lingual\ninstruction tuning dataset on 10 languages, namely X-Instruction. The\ninstruction data built using our method incorporate more language-specific\nknowledge compared with the naive translation method. Experimental results have\nshown that the response quality of the model tuned on X-Instruction greatly\nexceeds the model distilled from a powerful teacher model, reaching or even\nsurpassing the ones of ChatGPT. In addition, we find that models tuned on\ncross-lingual instruction following samples can follow the instruction in the\noutput language without further tuning.\n",
        "authors": "Chong Li; Wen Yang; Jiajun Zhang; Jinliang Lu; Shaonan Wang; Chengqing Zong",
        "status": 0,
        "relevancy": 0.5372564816328679,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19606",
        "date": "2024-05-30",
        "title": "Relation Modeling and Distillation for Learning with Noisy Labels",
        "abstract": "  Learning with noisy labels has become an effective strategy for enhancing the\nrobustness of models, which enables models to better tolerate inaccurate data.\nExisting methods either focus on optimizing the loss function to mitigate the\ninterference from noise, or design procedures to detect potential noise and\ncorrect errors. However, their effectiveness is often compromised in\nrepresentation learning due to the dilemma where models overfit to noisy\nlabels. To address this issue, this paper proposes a relation modeling and\ndistillation framework that models inter-sample relationships via\nself-supervised learning and employs knowledge distillation to enhance\nunderstanding of latent associations, which mitigate the impact of noisy\nlabels. Specifically, the proposed method, termed RMDNet, includes two main\nmodules, where the relation modeling (RM) module implements the contrastive\nlearning technique to learn representations of all data, an unsupervised\napproach that effectively eliminates the interference of noisy tags on feature\nextraction. The relation-guided representation learning (RGRL) module utilizes\ninter-sample relation learned from the RM module to calibrate the\nrepresentation distribution for noisy samples, which is capable of improving\nthe generalization of the model in the inference phase. Notably, the proposed\nRMDNet is a plug-and-play framework that can integrate multiple methods to its\nadvantage. Extensive experiments were conducted on two datasets, including\nperformance comparison, ablation study, in-depth analysis and case study. The\nresults show that RMDNet can learn discriminative representations for noisy\ndata, which results in superior performance than the existing methods.\n",
        "authors": "Xiaming Che; Junlin Zhang; Zhuang Qi; Xin Qi",
        "status": 0,
        "relevancy": 0.5236682767321168,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19783",
        "date": "2024-05-30",
        "title": "Instruction-Guided Visual Masking",
        "abstract": "  Instruction following is crucial in contemporary LLM. However, when extended\nto multimodal setting, it often suffers from misalignment between specific\ntextual instruction and targeted local region of an image. To achieve more\naccurate and nuanced multimodal instruction following, we introduce\nInstruction-guided Visual Masking (IVM), a new versatile visual grounding model\nthat is compatible with diverse multimodal models, such as LMM and robot model.\nBy constructing visual masks for instruction-irrelevant regions, IVM-enhanced\nmultimodal models can effectively focus on task-relevant image regions to\nbetter align with complex instructions. Specifically, we design a visual\nmasking data generation pipeline and create an IVM-Mix-1M dataset with 1\nmillion image-instruction pairs. We further introduce a new learning technique,\nDiscriminator Weighted Supervised Learning (DWSL) for preferential IVM training\nthat prioritizes high-quality data samples. Experimental results on generic\nmultimodal tasks such as VQA and embodied robotic control demonstrate the\nversatility of IVM, which as a plug-and-play tool, significantly boosts the\nperformance of diverse multimodal models, yielding new state-of-the-art results\nacross challenging multimodal benchmarks. Code is available at\nhttps://github.com/2toinf/IVM.\n",
        "authors": "Jinliang Zheng; Jianxiong Li; Sijie Cheng; Yinan Zheng; Jiaming Li; Jihao Liu; Yu Liu; Jingjing Liu; Xianyuan Zhan",
        "status": 0,
        "relevancy": 0.5236245343669101,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19946",
        "date": "2024-05-30",
        "title": "Learning to Discuss Strategically: A Case Study on One Night Ultimate\n  Werewolf",
        "abstract": "  Communication is a fundamental aspect of human society, facilitating the\nexchange of information and beliefs among people. Despite the advancements in\nlarge language models (LLMs), recent agents built with these often neglect the\ncontrol over discussion tactics, which are essential in communication scenarios\nand games. As a variant of the famous communication game Werewolf, One Night\nUltimate Werewolf (ONUW) requires players to develop strategic discussion\npolicies due to the potential role changes that increase the uncertainty and\ncomplexity of the game. In this work, we first present the existence of the\nPerfect Bayesian Equilibria (PBEs) in two scenarios of the ONUW game: one with\ndiscussion and one without. The results showcase that the discussion greatly\nchanges players' utilities by affecting their beliefs, emphasizing the\nsignificance of discussion tactics. Based on the insights obtained from the\nanalyses, we propose an RL-instructed language agent framework, where a\ndiscussion policy trained by reinforcement learning (RL) is employed to\ndetermine appropriate discussion tactics to adopt. Our experimental results on\nseveral ONUW game settings demonstrate the effectiveness and generalizability\nof our proposed framework.\n",
        "authors": "Xuanfa Jin; Ziyan Wang; Yali Du; Meng Fang; Haifeng Zhang; Jun Wang",
        "status": 0,
        "relevancy": 0.5235238922992325,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19909",
        "date": "2024-05-30",
        "title": "Adaptive Advantage-Guided Policy Regularization for Offline\n  Reinforcement Learning",
        "abstract": "  In offline reinforcement learning, the challenge of out-of-distribution (OOD)\nis pronounced. To address this, existing methods often constrain the learned\npolicy through policy regularization. However, these methods often suffer from\nthe issue of unnecessary conservativeness, hampering policy improvement. This\noccurs due to the indiscriminate use of all actions from the behavior policy\nthat generates the offline dataset as constraints. The problem becomes\nparticularly noticeable when the quality of the dataset is suboptimal. Thus, we\npropose Adaptive Advantage-guided Policy Regularization (A2PR), obtaining\nhigh-advantage actions from an augmented behavior policy combined with VAE to\nguide the learned policy. A2PR can select high-advantage actions that differ\nfrom those present in the dataset, while still effectively maintaining\nconservatism from OOD actions. This is achieved by harnessing the VAE capacity\nto generate samples matching the distribution of the data points. We\ntheoretically prove that the improvement of the behavior policy is guaranteed.\nBesides, it effectively mitigates value overestimation with a bounded\nperformance gap. Empirically, we conduct a series of experiments on the D4RL\nbenchmark, where A2PR demonstrates state-of-the-art performance. Furthermore,\nexperimental results on additional suboptimal mixed datasets reveal that A2PR\nexhibits superior performance. Code is available at\nhttps://github.com/ltlhuuu/A2PR.\n",
        "authors": "Tenglong Liu; Yang Li; Yixing Lan; Hao Gao; Wei Pan; Xin Xu",
        "status": 0,
        "relevancy": 0.519748050812327,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19592",
        "date": "2024-05-30",
        "title": "Why Larger Language Models Do In-context Learning Differently?",
        "abstract": "  Large language models (LLM) have emerged as a powerful tool for AI, with the\nkey ability of in-context learning (ICL), where they can perform well on unseen\ntasks based on a brief series of task examples without necessitating any\nadjustments to the model parameters. One recent interesting mysterious\nobservation is that models of different scales may have different ICL\nbehaviors: larger models tend to be more sensitive to noise in the test\ncontext. This work studies this observation theoretically aiming to improve the\nunderstanding of LLM and ICL. We analyze two stylized settings: (1) linear\nregression with one-layer single-head linear transformers and (2) parity\nclassification with two-layer multiple attention heads transformers (non-linear\ndata and non-linear model). In both settings, we give closed-form optimal\nsolutions and find that smaller models emphasize important hidden features\nwhile larger ones cover more hidden features; thus, smaller models are more\nrobust to noise while larger ones are more easily distracted, leading to\ndifferent ICL behaviors. This sheds light on where transformers pay attention\nto and how that affects ICL. Preliminary experimental results on large base and\nchat models provide positive support for our analysis.\n",
        "authors": "Zhenmei Shi; Junyi Wei; Zhuoyan Xu; Yingyu Liang",
        "status": 0,
        "relevancy": 0.5112408702582242,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19933",
        "date": "2024-05-30",
        "title": "Learning Latent Graph Structures and their Uncertainty",
        "abstract": "  Within a prediction task, Graph Neural Networks (GNNs) use relational\ninformation as an inductive bias to enhance the model's accuracy. As\ntask-relevant relations might be unknown, graph structure learning approaches\nhave been proposed to learn them while solving the downstream prediction task.\nIn this paper, we demonstrate that minimization of a point-prediction loss\nfunction, e.g., the mean absolute error, does not guarantee proper learning of\nthe latent relational information and its associated uncertainty. Conversely,\nwe prove that a suitable loss function on the stochastic model outputs\nsimultaneously grants (i) the unknown adjacency matrix latent distribution and\n(ii) optimal performance on the prediction task. Finally, we propose a\nsampling-based method that solves this joint learning task. Empirical results\nvalidate our theoretical claims and demonstrate the effectiveness of the\nproposed approach.\n",
        "authors": "Alessandro Manenti; Daniele Zambon; Cesare Alippi",
        "status": 0,
        "relevancy": 0.5108126705428825,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19874",
        "date": "2024-05-30",
        "title": "Is In-Context Learning Sufficient for Instruction Following in LLMs?",
        "abstract": "  In-context learning (ICL) allows LLMs to learn from examples without changing\ntheir weights, which is a particularly promising capability for long-context\nLLMs that can potentially learn from many examples. Recently, Lin et al. (2024)\nproposed URIAL, a method using only three in-context examples to align base\nLLMs, achieving non-trivial instruction following performance. In this work, we\nshow that, while effective, ICL alignment with URIAL still underperforms\ncompared to instruction fine-tuning on established benchmarks such as MT-Bench\nand AlpacaEval 2.0 (LC), especially with more capable base LMs. Unlike for\ntasks such as classification, translation, or summarization, adding more ICL\ndemonstrations for long-context LLMs does not systematically improve\ninstruction following performance. To address this limitation, we derive a\ngreedy selection approach for ICL examples that noticeably improves\nperformance, yet without bridging the gap to instruction fine-tuning. Finally,\nwe provide a series of ablation studies to better understand the reasons behind\nthe remaining gap, and we show how some aspects of ICL depart from the existing\nknowledge and are specific to the instruction tuning setting. Overall, our work\nadvances the understanding of ICL as an alignment technique. We provide our\ncode at https://github.com/tml-epfl/icl-alignment.\n",
        "authors": "Hao Zhao; Maksym Andriushchenko; Francesco Croce; Nicolas Flammarion",
        "status": 0,
        "relevancy": 0.5101523277778419,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19795",
        "date": "2024-05-30",
        "title": "SLM as Guardian: Pioneering AI Safety with Small Language Models",
        "abstract": "  Most prior safety research of large language models (LLMs) has focused on\nenhancing the alignment of LLMs to better suit the safety requirements of\nhumans. However, internalizing such safeguard features into larger models\nbrought challenges of higher training cost and unintended degradation of\nhelpfulness. To overcome such challenges, a modular approach employing a\nsmaller LLM to detect harmful user queries is regarded as a convenient solution\nin designing LLM-based system with safety requirements.\n  In this paper, we leverage a smaller LLM for both harmful query detection and\nsafeguard response generation. We introduce our safety requirements and the\ntaxonomy of harmfulness categories, and then propose a multi-task learning\nmechanism fusing the two tasks into a single model. We demonstrate the\neffectiveness of our approach, providing on par or surpassing harmful query\ndetection and safeguard response performance compared to the publicly available\nLLMs.\n",
        "authors": "Ohjoon Kwon; Donghyeon Jeon; Nayoung Choi; Gyu-Hwung Cho; Changbong Kim; Hyunwoo Lee; Inho Kang; Sun Kim; Taiwoo Park",
        "status": 0,
        "relevancy": 0.4966200069020835,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19581",
        "date": "2024-05-30",
        "title": "Source Code Foundation Models are Transferable Binary Analysis Knowledge\n  Bases",
        "abstract": "  Human-Oriented Binary Reverse Engineering (HOBRE) lies at the intersection of\nbinary and source code, aiming to lift binary code to human-readable content\nrelevant to source code, thereby bridging the binary-source semantic gap.\nRecent advancements in uni-modal code model pre-training, particularly in\ngenerative Source Code Foundation Models (SCFMs) and binary understanding\nmodels, have laid the groundwork for transfer learning applicable to HOBRE.\nHowever, existing approaches for HOBRE rely heavily on uni-modal models like\nSCFMs for supervised fine-tuning or general LLMs for prompting, resulting in\nsub-optimal performance. Inspired by recent progress in large multi-modal\nmodels, we propose that it is possible to harness the strengths of uni-modal\ncode models from both sides to bridge the semantic gap effectively. In this\npaper, we introduce a novel probe-and-recover framework that incorporates a\nbinary-source encoder-decoder model and black-box LLMs for binary analysis. Our\napproach leverages the pre-trained knowledge within SCFMs to synthesize\nrelevant, symbol-rich code fragments as context. This additional context\nenables black-box LLMs to enhance recovery accuracy. We demonstrate significant\nimprovements in zero-shot binary summarization and binary function name\nrecovery, with a 10.3% relative gain in CHRF and a 16.7% relative gain in a\nGPT4-based metric for summarization, as well as a 6.7% and 7.4% absolute\nincrease in token-level precision and recall for name recovery, respectively.\nThese results highlight the effectiveness of our approach in automating and\nimproving binary code analysis.\n",
        "authors": "Zian Su; Xiangzhe Xu; Ziyang Huang; Kaiyuan Zhang; Xiangyu Zhang",
        "status": 0,
        "relevancy": 0.49597674797286095,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19690",
        "date": "2024-05-30",
        "title": "Diffusion Policies creating a Trust Region for Offline Reinforcement\n  Learning",
        "abstract": "  Offline reinforcement learning (RL) leverages pre-collected datasets to train\noptimal policies. Diffusion Q-Learning (DQL), introducing diffusion models as a\npowerful and expressive policy class, significantly boosts the performance of\noffline RL. However, its reliance on iterative denoising sampling to generate\nactions slows down both training and inference. While several recent attempts\nhave tried to accelerate diffusion-QL, the improvement in training and/or\ninference speed often results in degraded performance. In this paper, we\nintroduce a dual policy approach, Diffusion Trusted Q-Learning (DTQL), which\ncomprises a diffusion policy for pure behavior cloning and a practical one-step\npolicy. We bridge the two polices by a newly introduced diffusion trust region\nloss. The diffusion policy maintains expressiveness, while the trust region\nloss directs the one-step policy to explore freely and seek modes within the\nregion defined by the diffusion policy. DTQL eliminates the need for iterative\ndenoising sampling during both training and inference, making it remarkably\ncomputationally efficient. We evaluate its effectiveness and algorithmic\ncharacteristics against popular Kullback-Leibler (KL) based distillation\nmethods in 2D bandit scenarios and gym tasks. We then show that DTQL could not\nonly outperform other methods on the majority of the D4RL benchmark tasks but\nalso demonstrate efficiency in training and inference speeds. The PyTorch\nimplementation will be made available.\n",
        "authors": "Tianyu Chen; Zhendong Wang; Mingyuan Zhou",
        "status": 0,
        "relevancy": 0.4947105804434925,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19736",
        "date": "2024-05-30",
        "title": "Learning Task-relevant Sequence Representations via Intrinsic Dynamics\n  Characteristics in Reinforcement Learning",
        "abstract": "  Learning task-relevant state representations is crucial to solving the\nproblem of scene generalization in visual deep reinforcement learning. Prior\nwork typically establishes a self-supervised auxiliary learner, introducing\nelements (e.g., rewards and actions) to extract task-relevant state information\nfrom observations through behavioral similarity metrics. However, the methods\noften ignore the inherent relationships between the elements (e.g., dynamics\nrelationships) that are essential for learning accurate representations, and\nthey are also limited to single-step metrics, which impedes the discrimination\nof short-term similar task/behavior information in long-term dynamics\ntransitions. To solve the issues, we propose an intrinsic dynamic\ncharacteristics-driven sequence representation learning method (DSR) over a\ncommon DRL frame. Concretely, inspired by the fact of state transition in the\nunderlying system, it constrains the optimization of the encoder via modeling\nthe dynamics equations related to the state transition, which prompts the\nlatent encoding information to satisfy the state transition process and thereby\ndistinguishes state space and noise space. Further, to refine the ability of\nencoding similar tasks based on dynamics constraints, DSR also sequentially\nmodels inherent dynamics equation relationships from the perspective of\nsequence elements' frequency domain and multi-step prediction. Finally,\nexperimental results show that DSR has achieved a significant performance boost\nin the Distracting DMControl Benchmark, with an average of 78.9% over the\nbackbone baseline. Further results indicate that it also achieves the best\nperformance in real-world autonomous driving tasks in the CARLA simulator.\nMoreover, the qualitative analysis results of t-SNE visualization validate that\nour method possesses superior representation ability on visual tasks.\n",
        "authors": "Dayang Liang; Jinyang Lai; Yunlong Liu",
        "status": 0,
        "relevancy": 0.4940873058207249,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19778",
        "date": "2024-05-30",
        "title": "Enhancing Consistency and Role-Specific Knowledge Capturing by\n  Rebuilding Fictional Character's Persona",
        "abstract": "  With the recent introduction of Assistants API, it is expected that\ndocument-based language models will be actively used in various domains,\nespecially Role-playing. However, a key challenge lies in utilizing\nprotagonist's persona: Assistants API often fails to achieve with its search\nbecause the information extraction part is different each time and it often\nomits important information such as protagonist's backstory or relationships.\nIt is hard to maintain a consistent persona simply by using the persona\ndocument as input to the Assistants API. To address the challenge of achieving\nstable persona consistency, we propose CharacterGPT, a novel persona\nreconstruction framework to alleviate the shortcomings of the Assistants API.\nOur method involves Character Persona Training (CPT), an effective persona\nrebuilding process that updates the character persona by extracting the\ncharacter's traits from given summary of the novel for each character as if the\nstory in a novel progresses. In our experiments, we ask each character to take\nthe Big Five Inventory personality test in various settings and analyze the\nresults. To assess whether it can think outside the box, we let each character\ngenerate short novels. Extensive experiments and human evaluation demonstrate\nthat CharacterGPT presents new possibilities for role-playing agent research.\n",
        "authors": "Jeiyoon Park; Chanjun Park; Heuiseok Lim",
        "status": 0,
        "relevancy": 0.4936318081392568,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19715",
        "date": "2024-05-30",
        "title": "SpecDec++: Boosting Speculative Decoding via Adaptive Candidate Lengths",
        "abstract": "  Speculative decoding reduces the inference latency of a target large language\nmodel via utilizing a smaller and faster draft model. Its performance depends\non a hyperparameter K -- the candidate length, i.e., the number of candidate\ntokens for the target model to verify in each round. However, previous methods\noften use simple heuristics to choose K, which may result in sub-optimal\nperformance. We study the choice of the candidate length K and formulate it as\na Markov Decision Process. We theoretically show that the optimal policy of\nthis Markov decision process takes the form of a threshold policy, i.e., the\ncurrent speculation should stop and be verified when the probability of getting\na rejection exceeds a threshold value. Motivated by this theory, we propose\nSpecDec++, an enhanced version of speculative decoding that adaptively\ndetermines the candidate length on the fly. We augment the draft model with a\ntrained acceptance prediction head to predict the conditional acceptance\nprobability of the candidate tokens. SpecDec++ will stop the current\nspeculation when the predicted probability that at least one token gets\nrejected exceeds a threshold. We implement SpecDec++ and apply it to the\nllama-2-chat 7B & 70B model pair. Our adaptive method achieves a 2.04x speedup\non the Alpaca dataset (an additional 7.2% improvement over the baseline\nspeculative decoding). On the GSM8K and HumanEval datasets, our method achieves\na 2.26x speedup (9.4% improvement) and 2.23x speedup (11.1% improvement),\nrespectively.\n",
        "authors": "Kaixuan Huang; Xudong Guo; Mengdi Wang",
        "status": 0,
        "relevancy": 0.49233093933001637,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20081",
        "date": "2024-05-30",
        "title": "NoiseBoost: Alleviating Hallucination with Noise Perturbation for\n  Multimodal Large Language Models",
        "abstract": "  Multimodal large language models (MLLMs) contribute a powerful mechanism to\nunderstanding visual information building on large language models. However,\nMLLMs are notorious for suffering from hallucinations, especially when\ngenerating lengthy, detailed descriptions for images. Our analysis reveals that\nhallucinations stem from the inherent summarization mechanism of large language\nmodels, leading to excessive dependence on linguistic tokens while neglecting\nvision information. In this paper, we propose NoiseBoost, a broadly applicable\nand simple method for alleviating hallucinations for MLLMs through the\nintegration of noise feature perturbations. Noise perturbation acts as a\nregularizer, facilitating a balanced distribution of attention weights among\nvisual and linguistic tokens. Despite its simplicity, NoiseBoost consistently\nenhances the performance of MLLMs across common training strategies, including\nsupervised fine-tuning and reinforcement learning. Further, NoiseBoost\npioneerly enables semi-supervised learning for MLLMs, unleashing the power of\nunlabeled data. Comprehensive experiments demonstrate that NoiseBoost improves\ndense caption accuracy by 8.1% with human evaluation and achieves comparable\nresults with 50% of the data by mining unlabeled data. Code and models are\navailable at https://kaiwu5.github.io/noiseboost.\n",
        "authors": "Kai Wu; Boyuan Jiang; Zhengkai Jiang; Qingdong He; Donghao Luo; Shengzhi Wang; Qingwen Liu; Chengjie Wang",
        "status": 0,
        "relevancy": 0.4911574666255476,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20247",
        "date": "2024-05-30",
        "title": "KerasCV and KerasNLP: Vision and Language Power-Ups",
        "abstract": "  We present the Keras domain packages KerasCV and KerasNLP, extensions of the\nKeras API for Computer Vision and Natural Language Processing workflows,\ncapable of running on either JAX, TensorFlow, or PyTorch. These domain packages\nare designed to enable fast experimentation, with a focus on ease-of-use and\nperformance. We adopt a modular, layered design: at the library's lowest level\nof abstraction, we provide building blocks for creating models and data\npreprocessing pipelines, and at the library's highest level of abstraction, we\nprovide pretrained ``task\" models for popular architectures such as Stable\nDiffusion, YOLOv8, GPT2, BERT, Mistral, CLIP, Gemma, T5, etc. Task models have\nbuilt-in preprocessing, pretrained weights, and can be fine-tuned on raw\ninputs. To enable efficient training, we support XLA compilation for all\nmodels, and run all preprocessing via a compiled graph of TensorFlow operations\nusing the tf.data API. The libraries are fully open-source (Apache 2.0 license)\nand available on GitHub.\n",
        "authors": "Matthew Watson; Divyashree Shivakumar Sreepathihalli; Francois Chollet; Martin Gorner; Kiranbir Sodhia; Ramesh Sampath; Tirth Patel; Haifeng Jin; Neel Kovelamudi; Gabriel Rasskin; Samaneh Saadat; Luke Wood; Chen Qian; Jonathan Bischof; Ian Stenbit",
        "status": 0,
        "relevancy": 0.48989663697013364,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19723",
        "date": "2024-05-30",
        "title": "Encoding and Controlling Global Semantics for Long-form Video Question\n  Answering",
        "abstract": "  Seeking answers effectively for long videos is essential to build video\nquestion answering (videoQA) systems. Previous methods adaptively select frames\nand regions from long videos to save computations. However, this fails to\nreason over the whole sequence of video, leading to sub-optimal performance. To\naddress this problem, we introduce a state space layer (SSL) into multi-modal\nTransformer to efficiently integrate global semantics of the video, which\nmitigates the video information loss caused by frame and region selection\nmodules. Our SSL includes a gating unit to enable controllability over the flow\nof global semantics into visual representations. To further enhance the\ncontrollability, we introduce a cross-modal compositional congruence (C^3)\nobjective to encourage global semantics aligned with the question. To\nrigorously evaluate long-form videoQA capacity, we construct two new benchmarks\nEgo-QA and MAD-QA featuring videos of considerably long length, i.e. 17.5\nminutes and 1.9 hours, respectively. Extensive experiments demonstrate the\nsuperiority of our framework on these new as well as existing datasets.\n",
        "authors": "Thong Thanh Nguyen; Zhiyuan Hu; Xiaobao Wu; Cong-Duy T Nguyen; See-Kiong Ng; Anh Tuan Luu",
        "status": 0,
        "relevancy": 0.48418333482341813,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19697",
        "date": "2024-05-30",
        "title": "Bilevel reinforcement learning via the development of hyper-gradient\n  without lower-level convexity",
        "abstract": "  Bilevel reinforcement learning (RL), which features intertwined two-level\nproblems, has attracted growing interest recently. The inherent non-convexity\nof the lower-level RL problem is, however, to be an impediment to developing\nbilevel optimization methods. By employing the fixed point equation associated\nwith the regularized RL, we characterize the hyper-gradient via fully\nfirst-order information, thus circumventing the assumption of lower-level\nconvexity. This, remarkably, distinguishes our development of hyper-gradient\nfrom the general AID-based bilevel frameworks since we take advantage of the\nspecific structure of RL problems. Moreover, we propose both model-based and\nmodel-free bilevel reinforcement learning algorithms, facilitated by access to\nthe fully first-order hyper-gradient. Both algorithms are provable to enjoy the\nconvergence rate $\\mathcal{O}(\\epsilon^{-1})$. To the best of our knowledge,\nthis is the first time that AID-based bilevel RL gets rid of additional\nassumptions on the lower-level problem. In addition, numerical experiments\ndemonstrate that the hyper-gradient indeed serves as an integration of\nexploitation and exploration.\n",
        "authors": "Yan Yang; Bin Gao; Ya-xiang Yuan",
        "status": 0,
        "relevancy": 0.4836568828964227,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20132",
        "date": "2024-05-30",
        "title": "LLaMEA: A Large Language Model Evolutionary Algorithm for Automatically\n  Generating Metaheuristics",
        "abstract": "  Large Language Models (LLMs) such as GPT-4 have demonstrated their ability to\nunderstand natural language and generate complex code snippets. This paper\nintroduces a novel Large Language Model Evolutionary Algorithm (LLaMEA)\nframework, leveraging GPT models for the automated generation and refinement of\nalgorithms. Given a set of criteria and a task definition (the search space),\nLLaMEA iteratively generates, mutates and selects algorithms based on\nperformance metrics and feedback from runtime evaluations. This framework\noffers a unique approach to generating optimized algorithms without requiring\nextensive prior expertise. We show how this framework can be used to generate\nnovel black-box metaheuristic optimization algorithms automatically. LLaMEA\ngenerates multiple algorithms that outperform state-of-the-art optimization\nalgorithms (Covariance Matrix Adaptation Evolution Strategy and Differential\nEvolution) on the five dimensional black box optimization benchmark (BBOB). The\nresults demonstrate the feasibility of the framework and identify future\ndirections for automated generation and optimization of algorithms via LLMs.\n",
        "authors": "Niki van Stein; Thomas Bäck",
        "status": 0,
        "relevancy": 0.48045015810835356,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19950",
        "date": "2024-05-30",
        "title": "MM-Lego: Modular Biomedical Multimodal Models with Minimal Fine-Tuning",
        "abstract": "  Learning holistic computational representations in physical, chemical or\nbiological systems requires the ability to process information from different\ndistributions and modalities within the same model. Thus, the demand for\nmultimodal machine learning models has sharply risen for modalities that go\nbeyond vision and language, such as sequences, graphs, time series, or tabular\ndata. While there are many available multimodal fusion and alignment\napproaches, most of them require end-to-end training, scale quadratically with\nthe number of modalities, cannot handle cases of high modality imbalance in the\ntraining set, or are highly topology-specific, making them too restrictive for\nmany biomedical learning tasks. This paper presents Multimodal Lego (MM-Lego),\na modular and general-purpose fusion and model merging framework to turn any\nset of encoders into a competitive multimodal model with no or minimal\nfine-tuning. We achieve this by introducing a wrapper for unimodal encoders\nthat enforces lightweight dimensionality assumptions between modalities and\nharmonises their representations by learning features in the frequency domain\nto enable model merging with little signal interference. We show that MM-Lego\n1) can be used as a model merging method which achieves competitive performance\nwith end-to-end fusion models without any fine-tuning, 2) can operate on any\nunimodal encoder, and 3) is a model fusion method that, with minimal\nfine-tuning, achieves state-of-the-art results on six benchmarked multimodal\nbiomedical tasks.\n",
        "authors": "Konstantin Hemker; Nikola Simidjievski; Mateja Jamnik",
        "status": 0,
        "relevancy": 0.4798264065767728,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20183",
        "date": "2024-05-30",
        "title": "A Survey Study on the State of the Art of Programming Exercise\n  Generation using Large Language Models",
        "abstract": "  This paper analyzes Large Language Models (LLMs) with regard to their\nprogramming exercise generation capabilities. Through a survey study, we\ndefined the state of the art, extracted their strengths and weaknesses and\nfinally proposed an evaluation matrix, helping researchers and educators to\ndecide which LLM is the best fitting for the programming exercise generation\nuse case. We also found that multiple LLMs are capable of producing useful\nprogramming exercises. Nevertheless, there exist challenges like the ease with\nwhich LLMs might solve exercises generated by LLMs. This paper contributes to\nthe ongoing discourse on the integration of LLMs in education.\n",
        "authors": "Eduard Frankford; Ingo Höhn; Clemens Sauerwein; Ruth Breu",
        "status": 0,
        "relevancy": 0.47859261643548645,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20245",
        "date": "2024-05-30",
        "title": "Retrieval Augmented Structured Generation: Business Document Information\n  Extraction As Tool Use",
        "abstract": "  Business Document Information Extraction (BDIE) is the problem of\ntransforming a blob of unstructured information (raw text, scanned documents,\netc.) into a structured format that downstream systems can parse and use. It\nhas two main tasks: Key-Information Extraction (KIE) and Line Items Recognition\n(LIR). In this paper, we argue that BDIE is best modeled as a Tool Use problem,\nwhere the tools are these downstream systems. We then present Retrieval\nAugmented Structured Generation (RASG), a novel general framework for BDIE that\nachieves state of the art (SOTA) results on both KIE and LIR tasks on BDIE\nbenchmarks.\n  The contributions of this paper are threefold: (1) We show, with ablation\nbenchmarks, that Large Language Models (LLMs) with RASG are already competitive\nwith or surpasses current SOTA Large Multimodal Models (LMMs) without RASG on\nBDIE benchmarks. (2) We propose a new metric class for Line Items Recognition,\nGeneral Line Items Recognition Metric (GLIRM), that is more aligned with\npractical BDIE use cases compared to existing metrics, such as ANLS*, DocILE,\nand GriTS. (3) We provide a heuristic algorithm for backcalculating bounding\nboxes of predicted line items and tables without the need for vision encoders.\nFinally, we claim that, while LMMs might sometimes offer marginal performance\nbenefits, LLMs + RASG is oftentimes superior given real-world applications and\nconstraints of BDIE.\n",
        "authors": "Franz Louis Cesista; Rui Aguiar; Jason Kim; Paolo Acilo",
        "status": 0,
        "relevancy": 0.4753594426074407,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19673",
        "date": "2024-05-30",
        "title": "Bridging Model-Based Optimization and Generative Modeling via\n  Conservative Fine-Tuning of Diffusion Models",
        "abstract": "  AI-driven design problems, such as DNA/protein sequence design, are commonly\ntackled from two angles: generative modeling, which efficiently captures the\nfeasible design space (e.g., natural images or biological sequences), and\nmodel-based optimization, which utilizes reward models for extrapolation. To\ncombine the strengths of both approaches, we adopt a hybrid method that\nfine-tunes cutting-edge diffusion models by optimizing reward models through\nRL. Although prior work has explored similar avenues, they primarily focus on\nscenarios where accurate reward models are accessible. In contrast, we\nconcentrate on an offline setting where a reward model is unknown, and we must\nlearn from static offline datasets, a common scenario in scientific domains. In\noffline scenarios, existing approaches tend to suffer from overoptimization, as\nthey may be misled by the reward model in out-of-distribution regions. To\naddress this, we introduce a conservative fine-tuning approach, BRAID, by\noptimizing a conservative reward model, which includes additional penalization\noutside of offline data distributions. Through empirical and theoretical\nanalysis, we demonstrate the capability of our approach to outperform the best\ndesigns in offline data, leveraging the extrapolation capabilities of reward\nmodels while avoiding the generation of invalid designs through pre-trained\ndiffusion models.\n",
        "authors": "Masatoshi Uehara; Yulai Zhao; Ehsan Hajiramezanali; Gabriele Scalia; Gökcen Eraslan; Avantika Lal; Sergey Levine; Tommaso Biancalani",
        "status": 0,
        "relevancy": 0.4743536369081548,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20274",
        "date": "2024-05-30",
        "title": "ROAST: Review-level Opinion Aspect Sentiment Target Joint Detection",
        "abstract": "  Aspect-Based Sentiment Analysis (ABSA) has experienced tremendous expansion\nand diversity due to various shared tasks spanning several languages and fields\nand organized via SemEval workshops and Germeval. Nonetheless, a few\nshortcomings still need to be addressed, such as the lack of low-resource\nlanguage evaluations and the emphasis on sentence-level analysis. To thoroughly\nassess ABSA techniques in the context of complete reviews, this research\npresents a novel task, Review-Level Opinion Aspect Sentiment Target (ROAST).\nROAST seeks to close the gap between sentence-level and text-level ABSA by\nidentifying every ABSA constituent at the review level. We extend the available\ndatasets to enable ROAST, addressing the drawbacks noted in previous research\nby incorporating low-resource languages, numerous languages, and a variety of\ntopics. Through this effort, ABSA research will be able to cover more ground\nand get a deeper comprehension of the task and its practical application in a\nvariety of languages and domains (https://github.com/RiTUAL-UH/ROAST-ABSA).\n",
        "authors": "Siva Uday Sampreeth Chebolu; Franck Dernoncourt; Nedim Lipka; Thamar Solorio",
        "status": 0,
        "relevancy": 0.4727940839780025,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19694",
        "date": "2024-05-30",
        "title": "Grade Like a Human: Rethinking Automated Assessment with Large Language\n  Models",
        "abstract": "  While large language models (LLMs) have been used for automated grading, they\nhave not yet achieved the same level of performance as humans, especially when\nit comes to grading complex questions. Existing research on this topic focuses\non a particular step in the grading procedure: grading using predefined\nrubrics. However, grading is a multifaceted procedure that encompasses other\ncrucial steps, such as grading rubrics design and post-grading review. There\nhas been a lack of systematic research exploring the potential of LLMs to\nenhance the entire grading~process.\n  In this paper, we propose an LLM-based grading system that addresses the\nentire grading procedure, including the following key components: 1) Developing\ngrading rubrics that not only consider the questions but also the student\nanswers, which can more accurately reflect students' performance. 2) Under the\nguidance of grading rubrics, providing accurate and consistent scores for each\nstudent, along with customized feedback. 3) Conducting post-grading review to\nbetter ensure accuracy and fairness. Additionally, we collected a new dataset\nnamed OS from a university operating system course and conducted extensive\nexperiments on both our new dataset and the widely used Mohler dataset.\nExperiments demonstrate the effectiveness of our proposed approach, providing\nsome new insights for developing automated grading systems based on LLMs.\n",
        "authors": "Wenjing Xie; Juxin Niu; Chun Jason Xue; Nan Guan",
        "status": 0,
        "relevancy": 0.46883618289192464,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19708",
        "date": "2024-05-30",
        "title": "Text Guided Image Editing with Automatic Concept Locating and Forgetting",
        "abstract": "  With the advancement of image-to-image diffusion models guided by text,\nsignificant progress has been made in image editing. However, a persistent\nchallenge remains in seamlessly incorporating objects into images based on\ntextual instructions, without relying on extra user-provided guidance. Text and\nimages are inherently distinct modalities, bringing out difficulties in fully\ncapturing the semantic intent conveyed through language and accurately\ntranslating that into the desired visual modifications. Therefore, text-guided\nimage editing models often produce generations with residual object attributes\nthat do not fully align with human expectations. To address this challenge, the\nmodels should comprehend the image content effectively away from a disconnect\nbetween the provided textual editing prompts and the actual modifications made\nto the image. In our paper, we propose a novel method called Locate and Forget\n(LaF), which effectively locates potential target concepts in the image for\nmodification by comparing the syntactic trees of the target prompt and scene\ndescriptions in the input image, intending to forget their existence clues in\nthe generated image. Compared to the baselines, our method demonstrates its\nsuperiority in text-guided image editing tasks both qualitatively and\nquantitatively.\n",
        "authors": "Jia Li; Lijie Hu; Zhixian He; Jingfeng Zhang; Tianhang Zheng; Di Wang",
        "status": 0,
        "relevancy": 0.4677283584526706,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19796",
        "date": "2024-05-30",
        "title": "Explainable Attribute-Based Speaker Verification",
        "abstract": "  This paper proposes a fully explainable approach to speaker verification\n(SV), a task that fundamentally relies on individual speaker characteristics.\nThe opaque use of speaker attributes in current SV systems raises concerns of\ntrust. Addressing this, we propose an attribute-based explainable SV system\nthat identifies speakers by comparing personal attributes such as gender,\nnationality, and age extracted automatically from voice recordings. We believe\nthis approach better aligns with human reasoning, making it more understandable\nthan traditional methods. Evaluated on the Voxceleb1 test set, the best\nperformance of our system is comparable with the ground truth established when\nusing all correct attributes, proving its efficacy. Whilst our approach\nsacrifices some performance compared to non-explainable methods, we believe\nthat it moves us closer to the goal of transparent, interpretable AI and lays\nthe groundwork for future enhancements through attribute expansion.\n",
        "authors": "Xiaoliang Wu; Chau Luu; Peter Bell; Ajitha Rajan",
        "status": 0,
        "relevancy": 0.45955810526014285,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20216",
        "date": "2024-05-30",
        "title": "Boost Your Own Human Image Generation Model via Direct Preference\n  Optimization with AI Feedback",
        "abstract": "  The generation of high-quality human images through text-to-image (T2I)\nmethods is a significant yet challenging task. Distinct from general image\ngeneration, human image synthesis must satisfy stringent criteria related to\nhuman pose, anatomy, and alignment with textual prompts, making it particularly\ndifficult to achieve realistic results. Recent advancements in T2I generation\nbased on diffusion models have shown promise, yet challenges remain in meeting\nhuman-specific preferences. In this paper, we introduce a novel approach\ntailored specifically for human image generation utilizing Direct Preference\nOptimization (DPO). Specifically, we introduce an efficient method for\nconstructing a specialized DPO dataset for training human image generation\nmodels without the need for costly human feedback. We also propose a modified\nloss function that enhances the DPO training process by minimizing artifacts\nand improving image fidelity. Our method demonstrates its versatility and\neffectiveness in generating human images, including personalized text-to-image\ngeneration. Through comprehensive evaluations, we show that our approach\nsignificantly advances the state of human image generation, achieving superior\nresults in terms of natural anatomies, poses, and text-image alignment.\n",
        "authors": "Sanghyeon Na; Yonggyu Kim; Hyunjoon Lee",
        "status": 0,
        "relevancy": 0.4589247821765172,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20003",
        "date": "2024-05-30",
        "title": "Kernel Language Entropy: Fine-grained Uncertainty Quantification for\n  LLMs from Semantic Similarities",
        "abstract": "  Uncertainty quantification in Large Language Models (LLMs) is crucial for\napplications where safety and reliability are important. In particular,\nuncertainty can be used to improve the trustworthiness of LLMs by detecting\nfactually incorrect model responses, commonly called hallucinations.\nCritically, one should seek to capture the model's semantic uncertainty, i.e.,\nthe uncertainty over the meanings of LLM outputs, rather than uncertainty over\nlexical or syntactic variations that do not affect answer correctness. To\naddress this problem, we propose Kernel Language Entropy (KLE), a novel method\nfor uncertainty estimation in white- and black-box LLMs. KLE defines positive\nsemidefinite unit trace kernels to encode the semantic similarities of LLM\noutputs and quantifies uncertainty using the von Neumann entropy. It considers\npairwise semantic dependencies between answers (or semantic clusters),\nproviding more fine-grained uncertainty estimates than previous methods based\non hard clustering of answers. We theoretically prove that KLE generalizes the\nprevious state-of-the-art method called semantic entropy and empirically\ndemonstrate that it improves uncertainty quantification performance across\nmultiple natural language generation datasets and LLM architectures.\n",
        "authors": "Alexander Nikitin; Jannik Kossen; Yarin Gal; Pekka Marttinen",
        "status": 0,
        "relevancy": 0.4559010398248027,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19815",
        "date": "2024-05-30",
        "title": "Efficient Stimuli Generation using Reinforcement Learning in Design\n  Verification",
        "abstract": "  The increasing design complexity of System-on-Chips (SoCs) has led to\nsignificant verification challenges, particularly in meeting coverage targets\nwithin a timely manner. At present, coverage closure is heavily dependent on\nconstrained random and coverage driven verification methodologies where the\nrandomized stimuli are bounded to verify certain scenarios and to reach\ncoverage goals. This process is said to be exhaustive and to consume a lot of\nproject time. In this paper, a novel methodology is proposed to generate\nefficient stimuli with the help of Reinforcement Learning (RL) to reach the\nmaximum code coverage of the Design Under Verification (DUV). Additionally, an\nautomated framework is created using metamodeling to generate a SystemVerilog\ntestbench and an RL environment for any given design. The proposed approach is\napplied to various designs and the produced results proves that the RL agent\nprovides effective stimuli to achieve code coverage faster in comparison with\nbaseline random simulations. Furthermore, various RL agents and reward schemes\nare analyzed in our work.\n",
        "authors": "Deepak Narayan Gadde; Thomas Nalapat; Aman Kumar; Djones Lettnin; Wolfgang Kunz; Sebastian Simon",
        "status": 0,
        "relevancy": 0.44928077451128423,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19654",
        "date": "2024-05-30",
        "title": "Unlocking the Power of Spatial and Temporal Information in Medical\n  Multimodal Pre-training",
        "abstract": "  Medical vision-language pre-training methods mainly leverage the\ncorrespondence between paired medical images and radiological reports. Although\nmulti-view spatial images and temporal sequences of image-report pairs are\navailable in off-the-shelf multi-modal medical datasets, most existing methods\nhave not thoroughly tapped into such extensive supervision signals. In this\npaper, we introduce the Med-ST framework for fine-grained spatial and temporal\nmodeling to exploit information from multiple spatial views of chest\nradiographs and temporal historical records. For spatial modeling, Med-ST\nemploys the Mixture of View Expert (MoVE) architecture to integrate different\nvisual features from both frontal and lateral views. To achieve a more\ncomprehensive alignment, Med-ST not only establishes the global alignment\nbetween whole images and texts but also introduces modality-weighted local\nalignment between text tokens and spatial regions of images. For temporal\nmodeling, we propose a novel cross-modal bidirectional cycle consistency\nobjective by forward mapping classification (FMC) and reverse mapping\nregression (RMR). By perceiving temporal information from simple to complex,\nMed-ST can learn temporal semantics. Experimental results across four distinct\ntasks demonstrate the effectiveness of Med-ST, especially in temporal\nclassification tasks. Our code and model are available at\nhttps://github.com/SVT-Yang/MedST.\n",
        "authors": "Jinxia Yang; Bing Su; Wayne Xin Zhao; Ji-Rong Wen",
        "status": 0,
        "relevancy": 0.448925720240238,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19931",
        "date": "2024-05-30",
        "title": "Exploring Diffusion Models' Corruption Stage in Few-Shot Fine-tuning and\n  Mitigating with Bayesian Neural Networks",
        "abstract": "  Few-shot fine-tuning of Diffusion Models (DMs) is a key advancement,\nsignificantly reducing training costs and enabling personalized AI\napplications. However, we explore the training dynamics of DMs and observe an\nunanticipated phenomenon: during the training process, image fidelity initially\nimproves, then unexpectedly deteriorates with the emergence of noisy patterns,\nonly to recover later with severe overfitting. We term the stage with generated\nnoisy patterns as corruption stage. To understand this corruption stage, we\nbegin by theoretically modeling the one-shot fine-tuning scenario, and then\nextend this modeling to more general cases. Through this modeling, we identify\nthe primary cause of this corruption stage: a narrowed learning distribution\ninherent in the nature of few-shot fine-tuning. To tackle this, we apply\nBayesian Neural Networks (BNNs) on DMs with variational inference to implicitly\nbroaden the learned distribution, and present that the learning target of the\nBNNs can be naturally regarded as an expectation of the diffusion loss and a\nfurther regularization with the pretrained DMs. This approach is highly\ncompatible with current few-shot fine-tuning methods in DMs and does not\nintroduce any extra inference costs. Experimental results demonstrate that our\nmethod significantly mitigates corruption, and improves the fidelity, quality\nand diversity of the generated images in both object-driven and subject-driven\ngeneration tasks.\n",
        "authors": "Xiaoyu Wu; Jiaru Zhang; Yang Hua; Bohan Lyu; Hao Wang; Tao Song; Haibing Guan",
        "status": 0,
        "relevancy": 0.44860151310205854,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20213",
        "date": "2024-05-30",
        "title": "PostDoc: Generating Poster from a Long Multimodal Document Using Deep\n  Submodular Optimization",
        "abstract": "  A poster from a long input document can be considered as a one-page\neasy-to-read multimodal (text and images) summary presented on a nice template\nwith good design elements. Automatic transformation of a long document into a\nposter is a very less studied but challenging task. It involves content\nsummarization of the input document followed by template generation and\nharmonization. In this work, we propose a novel deep submodular function which\ncan be trained on ground truth summaries to extract multimodal content from the\ndocument and explicitly ensures good coverage, diversity and alignment of text\nand images. Then, we use an LLM based paraphraser and propose to generate a\ntemplate with various design aspects conditioned on the input content. We show\nthe merits of our approach through extensive automated and human evaluations.\n",
        "authors": "Vijay Jaisankar; Sambaran Bandyopadhyay; Kalp Vyas; Varre Chaitanya; Shwetha Somasundaram",
        "status": 0,
        "relevancy": 0.44536321945538926,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19958",
        "date": "2024-05-30",
        "title": "Multi-Aspect Controllable Text Generation with Disentangled\n  Counterfactual Augmentation",
        "abstract": "  Multi-aspect controllable text generation aims to control the generated texts\nin attributes from multiple aspects (e.g., \"positive\" from sentiment and\n\"sport\" from topic). For ease of obtaining training samples, existing works\nneglect attribute correlations formed by the intertwining of different\nattributes. Particularly, the stereotype formed by imbalanced attribute\ncorrelations significantly affects multi-aspect control. In this paper, we\npropose MAGIC, a new multi-aspect controllable text generation method with\ndisentangled counterfactual augmentation. We alleviate the issue of imbalanced\nattribute correlations during training using counterfactual feature vectors in\nthe attribute latent space by disentanglement. During inference, we enhance\nattribute correlations by target-guided counterfactual augmentation to further\nimprove multi-aspect control. Experiments show that MAGIC outperforms\nstate-of-the-art baselines in both imbalanced and balanced attribute\ncorrelation scenarios. Our source code and data are available at\nhttps://github.com/nju-websoft/MAGIC.\n",
        "authors": "Yi Liu; Xiangyu Liu; Xiangrong Zhu; Wei Hu",
        "status": 0,
        "relevancy": 0.4448100532707844,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20202",
        "date": "2024-05-30",
        "title": "One QuantLLM for ALL: Fine-tuning Quantized LLMs Once for Efficient\n  Deployments",
        "abstract": "  Large Language Models (LLMs) have advanced rapidly but face significant\nmemory demands. While quantization has shown promise for LLMs, current methods\ntypically require lengthy training to alleviate the performance degradation\nfrom quantization loss. However, deploying LLMs across diverse scenarios with\ndifferent resource constraints, e.g., servers and personal computers, requires\nrepeated training per application, which amplifies the lengthy training\nproblem. Given that, it is advantageous to train a once-for-all (OFA) supernet\ncapable of yielding diverse optimal subnets for downstream applications through\none-shot training. Nonetheless, the scale of current language models impedes\nefficiency and amplifies interference from weight sharing between subnets. We\nmake an initial attempt to extend the once-for-all framework to large language\nmodels. Specifically, we decouple shared weights to eliminate the interference\nand incorporate Low-Rank adapters for training efficiency. Furthermore, we\nobserve the imbalance allocation of training resources from the traditional\nuniform sampling. A non-parametric scheduler is introduced to adjust the\nsampling rate for each quantization configuration, achieving a more balanced\nallocation among subnets with varying demands. We validate the approach on\nLLaMA2 families, and downstream evaluation confirms our ability to maintain\nhigh performance while significantly reducing deployment time faced with\nmultiple scenarios.\n",
        "authors": "Ke Yi; Yuhui Xu; Heng Chang; Chen Tang; Yuan Meng; Tong Zhang; Jia Li",
        "status": 0,
        "relevancy": 0.443071356784724,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19816",
        "date": "2024-05-30",
        "title": "Growing Tiny Networks: Spotting Expressivity Bottlenecks and Fixing Them\n  Optimally",
        "abstract": "  Machine learning tasks are generally formulated as optimization problems,\nwhere one searches for an optimal function within a certain functional space.\nIn practice, parameterized functional spaces are considered, in order to be\nable to perform gradient descent. Typically, a neural network architecture is\nchosen and fixed, and its parameters (connection weights) are optimized,\nyielding an architecture-dependent result. This way of proceeding however\nforces the evolution of the function during training to lie within the realm of\nwhat is expressible with the chosen architecture, and prevents any optimization\nacross architectures. Costly architectural hyper-parameter optimization is\noften performed to compensate for this. Instead, we propose to adapt the\narchitecture on the fly during training. We show that the information about\ndesirable architectural changes, due to expressivity bottlenecks when\nattempting to follow the functional gradient, can be extracted from %the\nbackpropagation. To do this, we propose a mathematical definition of\nexpressivity bottlenecks, which enables us to detect, quantify and solve them\nwhile training, by adding suitable neurons when and where needed. Thus, while\nthe standard approach requires large networks, in terms of number of neurons\nper layer, for expressivity and optimization reasons, we are able to start with\nvery small neural networks and let them grow appropriately. As a proof of\nconcept, we show results~on the CIFAR dataset, matching large neural network\naccuracy, with competitive training time, while removing the need for standard\narchitectural hyper-parameter search.\n",
        "authors": "Manon Verbockhaven; Sylvain Chevallier; Guillaume Charpiat",
        "status": 0,
        "relevancy": 0.44195345501328087,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19982",
        "date": "2024-05-30",
        "title": "A Deep Reinforcement Learning Approach for Trading Optimization in the\n  Forex Market with Multi-Agent Asynchronous Distribution",
        "abstract": "  In today's forex market traders increasingly turn to algorithmic trading,\nleveraging computers to seek more profits. Deep learning techniques as\ncutting-edge advancements in machine learning, capable of identifying patterns\nin financial data. Traders utilize these patterns to execute more effective\ntrades, adhering to algorithmic trading rules. Deep reinforcement learning\nmethods (DRL), by directly executing trades based on identified patterns and\nassessing their profitability, offer advantages over traditional DL approaches.\nThis research pioneers the application of a multi-agent (MA) RL framework with\nthe state-of-the-art Asynchronous Advantage Actor-Critic (A3C) algorithm. The\nproposed method employs parallel learning across multiple asynchronous workers,\neach specialized in trading across multiple currency pairs to explore the\npotential for nuanced strategies tailored to different market conditions and\ncurrency pairs. Two different A3C with lock and without lock MA model was\nproposed and trained on single currency and multi-currency. The results\nindicate that both model outperform on Proximal Policy Optimization model. A3C\nwith lock outperforms other in single currency training scenario and A3C\nwithout Lock outperforms other in multi-currency scenario. The findings\ndemonstrate that this approach facilitates broader and faster exploration of\ndifferent currency pairs, significantly enhancing trading returns.\nAdditionally, the agent can learn a more profitable trading strategy in a\nshorter time.\n",
        "authors": "Davoud Sarani; Dr. Parviz Rashidi-Khazaee",
        "status": 0,
        "relevancy": 0.4410347837315911,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19837",
        "date": "2024-05-30",
        "title": "Lifelong learning challenges in the era of artificial intelligence: a\n  computational thinking perspective",
        "abstract": "  The rapid advancement of artificial intelligence (AI) has brought significant\nchallenges to the education and workforce skills required to take advantage of\nAI for human-AI collaboration in the workplace. As AI continues to reshape\nindustries and job markets, the need to define how AI literacy can be\nconsidered in lifelong learning has become increasingly critical (Cetindamar et\nal., 2022; Laupichler et al., 2022; Romero et al., 2023). Like any new\ntechnology, AI is the subject of both hopes and fears, and what it entails\ntoday presents major challenges (Cugurullo \\& Acheampong, 2023; Villani et al.,\n2018). It also raises profound questions about our own humanity. Will the\nmachine surpass the intelligence of the humans who designed it? What will be\nthe relationship between so-called AI and our human intelligences? How could\nhuman-AI collaboration be regulated in a way that serves the Sustainable\nDevelopment Goals (SDGs)? This paper provides a review of the challenges of\nlifelong learning in the era of AI from a computational thinking, critical\nthinking, and creative competencies perspective, highlighting the implications\nfor management and leadership in organizations.\n",
        "authors": "Margarida Romero",
        "status": 0,
        "relevancy": 0.43820782155057236,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19861",
        "date": "2024-05-30",
        "title": "Hierarchical Object-Centric Learning with Capsule Networks",
        "abstract": "  Capsule networks (CapsNets) were introduced to address convolutional neural\nnetworks limitations, learning object-centric representations that are more\nrobust, pose-aware, and interpretable. They organize neurons into groups called\ncapsules, where each capsule encodes the instantiation parameters of an object\nor one of its parts. Moreover, a routing algorithm connects capsules in\ndifferent layers, thereby capturing hierarchical part-whole relationships in\nthe data.\n  This thesis investigates the intriguing aspects of CapsNets and focuses on\nthree key questions to unlock their full potential. First, we explore the\neffectiveness of the routing algorithm, particularly in small-sized networks.\nWe propose a novel method that anneals the number of routing iterations during\ntraining, enhancing performance in architectures with fewer parameters.\n  Secondly, we investigate methods to extract more effective first-layer\ncapsules, also known as primary capsules. By exploiting pruned backbones, we\naim to improve computational efficiency by reducing the number of capsules\nwhile achieving high generalization. This approach reduces CapsNets memory\nrequirements and computational effort.\n  Third, we explore part-relationship learning in CapsNets. Through extensive\nresearch, we demonstrate that capsules with low entropy can extract more\nconcise and discriminative part-whole relationships compared to traditional\ncapsule networks, even with reasonable network sizes.\n  Lastly, we showcase how CapsNets can be utilized in real-world applications,\nincluding autonomous localization of unmanned aerial vehicles, quaternion-based\nrotations prediction in synthetic datasets, and lung nodule segmentation in\nbiomedical imaging.\n  The findings presented in this thesis contribute to a deeper understanding of\nCapsNets and highlight their potential to address complex computer vision\nchallenges.\n",
        "authors": "Riccardo Renzulli",
        "status": 0,
        "relevancy": 0.4375315160940294,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19850",
        "date": "2024-05-30",
        "title": "Deciphering Human Mobility: Inferring Semantics of Trajectories with\n  Large Language Models",
        "abstract": "  Understanding human mobility patterns is essential for various applications,\nfrom urban planning to public safety. The individual trajectory such as mobile\nphone location data, while rich in spatio-temporal information, often lacks\nsemantic detail, limiting its utility for in-depth mobility analysis. Existing\nmethods can infer basic routine activity sequences from this data, lacking\ndepth in understanding complex human behaviors and users' characteristics.\nAdditionally, they struggle with the dependency on hard-to-obtain auxiliary\ndatasets like travel surveys. To address these limitations, this paper defines\ntrajectory semantic inference through three key dimensions: user occupation\ncategory, activity sequence, and trajectory description, and proposes the\nTrajectory Semantic Inference with Large Language Models (TSI-LLM) framework to\nleverage LLMs infer trajectory semantics comprehensively and deeply. We adopt\nspatio-temporal attributes enhanced data formatting (STFormat) and design a\ncontext-inclusive prompt, enabling LLMs to more effectively interpret and infer\nthe semantics of trajectory data. Experimental validation on real-world\ntrajectory datasets demonstrates the efficacy of TSI-LLM in deciphering complex\nhuman mobility patterns. This study explores the potential of LLMs in enhancing\nthe semantic analysis of trajectory data, paving the way for more sophisticated\nand accessible human mobility research.\n",
        "authors": "Yuxiao Luo; Zhongcai Cao; Xin Jin; Kang Liu; Ling Yin",
        "status": 0,
        "relevancy": 0.43706604976747854,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19631",
        "date": "2024-05-30",
        "title": "Leveraging Open-Source Large Language Models for encoding Social\n  Determinants of Health using an Intelligent Router",
        "abstract": "  Social Determinants of Health (SDOH) play a significant role in patient\nhealth outcomes. The Center of Disease Control (CDC) introduced a subset of\nICD-10 codes called Z-codes in an attempt to officially recognize and measure\nSDOH in the health care system. However, these codes are rarely annotated in a\npatient's Electronic Health Record (EHR), and instead, in many cases, need to\nbe inferred from clinical notes. Previous research has shown that large\nlanguage models (LLMs) show promise on extracting unstructured data from EHRs.\nHowever, with thousands of models to choose from with unique architectures and\ntraining sets, it's difficult to choose one model that performs the best on\ncoding tasks. Further, clinical notes contain trusted health information making\nthe use of closed-source language models from commercial vendors difficult, so\nthe identification of open source LLMs that can be run within health\norganizations and exhibits high performance on SDOH tasks is an urgent problem.\nHere, we introduce an intelligent routing system for SDOH coding that uses a\nlanguage model router to direct medical record data to open source LLMs that\ndemonstrate optimal performance on specific SDOH codes. The intelligent routing\nsystem exhibits state of the art performance of 97.4% accuracy averaged across\n5 codes, including homelessness and food insecurity, on par with closed models\nsuch as GPT-4o. In order to train the routing system and validate models, we\nalso introduce a synthetic data generation and validation paradigm to increase\nthe scale of training data without needing privacy protected medical records.\nTogether, we demonstrate an architecture for intelligent routing of inputs to\ntask-optimal language models to achieve high performance across a set of\nmedical coding sub-tasks.\n",
        "authors": "Akul Goel; Surya Narayanan Hari; Belinda Waltman; Matt Thomson",
        "status": 0,
        "relevancy": 0.42855517518640984,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20204",
        "date": "2024-05-30",
        "title": "Jina CLIP: Your CLIP Model Is Also Your Text Retriever",
        "abstract": "  Contrastive Language-Image Pretraining (CLIP) is widely used to train models\nto align images and texts in a common embedding space by mapping them to\nfixed-sized vectors. These models are key to multimodal information retrieval\nand related tasks. However, CLIP models generally underperform in text-only\ntasks compared to specialized text models. This creates inefficiencies for\ninformation retrieval systems that keep separate embeddings and models for\ntext-only and multimodal tasks. We propose a novel, multi-task contrastive\ntraining method to address this issue, which we use to train the jina-clip-v1\nmodel to achieve the state-of-the-art performance on both text-image and\ntext-text retrieval tasks.\n",
        "authors": "Andreas Koukounas; Georgios Mastrapas; Michael Günther; Bo Wang; Scott Martens; Isabelle Mohr; Saba Sturua; Mohammad Kalim Akram; Joan Fontanals Martínez; Saahil Ognawala; Susana Guzman; Maximilian Werk; Nan Wang; Han Xiao",
        "status": 0,
        "relevancy": 0.4233779231858861,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20218",
        "date": "2024-05-30",
        "title": "ESG-FTSE: A corpus of news articles with ESG relevance labels and use\n  cases",
        "abstract": "  We present ESG-FTSE, the first corpus comprised of news articles with\nEnvironmental, Social and Governance (ESG) relevance annotations. In recent\nyears, investors and regulators have pushed ESG investing to the mainstream due\nto the urgency of climate change. This has led to the rise of ESG scores to\nevaluate an investment's credentials as socially responsible. While demand for\nESG scores is high, their quality varies wildly. Quantitative techniques can be\napplied to improve ESG scores, thus, responsible investing. To contribute to\nresource building for ESG and financial text mining, we pioneer the ESG-FTSE\ncorpus. We further present the first of its kind ESG annotation schema. It has\nthree levels: a binary classification (relevant versus irrelevant news\narticles), ESG classification (ESG-related news articles), and target company.\nBoth supervised and unsupervised learning experiments for ESG relevance\ndetection were conducted to demonstrate that the corpus can be used in\ndifferent settings to derive accurate ESG predictions. Keywords: corpus\nannotation, ESG labels, annotation schema, news article, natural language\nprocessing\n",
        "authors": "Mariya Pavlova; Bernard Casey; Miaosen Wang",
        "status": 0,
        "relevancy": 0.4120645248126876,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20233",
        "date": "2024-05-30",
        "title": "Grokfast: Accelerated Grokking by Amplifying Slow Gradients",
        "abstract": "  One puzzling artifact in machine learning dubbed grokking is where delayed\ngeneralization is achieved tenfolds of iterations after near perfect\noverfitting to the training data. Focusing on the long delay itself on behalf\nof machine learning practitioners, our goal is to accelerate generalization of\na model under grokking phenomenon. By regarding a series of gradients of a\nparameter over training iterations as a random signal over time, we can\nspectrally decompose the parameter trajectories under gradient descent into two\ncomponents: the fast-varying, overfitting-yielding component and the\nslow-varying, generalization-inducing component. This analysis allows us to\naccelerate the grokking phenomenon more than $\\times 50$ with only a few lines\nof code that amplifies the slow-varying components of gradients. The\nexperiments show that our algorithm applies to diverse tasks involving images,\nlanguages, and graphs, enabling practical availability of this peculiar\nartifact of sudden generalization. Our code is available at\n\\url{https://github.com/ironjr/grokfast}.\n",
        "authors": "Jaerin Lee; Bong Gyun Kang; Kihoon Kim; Kyoung Mu Lee",
        "status": 0,
        "relevancy": 0.4115985844813268,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19678",
        "date": "2024-05-30",
        "title": "View-Consistent Hierarchical 3D SegmentationUsing Ultrametric Feature\n  Fields",
        "abstract": "  Large-scale vision foundation models such as Segment Anything (SAM)\ndemonstrate impressive performance in zero-shot image segmentation at multiple\nlevels of granularity. However, these zero-shot predictions are rarely\n3D-consistent. As the camera viewpoint changes in a scene, so do the\nsegmentation predictions, as well as the characterizations of ``coarse\" or\n``fine\" granularity. In this work, we address the challenging task of lifting\nmulti-granular and view-inconsistent image segmentations into a hierarchical\nand 3D-consistent representation. We learn a novel feature field within a\nNeural Radiance Field (NeRF) representing a 3D scene, whose segmentation\nstructure can be revealed at different scales by simply using different\nthresholds on feature distance. Our key idea is to learn an ultrametric feature\nspace, which unlike a Euclidean space, exhibits transitivity in distance-based\ngrouping, naturally leading to a hierarchical clustering. Put together, our\nmethod takes view-inconsistent multi-granularity 2D segmentations as input and\nproduces a hierarchy of 3D-consistent segmentations as output. We evaluate our\nmethod and several baselines on synthetic datasets with multi-view images and\nmulti-granular segmentation, showcasing improved accuracy and\nviewpoint-consistency. We additionally provide qualitative examples of our\nmodel's 3D hierarchical segmentations in real world scenes.\\footnote{The code\nand dataset are available at:\n",
        "authors": "Haodi He; Colton Stearns; Adam W. Harley; Leonidas J. Guibas",
        "status": 0,
        "relevancy": 0.40922065179453393,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20319",
        "date": "2024-05-30",
        "title": "ParSEL: Parameterized Shape Editing with Language",
        "abstract": "  The ability to edit 3D assets from natural language presents a compelling\nparadigm to aid in the democratization of 3D content creation. However, while\nnatural language is often effective at communicating general intent, it is\npoorly suited for specifying precise manipulation. To address this gap, we\nintroduce ParSEL, a system that enables controllable editing of high-quality 3D\nassets from natural language. Given a segmented 3D mesh and an editing request,\nParSEL produces a parameterized editing program. Adjusting the program\nparameters allows users to explore shape variations with a precise control over\nthe magnitudes of edits. To infer editing programs which align with an input\nedit request, we leverage the abilities of large-language models (LLMs).\nHowever, while we find that LLMs excel at identifying initial edit operations,\nthey often fail to infer complete editing programs, and produce outputs that\nviolate shape semantics. To overcome this issue, we introduce Analytical Edit\nPropagation (AEP), an algorithm which extends a seed edit with additional\noperations until a complete editing program has been formed. Unlike prior\nmethods, AEP searches for analytical editing operations compatible with a range\nof possible user edits through the integration of computer algebra systems for\ngeometric analysis. Experimentally we demonstrate ParSEL's effectiveness in\nenabling controllable editing of 3D objects through natural language requests\nover alternative system designs.\n",
        "authors": "Aditya Ganeshan; Ryan Y. Huang; Xianghao Xu; R. Kenny Jones; Daniel Ritchie",
        "status": 0,
        "relevancy": 0.40658810338109996,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19765",
        "date": "2024-05-30",
        "title": "Towards Unified Multi-granularity Text Detection with Interactive\n  Attention",
        "abstract": "  Existing OCR engines or document image analysis systems typically rely on\ntraining separate models for text detection in varying scenarios and\ngranularities, leading to significant computational complexity and resource\ndemands. In this paper, we introduce \"Detect Any Text\" (DAT), an advanced\nparadigm that seamlessly unifies scene text detection, layout analysis, and\ndocument page detection into a cohesive, end-to-end model. This design enables\nDAT to efficiently manage text instances at different granularities, including\n*word*, *line*, *paragraph* and *page*. A pivotal innovation in DAT is the\nacross-granularity interactive attention module, which significantly enhances\nthe representation learning of text instances at varying granularities by\ncorrelating structural information across different text queries. As a result,\nit enables the model to achieve mutually beneficial detection performances\nacross multiple text granularities. Additionally, a prompt-based segmentation\nmodule refines detection outcomes for texts of arbitrary curvature and complex\nlayouts, thereby improving DAT's accuracy and expanding its real-world\napplicability. Experimental results demonstrate that DAT achieves\nstate-of-the-art performances across a variety of text-related benchmarks,\nincluding multi-oriented/arbitrarily-shaped scene text detection, document\nlayout analysis and page detection tasks.\n",
        "authors": "Xingyu Wan; Chengquan Zhang; Pengyuan Lyu; Sen Fan; Zihan Ni; Kun Yao; Errui Ding; Jingdong Wang",
        "status": 0,
        "relevancy": 0.4065289484620488,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20337",
        "date": "2024-05-30",
        "title": "OccSora: 4D Occupancy Generation Models as World Simulators for\n  Autonomous Driving",
        "abstract": "  Understanding the evolution of 3D scenes is important for effective\nautonomous driving. While conventional methods mode scene development with the\nmotion of individual instances, world models emerge as a generative framework\nto describe the general scene dynamics. However, most existing methods adopt an\nautoregressive framework to perform next-token prediction, which suffer from\ninefficiency in modeling long-term temporal evolutions. To address this, we\npropose a diffusion-based 4D occupancy generation model, OccSora, to simulate\nthe development of the 3D world for autonomous driving. We employ a 4D scene\ntokenizer to obtain compact discrete spatial-temporal representations for 4D\noccupancy input and achieve high-quality reconstruction for long-sequence\noccupancy videos. We then learn a diffusion transformer on the spatial-temporal\nrepresentations and generate 4D occupancy conditioned on a trajectory prompt.\nWe conduct extensive experiments on the widely used nuScenes dataset with Occ3D\noccupancy annotations. OccSora can generate 16s-videos with authentic 3D layout\nand temporal consistency, demonstrating its ability to understand the spatial\nand temporal distributions of driving scenes. With trajectory-aware 4D\ngeneration, OccSora has the potential to serve as a world simulator for the\ndecision-making of autonomous driving. Code is available at:\nhttps://github.com/wzzheng/OccSora.\n",
        "authors": "Lening Wang; Wenzhao Zheng; Yilong Ren; Han Jiang; Zhiyong Cui; Haiyang Yu; Jiwen Lu",
        "status": 0,
        "relevancy": 0.405878936415753,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20015",
        "date": "2024-05-30",
        "title": "Efficient LLM-Jailbreaking by Introducing Visual Modality",
        "abstract": "  This paper focuses on jailbreaking attacks against large language models\n(LLMs), eliciting them to generate objectionable content in response to harmful\nuser queries. Unlike previous LLM-jailbreaks that directly orient to LLMs, our\napproach begins by constructing a multimodal large language model (MLLM)\nthrough the incorporation of a visual module into the target LLM. Subsequently,\nwe conduct an efficient MLLM-jailbreak to generate jailbreaking embeddings\nembJS. Finally, we convert the embJS into text space to facilitate the\njailbreaking of the target LLM. Compared to direct LLM-jailbreaking, our\napproach is more efficient, as MLLMs are more vulnerable to jailbreaking than\npure LLM. Additionally, to improve the attack success rate (ASR) of\njailbreaking, we propose an image-text semantic matching scheme to identify a\nsuitable initial input. Extensive experiments demonstrate that our approach\nsurpasses current state-of-the-art methods in terms of both efficiency and\neffectiveness. Moreover, our approach exhibits superior cross-class\njailbreaking capabilities.\n",
        "authors": "Zhenxing Niu; Yuyao Sun; Haodong Ren; Haoxuan Ji; Quan Wang; Xiaoke Ma; Gang Hua; Rong Jin",
        "status": 0,
        "relevancy": 0.40555543538695793,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20234",
        "date": "2024-05-30",
        "title": "Context Injection Attacks on Large Language Models",
        "abstract": "  Large Language Models (LLMs) such as ChatGPT and Llama-2 have become\nprevalent in real-world applications, exhibiting impressive text generation\nperformance. LLMs are fundamentally developed from a scenario where the input\ndata remains static and lacks a clear structure. To behave interactively over\ntime, LLM-based chat systems must integrate additional contextual information\n(i.e., chat history) into their inputs, following a pre-defined structure. This\npaper identifies how such integration can expose LLMs to misleading context\nfrom untrusted sources and fail to differentiate between system and user\ninputs, allowing users to inject context. We present a systematic methodology\nfor conducting context injection attacks aimed at eliciting disallowed\nresponses by introducing fabricated context. This could lead to illegal\nactions, inappropriate content, or technology misuse. Our context fabrication\nstrategies, acceptance elicitation and word anonymization, effectively create\nmisleading contexts that can be structured with attacker-customized prompt\ntemplates, achieving injection through malicious user messages. Comprehensive\nevaluations on real-world LLMs such as ChatGPT and Llama-2 confirm the efficacy\nof the proposed attack with success rates reaching 97%. We also discuss\npotential countermeasures that can be adopted for attack detection and\ndeveloping more secure models. Our findings provide insights into the\nchallenges associated with the real-world deployment of LLMs for interactive\nand structured data scenarios.\n",
        "authors": "Cheng'an Wei; Kai Chen; Yue Zhao; Yujia Gong; Lu Xiang; Shenchen Zhu",
        "status": 0,
        "relevancy": 0.4048507842357849,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19642",
        "date": "2024-05-30",
        "title": "Few-shot fault diagnosis based on multi-scale graph convolution\n  filtering for industry",
        "abstract": "  Industrial equipment fault diagnosis often encounter challenges such as the\nscarcity of fault data, complex operating conditions, and varied types of\nfailures. Signal analysis, data statistical learning, and conventional deep\nlearning techniques face constraints under these conditions due to their\nsubstantial data requirements and the necessity for transfer learning to\naccommodate new failure modes. To effectively leverage information and extract\nthe intrinsic characteristics of faults across different domains under limited\nsample conditions, this paper introduces a fault diagnosis approach employing\nMulti-Scale Graph Convolution Filtering (MSGCF). MSGCF enhances the traditional\nGraph Neural Network (GNN) framework by integrating both local and global\ninformation fusion modules within the graph convolution filter block. This\nadvancement effectively mitigates the over-smoothing issue associated with\nexcessive layering of graph convolutional layers while preserving a broad\nreceptive field. It also reduces the risk of overfitting in few-shot diagnosis,\nthereby augmenting the model's representational capacity. Experiments on the\nUniversity of Paderborn bearing dataset (PU) demonstrate that the MSGCF method\nproposed herein surpasses alternative approaches in accuracy, thereby offering\nvaluable insights for industrial fault diagnosis in few-shot learning\nscenarios.\n",
        "authors": "Mengjie Gan; Penglong Lian; Zhiheng Su; Jiyang Zhang; Jialong Huang; Benhao Wang; Jianxiao Zou; Shicai Fan",
        "status": 0,
        "relevancy": 0.40468896887458816,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19761",
        "date": "2024-05-30",
        "title": "Revisiting CNNs for Trajectory Similarity Learning",
        "abstract": "  Similarity search is a fundamental but expensive operator in querying\ntrajectory data, due to its quadratic complexity of distance computation. To\nmitigate the computational burden for long trajectories, neural networks have\nbeen widely employed for similarity learning and each trajectory is encoded as\na high-dimensional vector for similarity search with linear complexity. Given\nthe sequential nature of trajectory data, previous efforts have been primarily\ndevoted to the utilization of RNNs or Transformers.\n  In this paper, we argue that the common practice of treating trajectory as\nsequential data results in excessive attention to capturing long-term global\ndependency between two sequences. Instead, our investigation reveals the\npivotal role of local similarity, prompting a revisit of simple CNNs for\ntrajectory similarity learning. We introduce ConvTraj, incorporating both 1D\nand 2D convolutions to capture sequential and geo-distribution features of\ntrajectories, respectively. In addition, we conduct a series of theoretical\nanalyses to justify the effectiveness of ConvTraj. Experimental results on\nthree real-world large-scale datasets demonstrate that ConvTraj achieves\nstate-of-the-art accuracy in trajectory similarity search. Owing to the simple\nnetwork structure of ConvTraj, the training and inference speed on the Porto\ndataset with 1.6 million trajectories are increased by at least $240$x and\n$2.16$x, respectively. The source code and dataset can be found at\n\\textit{\\url{https://github.com/Proudc/ConvTraj}}.\n",
        "authors": "Zhihao Chang; Linzhu Yu; Huan Li; Sai Wu; Gang Chen; Dongxiang Zhang",
        "status": 0,
        "relevancy": 0.40441262870956474,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20082",
        "date": "2024-05-30",
        "title": "Segment, Shuffle, and Stitch: A Simple Mechanism for Improving\n  Time-Series Representations",
        "abstract": "  Existing approaches for learning representations of time-series keep the\ntemporal arrangement of the time-steps intact with the presumption that the\noriginal order is the most optimal for learning. However, non-adjacent sections\nof real-world time-series may have strong dependencies. Accordingly we raise\nthe question: Is there an alternative arrangement for time-series which could\nenable more effective representation learning? To address this, we propose a\nsimple plug-and-play mechanism called Segment, Shuffle, and Stitch (S3)\ndesigned to improve time-series representation learning of existing models. S3\nworks by creating non-overlapping segments from the original sequence and\nshuffling them in a learned manner that is the most optimal for the task at\nhand. It then re-attaches the shuffled segments back together and performs a\nlearned weighted sum with the original input to capture both the newly shuffled\nsequence along with the original sequence. S3 is modular and can be stacked to\ncreate various degrees of granularity, and can be added to many forms of neural\narchitectures including CNNs or Transformers with negligible computation\noverhead. Through extensive experiments on several datasets and\nstate-of-the-art baselines, we show that incorporating S3 results in\nsignificant improvements for the tasks of time-series classification and\nforecasting, improving performance on certain datasets by up to 68\\%. We also\nshow that S3 makes the learning more stable with a smoother training loss curve\nand loss landscape compared to the original baseline. The code is available at\nhttps://github.com/shivam-grover/S3-TimeSeries .\n",
        "authors": "Shivam Grover; Amin Jalali; Ali Etemad",
        "status": 0,
        "relevancy": 0.4005710419662505,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19818",
        "date": "2024-05-30",
        "title": "WebUOT-1M: Advancing Deep Underwater Object Tracking with A\n  Million-Scale Benchmark",
        "abstract": "  Underwater object tracking (UOT) is a foundational task for identifying and\ntracing submerged entities in underwater video sequences. However, current UOT\ndatasets suffer from limitations in scale, diversity of target categories and\nscenarios covered, hindering the training and evaluation of modern tracking\nalgorithms. To bridge this gap, we take the first step and introduce WebUOT-1M,\n\\ie, the largest public UOT benchmark to date, sourced from complex and\nrealistic underwater environments. It comprises 1.1 million frames across 1,500\nvideo clips filtered from 408 target categories, largely surpassing previous\nUOT datasets, \\eg, UVOT400. Through meticulous manual annotation and\nverification, we provide high-quality bounding boxes for underwater targets.\nAdditionally, WebUOT-1M includes language prompts for video sequences,\nexpanding its application areas, \\eg, underwater vision-language tracking. Most\nexisting trackers are tailored for open-air environments, leading to\nperformance degradation when applied to UOT due to domain gaps. Retraining and\nfine-tuning these trackers are challenging due to sample imbalances and limited\nreal-world underwater datasets. To tackle these challenges, we propose a novel\nomni-knowledge distillation framework based on WebUOT-1M, incorporating various\nstrategies to guide the learning of the student Transformer. To the best of our\nknowledge, this framework is the first to effectively transfer open-air domain\nknowledge to the UOT model through knowledge distillation, as demonstrated by\nresults on both existing UOT datasets and the newly proposed WebUOT-1M.\nFurthermore, we comprehensively evaluate WebUOT-1M using 30 deep trackers,\nshowcasing its value as a benchmark for UOT research by presenting new\nchallenges and opportunities for future studies. The complete dataset, codes\nand tracking results, will be made publicly available.\n",
        "authors": "Chunhui Zhang; Li Liu; Guanjie Huang; Hao Wen; Xi Zhou; Yanfeng Wang",
        "status": 0,
        "relevancy": 0.39869194825448206,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20180",
        "date": "2024-05-30",
        "title": "Transformers and Slot Encoding for Sample Efficient Physical World\n  Modelling",
        "abstract": "  World modelling, i.e. building a representation of the rules that govern the\nworld so as to predict its evolution, is an essential ability for any agent\ninteracting with the physical world. Recent applications of the Transformer\narchitecture to the problem of world modelling from video input show notable\nimprovements in sample efficiency. However, existing approaches tend to work\nonly at the image level thus disregarding that the environment is composed of\nobjects interacting with each other. In this paper, we propose an architecture\ncombining Transformers for world modelling with the slot-attention paradigm, an\napproach for learning representations of objects appearing in a scene. We\ndescribe the resulting neural architecture and report experimental results\nshowing an improvement over the existing solutions in terms of sample\nefficiency and a reduction of the variation of the performance over the\ntraining examples. The code for our architecture and experiments is available\nat https://github.com/torchipeppo/transformers-and-slot-encoding-for-wm\n",
        "authors": "Francesco Petri; Luigi Asprino; Aldo Gangemi",
        "status": 0,
        "relevancy": 0.3962625571167996,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19996",
        "date": "2024-05-30",
        "title": "DP-IQA: Utilizing Diffusion Prior for Blind Image Quality Assessment in\n  the Wild",
        "abstract": "  Image quality assessment (IQA) plays a critical role in selecting\nhigh-quality images and guiding compression and enhancement methods in a series\nof applications. The blind IQA, which assesses the quality of in-the-wild\nimages containing complex authentic distortions without reference images, poses\ngreater challenges. Existing methods are limited to modeling a uniform\ndistribution with local patches and are bothered by the gap between low and\nhigh-level visions (caused by widely adopted pre-trained classification\nnetworks). In this paper, we propose a novel IQA method called diffusion\npriors-based IQA (DP-IQA), which leverages the prior knowledge from the\npre-trained diffusion model with its excellent powers to bridge semantic gaps\nin the perception of the visual quality of images. Specifically, we use\npre-trained stable diffusion as the backbone, extract multi-level features from\nthe denoising U-Net during the upsampling process at a specified timestep, and\ndecode them to estimate the image quality score. The text and image adapters\nare adopted to mitigate the domain gap for downstream tasks and correct the\ninformation loss caused by the variational autoencoder bottleneck. Finally, we\ndistill the knowledge in the above model into a CNN-based student model,\nsignificantly reducing the parameter to enhance applicability, with the student\nmodel performing similarly or even better than the teacher model surprisingly.\nExperimental results demonstrate that our DP-IQA achieves state-of-the-art\nresults on various in-the-wild datasets with better generalization capability,\nwhich shows the superiority of our method in global modeling and utilizing the\nhierarchical feature clues of diffusion for evaluating image quality.\n",
        "authors": "Honghao Fu; Yufei Wang; Wenhan Yang; Bihan Wen",
        "status": 0,
        "relevancy": 0.3917643603771399,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19754",
        "date": "2024-05-30",
        "title": "Mitigating annotation shift in cancer classification using single image\n  generative models",
        "abstract": "  Artificial Intelligence (AI) has emerged as a valuable tool for assisting\nradiologists in breast cancer detection and diagnosis. However, the success of\nAI applications in this domain is restricted by the quantity and quality of\navailable data, posing challenges due to limited and costly data annotation\nprocedures that often lead to annotation shifts. This study simulates, analyses\nand mitigates annotation shifts in cancer classification in the breast\nmammography domain. First, a high-accuracy cancer risk prediction model is\ndeveloped, which effectively distinguishes benign from malignant lesions. Next,\nmodel performance is used to quantify the impact of annotation shift. We\nuncover a substantial impact of annotation shift on multiclass classification\nperformance particularly for malignant lesions. We thus propose a training data\naugmentation approach based on single-image generative models for the affected\nclass, requiring as few as four in-domain annotations to considerably mitigate\nannotation shift, while also addressing dataset imbalance. Lastly, we further\nincrease performance by proposing and validating an ensemble architecture based\non multiple models trained under different data augmentation regimes. Our study\noffers key insights into annotation shift in deep learning breast cancer\nclassification and explores the potential of single-image generative models to\novercome domain shift challenges.\n",
        "authors": "Marta Buetas Arcas; Richard Osuala; Karim Lekadir; Oliver Díaz",
        "status": 0,
        "relevancy": 0.39038447492082073,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19600",
        "date": "2024-05-30",
        "title": "Do spectral cues matter in contrast-based graph self-supervised\n  learning?",
        "abstract": "  The recent surge in contrast-based graph self-supervised learning has\nprominently featured an intensified exploration of spectral cues. However, an\nintriguing paradox emerges, as methods grounded in seemingly conflicting\nassumptions or heuristic approaches regarding the spectral domain demonstrate\nnotable enhancements in learning performance. This paradox prompts a critical\ninquiry into the genuine contribution of spectral information to contrast-based\ngraph self-supervised learning. This study undertakes an extensive\ninvestigation into this inquiry, conducting a thorough study of the\nrelationship between spectral characteristics and the learning outcomes of\ncontemporary methodologies. Based on this analysis, we claim that the\neffectiveness and significance of spectral information need to be questioned.\nInstead, we revisit simple edge perturbation: random edge dropping designed for\nnode-level self-supervised learning and random edge adding intended for\ngraph-level self-supervised learning. Compelling evidence is presented that\nthese simple yet effective strategies consistently yield superior performance\nwhile demanding significantly fewer computational resources compared to all\nprior spectral augmentation methods. The proposed insights represent a\nsignificant leap forward in the field, potentially reshaping the understanding\nand implementation of graph self-supervised learning.\n",
        "authors": "Xiangru Jian; Xinjian Zhao; Wei Pang; Chaolong Ying; Yimu Wang; Yaoyao Xu; Tianshu Yu",
        "status": 0,
        "relevancy": 0.39015523518223405,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19597",
        "date": "2024-05-30",
        "title": "SVFT: Parameter-Efficient Fine-Tuning with Singular Vectors",
        "abstract": "  Popular parameter-efficient fine-tuning (PEFT) methods, such as LoRA and its\nvariants, freeze pre-trained model weights \\(W\\) and inject learnable matrices\n\\(\\Delta W\\). These \\(\\Delta W\\) matrices are structured for efficient\nparameterization, often using techniques like low-rank approximations or\nscaling vectors. However, these methods typically show a performance gap\ncompared to full fine-tuning. Although recent PEFT methods have narrowed this\ngap, they do so at the cost of additional learnable parameters. We propose\nSVFT, a simple approach that fundamentally differs from existing methods: the\nstructure imposed on \\(\\Delta W\\) depends on the specific weight matrix \\(W\\).\nSpecifically, SVFT updates \\(W\\) as a sparse combination of outer products of\nits singular vectors, training only the coefficients (scales) of these sparse\ncombinations. This approach allows fine-grained control over expressivity\nthrough the number of coefficients. Extensive experiments on language and\nvision benchmarks show that SVFT recovers up to 96% of full fine-tuning\nperformance while training only 0.006 to 0.25% of parameters, outperforming\nexisting methods that only recover up to 85% performance using 0.03 to 0.8% of\nthe trainable parameter budget.\n",
        "authors": "Vijay Lingam; Atula Tejaswi; Aditya Vavre; Aneesh Shetty; Gautham Krishna Gudur; Joydeep Ghosh; Alex Dimakis; Eunsol Choi; Aleksandar Bojchevski; Sujay Sanghavi",
        "status": 0,
        "relevancy": 0.38953830302401415,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20330",
        "date": "2024-05-30",
        "title": "4DHands: Reconstructing Interactive Hands in 4D with Transformers",
        "abstract": "  In this paper, we introduce 4DHands, a robust approach to recovering\ninteractive hand meshes and their relative movement from monocular inputs. Our\napproach addresses two major limitations of previous methods: lacking a unified\nsolution for handling various hand image inputs and neglecting the positional\nrelationship of two hands within images. To overcome these challenges, we\ndevelop a transformer-based architecture with novel tokenization and feature\nfusion strategies. Specifically, we propose a Relation-aware Two-Hand\nTokenization (RAT) method to embed positional relation information into the\nhand tokens. In this way, our network can handle both single-hand and two-hand\ninputs and explicitly leverage relative hand positions, facilitating the\nreconstruction of intricate hand interactions in real-world scenarios. As such\ntokenization indicates the relative relationship of two hands, it also supports\nmore effective feature fusion. To this end, we further develop a\nSpatio-temporal Interaction Reasoning (SIR) module to fuse hand tokens in 4D\nwith attention and decode them into 3D hand meshes and relative temporal\nmovements. The efficacy of our approach is validated on several benchmark\ndatasets. The results on in-the-wild videos and real-world scenarios\ndemonstrate the superior performances of our approach for interactive hand\nreconstruction. More video results can be found on the project page:\nhttps://4dhands.github.io.\n",
        "authors": "Dixuan Lin; Yuxiang Zhang; Mengcheng Li; Yebin Liu; Wei Jing; Qi Yan; Qianying Wang; Hongwen Zhang",
        "status": 0,
        "relevancy": 0.3871932143211807,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19656",
        "date": "2024-05-30",
        "title": "Accurate and Reliable Predictions with Mutual-Transport Ensemble",
        "abstract": "  Deep Neural Networks (DNNs) have achieved remarkable success in a variety of\ntasks, especially when it comes to prediction accuracy. However, in complex\nreal-world scenarios, particularly in safety-critical applications, high\naccuracy alone is not enough. Reliable uncertainty estimates are crucial.\nModern DNNs, often trained with cross-entropy loss, tend to be overconfident,\nespecially with ambiguous samples. To improve uncertainty calibration, many\ntechniques have been developed, but they often compromise prediction accuracy.\nTo tackle this challenge, we propose the ``mutual-transport ensemble'' (MTE).\nThis approach introduces a co-trained auxiliary model and adaptively\nregularizes the cross-entropy loss using Kullback-Leibler (KL) divergence\nbetween the prediction distributions of the primary and auxiliary models. We\nconducted extensive studies on various benchmarks to validate the effectiveness\nof our method. The results show that MTE can simultaneously enhance both\naccuracy and uncertainty calibration. For example, on the CIFAR-100 dataset,\nour MTE method on ResNet34/50 achieved significant improvements compared to\nprevious state-of-the-art method, with absolute accuracy increases of\n2.4%/3.7%, relative reductions in ECE of $42.3%/29.4%, and relative reductions\nin classwise-ECE of 11.6%/15.3%.\n",
        "authors": "Han Liu; Peng Cui; Bingning Wang; Jun Zhu; Xiaolin Hu",
        "status": 0,
        "relevancy": 0.38662846418346786,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20289",
        "date": "2024-05-30",
        "title": "DITTO-2: Distilled Diffusion Inference-Time T-Optimization for Music\n  Generation",
        "abstract": "  Controllable music generation methods are critical for human-centered\nAI-based music creation, but are currently limited by speed, quality, and\ncontrol design trade-offs. Diffusion Inference-Time T-optimization (DITTO), in\nparticular, offers state-of-the-art results, but is over 10x slower than\nreal-time, limiting practical use. We propose Distilled Diffusion\nInference-Time T -Optimization (or DITTO-2), a new method to speed up\ninference-time optimization-based control and unlock faster-than-real-time\ngeneration for a wide-variety of applications such as music inpainting,\noutpainting, intensity, melody, and musical structure control. Our method works\nby (1) distilling a pre-trained diffusion model for fast sampling via an\nefficient, modified consistency or consistency trajectory distillation process\n(2) performing inference-time optimization using our distilled model with\none-step sampling as an efficient surrogate optimization task and (3) running a\nfinal multi-step sampling generation (decoding) using our estimated noise\nlatents for best-quality, fast, controllable generation. Through thorough\nevaluation, we find our method not only speeds up generation over 10-20x, but\nsimultaneously improves control adherence and generation quality all at once.\nFurthermore, we apply our approach to a new application of maximizing text\nadherence (CLAP score) and show we can convert an unconditional diffusion model\nwithout text inputs into a model that yields state-of-the-art text control.\nSound examples can be found at https://ditto-music.github.io/ditto2/.\n",
        "authors": "Zachary Novack; Julian McAuley; Taylor Berg-Kirkpatrick; Nicholas Bryan",
        "status": 0,
        "relevancy": 0.3818986811651287,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19808",
        "date": "2024-05-30",
        "title": "AI with Alien Content and Alien Metasemantics",
        "abstract": "  AlphaGo plays chess and Go in a creative and novel way. It is natural for us\nto attribute contents to it, such as that it doesn't view being several pawns\nbehind, if it has more board space, as bad. The framework introduced in\nCappelen and Dever (2021) provides a way of thinking about the semantics and\nthe metasemantics of AI content: does AlphaGo entertain contents like this, and\nif so, in virtue of what does a given state of the program mean that particular\ncontent? One salient question Cappelen and Dever didn't consider was the\npossibility of alien content. Alien content is content that is not or cannot be\nexpressed by human beings. It's highly plausible that AlphaGo, or any other\nsophisticated AI system, expresses alien contents. That this is so, moreover,\nis plausibly a metasemantic fact: a fact that has to do with how AI comes to\nentertain content in the first place, one that will heed the vastly different\netiology of AI and human content. This chapter explores the question of alien\ncontent in AI from a semantic and metasemantic perspective. It lays out the\nlogical space of possible responses to the semantic and metasemantic questions\nalien content poses, considers whether and how we humans could communicate with\nentities who express alien content, and points out that getting clear about\nsuch questions might be important for more 'applied' issues in the philosophy\nof AI, such as existential risk and XAI.\n",
        "authors": "Herman Cappelen; Josh Dever",
        "status": 0,
        "relevancy": 0.38163742004054024,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19784",
        "date": "2024-05-30",
        "title": "PixelsDB: Serverless and Natural-Language-Aided Data Analytics with\n  Flexible Service Levels and Prices",
        "abstract": "  Serverless query processing has become increasingly popular due to its\nadvantages, including automated hardware and software management, high\nelasticity, and pay-as-you-go pricing. For users who are not system experts,\nserverless query processing greatly reduces the cost of owning a data analytic\nsystem. However, it is still a significant challenge for non-expert users to\ntransform their complex and evolving data analytic needs into proper SQL\nqueries and select a serverless query engine that delivers satisfactory\nperformance and price for each type of query.\n  This paper presents PixelsDB, an open-source data analytic system that allows\nusers who lack system or SQL expertise to explore data efficiently. It allows\nusers to generate and debug SQL queries using a natural language interface\npowered by fine-tuned language models. The queries are then executed by a\nserverless query engine that offers varying prices for different service levels\non query urgency. The service levels are natively supported by dedicated\narchitecture design and heterogeneous resource scheduling that can apply\ncost-efficient resources to process non-urgent queries. We envision that the\ncombination of a serverless paradigm, a natural-language-aided interface, and\nflexible service levels and prices will substantially improve the user\nexperience in data analysis.\n",
        "authors": "Haoqiong Bian; Dongyang Geng; Haoyang Li; Anastasia Ailamaki",
        "status": 0,
        "relevancy": 0.38030300445777143,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19899",
        "date": "2024-05-30",
        "title": "Open-Set Domain Adaptation for Semantic Segmentation",
        "abstract": "  Unsupervised domain adaptation (UDA) for semantic segmentation aims to\ntransfer the pixel-wise knowledge from the labeled source domain to the\nunlabeled target domain. However, current UDA methods typically assume a shared\nlabel space between source and target, limiting their applicability in\nreal-world scenarios where novel categories may emerge in the target domain. In\nthis paper, we introduce Open-Set Domain Adaptation for Semantic Segmentation\n(OSDA-SS) for the first time, where the target domain includes unknown classes.\nWe identify two major problems in the OSDA-SS scenario as follows: 1) the\nexisting UDA methods struggle to predict the exact boundary of the unknown\nclasses, and 2) they fail to accurately predict the shape of the unknown\nclasses. To address these issues, we propose Boundary and Unknown Shape-Aware\nopen-set domain adaptation, coined BUS. Our BUS can accurately discern the\nboundaries between known and unknown classes in a contrastive manner using a\nnovel dilation-erosion-based contrastive loss. In addition, we propose\nOpenReMix, a new domain mixing augmentation method that guides our model to\neffectively learn domain and size-invariant features for improving the shape\ndetection of the known and unknown classes. Through extensive experiments, we\ndemonstrate that our proposed BUS effectively detects unknown classes in the\nchallenging OSDA-SS scenario compared to the previous methods by a large\nmargin. The code is available at https://github.com/KHU-AGI/BUS.\n",
        "authors": "Seun-An Choe; Ah-Hyung Shin; Keon-Hee Park; Jinwoo Choi; Gyeong-Moon Park",
        "status": 0,
        "relevancy": 0.37924322881298234,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20279",
        "date": "2024-05-30",
        "title": "CV-VAE: A Compatible Video VAE for Latent Generative Video Models",
        "abstract": "  Spatio-temporal compression of videos, utilizing networks such as Variational\nAutoencoders (VAE), plays a crucial role in OpenAI's SORA and numerous other\nvideo generative models. For instance, many LLM-like video models learn the\ndistribution of discrete tokens derived from 3D VAEs within the VQVAE\nframework, while most diffusion-based video models capture the distribution of\ncontinuous latent extracted by 2D VAEs without quantization. The temporal\ncompression is simply realized by uniform frame sampling which results in\nunsmooth motion between consecutive frames. Currently, there lacks of a\ncommonly used continuous video (3D) VAE for latent diffusion-based video models\nin the research community. Moreover, since current diffusion-based approaches\nare often implemented using pre-trained text-to-image (T2I) models, directly\ntraining a video VAE without considering the compatibility with existing T2I\nmodels will result in a latent space gap between them, which will take huge\ncomputational resources for training to bridge the gap even with the T2I models\nas initialization. To address this issue, we propose a method for training a\nvideo VAE of latent video models, namely CV-VAE, whose latent space is\ncompatible with that of a given image VAE, e.g., image VAE of Stable Diffusion\n(SD). The compatibility is achieved by the proposed novel latent space\nregularization, which involves formulating a regularization loss using the\nimage VAE. Benefiting from the latent space compatibility, video models can be\ntrained seamlessly from pre-trained T2I or video models in a truly\nspatio-temporally compressed latent space, rather than simply sampling video\nframes at equal intervals. With our CV-VAE, existing video models can generate\nfour times more frames with minimal finetuning. Extensive experiments are\nconducted to demonstrate the effectiveness of the proposed video VAE.\n",
        "authors": "Sijie Zhao; Yong Zhang; Xiaodong Cun; Shaoshu Yang; Muyao Niu; Xiaoyu Li; Wenbo Hu; Ying Shan",
        "status": 0,
        "relevancy": 0.3792280354540144,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20172",
        "date": "2024-05-30",
        "title": "Iterative Feature Boosting for Explainable Speech Emotion Recognition",
        "abstract": "  In speech emotion recognition (SER), using predefined features without\nconsidering their practical importance may lead to high dimensional datasets,\nincluding redundant and irrelevant information. Consequently, high-dimensional\nlearning often results in decreasing model accuracy while increasing\ncomputational complexity. Our work underlines the importance of carefully\nconsidering and analyzing features in order to build efficient SER systems. We\npresent a new supervised SER method based on an efficient feature engineering\napproach. We pay particular attention to the explainability of results to\nevaluate feature relevance and refine feature sets. This is performed\niteratively through feature evaluation loop, using Shapley values to boost\nfeature selection and improve overall framework performance. Our approach\nallows thus to balance the benefits between model performance and transparency.\nThe proposed method outperforms human-level performance (HLP) and\nstate-of-the-art machine learning methods in emotion recognition on the TESS\ndataset.\n",
        "authors": "Alaa Nfissi; Wassim Bouachir; Nizar Bouguila; Brian Mishara",
        "status": 0,
        "relevancy": 0.3720850311410322,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19832",
        "date": "2024-05-30",
        "title": "AI Safety: A Climb To Armageddon?",
        "abstract": "  This paper presents an argument that certain AI safety measures, rather than\nmitigating existential risk, may instead exacerbate it. Under certain key\nassumptions - the inevitability of AI failure, the expected correlation between\nan AI system's power at the point of failure and the severity of the resulting\nharm, and the tendency of safety measures to enable AI systems to become more\npowerful before failing - safety efforts have negative expected utility. The\npaper examines three response strategies: Optimism, Mitigation, and Holism.\nEach faces challenges stemming from intrinsic features of the AI safety\nlandscape that we term Bottlenecking, the Perfection Barrier, and Equilibrium\nFluctuation. The surprising robustness of the argument forces a re-examination\nof core assumptions around AI safety and points to several avenues for further\nresearch.\n",
        "authors": "Herman Cappelen; Josh Dever; John Hawthorne",
        "status": 0,
        "relevancy": 0.36714458446619347,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20222",
        "date": "2024-05-30",
        "title": "MOFA-Video: Controllable Image Animation via Generative Motion Field\n  Adaptions in Frozen Image-to-Video Diffusion Model",
        "abstract": "  We present MOFA-Video, an advanced controllable image animation method that\ngenerates video from the given image using various additional controllable\nsignals (such as human landmarks reference, manual trajectories, and another\neven provided video) or their combinations. This is different from previous\nmethods which only can work on a specific motion domain or show weak control\nabilities with diffusion prior. To achieve our goal, we design several\ndomain-aware motion field adapters (\\ie, MOFA-Adapters) to control the\ngenerated motions in the video generation pipeline. For MOFA-Adapters, we\nconsider the temporal motion consistency of the video and generate the dense\nmotion flow from the given sparse control conditions first, and then, the\nmulti-scale features of the given image are wrapped as a guided feature for\nstable video diffusion generation. We naively train two motion adapters for the\nmanual trajectories and the human landmarks individually since they both\ncontain sparse information about the control. After training, the MOFA-Adapters\nin different domains can also work together for more controllable video\ngeneration.\n",
        "authors": "Muyao Niu; Xiaodong Cun; Xintao Wang; Yong Zhang; Ying Shan; Yinqiang Zheng",
        "status": 0,
        "relevancy": 0.36642647419455154,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20114",
        "date": "2024-05-30",
        "title": "Near Optimal Decentralized Optimization with Compression and Momentum\n  Tracking",
        "abstract": "  Communication efficiency has garnered significant attention as it is\nconsidered the main bottleneck for large-scale decentralized Machine Learning\napplications in distributed and federated settings. In this regime, clients are\nrestricted to transmitting small amounts of quantized information to their\nneighbors over a communication graph. Numerous endeavors have been made to\naddress this challenging problem by developing algorithms with compressed\ncommunication for decentralized non-convex optimization problems. Despite\nconsiderable efforts, the current results suffer from various issues such as\nnon-scalability with the number of clients, requirements for large batches, or\nbounded gradient assumption. In this paper, we introduce MoTEF, a novel\napproach that integrates communication compression with Momentum Tracking and\nError Feedback. Our analysis demonstrates that MoTEF achieves most of the\ndesired properties, and significantly outperforms existing methods under\narbitrary data heterogeneity. We provide numerical experiments to validate our\ntheoretical findings and confirm the practical superiority of MoTEF.\n",
        "authors": "Rustem Islamov; Yuan Gao; Sebastian U. Stich",
        "status": 0,
        "relevancy": 0.35704846067221097,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19757",
        "date": "2024-05-30",
        "title": "Improving SMOTE via Fusing Conditional VAE for Data-adaptive Noise\n  Filtering",
        "abstract": "  Recent advances in a generative neural network model extend the development\nof data augmentation methods. However, the augmentation methods based on the\nmodern generative models fail to achieve notable performance for class\nimbalance data compared to the conventional model, the SMOTE. We investigate\nthe problem of the generative model for imbalanced classification and introduce\na framework to enhance the SMOTE algorithm using Variational Autoencoders\n(VAE). Our approach systematically quantifies the density of data points in a\nlow-dimensional latent space using the VAE, simultaneously incorporating\ninformation on class labels and classification difficulty. Then, the data\npoints potentially degrading the augmentation are systematically excluded, and\nthe neighboring observations are directly augmented on the data space.\nEmpirical studies on several imbalanced datasets represent that this simple\nprocess innovatively improves the conventional SMOTE algorithm over the deep\nlearning models. Consequently, we conclude that the selection of minority data\nand the interpolation in the data space are beneficial for imbalanced\nclassification problems with a relatively small number of data points.\n",
        "authors": "Sungchul Hong; Seunghwan An; Jong-June Jeon",
        "status": 0,
        "relevancy": 0.3568938759743223,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19743",
        "date": "2024-05-30",
        "title": "May the Dance be with You: Dance Generation Framework for Non-Humanoids",
        "abstract": "  We hypothesize dance as a motion that forms a visual rhythm from music, where\nthe visual rhythm can be perceived from an optical flow. If an agent can\nrecognize the relationship between visual rhythm and music, it will be able to\ndance by generating a motion to create a visual rhythm that matches the music.\nBased on this, we propose a framework for any kind of non-humanoid agents to\nlearn how to dance from human videos. Our framework works in two processes: (1)\ntraining a reward model which perceives the relationship between optical flow\n(visual rhythm) and music from human dance videos, (2) training the\nnon-humanoid dancer based on that reward model, and reinforcement learning. Our\nreward model consists of two feature encoders for optical flow and music. They\nare trained based on contrastive learning which makes the higher similarity\nbetween concurrent optical flow and music features. With this reward model, the\nagent learns dancing by getting a higher reward when its action creates an\noptical flow whose feature has a higher similarity with the given music\nfeature. Experiment results show that generated dance motion can align with the\nmusic beat properly, and user study result indicates that our framework is more\npreferred by humans compared to the baselines. To the best of our knowledge,\nour work of non-humanoid agents which learn dance from human videos is\nunprecedented. An example video can be found at https://youtu.be/dOUPvo-O3QY.\n",
        "authors": "Hyemin Ahn",
        "status": 0,
        "relevancy": 0.35629470656024,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20231",
        "date": "2024-05-30",
        "title": "The Empirical Impact of Neural Parameter Symmetries, or Lack Thereof",
        "abstract": "  Many algorithms and observed phenomena in deep learning appear to be affected\nby parameter symmetries -- transformations of neural network parameters that do\nnot change the underlying neural network function. These include linear mode\nconnectivity, model merging, Bayesian neural network inference, metanetworks,\nand several other characteristics of optimization or loss-landscapes. However,\ntheoretical analysis of the relationship between parameter space symmetries and\nthese phenomena is difficult. In this work, we empirically investigate the\nimpact of neural parameter symmetries by introducing new neural network\narchitectures that have reduced parameter space symmetries. We develop two\nmethods, with some provable guarantees, of modifying standard neural networks\nto reduce parameter space symmetries. With these new methods, we conduct a\ncomprehensive experimental study consisting of multiple tasks aimed at\nassessing the effect of removing parameter symmetries. Our experiments reveal\nseveral interesting observations on the empirical impact of parameter\nsymmetries; for instance, we observe linear mode connectivity between our\nnetworks without alignment of weight spaces, and we find that our networks\nallow for faster and more effective Bayesian neural network training.\n",
        "authors": "Derek Lim; Moe Putterman; Robin Walters; Haggai Maron; Stefanie Jegelka",
        "status": 0,
        "relevancy": 0.3556465326771272,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19729",
        "date": "2024-05-30",
        "title": "Dynamic feature selection in medical predictive monitoring by\n  reinforcement learning",
        "abstract": "  In this paper, we investigate dynamic feature selection within multivariate\ntime-series scenario, a common occurrence in clinical prediction monitoring\nwhere each feature corresponds to a bio-test result. Many existing feature\nselection methods fall short in effectively leveraging time-series information,\nprimarily because they are designed for static data. Our approach addresses\nthis limitation by enabling the selection of time-varying feature subsets for\neach patient. Specifically, we employ reinforcement learning to optimize a\npolicy under maximum cost restrictions. The prediction model is subsequently\nupdated using synthetic data generated by trained policy. Our method can\nseamlessly integrate with non-differentiable prediction models. We conducted\nexperiments on a sizable clinical dataset encompassing regression and\nclassification tasks. The results demonstrate that our approach outperforms\nstrong feature selection baselines, particularly when subjected to stringent\ncost limitations. Code will be released once paper is accepted.\n",
        "authors": "Yutong Chen; Jiandong Gao; Ji Wu",
        "status": 0,
        "relevancy": 0.3519337342152189,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20287",
        "date": "2024-05-30",
        "title": "Flexible SE(2) graph neural networks with applications to PDE surrogates",
        "abstract": "  This paper presents a novel approach for constructing graph neural networks\nequivariant to 2D rotations and translations and leveraging them as PDE\nsurrogates on non-gridded domains. We show that aligning the representations\nwith the principal axis allows us to sidestep many constraints while preserving\nSE(2) equivariance. By applying our model as a surrogate for fluid flow\nsimulations and conducting thorough benchmarks against non-equivariant models,\nwe demonstrate significant gains in terms of both data efficiency and accuracy.\n",
        "authors": "Maria Bånkestad; Olof Mogren; Aleksis Pirinen",
        "status": 0,
        "relevancy": 0.3519032565832092,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19822",
        "date": "2024-05-30",
        "title": "Improving Object Detector Training on Synthetic Data by Starting With a\n  Strong Baseline Methodology",
        "abstract": "  Collecting and annotating real-world data for the development of object\ndetection models is a time-consuming and expensive process. In the military\ndomain in particular, data collection can also be dangerous or infeasible.\nTraining models on synthetic data may provide a solution for cases where access\nto real-world training data is restricted. However, bridging the reality gap\nbetween synthetic and real data remains a challenge. Existing methods usually\nbuild on top of baseline Convolutional Neural Network (CNN) models that have\nbeen shown to perform well when trained on real data, but have limited ability\nto perform well when trained on synthetic data. For example, some architectures\nallow for fine-tuning with the expectation of large quantities of training data\nand are prone to overfitting on synthetic data. Related work usually ignores\nvarious best practices from object detection on real data, e.g. by training on\nsynthetic data from a single environment with relatively little variation. In\nthis paper we propose a methodology for improving the performance of a\npre-trained object detector when training on synthetic data. Our approach\nfocuses on extracting the salient information from synthetic data without\nforgetting useful features learned from pre-training on real images. Based on\nthe state of the art, we incorporate data augmentation methods and a\nTransformer backbone. Besides reaching relatively strong performance without\nany specialized synthetic data transfer methods, we show that our methods\nimprove the state of the art on synthetic data trained object detection for the\nRarePlanes and DGTA-VisDrone datasets, and reach near-perfect performance on an\nin-house vehicle detection dataset.\n",
        "authors": "Frank A. Ruis; Alma M. Liezenga; Friso G. Heslinga; Luca Ballan; Thijs A. Eker; Richard J. M. den Hollander; Martin C. van Leeuwen; Judith Dijk; Wyke Huizinga",
        "status": 0,
        "relevancy": 0.34827107155345904,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19956",
        "date": "2024-05-30",
        "title": "HOLMES: to Detect Adversarial Examples with Multiple Detectors",
        "abstract": "  Deep neural networks (DNNs) can easily be cheated by some imperceptible but\npurposeful noise added to images, and erroneously classify them. Previous\ndefensive work mostly focused on retraining the models or detecting the noise,\nbut has either shown limited success rates or been attacked by new adversarial\nexamples. Instead of focusing on adversarial images or the interior of DNN\nmodels, we observed that adversarial examples generated by different algorithms\ncan be identified based on the output of DNNs (logits). Logit can serve as an\nexterior feature to train detectors. Then, we propose HOLMES (Hierarchically\nOrganized Light-weight Multiple dEtector System) to reinforce DNNs by detecting\npotential adversarial examples to minimize the threats they may bring in\npractical. HOLMES is able to distinguish \\textit{unseen} adversarial examples\nfrom multiple attacks with high accuracy and low false positive rates than\nsingle detector systems even in an adaptive model. To ensure the diversity and\nrandomness of detectors in HOLMES, we use two methods: training dedicated\ndetectors for each label and training detectors with top-k logits. Our\neffective and inexpensive strategies neither modify original DNN models nor\nrequire its internal parameters. HOLMES is not only compatible with all kinds\nof learning models (even only with external APIs), but also complementary to\nother defenses to achieve higher detection rates (may also fully protect the\nsystem against various adversarial examples).\n",
        "authors": "Jing Wen",
        "status": 0,
        "relevancy": 0.34799041283614096,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19677",
        "date": "2024-05-30",
        "title": "Large Language Model Watermark Stealing With Mixed Integer Programming",
        "abstract": "  The Large Language Model (LLM) watermark is a newly emerging technique that\nshows promise in addressing concerns surrounding LLM copyright, monitoring\nAI-generated text, and preventing its misuse. The LLM watermark scheme commonly\nincludes generating secret keys to partition the vocabulary into green and red\nlists, applying a perturbation to the logits of tokens in the green list to\nincrease their sampling likelihood, thus facilitating watermark detection to\nidentify AI-generated text if the proportion of green tokens exceeds a\nthreshold. However, recent research indicates that watermarking methods using\nnumerous keys are susceptible to removal attacks, such as token editing,\nsynonym substitution, and paraphrasing, with robustness declining as the number\nof keys increases. Therefore, the state-of-the-art watermark schemes that\nemploy fewer or single keys have been demonstrated to be more robust against\ntext editing and paraphrasing. In this paper, we propose a novel green list\nstealing attack against the state-of-the-art LLM watermark scheme and\nsystematically examine its vulnerability to this attack. We formalize the\nattack as a mixed integer programming problem with constraints. We evaluate our\nattack under a comprehensive threat model, including an extreme scenario where\nthe attacker has no prior knowledge, lacks access to the watermark detector\nAPI, and possesses no information about the LLM's parameter settings or\nwatermark injection/detection scheme. Extensive experiments on LLMs, such as\nOPT and LLaMA, demonstrate that our attack can successfully steal the green\nlist and remove the watermark across all settings.\n",
        "authors": "Zhaoxi Zhang; Xiaomei Zhang; Yanjun Zhang; Leo Yu Zhang; Chao Chen; Shengshan Hu; Asif Gill; Shirui Pan",
        "status": 0,
        "relevancy": 0.34223031569876095,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20323",
        "date": "2024-05-30",
        "title": "$\\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous\n  Driving",
        "abstract": "  Photorealistic 3D reconstruction of street scenes is a critical technique for\ndeveloping real-world simulators for autonomous driving. Despite the efficacy\nof Neural Radiance Fields (NeRF) for driving scenes, 3D Gaussian Splatting\n(3DGS) emerges as a promising direction due to its faster speed and more\nexplicit representation. However, most existing street 3DGS methods require\ntracked 3D vehicle bounding boxes to decompose the static and dynamic elements\nfor effective reconstruction, limiting their applications for in-the-wild\nscenarios. To facilitate efficient 3D scene reconstruction without costly\nannotations, we propose a self-supervised street Gaussian\n($\\textit{S}^3$Gaussian) method to decompose dynamic and static elements from\n4D consistency. We represent each scene with 3D Gaussians to preserve the\nexplicitness and further accompany them with a spatial-temporal field network\nto compactly model the 4D dynamics. We conduct extensive experiments on the\nchallenging Waymo-Open dataset to evaluate the effectiveness of our method. Our\n$\\textit{S}^3$Gaussian demonstrates the ability to decompose static and dynamic\nscenes and achieves the best performance without using 3D annotations. Code is\navailable at: https://github.com/nnanhuang/S3Gaussian/.\n",
        "authors": "Nan Huang; Xiaobao Wei; Wenzhao Zheng; Pengju An; Ming Lu; Wei Zhan; Masayoshi Tomizuka; Kurt Keutzer; Shanghang Zhang",
        "status": 0,
        "relevancy": 0.3400316459670276,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19701",
        "date": "2024-05-30",
        "title": "Significance of Chain of Thought in Gender Bias Mitigation for\n  English-Dravidian Machine Translation",
        "abstract": "  Gender bias in machine translation (MT) systems poses a significant challenge\nto achieving accurate and inclusive translations. This paper examines gender\nbias in machine translation systems for languages such as Telugu and Kannada\nfrom the Dravidian family, analyzing how gender inflections affect translation\naccuracy and neutrality using Google Translate and ChatGPT. It finds that while\nplural forms can reduce bias, individual-centric sentences often maintain the\nbias due to historical stereotypes. The study evaluates the Chain of Thought\nprocessing, noting significant bias mitigation from 80% to 4% in Telugu and\nfrom 40% to 0% in Kannada. It also compares Telugu and Kannada translations,\nemphasizing the need for language specific strategies to address these\nchallenges and suggesting directions for future research to enhance fairness in\nboth data preparation and prompts during inference.\n",
        "authors": "Lavanya Prahallad; Radhika Mamidi",
        "status": 0,
        "relevancy": 0.33529172424073583,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20320",
        "date": "2024-05-30",
        "title": "Improving the Training of Rectified Flows",
        "abstract": "  Diffusion models have shown great promise for image and video generation, but\nsampling from state-of-the-art models requires expensive numerical integration\nof a generative ODE. One approach for tackling this problem is rectified flows,\nwhich iteratively learn smooth ODE paths that are less susceptible to\ntruncation error. However, rectified flows still require a relatively large\nnumber of function evaluations (NFEs). In this work, we propose improved\ntechniques for training rectified flows, allowing them to compete with\nknowledge distillation methods even in the low NFE setting. Our main insight is\nthat under realistic settings, a single iteration of the Reflow algorithm for\ntraining rectified flows is sufficient to learn nearly straight trajectories;\nhence, the current practice of using multiple Reflow iterations is unnecessary.\nWe thus propose techniques to improve one-round training of rectified flows,\nincluding a U-shaped timestep distribution and LPIPS-Huber premetric. With\nthese techniques, we improve the FID of the previous 2-rectified flow by up to\n72% in the 1 NFE setting on CIFAR-10. On ImageNet 64$\\times$64, our improved\nrectified flow outperforms the state-of-the-art distillation methods such as\nconsistency distillation and progressive distillation in both one-step and\ntwo-step settings and rivals the performance of improved consistency training\n(iCT) in FID. Code is available at https://github.com/sangyun884/rfpp.\n",
        "authors": "Sangyun Lee; Zinan Lin; Giulia Fanti",
        "status": 0,
        "relevancy": 0.3346698803247835,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19657",
        "date": "2024-05-30",
        "title": "Uncertainty-guided Optimal Transport in Depth Supervised Sparse-View 3D\n  Gaussian",
        "abstract": "  3D Gaussian splatting has demonstrated impressive performance in real-time\nnovel view synthesis. However, achieving successful reconstruction from RGB\nimages generally requires multiple input views captured under static\nconditions. To address the challenge of sparse input views, previous approaches\nhave incorporated depth supervision into the training of 3D Gaussians to\nmitigate overfitting, using dense predictions from pretrained depth networks as\npseudo-ground truth. Nevertheless, depth predictions from monocular depth\nestimation models inherently exhibit significant uncertainty in specific areas.\nRelying solely on pixel-wise L2 loss may inadvertently incorporate detrimental\nnoise from these uncertain areas. In this work, we introduce a novel method to\nsupervise the depth distribution of 3D Gaussians, utilizing depth priors with\nintegrated uncertainty estimates. To address these localized errors in depth\npredictions, we integrate a patch-wise optimal transport strategy to complement\ntraditional L2 loss in depth supervision. Extensive experiments conducted on\nthe LLFF, DTU, and Blender datasets demonstrate that our approach, UGOT,\nachieves superior novel view synthesis and consistently outperforms\nstate-of-the-art methods.\n",
        "authors": "Wei Sun; Qi Zhang; Yanzhao Zhou; Qixiang Ye; Jianbin Jiao; Yuan Li",
        "status": 0,
        "relevancy": 0.3276515152081394,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19650",
        "date": "2024-05-30",
        "title": "Few for Many: Tchebycheff Set Scalarization for Many-Objective\n  Optimization",
        "abstract": "  Multi-objective optimization can be found in many real-world applications\nwhere some conflicting objectives can not be optimized by a single solution.\nExisting optimization methods often focus on finding a set of Pareto solutions\nwith different optimal trade-offs among the objectives. However, the required\nnumber of solutions to well approximate the whole Pareto optimal set could be\nexponentially large with respect to the number of objectives, which makes these\nmethods unsuitable for handling many optimization objectives. In this work,\ninstead of finding a dense set of Pareto solutions, we propose a novel\nTchebycheff set scalarization method to find a few representative solutions\n(e.g., 5) to cover a large number of objectives (e.g., $>100$) in a\ncollaborative and complementary manner. In this way, each objective can be well\naddressed by at least one solution in the small solution set. In addition, we\nfurther develop a smooth Tchebycheff set scalarization approach for efficient\noptimization with good theoretical guarantees. Experimental studies on\ndifferent problems with many optimization objectives demonstrate the\neffectiveness of our proposed method.\n",
        "authors": "Xi Lin; Yilu Liu; Xiaoyuan Zhang; Fei Liu; Zhenkun Wang; Qingfu Zhang",
        "status": 0,
        "relevancy": 0.32411345654089296,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20024",
        "date": "2024-05-30",
        "title": "Applications of Generative AI (GAI) for Mobile and Wireless Networking:\n  A Survey",
        "abstract": "  The success of Artificial Intelligence (AI) in multiple disciplines and\nvertical domains in recent years has promoted the evolution of mobile\nnetworking and the future Internet toward an AI-integrated Internet-of-Things\n(IoT) era. Nevertheless, most AI techniques rely on data generated by physical\ndevices (e.g., mobile devices and network nodes) or specific applications\n(e.g., fitness trackers and mobile gaming). To bypass this circumvent,\nGenerative AI (GAI), a.k.a. AI-generated content (AIGC), has emerged as a\npowerful AI paradigm; thanks to its ability to efficiently learn complex data\ndistributions and generate synthetic data to represent the original data in\nvarious forms. This impressive feature is projected to transform the management\nof mobile networking and diversify the current services and applications\nprovided. On this basis, this work presents a concise tutorial on the role of\nGAIs in mobile and wireless networking. In particular, this survey first\nprovides the fundamentals of GAI and representative GAI models, serving as an\nessential preliminary to the understanding of the applications of GAI in mobile\nand wireless networking. Then, this work provides a comprehensive review of\nstate-of-the-art studies and GAI applications in network management, wireless\nsecurity, semantic communication, and lessons learned from the open literature.\nFinally, this work summarizes the current research on GAI for mobile and\nwireless networking by outlining important challenges that need to be resolved\nto facilitate the development and applicability of GAI in this edge-cutting\narea.\n",
        "authors": "Thai-Hoc Vu; Senthil Kumar Jagatheesaperumal; Minh-Duong Nguyen; Nguyen Van Huynh; Sunghwan Kim; Quoc-Viet Pham",
        "status": 0,
        "relevancy": 0.3177001823446892,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19730",
        "date": "2024-05-30",
        "title": "Research on Foundation Model for Spatial Data Intelligence: China's 2024\n  White Paper on Strategic Development of Spatial Data Intelligence",
        "abstract": "  This report focuses on spatial data intelligent large models, delving into\nthe principles, methods, and cutting-edge applications of these models. It\nprovides an in-depth discussion on the definition, development history, current\nstatus, and trends of spatial data intelligent large models, as well as the\nchallenges they face. The report systematically elucidates the key technologies\nof spatial data intelligent large models and their applications in urban\nenvironments, aerospace remote sensing, geography, transportation, and other\nscenarios. Additionally, it summarizes the latest application cases of spatial\ndata intelligent large models in themes such as urban development, multimodal\nsystems, remote sensing, smart transportation, and resource environments.\nFinally, the report concludes with an overview and outlook on the development\nprospects of spatial data intelligent large models.\n",
        "authors": "Shaohua Wang; Xing Xie; Yong Li; Danhuai Guo; Zhi Cai; Yu Liu; Yang Yue; Xiao Pan; Feng Lu; Huayi Wu; Zhipeng Gui; Zhiming Ding; Bolong Zheng; Fuzheng Zhang; Tao Qin; Jingyuan Wang; Chuang Tao; Zhengchao Chen; Hao Lu; Jiayi Li; Hongyang Chen; Peng Yue; Wenhao Yu; Yao Yao; Leilei Sun; Yong Zhang; Longbiao Chen; Xiaoping Du; Xiang Li; Xueying Zhang; Kun Qin; Zhaoya Gong; Weihua Dong; Xiaofeng Meng",
        "status": 0,
        "relevancy": 0.3171888362381221,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19957",
        "date": "2024-05-30",
        "title": "PLA4D: Pixel-Level Alignments for Text-to-4D Gaussian Splatting",
        "abstract": "  As text-conditioned diffusion models (DMs) achieve breakthroughs in image,\nvideo, and 3D generation, the research community's focus has shifted to the\nmore challenging task of text-to-4D synthesis, which introduces a temporal\ndimension to generate dynamic 3D objects. In this context, we identify Score\nDistillation Sampling (SDS), a widely used technique for text-to-3D synthesis,\nas a significant hindrance to text-to-4D performance due to its Janus-faced and\ntexture-unrealistic problems coupled with high computational costs. In this\npaper, we propose \\textbf{P}ixel-\\textbf{L}evel \\textbf{A}lignments for\nText-to-\\textbf{4D} Gaussian Splatting (\\textbf{PLA4D}), a novel method that\nutilizes text-to-video frames as explicit pixel alignment targets to generate\nstatic 3D objects and inject motion into them. Specifically, we introduce Focal\nAlignment to calibrate camera poses for rendering and GS-Mesh Contrastive\nLearning to distill geometry priors from rendered image contrasts at the pixel\nlevel. Additionally, we develop Motion Alignment using a deformation network to\ndrive changes in Gaussians and implement Reference Refinement for smooth 4D\nobject surfaces. These techniques enable 4D Gaussian Splatting to align\ngeometry, texture, and motion with generated videos at the pixel level.\nCompared to previous methods, PLA4D produces synthesized outputs with better\ntexture details in less time and effectively mitigates the Janus-faced problem.\nPLA4D is fully implemented using open-source models, offering an accessible,\nuser-friendly, and promising direction for 4D digital content creation. Our\nproject page:\n\\href{https://github.com/MiaoQiaowei/PLA4D.github.io}{https://github.com/MiaoQiaowei/PLA4D.github.io}.\n",
        "authors": "Qiaowei Miao; Yawei Luo; Yi Yang",
        "status": 0,
        "relevancy": 0.31119368259059876,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19970",
        "date": "2024-05-30",
        "title": "Strategies to Counter Artificial Intelligence in Law Enforcement:\n  Cross-Country Comparison of Citizens in Greece, Italy and Spain",
        "abstract": "  This paper investigates citizens' counter-strategies to the use of Artificial\nIntelligence (AI) by law enforcement agencies (LEAs). Based on information from\nthree countries (Greece, Italy and Spain) we demonstrate disparities in the\nlikelihood of ten specific counter-strategies. We further identified factors\nthat increase the propensity for counter-strategies. Our study provides an\nimportant new perspective to societal impacts of security-focused AI\napplications by illustrating the conscious, strategic choices by citizens when\nconfronted with AI capabilities for LEAs.\n",
        "authors": "Petra Saskia Bayerl; Babak Akhgar; Ernesto La Mattina; Barbara Pirillo; Ioana Cotoi; Davide Ariu; Matteo Mauri; Jorge Garcia; Dimitris Kavallieros; Antonia Kardara; Konstantina Karagiorgou",
        "status": 0,
        "relevancy": 0.3100039863386229,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20121",
        "date": "2024-05-30",
        "title": "A Structure-Aware Lane Graph Transformer Model for Vehicle Trajectory\n  Prediction",
        "abstract": "  Accurate prediction of future trajectories for surrounding vehicles is vital\nfor the safe operation of autonomous vehicles. This study proposes a Lane Graph\nTransformer (LGT) model with structure-aware capabilities. Its key contribution\nlies in encoding the map topology structure into the attention mechanism. To\naddress variations in lane information from different directions, four Relative\nPositional Encoding (RPE) matrices are introduced to capture the local details\nof the map topology structure. Additionally, two Shortest Path Distance (SPD)\nmatrices are employed to capture distance information between two accessible\nlanes. Numerical results indicate that the proposed LGT model achieves a\nsignificantly higher prediction performance on the Argoverse 2 dataset.\nSpecifically, the minFDE$_6$ metric was decreased by 60.73% compared to the\nArgoverse 2 baseline model (Nearest Neighbor) and the b-minFDE$_6$ metric was\nreduced by 2.65% compared to the baseline LaneGCN model. Furthermore, ablation\nexperiments demonstrated that the consideration of map topology structure led\nto a 4.24% drop in the b-minFDE$_6$ metric, validating the effectiveness of\nthis model.\n",
        "authors": "Sun Zhanbo; Dong Caiyin; Ji Ang; Zhao Ruibin; Zhao Yu",
        "status": 0,
        "relevancy": 0.3070301747801837,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19644",
        "date": "2024-05-30",
        "title": "EgoSurgery-Phase: A Dataset of Surgical Phase Recognition from\n  Egocentric Open Surgery Videos",
        "abstract": "  Surgical phase recognition has gained significant attention due to its\npotential to offer solutions to numerous demands of the modern operating room.\nHowever, most existing methods concentrate on minimally invasive surgery (MIS),\nleaving surgical phase recognition for open surgery understudied. This\ndiscrepancy is primarily attributed to the scarcity of publicly available open\nsurgery video datasets for surgical phase recognition. To address this issue,\nwe introduce a new egocentric open surgery video dataset for phase recognition,\nnamed EgoSurgery-Phase. This dataset comprises 15 hours of real open surgery\nvideos spanning 9 distinct surgical phases all captured using an egocentric\ncamera attached to the surgeon's head. In addition to video, the\nEgoSurgery-Phase offers eye gaze. As far as we know, it is the first real open\nsurgery video dataset for surgical phase recognition publicly available.\nFurthermore, inspired by the notable success of masked autoencoders (MAEs) in\nvideo understanding tasks (e.g., action recognition), we propose a gaze-guided\nmasked autoencoder (GGMAE). Considering the regions where surgeons' gaze\nfocuses are often critical for surgical phase recognition (e.g., surgical\nfield), in our GGMAE, the gaze information acts as an empirical semantic\nrichness prior to guiding the masking process, promoting better attention to\nsemantically rich spatial regions. GGMAE significantly improves the previous\nstate-of-the-art recognition method (6.4% in Jaccard) and the masked\nautoencoder-based method (3.1% in Jaccard) on EgoSurgery-Phase. The dataset\nwill be released at https://github.com/Fujiry0/EgoSurgery.\n",
        "authors": "Ryo Fujii; Masashi Hatano; Hideo Saito; Hiroki Kajita",
        "status": 0,
        "relevancy": 0.29810934871568195,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20278",
        "date": "2024-05-30",
        "title": "Length independent generalization bounds for deep SSM architectures with\n  stability constraints",
        "abstract": "  Many state-of-the-art models trained on long-range sequences, for example S4,\nS5 or LRU, are made of sequential blocks combining State-Space Models (SSMs)\nwith neural networks. In this paper we provide a PAC bound that holds for these\nkind of architectures with stable SSM blocks and does not depend on the length\nof the input sequence. Imposing stability of the SSM blocks is a standard\npractice in the literature, and it is known to help performance. Our results\nprovide a theoretical justification for the use of stable SSM blocks as the\nproposed PAC bound decreases as the degree of stability of the SSM blocks\nincreases.\n",
        "authors": "Dániel Rácz; Mihály Petreczky; Bálint Daróczy",
        "status": 0,
        "relevancy": 0.28922355853302295,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20142",
        "date": "2024-05-30",
        "title": "MSSC-BiMamba: Multimodal Sleep Stage Classification and Early Diagnosis\n  of Sleep Disorders with Bidirectional Mamba",
        "abstract": "  Background and Objectives: Monitoring sleep states is crucial for assessing\nsleep quality and diagnosing sleep disorders. Traditional manual staging\nmethods are not only time-consuming but also subject to subjective judgment,\nleading to inconsistent results. This study developed an automated sleep\nstaging and sleep disorder classification model through deep learning\ntechnology, aimed at improving diagnostic accuracy and efficiency.\n  Methods: Considering the characteristics of polysomnography (PSG) multi-lead\nsleep monitoring, we designed a sleep state classification model, MSSC-BiMamba,\nthat combines an Efficient Channel Attention (ECA) mechanism with a\nBidirectional State Space Model (BSSM). The ECA module allows for weighting\ndata from different sensor channels, thereby amplifying the influence of\ndiverse sensor inputs. Additionally, the implementation of mamba enables the\nmodel to effectively capture the multidimensional features and long-range\ndependencies of PSG data.\n  Results: The developed model demonstrated impressive performance on sleep\nstage classification tasks. Furthermore, the model exhibited an accuracy of\n0.952 for sleep health prediction when evaluated on a combined dataset\nconsisting of ISRUC and Sleep-EDF.\n  Conclusion: Our model is the first to apply the bidirectional Mamba to sleep\nstaging with complex PSG data, showing substantial gains in computational and\nmemory efficiency over traditional Transformer-style models. This method not\nonly makes health monitoring more accessible but also broadens the reach of\nadvanced healthcare, thereby enhancing sleep health management with innovative\ntechnology.\n",
        "authors": "Chao Zhanga; Weirong Cuia; Jingjing Guo",
        "status": 0,
        "relevancy": 0.27258357389492793,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19915",
        "date": "2024-05-30",
        "title": "P$^2$-ViT: Power-of-Two Post-Training Quantization and Acceleration for\n  Fully Quantized Vision Transformer",
        "abstract": "  Vision Transformers (ViTs) have excelled in computer vision tasks but are\nmemory-consuming and computation-intensive, challenging their deployment on\nresource-constrained devices. To tackle this limitation, prior works have\nexplored ViT-tailored quantization algorithms but retained floating-point\nscaling factors, which yield non-negligible re-quantization overhead, limiting\nViTs' hardware efficiency and motivating more hardware-friendly solutions. To\nthis end, we propose \\emph{P$^2$-ViT}, the first \\underline{P}ower-of-Two (PoT)\n\\underline{p}ost-training quantization and acceleration framework to accelerate\nfully quantized ViTs. Specifically, {as for quantization,} we explore a\ndedicated quantization scheme to effectively quantize ViTs with PoT scaling\nfactors, thus minimizing the re-quantization overhead. Furthermore, we propose\ncoarse-to-fine automatic mixed-precision quantization to enable better\naccuracy-efficiency trade-offs. {In terms of hardware,} we develop {a dedicated\nchunk-based accelerator} featuring multiple tailored sub-processors to\nindividually handle ViTs' different types of operations, alleviating\nreconfigurable overhead. Additionally, we design {a tailored row-stationary\ndataflow} to seize the pipeline processing opportunity introduced by our PoT\nscaling factors, thereby enhancing throughput. Extensive experiments\nconsistently validate P$^2$-ViT's effectiveness. {Particularly, we offer\ncomparable or even superior quantization performance with PoT scaling factors\nwhen compared to the counterpart with floating-point scaling factors. Besides,\nwe achieve up to $\\mathbf{10.1\\times}$ speedup and $\\mathbf{36.8\\times}$ energy\nsaving over GPU's Turing Tensor Cores, and up to $\\mathbf{1.84\\times}$ higher\ncomputation utilization efficiency against SOTA quantization-based ViT\naccelerators. Codes are available at\n\\url{https://github.com/shihuihong214/P2-ViT}.\n",
        "authors": "Huihong Shi; Xin Cheng; Wendong Mao; Zhongfeng Wang",
        "status": 0,
        "relevancy": 0.27078654329183693,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20138",
        "date": "2024-05-30",
        "title": "Separation and Collapse of Equilibria Inequalities on AND-OR Trees\n  without Shape Constraints",
        "abstract": "  Herein, we investigate the randomized complexity, which is the least cost\nagainst the worst input, of AND-OR tree computation by imposing various\nrestrictions on the algorithm to find the Boolean value of the root of that\ntree and no restrictions on the tree shape. When a tree satisfies a certain\ncondition regarding its symmetry, directional algorithms proposed by Saks and\nWigderson (1986), special randomized algorithms, are known to achieve the\nrandomized complexity. Furthermore, there is a known example of a tree that is\nso unbalanced that no directional algorithm achieves the randomized complexity\n(Vereshchagin 1998). In this study, we aim to identify where deviations arise\nbetween the general randomized Boolean decision tree and its special case,\ndirectional algorithms. In this paper, we show that for any AND-OR tree,\nrandomized depth-first algorithms, which form a broader class compared with\ndirectional algorithms, have the same equilibrium as that of the directional\nalgorithms. Thus, we get the collapse result on equilibria inequalities that\nholds for an arbitrary AND-OR tree. This implies that there exists a case where\neven depth-first algorithms cannot be the fastest, leading to the separation\nresult on equilibria inequality. Additionally, a new algorithm is introduced as\na key concept for proof of the separation result.\n",
        "authors": "Fuki Ito; Toshio Suzuki",
        "status": 0,
        "relevancy": 0.2657009635498164,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20237",
        "date": "2024-05-30",
        "title": "Training-efficient density quantum machine learning",
        "abstract": "  Quantum machine learning requires powerful, flexible and efficiently\ntrainable models to be successful in solving challenging problems. In this\nwork, we present density quantum neural networks, a learning model\nincorporating randomisation over a set of trainable unitaries. These models\ngeneralise quantum neural networks using parameterised quantum circuits, and\nallow a trade-off between expressibility and efficient trainability,\nparticularly on quantum hardware. We demonstrate the flexibility of the\nformalism by applying it to two recently proposed model families. The first are\ncommuting-block quantum neural networks (QNNs) which are efficiently trainable\nbut may be limited in expressibility. The second are orthogonal (Hamming-weight\npreserving) quantum neural networks which provide well-defined and\ninterpretable transformations on data but are challenging to train at scale on\nquantum devices. Density commuting QNNs improve capacity with minimal gradient\ncomplexity overhead, and density orthogonal neural networks admit a\nquadratic-to-constant gradient query advantage with minimal to no performance\nloss. We conduct numerical experiments on synthetic translationally invariant\ndata and MNIST image data with hyperparameter optimisation to support our\nfindings. Finally, we discuss the connection to post-variational quantum neural\nnetworks, measurement-based quantum machine learning and the dropout mechanism.\n",
        "authors": "Brian Coyle; El Amine Cherrat; Nishant Jain; Natansh Mathur; Snehal Raj; Skander Kazdaghli; Iordanis Kerenidis",
        "status": 0,
        "relevancy": 0.2616809235221397,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19823",
        "date": "2024-05-30",
        "title": "Joint Selective State Space Model and Detrending for Robust Time Series\n  Anomaly Detection",
        "abstract": "  Deep learning-based sequence models are extensively employed in Time Series\nAnomaly Detection (TSAD) tasks due to their effective sequential modeling\ncapabilities. However, the ability of TSAD is limited by two key challenges:\n(i) the ability to model long-range dependency and (ii) the generalization\nissue in the presence of non-stationary data. To tackle these challenges, an\nanomaly detector that leverages the selective state space model known for its\nproficiency in capturing long-term dependencies across various domains is\nproposed. Additionally, a multi-stage detrending mechanism is introduced to\nmitigate the prominent trend component in non-stationary data to address the\ngeneralization issue. Extensive experiments conducted on realworld public\ndatasets demonstrate that the proposed methods surpass all 12 compared baseline\nmethods.\n",
        "authors": "Junqi Chen; Xu Tan; Sylwan Rahardja; Jiawei Yang; Susanto Rahardja",
        "status": 0,
        "relevancy": 0.24535769062368173,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19864",
        "date": "2024-05-30",
        "title": "Out-of-distribution Reject Option Method for Dataset Shift Problem in\n  Early Disease Onset Prediction",
        "abstract": "  Machine learning is increasingly used to predict lifestyle-related disease\nonset using health and medical data. However, the prediction effectiveness is\nhindered by dataset shift, which involves discrepancies in data distribution\nbetween the training and testing datasets, misclassifying out-of-distribution\n(OOD) data. To diminish dataset shift effects, this paper proposes the\nout-of-distribution reject option for prediction (ODROP), which integrates OOD\ndetection models to preclude OOD data from the prediction phase. We\ninvestigated the efficacy of five OOD detection methods (variational\nautoencoder, neural network ensemble std, neural network ensemble epistemic,\nneural network energy, and neural network gaussian mixture based energy\nmeasurement) across two datasets, the Hirosaki and Wakayama health checkup\ndata, in the context of three disease onset prediction tasks: diabetes,\ndyslipidemia, and hypertension. To evaluate the ODROP method, we trained\ndisease onset prediction models and OOD detection models on Hirosaki data and\nused AUROC-rejection curve plots from Wakayama data. The variational\nautoencoder method showed superior stability and magnitude of improvement in\nArea Under the Receiver Operating Curve (AUROC) in five cases: AUROC in the\nWakayama data was improved from 0.80 to 0.90 at a 31.1% rejection rate for\ndiabetes onset and from 0.70 to 0.76 at a 34% rejection rate for dyslipidemia.\nWe categorized dataset shifts into two types using SHAP clustering - those that\nconsiderably affect predictions and those that do not. We expect that this\nclassification will help standardize measuring instruments. This study is the\nfirst to apply OOD detection to actual health and medical data, demonstrating\nits potential to substantially improve the accuracy and reliability of disease\nprediction models amidst dataset shift.\n",
        "authors": "Taisei Tosaki; Eiichiro Uchino; Ryosuke Kojima; Yohei Mineharu; Mikio Arita; Nobuyuki Miyai; Yoshinori Tamada; Tatsuya Mikami; Koichi Murashita; Shigeyuki Nakaji; Yasushi Okuno",
        "status": 0,
        "relevancy": 0.23121717909191675,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.19751",
        "date": "2024-05-30",
        "title": "HQ-DiT: Efficient Diffusion Transformer with FP4 Hybrid Quantization",
        "abstract": "  Diffusion Transformers (DiTs) have recently gained substantial attention in\nboth industrial and academic fields for their superior visual generation\ncapabilities, outperforming traditional diffusion models that use U-Net.\nHowever,the enhanced performance of DiTs also comes with high parameter counts\nand implementation costs, seriously restricting their use on resource-limited\ndevices such as mobile phones. To address these challenges, we introduce the\nHybrid Floating-point Quantization for DiT(HQ-DiT), an efficient post-training\nquantization method that utilizes 4-bit floating-point (FP) precision on both\nweights and activations for DiT inference. Compared to fixed-point quantization\n(e.g., INT8), FP quantization, complemented by our proposed clipping range\nselection mechanism, naturally aligns with the data distribution within DiT,\nresulting in a minimal quantization error. Furthermore, HQ-DiT also implements\na universal identity mathematical transform to mitigate the serious\nquantization error caused by the outliers. The experimental results demonstrate\nthat DiT can achieve extremely low-precision quantization (i.e., 4 bits) with\nnegligible impact on performance. Our approach marks the first instance where\nboth weights and activations in DiTs are quantized to just 4 bits, with only a\n0.12 increase in sFID on ImageNet.\n",
        "authors": "Wenxuan Liu; Saiqian Zhang",
        "status": 0,
        "relevancy": 0.21837478821610912,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20059",
        "date": "2024-05-30",
        "title": "Spectral Mapping of Singing Voices: U-Net-Assisted Vocal Segmentation",
        "abstract": "  Separating vocal elements from musical tracks is a longstanding challenge in\naudio signal processing. This study tackles the distinct separation of vocal\ncomponents from musical spectrograms. We employ the Short Time Fourier\nTransform (STFT) to extract audio waves into detailed frequency-time\nspectrograms, utilizing the benchmark MUSDB18 dataset for music separation.\nSubsequently, we implement a UNet neural network to segment the spectrogram\nimage, aiming to delineate and extract singing voice components accurately. We\nachieved noteworthy results in audio source separation using of our U-Net-based\nmodels. The combination of frequency-axis normalization with Min/Max scaling\nand the Mean Absolute Error (MAE) loss function achieved the highest\nSource-to-Distortion Ratio (SDR) of 7.1 dB, indicating a high level of accuracy\nin preserving the quality of the original signal during separation. This setup\nalso recorded impressive Source-to-Interference Ratio (SIR) and\nSource-to-Artifact Ratio (SAR) scores of 25.2 dB and 7.2 dB, respectively.\nThese values significantly outperformed other configurations, particularly\nthose using Quantile-based normalization or a Mean Squared Error (MSE) loss\nfunction. Our source code, model weights, and demo material can be found at the\nproject's GitHub repository: https://github.com/mbrotos/SoundSeg\n",
        "authors": "Adam Sorrenti",
        "status": 0,
        "relevancy": 0.2073597021974346,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      },
      {
        "id": "2405.20032",
        "date": "2024-05-30",
        "title": "Promptus: Can Prompts Streaming Replace Video Streaming with Stable\n  Diffusion",
        "abstract": "  With the exponential growth of video traffic, traditional video streaming\nsystems are approaching their limits in compression efficiency and\ncommunication capacity. To further reduce bitrate while maintaining quality, we\npropose Promptus, a disruptive novel system that streaming prompts instead of\nvideo content with Stable Diffusion, which converts video frames into a series\nof \"prompts\" for delivery. To ensure pixel alignment, a gradient descent-based\nprompt fitting framework is proposed. To achieve adaptive bitrate for prompts,\na low-rank decomposition-based bitrate control algorithm is introduced. For\ninter-frame compression of prompts, a temporal smoothing-based prompt\ninterpolation algorithm is proposed. Evaluations across various video domains\nand real network traces demonstrate Promptus can enhance the perceptual quality\nby 0.111 and 0.092 (in LPIPS) compared to VAE and H.265, respectively, and\ndecreases the ratio of severely distorted frames by 89.3% and 91.7%. Moreover,\nPromptus achieves real-time video generation from prompts at over 150 FPS. To\nthe best of our knowledge, Promptus is the first attempt to replace video\ncodecs with prompt inversion and the first to use prompt streaming instead of\nvideo streaming. Our work opens up a new paradigm for efficient video\ncommunication beyond the Shannon limit.\n",
        "authors": "Jiangkai Wu; Liming Liu; Yunpeng Tan; Junlin Hao; Xinggong Zhang",
        "status": 0,
        "relevancy": 0.1889204359426131,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:58:28.951Z",
        "updatedAt": "2024-05-31T04:58:28.951Z",
        "DatesTable": {
          "value": "2024-05-30",
          "status": "complete",
          "count": 118,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:58:28.953Z"
        }
      }
    ]
  },
  {
    "date": {
      "value": "2024-05-29",
      "status": "complete",
      "count": 133,
      "createdAt": "2024-05-31 00:09:48.114 +00:00",
      "updatedAt": "2024-05-31 05:21:04.775 +00:00"
    },
    "papers": [
      {
        "id": "2405.18711",
        "date": "2024-05-29",
        "title": "Calibrating Reasoning in Language Models with Internal Consistency",
        "abstract": "  Large language models (LLMs) have demonstrated impressive capabilities in\nvarious reasoning tasks, aided by techniques like chain-of-thought (CoT)\nprompting that elicits verbalized reasoning. However, LLMs often generate text\nwith obvious mistakes and contradictions, raising doubts about their ability to\nrobustly process and utilize generated rationales. In this work, we investigate\nCoT reasoning in LLMs through the lens of internal representations, focusing on\nhow these representations are influenced by generated rationales. Our\npreliminary analysis reveals that while generated rationales improve answer\naccuracy, inconsistencies emerge between the model's internal representations\nin middle layers and those in final layers, potentially undermining the\nreliability of their reasoning processes. To address this, we propose internal\nconsistency as a measure of the model's confidence by examining the agreement\nof latent predictions decoded from intermediate layers. Extensive empirical\nstudies across different models and datasets demonstrate that internal\nconsistency effectively distinguishes between correct and incorrect reasoning\npaths. Motivated by this, we propose a new approach to calibrate CoT reasoning\nby up-weighting reasoning paths with high internal consistency, resulting in a\nsignificant boost in reasoning performance. Further analysis uncovers distinct\npatterns in attention and feed-forward modules across layers, providing\ninsights into the emergence of internal inconsistency. In summary, our results\ndemonstrate the potential of using internal representations for self-evaluation\nof LLMs.\n",
        "authors": "Zhihui Xie; Jizhou Guo; Tong Yu; Shuai Li",
        "status": 0,
        "relevancy": 0.623071608712894,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19332",
        "date": "2024-05-29",
        "title": "Self-Exploring Language Models: Active Preference Elicitation for Online\n  Alignment",
        "abstract": "  Preference optimization, particularly through Reinforcement Learning from\nHuman Feedback (RLHF), has achieved significant success in aligning Large\nLanguage Models (LLMs) to adhere to human intentions. Unlike offline alignment\nwith a fixed dataset, online feedback collection from humans or AI on model\ngenerations typically leads to more capable reward models and better-aligned\nLLMs through an iterative process. However, achieving a globally accurate\nreward model requires systematic exploration to generate diverse responses that\nspan the vast space of natural language. Random sampling from standard\nreward-maximizing LLMs alone is insufficient to fulfill this requirement. To\naddress this issue, we propose a bilevel objective optimistically biased\ntowards potentially high-reward responses to actively explore\nout-of-distribution regions. By solving the inner-level problem with the\nreparameterized reward function, the resulting algorithm, named Self-Exploring\nLanguage Models (SELM), eliminates the need for a separate RM and iteratively\nupdates the LLM with a straightforward objective. Compared to Direct Preference\nOptimization (DPO), the SELM objective reduces indiscriminate favor of unseen\nextrapolations and enhances exploration efficiency. Our experimental results\ndemonstrate that when finetuned on Zephyr-7B-SFT and Llama-3-8B-Instruct\nmodels, SELM significantly boosts the performance on instruction-following\nbenchmarks such as MT-Bench and AlpacaEval 2.0, as well as various standard\nacademic benchmarks in different settings. Our code and models are available at\nhttps://github.com/shenao-zhang/SELM.\n",
        "authors": "Shenao Zhang; Donghan Yu; Hiteshi Sharma; Ziyi Yang; Shuohang Wang; Hany Hassan; Zhaoran Wang",
        "status": 0,
        "relevancy": 0.6221507463363094,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18733",
        "date": "2024-05-29",
        "title": "Efficient Learning in Chinese Checkers: Comparing Parameter Sharing in\n  Multi-Agent Reinforcement Learning",
        "abstract": "  We show that multi-agent reinforcement learning (MARL) with full parameter\nsharing outperforms independent and partially shared architectures in the\ncompetitive perfect-information homogenous game of Chinese Checkers. To run our\nexperiments, we develop a new MARL environment: variable-size, six-player\nChinese Checkers. This custom environment was developed in PettingZoo and\nsupports all traditional rules of the game including chaining jumps. This is,\nto the best of our knowledge, the first implementation of Chinese Checkers that\nremains faithful to the true game.\n  Chinese Checkers is difficult to learn due to its large branching factor and\npotentially infinite horizons. We borrow the concept of branching actions\n(submoves) from complex action spaces in other RL domains, where a submove may\nnot end a player's turn immediately. This drastically reduces the\ndimensionality of the action space. Our observation space is inspired by\nAlphaGo with many binary game boards stacked in a 3D array to encode\ninformation.\n  The PettingZoo environment, training and evaluation logic, and analysis\nscripts can be found on\n\\href{https://github.com/noahadhikari/pettingzoo-chinese-checkers}{Github}.\n",
        "authors": "Noah Adhikari; Allen Gu",
        "status": 0,
        "relevancy": 0.6140474602633165,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19444",
        "date": "2024-05-29",
        "title": "MathChat: Benchmarking Mathematical Reasoning and Instruction Following\n  in Multi-Turn Interactions",
        "abstract": "  Large language models (LLMs) have demonstrated impressive capabilities in\nmathematical problem solving, particularly in single turn question answering\nformats. However, real world scenarios often involve mathematical question\nanswering that requires multi turn or interactive information exchanges, and\nthe performance of LLMs on these tasks is still underexplored. This paper\nintroduces MathChat, a comprehensive benchmark specifically designed to\nevaluate LLMs across a broader spectrum of mathematical tasks. These tasks are\nstructured to assess the models' abilities in multiturn interactions and open\nended generation. We evaluate the performance of various SOTA LLMs on the\nMathChat benchmark, and we observe that while these models excel in single turn\nquestion answering, they significantly underperform in more complex scenarios\nthat require sustained reasoning and dialogue understanding. To address the\nabove limitations of existing LLMs when faced with multiturn and open ended\ntasks, we develop MathChat sync, a synthetic dialogue based math dataset for\nLLM finetuning, focusing on improving models' interaction and instruction\nfollowing capabilities in conversations. Experimental results emphasize the\nneed for training LLMs with diverse, conversational instruction tuning datasets\nlike MathChatsync. We believe this work outlines one promising direction for\nimproving the multiturn mathematical reasoning abilities of LLMs, thus pushing\nforward the development of LLMs that are more adept at interactive mathematical\nproblem solving and real world applications.\n",
        "authors": "Zhenwen Liang; Dian Yu; Wenhao Yu; Wenlin Yao; Zhihan Zhang; Xiangliang Zhang; Dong Yu",
        "status": 0,
        "relevancy": 0.610756709252437,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18682",
        "date": "2024-05-29",
        "title": "Can GPT Redefine Medical Understanding? Evaluating GPT on Biomedical\n  Machine Reading Comprehension",
        "abstract": "  Large language models (LLMs) have shown remarkable performance on many tasks\nin different domains. However, their performance in closed-book biomedical\nmachine reading comprehension (MRC) has not been evaluated in depth. In this\nwork, we evaluate GPT on four closed-book biomedical MRC benchmarks. We\nexperiment with different conventional prompting techniques as well as\nintroduce our own novel prompting method. To solve some of the retrieval\nproblems inherent to LLMs, we propose a prompting strategy named Implicit\nRetrieval Augmented Generation (RAG) that alleviates the need for using vector\ndatabases to retrieve important chunks in traditional RAG setups. Moreover, we\nreport qualitative assessments on the natural language generation outputs from\nour approach. The results show that our new prompting technique is able to get\nthe best performance in two out of four datasets and ranks second in rest of\nthem. Experiments show that modern-day LLMs like GPT even in a zero-shot\nsetting can outperform supervised models, leading to new state-of-the-art\n(SoTA) results on two of the benchmarks.\n",
        "authors": "Shubham Vatsal; Ayush Singh",
        "status": 0,
        "relevancy": 0.5998147217848517,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19262",
        "date": "2024-05-29",
        "title": "Weak-to-Strong Search: Align Large Language Models via Searching over\n  Small Language Models",
        "abstract": "  Large language models are usually fine-tuned to align with human preferences.\nHowever, fine-tuning a large language model can be challenging. In this work,\nwe introduce $\\textit{weak-to-strong search}$, framing the alignment of a large\nlanguage model as a test-time greedy search to maximize the log-likelihood\ndifference between small tuned and untuned models while sampling from the\nfrozen large model. This method serves both as (i) a compute-efficient model\nup-scaling strategy that avoids directly tuning the large model and as (ii) an\ninstance of weak-to-strong generalization that enhances a strong model with\nweak test-time guidance. Empirically, we demonstrate the flexibility of\nweak-to-strong search across different tasks. In controlled-sentiment\ngeneration and summarization, we use tuned and untuned $\\texttt{gpt2}$s to\neffectively improve the alignment of large models without additional training.\nCrucially, in a more difficult instruction-following benchmark, AlpacaEval 2.0,\nwe show that reusing off-the-shelf small model pairs (e.g.,\n$\\texttt{zephyr-7b-beta}$ and its untuned version) can significantly improve\nthe length-controlled win rates of both white-box and black-box large models\nagainst $\\texttt{gpt-4-turbo}$ (e.g., $34.4 \\rightarrow 37.9$ for\n$\\texttt{Llama-3-70B-Instruct}$ and $16.0 \\rightarrow 20.1$ for\n$\\texttt{gpt-3.5-turbo-instruct}$), despite the small models' low win rates\n$\\approx 10.0$.\n",
        "authors": "Zhanhui Zhou; Zhixuan Liu; Jie Liu; Zhichen Dong; Chao Yang; Yu Qiao",
        "status": 0,
        "relevancy": 0.5852520404317045,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18727",
        "date": "2024-05-29",
        "title": "CtrlA: Adaptive Retrieval-Augmented Generation via Probe-Guided Control",
        "abstract": "  Retrieval-augmented generation (RAG) has emerged as a promising solution for\nmitigating hallucinations of large language models (LLMs) with retrieved\nexternal knowledge. Adaptive RAG enhances this approach by dynamically\nassessing the retrieval necessity, aiming to balance external and internal\nknowledge usage. However, existing adaptive RAG methods primarily realize\nretrieval on demand by relying on superficially verbalize-based or\nprobability-based feedback of LLMs, or directly fine-tuning LLMs via carefully\ncrafted datasets, resulting in unreliable retrieval necessity decisions, heavy\nextra costs, and sub-optimal response generation. We present the first attempts\nto delve into the internal states of LLMs to mitigate such issues by\nintroducing an effective probe-guided adaptive RAG framework, termed CtrlA.\nSpecifically, CtrlA employs an honesty probe to regulate the LLM's behavior by\nmanipulating its representations for increased honesty, and a confidence probe\nto monitor the internal states of LLM and assess confidence levels, determining\nthe retrieval necessity during generation. Experiments show that CtrlA is\nsuperior to existing adaptive RAG methods on a diverse set of tasks, the\nhonesty control can effectively make LLMs more honest and confidence monitoring\nis proven to be a promising indicator of retrieval trigger. Our codes are\navailable at https://github.com/HSLiu-Initial/CtrlA.git.\n",
        "authors": "Huanshuo Liu; Hao Zhang; Zhijiang Guo; Kuicai Dong; Xiangyang Li; Yi Quan Lee; Cong Zhang; Yong Liu",
        "status": 0,
        "relevancy": 0.5702015226569191,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19094",
        "date": "2024-05-29",
        "title": "Faithful Chart Summarization with ChaTS-Pi",
        "abstract": "  Chart-to-summary generation can help explore data, communicate insights, and\nhelp the visually impaired people. Multi-modal generative models have been used\nto produce fluent summaries, but they can suffer from factual and perceptual\nerrors. In this work we present CHATS-CRITIC, a reference-free chart\nsummarization metric for scoring faithfulness. CHATS-CRITIC is composed of an\nimage-to-text model to recover the table from a chart, and a tabular entailment\nmodel applied to score the summary sentence by sentence. We find that\nCHATS-CRITIC evaluates the summary quality according to human ratings better\nthan reference-based metrics, either learned or n-gram based, and can be\nfurther used to fix candidate summaries by removing not supported sentences. We\nthen introduce CHATS-PI, a chart-to-summary pipeline that leverages\nCHATS-CRITIC during inference to fix and rank sampled candidates from any\nchart-summarization model. We evaluate CHATS-PI and CHATS-CRITIC using human\nraters, establishing state-of-the-art results on two popular chart-to-summary\ndatasets.\n",
        "authors": "Syrine Krichene; Francesco Piccinno; Fangyu Liu; Julian Martin Eisenschlos",
        "status": 0,
        "relevancy": 0.568534057467102,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19080",
        "date": "2024-05-29",
        "title": "OMPO: A Unified Framework for RL under Policy and Dynamics Shifts",
        "abstract": "  Training reinforcement learning policies using environment interaction data\ncollected from varying policies or dynamics presents a fundamental challenge.\nExisting works often overlook the distribution discrepancies induced by policy\nor dynamics shifts, or rely on specialized algorithms with task priors, thus\noften resulting in suboptimal policy performances and high learning variances.\nIn this paper, we identify a unified strategy for online RL policy learning\nunder diverse settings of policy and dynamics shifts: transition occupancy\nmatching. In light of this, we introduce a surrogate policy learning objective\nby considering the transition occupancy discrepancies and then cast it into a\ntractable min-max optimization problem through dual reformulation. Our method,\ndubbed Occupancy-Matching Policy Optimization (OMPO), features a specialized\nactor-critic structure equipped with a distribution discriminator and a\nsmall-size local buffer. We conduct extensive experiments based on the OpenAI\nGym, Meta-World, and Panda Robots environments, encompassing policy shifts\nunder stationary and nonstationary dynamics, as well as domain adaption. The\nresults demonstrate that OMPO outperforms the specialized baselines from\ndifferent categories in all settings. We also find that OMPO exhibits\nparticularly strong performance when combined with domain randomization,\nhighlighting its potential in RL-based robotics applications\n",
        "authors": "Yu Luo; Tianying Ji; Fuchun Sun; Jianwei Zhang; Huazhe Xu; Xianyuan Zhan",
        "status": 0,
        "relevancy": 0.5545371968401408,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19220",
        "date": "2024-05-29",
        "title": "WRDScore: New Metric for Evaluation of Natural Language Generation\n  Models",
        "abstract": "  The problem of natural language generation, and, more specifically, method\nname prediction, faces significant difficulties when proposed models need to be\nevaluated on test data. Such a metric would need to consider the versatility\nwith which a single method can be named, with respect to both semantics and\nsyntax. Measuring the direct overlap between the predicted and reference (true)\nsequences will not be able to capture these subtleties. Other existing\nembedding based metrics either do not measure precision and recall or impose\nstrict unrealistic assumptions on both sequences. To address these issues, we\npropose a new metric that, on the one hand, is very simple and lightweight,\nand, on the other hand, is able to calculate precision and recall without\nresorting to any assumptions while obtaining good performance with respect to\nthe human judgement.\n",
        "authors": "Ravil Mussabayev",
        "status": 0,
        "relevancy": 0.5544849074751874,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19313",
        "date": "2024-05-29",
        "title": "Language Models Trained to do Arithmetic Predict Human Risky and\n  Intertemporal Choice",
        "abstract": "  The observed similarities in the behavior of humans and Large Language Models\n(LLMs) have prompted researchers to consider the potential of using LLMs as\nmodels of human cognition. However, several significant challenges must be\naddressed before LLMs can be legitimately regarded as cognitive models. For\ninstance, LLMs are trained on far more data than humans typically encounter,\nand may have been directly trained on human data in specific cognitive tasks or\naligned with human preferences. Consequently, the origins of these behavioral\nsimilarities are not well understood. In this paper, we propose a novel way to\nenhance the utility of LLMs as cognitive models. This approach involves (i)\nleveraging computationally equivalent tasks that both an LLM and a rational\nagent need to master for solving a cognitive problem and (ii) examining the\nspecific task distributions required for an LLM to exhibit human-like\nbehaviors. We apply this approach to decision-making -- specifically risky and\nintertemporal choice -- where the key computationally equivalent task is the\narithmetic of expected value calculations. We show that an LLM pretrained on an\necologically valid arithmetic dataset, which we call Arithmetic-GPT, predicts\nhuman behavior better than many traditional cognitive models. Pretraining LLMs\non ecologically valid arithmetic datasets is sufficient to produce a strong\ncorrespondence between these models and human decision-making. Our results also\nsuggest that LLMs used as cognitive models should be carefully investigated via\nablation studies of the pretraining data.\n",
        "authors": "Jian-Qiao Zhu; Haijiang Yan; Thomas L. Griffiths",
        "status": 0,
        "relevancy": 0.5536541798065598,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18915",
        "date": "2024-05-29",
        "title": "Towards Faithful Chain-of-Thought: Large Language Models are Bridging\n  Reasoners",
        "abstract": "  Large language models (LLMs) suffer from serious unfaithful chain-of-thought\n(CoT) issues. Previous work attempts to measure and explain it but lacks\nin-depth analysis within CoTs and does not consider the interactions among all\nreasoning components jointly. In this paper, we first study the CoT\nfaithfulness issue at the granularity of CoT steps, identify two reasoning\nparadigms: centralized reasoning and distributed reasoning, and find their\nrelationship with faithfulness. Subsequently, we conduct a joint analysis of\nthe causal relevance among the context, CoT, and answer during reasoning. The\nresult proves that, when the LLM predicts answers, it can recall correct\ninformation missing in the CoT from the context, leading to unfaithfulness\nissues. Finally, we propose the inferential bridging method to mitigate this\nissue, in which we use the attribution method to recall information as hints\nfor CoT generation and filter out noisy CoTs based on their semantic\nconsistency and attribution scores. Extensive experiments demonstrate that our\napproach effectively alleviates the unfaithful CoT problem.\n",
        "authors": "Jiachun Li; Pengfei Cao; Yubo Chen; Kang Liu; Jun Zhao",
        "status": 0,
        "relevancy": 0.5512908293507641,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18664",
        "date": "2024-05-29",
        "title": "Fast Explainability via Feasible Concept Sets Generator",
        "abstract": "  A long-standing dilemma prevents the broader application of explanation\nmethods: general applicability and inference speed. On the one hand, existing\nmodel-agnostic explanation methods usually make minimal pre-assumptions about\nthe prediction models to be explained. Still, they require additional queries\nto the model through propagation or back-propagation to approximate the models'\nbehaviors, resulting in slow inference and hindering their use in\ntime-sensitive tasks. On the other hand, various model-dependent explanations\nhave been proposed that achieve low-cost, fast inference but at the expense of\nlimiting their applicability to specific model structures. In this study, we\nbridge the gap between the universality of model-agnostic approaches and the\nefficiency of model-specific approaches by proposing a novel framework without\nassumptions on the prediction model's structures, achieving high efficiency\nduring inference and allowing for real-time explanations. To achieve this, we\nfirst define explanations through a set of human-comprehensible concepts and\npropose a framework to elucidate model predictions via minimal feasible concept\nsets. Second, we show that a minimal feasible set generator can be learned as a\ncompanion explainer to the prediction model, generating explanations for\npredictions. Finally, we validate this framework by implementing a novel\nmodel-agnostic method that provides robust explanations while facilitating\nreal-time inference. Our claims are substantiated by comprehensive experiments,\nhighlighting the effectiveness and efficiency of our approach.\n",
        "authors": "Deng Pan; Nuno Moniz; Nitesh Chawla",
        "status": 0,
        "relevancy": 0.5488259099104661,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19327",
        "date": "2024-05-29",
        "title": "MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model\n  Series",
        "abstract": "  Large Language Models (LLMs) have made great strides in recent years to\nachieve unprecedented performance across different tasks. However, due to\ncommercial interest, the most competitive models like GPT, Gemini, and Claude\nhave been gated behind proprietary interfaces without disclosing the training\ndetails. Recently, many institutions have open-sourced several strong LLMs like\nLLaMA-3, comparable to existing closed-source LLMs. However, only the model's\nweights are provided with most details (e.g., intermediate checkpoints,\npre-training corpus, and training code, etc.) being undisclosed. To improve the\ntransparency of LLMs, the research community has formed to open-source truly\nopen LLMs (e.g., Pythia, Amber, OLMo), where more details (e.g., pre-training\ncorpus and training code) are being provided. These models have greatly\nadvanced the scientific study of these large models including their strengths,\nweaknesses, biases and risks. However, we observe that the existing truly open\nLLMs on reasoning, knowledge, and coding tasks are still inferior to existing\nstate-of-the-art LLMs with similar model sizes. To this end, we open-source\nMAP-Neo, a highly capable and transparent bilingual language model with 7B\nparameters trained from scratch on 4.5T high-quality tokens. Our MAP-Neo is the\nfirst fully open-sourced bilingual LLM with comparable performance compared to\nexisting state-of-the-art LLMs. Moreover, we open-source all details to\nreproduce our MAP-Neo, where the cleaned pre-training corpus, data cleaning\npipeline, checkpoints, and well-optimized training/evaluation framework are\nprovided. Finally, we hope our MAP-Neo will enhance and strengthen the open\nresearch community and inspire more innovations and creativities to facilitate\nthe further improvements of LLMs.\n",
        "authors": "Ge Zhang; Scott Qu; Jiaheng Liu; Chenchen Zhang; Chenghua Lin; Chou Leuang Yu; Danny Pan; Esther Cheng; Jie Liu; Qunshu Lin; Raven Yuan; Tuney Zheng; Wei Pang; Xinrun Du; Yiming Liang; Yinghao Ma; Yizhi Li; Ziyang Ma; Bill Lin; Emmanouil Benetos; Huan Yang; Junting Zhou; Kaijing Ma; Minghao Liu; Morry Niu; Noah Wang; Quehry Que; Ruibo Liu; Sine Liu; Shawn Guo; Soren Gao; Wangchunshu Zhou; Xinyue Zhang; Yizhi Zhou; Yubo Wang; Yuelin Bai; Yuhan Zhang; Yuxiang Zhang; Zenith Wang; Zhenzhu Yang; Zijian Zhao; Jiajun Zhang; Wanli Ouyang; Wenhao Huang; Wenhu Chen",
        "status": 0,
        "relevancy": 0.5443444264491701,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18952",
        "date": "2024-05-29",
        "title": "Are You Sure? Rank Them Again: Repeated Ranking For Better Preference\n  Datasets",
        "abstract": "  Training Large Language Models (LLMs) with Reinforcement Learning from AI\nFeedback (RLAIF) aligns model outputs more closely with human preferences. This\ninvolves an evaluator model ranking multiple candidate responses to user\nprompts. However, the rankings from popular evaluator models such as GPT-4 can\nbe inconsistent. We propose the Repeat Ranking method - where we evaluate the\nsame responses multiple times and train only on those responses which are\nconsistently ranked. Using 2,714 prompts in 62 languages, we generated\nresponses from 7 top multilingual LLMs and had GPT-4 rank them five times each.\nEvaluating on MT-Bench chat benchmarks in six languages, our method\noutperformed the standard practice of training on all available prompts. Our\nwork highlights the quality versus quantity trade-off in RLAIF dataset\ngeneration and offers a stackable strategy for enhancing dataset and thus model\nquality.\n",
        "authors": "Peter Devine",
        "status": 0,
        "relevancy": 0.5442714278671904,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19255",
        "date": "2024-05-29",
        "title": "Towards Next-Generation Urban Decision Support Systems through\n  AI-Powered Generation of Scientific Ontology using Large Language Models -- A\n  Case in Optimizing Intermodal Freight Transportation",
        "abstract": "  The incorporation of Artificial Intelligence (AI) models into various\noptimization systems is on the rise. Yet, addressing complex urban and\nenvironmental management problems normally requires in-depth domain science and\ninformatics expertise. This expertise is essential for deriving data and\nsimulation-driven for informed decision support. In this context, we\ninvestigate the potential of leveraging the pre-trained Large Language Models\n(LLMs). By adopting ChatGPT API as the reasoning core, we outline an integrated\nworkflow that encompasses natural language processing, methontology-based\nprompt tuning, and transformers. This workflow automates the creation of\nscenario-based ontology using existing research articles and technical manuals\nof urban datasets and simulations. The outcomes of our methodology are\nknowledge graphs in widely adopted ontology languages (e.g., OWL, RDF, SPARQL).\nThese facilitate the development of urban decision support systems by enhancing\nthe data and metadata modeling, the integration of complex datasets, the\ncoupling of multi-domain simulation models, and the formulation of\ndecision-making metrics and workflow. The feasibility of our methodology is\nevaluated through a comparative analysis that juxtaposes our AI-generated\nontology with the well-known Pizza Ontology employed in tutorials for popular\nontology software (e.g., prot\\'eg\\'e). We close with a real-world case study of\noptimizing the complex urban system of multi-modal freight transportation by\ngenerating anthologies of various domain data and simulations to support\ninformed decision-making.\n",
        "authors": "Jose Tupayachi; Haowen Xu; Olufemi A. Omitaomu; Mustafa Can Camur; Aliza Sharmin; Xueping Li",
        "status": 0,
        "relevancy": 0.5437103103299856,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19107",
        "date": "2024-05-29",
        "title": "Offline Regularised Reinforcement Learning for Large Language Models\n  Alignment",
        "abstract": "  The dominant framework for alignment of large language models (LLM), whether\nthrough reinforcement learning from human feedback or direct preference\noptimisation, is to learn from preference data. This involves building datasets\nwhere each element is a quadruplet composed of a prompt, two independent\nresponses (completions of the prompt) and a human preference between the two\nindependent responses, yielding a preferred and a dis-preferred response. Such\ndata is typically scarce and expensive to collect. On the other hand,\n\\emph{single-trajectory} datasets where each element is a triplet composed of a\nprompt, a response and a human feedback is naturally more abundant. The\ncanonical element of such datasets is for instance an LLM's response to a\nuser's prompt followed by a user's feedback such as a thumbs-up/down.\nConsequently, in this work, we propose DRO, or \\emph{Direct Reward\nOptimisation}, as a framework and associated algorithms that do not require\npairwise preferences. DRO uses a simple mean-squared objective that can be\nimplemented in various ways. We validate our findings empirically, using T5\nencoder-decoder language models, and show DRO's performance over selected\nbaselines such as Kahneman-Tversky Optimization (KTO). Thus, we confirm that\nDRO is a simple and empirically compelling method for single-trajectory policy\noptimisation.\n",
        "authors": "Pierre Harvey Richemond; Yunhao Tang; Daniel Guo; Daniele Calandriello; Mohammad Gheshlaghi Azar; Rafael Rafailov; Bernardo Avila Pires; Eugene Tarassov; Lucas Spangher; Will Ellsworth; Aliaksei Severyn; Jonathan Mallinson; Lior Shani; Gil Shamir; Rishabh Joshi; Tianqi Liu; Remi Munos; Bilal Piot",
        "status": 0,
        "relevancy": 0.5432386954237568,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19164",
        "date": "2024-05-29",
        "title": "Learning from Litigation: Graphs and LLMs for Retrieval and Reasoning in\n  eDiscovery",
        "abstract": "  Electronic Discovery (eDiscovery) involves identifying relevant documents\nfrom a vast collection based on legal production requests. The integration of\nartificial intelligence (AI) and natural language processing (NLP) has\ntransformed this process, helping document review and enhance efficiency and\ncost-effectiveness. Although traditional approaches like BM25 or fine-tuned\npre-trained models are common in eDiscovery, they face performance,\ncomputational, and interpretability challenges. In contrast, Large Language\nModel (LLM)-based methods prioritize interpretability but sacrifice performance\nand throughput. This paper introduces DISCOvery Graph (DISCOG), a hybrid\napproach that combines the strengths of two worlds: a heterogeneous graph-based\nmethod for accurate document relevance prediction and subsequent LLM-driven\napproach for reasoning. Graph representational learning generates embeddings\nand predicts links, ranking the corpus for a given request, and the LLMs\nprovide reasoning for document relevance. Our approach handles datasets with\nbalanced and imbalanced distributions, outperforming baselines in F1-score,\nprecision, and recall by an average of 12%, 3%, and 16%, respectively. In an\nenterprise context, our approach drastically reduces document review costs by\n99.9% compared to manual processes and by 95% compared to LLM-based\nclassification methods\n",
        "authors": "Sounak Lahiri; Sumit Pai; Tim Weninger; Sanmitra Bhattacharya",
        "status": 0,
        "relevancy": 0.5420571473534375,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19561",
        "date": "2024-05-29",
        "title": "Quo Vadis ChatGPT? From Large Language Models to Large Knowledge Models",
        "abstract": "  The startling success of ChatGPT and other large language models (LLMs) using\ntransformer-based generative neural network architecture in applications such\nas natural language processing and image synthesis has many researchers excited\nabout potential opportunities in process systems engineering (PSE). The almost\nhuman-like performance of LLMs in these areas is indeed very impressive,\nsurprising, and a major breakthrough. Their capabilities are very useful in\ncertain tasks, such as writing first drafts of documents, code writing\nassistance, text summarization, etc. However, their success is limited in\nhighly scientific domains as they cannot yet reason, plan, or explain due to\ntheir lack of in-depth domain knowledge. This is a problem in domains such as\nchemical engineering as they are governed by fundamental laws of physics and\nchemistry (and biology), constitutive relations, and highly technical knowledge\nabout materials, processes, and systems. Although purely data-driven machine\nlearning has its immediate uses, the long-term success of AI in scientific and\nengineering domains would depend on developing hybrid AI systems that use first\nprinciples and technical knowledge effectively. We call these hybrid AI systems\nLarge Knowledge Models (LKMs), as they will not be limited to only NLP-based\ntechniques or NLP-like applications. In this paper, we discuss the challenges\nand opportunities in developing such systems in chemical engineering.\n",
        "authors": "Venkat Venkatasubramanian; Arijit Chakraborty",
        "status": 0,
        "relevancy": 0.5375948412157391,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19010",
        "date": "2024-05-29",
        "title": "Evaluating the External and Parametric Knowledge Fusion of Large\n  Language Models",
        "abstract": "  Integrating external knowledge into large language models (LLMs) presents a\npromising solution to overcome the limitations imposed by their antiquated and\nstatic parametric memory. Prior studies, however, have tended to over-reliance\non external knowledge, underestimating the valuable contributions of an LLMs'\nintrinsic parametric knowledge. The efficacy of LLMs in blending external and\nparametric knowledge remains largely unexplored, especially in cases where\nexternal knowledge is incomplete and necessitates supplementation by their\nparametric knowledge. We propose to deconstruct knowledge fusion into four\ndistinct scenarios, offering the first thorough investigation of LLM behavior\nacross each. We develop a systematic pipeline for data construction and\nknowledge infusion to simulate these fusion scenarios, facilitating a series of\ncontrolled experiments. Our investigation reveals that enhancing parametric\nknowledge within LLMs can significantly bolster their capability for knowledge\nintegration. Nonetheless, we identify persistent challenges in memorizing and\neliciting parametric knowledge, and determining parametric knowledge\nboundaries. Our findings aim to steer future explorations on harmonizing\nexternal and parametric knowledge within LLMs.\n",
        "authors": "Hao Zhang; Yuyang Zhang; Xiaoguang Li; Wenxuan Shi; Haonan Xu; Huanshuo Liu; Yasheng Wang; Lifeng Shang; Qun Liu; Yong Liu; Ruiming Tang",
        "status": 0,
        "relevancy": 0.5373678980927894,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18688",
        "date": "2024-05-29",
        "title": "Efficient Preference-based Reinforcement Learning via Aligned Experience\n  Estimation",
        "abstract": "  Preference-based reinforcement learning (PbRL) has shown impressive\ncapabilities in training agents without reward engineering. However, a notable\nlimitation of PbRL is its dependency on substantial human feedback. This\ndependency stems from the learning loop, which entails accurate reward learning\ncompounded with value/policy learning, necessitating a considerable number of\nsamples. To boost the learning loop, we propose SEER, an efficient PbRL method\nthat integrates label smoothing and policy regularization techniques. Label\nsmoothing reduces overfitting of the reward model by smoothing human preference\nlabels. Additionally, we bootstrap a conservative estimate $\\widehat{Q}$ using\nwell-supported state-action pairs from the current replay memory to mitigate\noverestimation bias and utilize it for policy learning regularization. Our\nexperimental results across a variety of complex tasks, both in online and\noffline settings, demonstrate that our approach improves feedback efficiency,\noutperforming state-of-the-art methods by a large margin. Ablation studies\nfurther reveal that SEER achieves a more accurate Q-function compared to prior\nwork.\n",
        "authors": "Fengshuo Bai; Rui Zhao; Hongming Zhang; Sijia Cui; Ying Wen; Yaodong Yang; Bo Xu; Lei Han",
        "status": 0,
        "relevancy": 0.5366568000368498,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18721",
        "date": "2024-05-29",
        "title": "Correctable Landmark Discovery via Large Models for Vision-Language\n  Navigation",
        "abstract": "  Vision-Language Navigation (VLN) requires the agent to follow language\ninstructions to reach a target position. A key factor for successful navigation\nis to align the landmarks implied in the instruction with diverse visual\nobservations. However, previous VLN agents fail to perform accurate modality\nalignment especially in unexplored scenes, since they learn from limited\nnavigation data and lack sufficient open-world alignment knowledge. In this\nwork, we propose a new VLN paradigm, called COrrectable LaNdmark DiScOvery via\nLarge ModEls (CONSOLE). In CONSOLE, we cast VLN as an open-world sequential\nlandmark discovery problem, by introducing a novel correctable landmark\ndiscovery scheme based on two large models ChatGPT and CLIP. Specifically, we\nuse ChatGPT to provide rich open-world landmark cooccurrence commonsense, and\nconduct CLIP-driven landmark discovery based on these commonsense priors. To\nmitigate the noise in the priors due to the lack of visual constraints, we\nintroduce a learnable cooccurrence scoring module, which corrects the\nimportance of each cooccurrence according to actual observations for accurate\nlandmark discovery. We further design an observation enhancement strategy for\nan elegant combination of our framework with different VLN agents, where we\nutilize the corrected landmark features to obtain enhanced observation features\nfor action decision. Extensive experimental results on multiple popular VLN\nbenchmarks (R2R, REVERIE, R4R, RxR) show the significant superiority of CONSOLE\nover strong baselines. Especially, our CONSOLE establishes the new\nstate-of-the-art results on R2R and R4R in unseen scenarios. Code is available\nat https://github.com/expectorlin/CONSOLE.\n",
        "authors": "Bingqian Lin; Yunshuang Nie; Ziming Wei; Yi Zhu; Hang Xu; Shikui Ma; Jianzhuang Liu; Xiaodan Liang",
        "status": 0,
        "relevancy": 0.5362481468861078,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19149",
        "date": "2024-05-29",
        "title": "CaLa: Complementary Association Learning for Augmenting Composed Image\n  Retrieval",
        "abstract": "  Composed Image Retrieval (CIR) involves searching for target images based on\nan image-text pair query. While current methods treat this as a query-target\nmatching problem, we argue that CIR triplets contain additional associations\nbeyond this primary relation. In our paper, we identify two new relations\nwithin triplets, treating each triplet as a graph node. Firstly, we introduce\nthe concept of text-bridged image alignment, where the query text serves as a\nbridge between the query image and the target image. We propose a hinge-based\ncross-attention mechanism to incorporate this relation into network learning.\nSecondly, we explore complementary text reasoning, considering CIR as a form of\ncross-modal retrieval where two images compose to reason about complementary\ntext. To integrate these perspectives effectively, we design a twin\nattention-based compositor. By combining these complementary associations with\nthe explicit query pair-target image relation, we establish a comprehensive set\nof constraints for CIR. Our framework, CaLa (Complementary Association Learning\nfor Augmenting Composed Image Retrieval), leverages these insights. We evaluate\nCaLa on CIRR and FashionIQ benchmarks with multiple backbones, demonstrating\nits superiority in composed image retrieval.\n",
        "authors": "Xintong Jiang; Yaxiong Wang; Mengjian Li; Yujiao Wu; Bingwen Hu; Xueming Qian",
        "status": 0,
        "relevancy": 0.5349794440807307,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19209",
        "date": "2024-05-29",
        "title": "VideoTree: Adaptive Tree-based Video Representation for LLM Reasoning on\n  Long Videos",
        "abstract": "  Video-language understanding tasks have focused on short video clips, often\nstruggling with long-form video understanding tasks. Recently, many long\nvideo-language understanding approaches have leveraged the reasoning\ncapabilities of Large Language Models (LLMs) to perform long video QA,\ntransforming videos into densely sampled frame captions, and asking LLMs to\nrespond to text queries over captions. However, the frames used for captioning\nare often redundant and contain irrelevant information, making dense sampling\ninefficient, and ignoring the fact that video QA requires varying levels of\ngranularity, with some video segments being highly relevant to the question\n(needing more fine-grained detail) while others being less relevant. Thus,\nthese LLM-based approaches are prone to missing information and operate on\nlarge numbers of irrelevant captions, lowering both performance and efficiency.\nTo address these issues, we introduce VideoTree, a query-adaptive and\nhierarchical framework for long-video understanding with LLMs. VideoTree\ndynamically extracts query-related information from a video and builds a\ntree-based representation for LLM reasoning. First, VideoTree adaptively\nselects frames for captioning by iteratively clustering frames based on their\nvisual features and scoring clusters using their relevance to the query.\nSecond, it organizes visual clusters into a query-adaptive and hierarchical\ntree structure; the tree encodes varying levels of granularity, with higher\nresolution on relevant segments. Finally, VideoTree produces an answer by\ntraversing the tree's keyframes and passing their captions to an LLM answerer.\nOur method improves both reasoning accuracy and efficiency compared to existing\nmethods: VideoTree achieves a 7.0%, 2.2%, and 2.7% accuracy gain over baselines\non the EgoSchema, NExT-QA, and IntentQA benchmarks, respectively, while\nreducing inference time by 40%.\n",
        "authors": "Ziyang Wang; Shoubin Yu; Elias Stengel-Eskin; Jaehong Yoon; Feng Cheng; Gedas Bertasius; Mohit Bansal",
        "status": 0,
        "relevancy": 0.5316191479269754,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19229",
        "date": "2024-05-29",
        "title": "On Generating Monolithic and Model Reconciling Explanations in\n  Probabilistic Scenarios",
        "abstract": "  Explanation generation frameworks aim to make AI systems' decisions\ntransparent and understandable to human users. However, generating explanations\nin uncertain environments characterized by incomplete information and\nprobabilistic models remains a significant challenge. In this paper, we propose\na novel framework for generating probabilistic monolithic explanations and\nmodel reconciling explanations. Monolithic explanations provide self-contained\nreasons for an explanandum without considering the agent receiving the\nexplanation, while model reconciling explanations account for the knowledge of\nthe agent receiving the explanation. For monolithic explanations, our approach\nintegrates uncertainty by utilizing probabilistic logic to increase the\nprobability of the explanandum. For model reconciling explanations, we propose\na framework that extends the logic-based variant of the model reconciliation\nproblem to account for probabilistic human models, where the goal is to find\nexplanations that increase the probability of the explanandum while minimizing\nconflicts between the explanation and the probabilistic human model. We\nintroduce explanatory gain and explanatory power as quantitative metrics to\nassess the quality of these explanations. Further, we present algorithms that\nexploit the duality between minimal correction sets and minimal unsatisfiable\nsets to efficiently compute both types of explanations in probabilistic\ncontexts. Extensive experimental evaluations on various benchmarks demonstrate\nthe effectiveness and scalability of our approach in generating explanations\nunder uncertainty.\n",
        "authors": "Stylianos Loukas Vasileiou; William Yeoh; Alessandro Previti; Tran Cao Son",
        "status": 0,
        "relevancy": 0.530953278153824,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19162",
        "date": "2024-05-29",
        "title": "Does learning the right latent variables necessarily improve in-context\n  learning?",
        "abstract": "  Large autoregressive models like Transformers can solve tasks through\nin-context learning (ICL) without learning new weights, suggesting avenues for\nefficiently solving new tasks. For many tasks, e.g., linear regression, the\ndata factorizes: examples are independent given a task latent that generates\nthe data, e.g., linear coefficients. While an optimal predictor leverages this\nfactorization by inferring task latents, it is unclear if Transformers\nimplicitly do so or if they instead exploit heuristics and statistical\nshortcuts enabled by attention layers. Both scenarios have inspired active\nongoing work. In this paper, we systematically investigate the effect of\nexplicitly inferring task latents. We minimally modify the Transformer\narchitecture with a bottleneck designed to prevent shortcuts in favor of more\nstructured solutions, and then compare performance against standard\nTransformers across various ICL tasks. Contrary to intuition and some recent\nworks, we find little discernible difference between the two; biasing towards\ntask-relevant latent variables does not lead to better out-of-distribution\nperformance, in general. Curiously, we find that while the bottleneck\neffectively learns to extract latent task variables from context, downstream\nprocessing struggles to utilize them for robust prediction. Our study\nhighlights the intrinsic limitations of Transformers in achieving structured\nICL solutions that generalize, and shows that while inferring the right latents\naids interpretability, it is not sufficient to alleviate this problem.\n",
        "authors": "Sarthak Mittal; Eric Elmoznino; Leo Gagnon; Sangnie Bhardwaj; Dhanya Sridhar; Guillaume Lajoie",
        "status": 0,
        "relevancy": 0.528705347329253,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19567",
        "date": "2024-05-29",
        "title": "Dr-LLaVA: Visual Instruction Tuning with Symbolic Clinical Grounding",
        "abstract": "  Vision-Language Models (VLM) can support clinicians by analyzing medical\nimages and engaging in natural language interactions to assist in diagnostic\nand treatment tasks. However, VLMs often exhibit \"hallucinogenic\" behavior,\ngenerating textual outputs not grounded in contextual multimodal information.\nThis challenge is particularly pronounced in the medical domain, where we do\nnot only require VLM outputs to be accurate in single interactions but also to\nbe consistent with clinical reasoning and diagnostic pathways throughout\nmulti-turn conversations. For this purpose, we propose a new alignment\nalgorithm that uses symbolic representations of clinical reasoning to ground\nVLMs in medical knowledge. These representations are utilized to (i) generate\nGPT-4-guided visual instruction tuning data at scale, simulating clinician-VLM\nconversations with demonstrations of clinical reasoning, and (ii) create an\nautomatic reward function that evaluates the clinical validity of VLM\ngenerations throughout clinician-VLM interactions. Our algorithm eliminates the\nneed for human involvement in training data generation or reward model\nconstruction, reducing costs compared to standard reinforcement learning with\nhuman feedback (RLHF). We apply our alignment algorithm to develop Dr-LLaVA, a\nconversational VLM finetuned for analyzing bone marrow pathology slides,\ndemonstrating strong performance in multi-turn medical conversations.\n",
        "authors": "Shenghuan Sun; Gregory M. Goldgof; Alexander Schubert; Zhiqing Sun; Thomas Hartvigsen; Atul J. Butte; Ahmed Alaa",
        "status": 0,
        "relevancy": 0.524865683713274,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18870",
        "date": "2024-05-29",
        "title": "LLMs achieve adult human performance on higher-order theory of mind\n  tasks",
        "abstract": "  This paper examines the extent to which large language models (LLMs) have\ndeveloped higher-order theory of mind (ToM); the human ability to reason about\nmultiple mental and emotional states in a recursive manner (e.g. I think that\nyou believe that she knows). This paper builds on prior work by introducing a\nhandwritten test suite -- Multi-Order Theory of Mind Q&A -- and using it to\ncompare the performance of five LLMs to a newly gathered adult human benchmark.\nWe find that GPT-4 and Flan-PaLM reach adult-level and near adult-level\nperformance on ToM tasks overall, and that GPT-4 exceeds adult performance on\n6th order inferences. Our results suggest that there is an interplay between\nmodel size and finetuning for the realisation of ToM abilities, and that the\nbest-performing LLMs have developed a generalised capacity for ToM. Given the\nrole that higher-order ToM plays in a wide range of cooperative and competitive\nhuman behaviours, these findings have significant implications for user-facing\nLLM applications.\n",
        "authors": "Winnie Street; John Oliver Siy; Geoff Keeling; Adrien Baranes; Benjamin Barnett; Michael McKibben; Tatenda Kanyere; Alison Lentz; Blaise Aguera y Arcas; Robin I. M. Dunbar",
        "status": 0,
        "relevancy": 0.5248202822452036,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19498",
        "date": "2024-05-29",
        "title": "Machine Psychology: Integrating Operant Conditioning with the\n  Non-Axiomatic Reasoning System for Advancing Artificial General Intelligence\n  Research",
        "abstract": "  This paper introduces an interdisciplinary framework called Machine\nPsychology, which merges principles from operant learning psychology with a\nspecific Artificial Intelligence model, the Non-Axiomatic Reasoning System\n(NARS), to enhance Artificial General Intelligence (AGI) research. The core\npremise of this framework is that adaptation is crucial to both biological and\nartificial intelligence and can be understood through operant conditioning\nprinciples. The study assesses this approach via three operant learning tasks\nusing OpenNARS for Applications (ONA): simple discrimination, changing\ncontingencies, and conditional discrimination tasks.\n  In the simple discrimination task, NARS demonstrated rapid learning,\nachieving perfect accuracy during both training and testing phases. The\nchanging contingencies task showcased NARS's adaptability, as it successfully\nadjusted its behavior when task conditions were reversed. In the conditional\ndiscrimination task, NARS handled complex learning scenarios effectively,\nachieving high accuracy by forming and utilizing intricate hypotheses based on\nconditional cues.\n  These findings support the application of operant conditioning as a framework\nfor creating adaptive AGI systems. NARS's ability to operate under conditions\nof insufficient knowledge and resources, coupled with its sensorimotor\nreasoning capabilities, establishes it as a robust model for AGI. The Machine\nPsychology framework, by incorporating elements of natural intelligence such as\ncontinuous learning and goal-driven behavior, offers a scalable and flexible\napproach for real-world applications. Future research should investigate using\nenhanced NARS systems, more advanced tasks, and applying this framework to\ndiverse, complex challenges to further progress the development of human-level\nAI.\n",
        "authors": "Robert Johansson",
        "status": 0,
        "relevancy": 0.5217213920706358,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18751",
        "date": "2024-05-29",
        "title": "On the Limits of Multi-modal Meta-Learning with Auxiliary Task\n  Modulation Using Conditional Batch Normalization",
        "abstract": "  Few-shot learning aims to learn representations that can tackle novel tasks\ngiven a small number of examples. Recent studies show that cross-modal learning\ncan improve representations for few-shot classification. More specifically,\nlanguage is a rich modality that can be used to guide visual learning. In this\nwork, we experiment with a multi-modal architecture for few-shot learning that\nconsists of three components: a classifier, an auxiliary network, and a bridge\nnetwork. While the classifier performs the main classification task, the\nauxiliary network learns to predict language representations from the same\ninput, and the bridge network transforms high-level features of the auxiliary\nnetwork into modulation parameters for layers of the few-shot classifier using\nconditional batch normalization. The bridge should encourage a form of\nlightweight semantic alignment between language and vision which could be\nuseful for the classifier. However, after evaluating the proposed approach on\ntwo popular few-shot classification benchmarks we find that a) the improvements\ndo not reproduce across benchmarks, and b) when they do, the improvements are\ndue to the additional compute and parameters introduced by the bridge network.\nWe contribute insights and recommendations for future work in multi-modal\nmeta-learning, especially when using language representations.\n",
        "authors": "Jordi Armengol-Estapé; Vincent Michalski; Ramnath Kumar; Pierre-Luc St-Charles; Doina Precup; Samira Ebrahimi Kahou",
        "status": 0,
        "relevancy": 0.5190552499712069,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19320",
        "date": "2024-05-29",
        "title": "Value-Incentivized Preference Optimization: A Unified Approach to Online\n  and Offline RLHF",
        "abstract": "  Reinforcement learning from human feedback (RLHF) has demonstrated great\npromise in aligning large language models (LLMs) with human preference.\nDepending on the availability of preference data, both online and offline RLHF\nare active areas of investigation. A key bottleneck is understanding how to\nincorporate uncertainty estimation in the reward function learned from the\npreference data for RLHF, regardless of how the preference data is collected.\nWhile the principles of optimism or pessimism under uncertainty are\nwell-established in standard reinforcement learning (RL), a\npractically-implementable and theoretically-grounded form amenable to large\nlanguage models is not yet available, as standard techniques for constructing\nconfidence intervals become intractable under arbitrary policy\nparameterizations.\n  In this paper, we introduce a unified approach to online and offline RLHF --\nvalue-incentivized preference optimization (VPO) -- which regularizes the\nmaximum-likelihood estimate of the reward function with the corresponding value\nfunction, modulated by a $\\textit{sign}$ to indicate whether the optimism or\npessimism is chosen. VPO also directly optimizes the policy with implicit\nreward modeling, and therefore shares a simpler RLHF pipeline similar to direct\npreference optimization. Theoretical guarantees of VPO are provided for both\nonline and offline settings, matching the rates of their standard RL\ncounterparts. Moreover, experiments on text summarization and dialog verify the\npracticality and effectiveness of VPO.\n",
        "authors": "Shicong Cen; Jincheng Mei; Katayoon Goshvadi; Hanjun Dai; Tong Yang; Sherry Yang; Dale Schuurmans; Yuejie Chi; Bo Dai",
        "status": 0,
        "relevancy": 0.5152347105726177,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19334",
        "date": "2024-05-29",
        "title": "LLMs Meet Multimodal Generation and Editing: A Survey",
        "abstract": "  With the recent advancement in large language models (LLMs), there is a\ngrowing interest in combining LLMs with multimodal learning. Previous surveys\nof multimodal large language models (MLLMs) mainly focus on understanding. This\nsurvey elaborates on multimodal generation across different domains, including\nimage, video, 3D, and audio, where we highlight the notable advancements with\nmilestone works in these fields. Specifically, we exhaustively investigate the\nkey technical components behind methods and multimodal datasets utilized in\nthese studies. Moreover, we dig into tool-augmented multimodal agents that can\nuse existing generative models for human-computer interaction. Lastly, we also\ncomprehensively discuss the advancement in AI safety and investigate emerging\napplications as well as future prospects. Our work provides a systematic and\ninsightful overview of multimodal generation, which is expected to advance the\ndevelopment of Artificial Intelligence for Generative Content (AIGC) and world\nmodels. A curated list of all related papers can be found at\nhttps://github.com/YingqingHe/Awesome-LLMs-meet-Multimodal-Generation\n",
        "authors": "Yingqing He; Zhaoyang Liu; Jingye Chen; Zeyue Tian; Hongyu Liu; Xiaowei Chi; Runtao Liu; Ruibin Yuan; Yazhou Xing; Wenhai Wang; Jifeng Dai; Yong Zhang; Wei Xue; Qifeng Liu; Yike Guo; Qifeng Chen",
        "status": 0,
        "relevancy": 0.5151688872910891,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19062",
        "date": "2024-05-29",
        "title": "SIG: Efficient Self-Interpretable Graph Neural Network for\n  Continuous-time Dynamic Graphs",
        "abstract": "  While dynamic graph neural networks have shown promise in various\napplications, explaining their predictions on continuous-time dynamic graphs\n(CTDGs) is difficult. This paper investigates a new research task:\nself-interpretable GNNs for CTDGs. We aim to predict future links within the\ndynamic graph while simultaneously providing causal explanations for these\npredictions. There are two key challenges: (1) capturing the underlying\nstructural and temporal information that remains consistent across both\nindependent and identically distributed (IID) and out-of-distribution (OOD)\ndata, and (2) efficiently generating high-quality link prediction results and\nexplanations. To tackle these challenges, we propose a novel causal inference\nmodel, namely the Independent and Confounded Causal Model (ICCM). ICCM is then\nintegrated into a deep learning architecture that considers both effectiveness\nand efficiency. Extensive experiments demonstrate that our proposed model\nsignificantly outperforms existing methods across link prediction accuracy,\nexplanation quality, and robustness to shortcut features. Our code and datasets\nare anonymously released at https://github.com/2024SIG/SIG.\n",
        "authors": "Lanting Fang; Yulian Yang; Kai Wang; Shanshan Feng; Kaiyu Feng; Jie Gui; Shuliang Wang; Yew-Soon Ong",
        "status": 0,
        "relevancy": 0.5146677004232605,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19207",
        "date": "2024-05-29",
        "title": "A Multi-Source Retrieval Question Answering Framework Based on RAG",
        "abstract": "  With the rapid development of large-scale language models,\nRetrieval-Augmented Generation (RAG) has been widely adopted. However, existing\nRAG paradigms are inevitably influenced by erroneous retrieval information,\nthereby reducing the reliability and correctness of generated results.\nTherefore, to improve the relevance of retrieval information, this study\nproposes a method that replaces traditional retrievers with GPT-3.5, leveraging\nits vast corpus knowledge to generate retrieval information. We also propose a\nweb retrieval based method to implement fine-grained knowledge retrieval,\nUtilizing the powerful reasoning capability of GPT-3.5 to realize semantic\npartitioning of problem.In order to mitigate the illusion of GPT retrieval and\nreduce noise in Web retrieval,we proposes a multi-source retrieval framework,\nnamed MSRAG, which combines GPT retrieval with web retrieval. Experiments on\nmultiple knowledge-intensive QA datasets demonstrate that the proposed\nframework in this study performs better than existing RAG framework in\nenhancing the overall efficiency and accuracy of QA systems.\n",
        "authors": "Ridong Wu; Shuhong Chen; Xiangbiao Su; Yuankai Zhu; Yifei Liao; Jianming Wu",
        "status": 0,
        "relevancy": 0.5088269168654478,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18917",
        "date": "2024-05-29",
        "title": "Causal Action Influence Aware Counterfactual Data Augmentation",
        "abstract": "  Offline data are both valuable and practical resources for teaching robots\ncomplex behaviors. Ideally, learning agents should not be constrained by the\nscarcity of available demonstrations, but rather generalize beyond the training\ndistribution. However, the complexity of real-world scenarios typically\nrequires huge amounts of data to prevent neural network policies from picking\nup on spurious correlations and learning non-causal relationships. We propose\nCAIAC, a data augmentation method that can create feasible synthetic\ntransitions from a fixed dataset without having access to online environment\ninteractions. By utilizing principled methods for quantifying causal influence,\nwe are able to perform counterfactual reasoning by swapping\n$\\it{action}$-unaffected parts of the state-space between independent\ntrajectories in the dataset. We empirically show that this leads to a\nsubstantial increase in robustness of offline learning algorithms against\ndistributional shift.\n",
        "authors": "Núria Armengol Urpí; Marco Bagatella; Marin Vlastelica; Georg Martius",
        "status": 0,
        "relevancy": 0.5087991529676509,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19024",
        "date": "2024-05-29",
        "title": "Inverse Concave-Utility Reinforcement Learning is Inverse Game Theory",
        "abstract": "  We consider inverse reinforcement learning problems with concave utilities.\nConcave Utility Reinforcement Learning (CURL) is a generalisation of the\nstandard RL objective, which employs a concave function of the state occupancy\nmeasure, rather than a linear function. CURL has garnered recent attention for\nits ability to represent instances of many important applications including the\nstandard RL such as imitation learning, pure exploration, constrained MDPs,\noffline RL, human-regularized RL, and others. Inverse reinforcement learning is\na powerful paradigm that focuses on recovering an unknown reward function that\ncan rationalize the observed behaviour of an agent. There has been recent\ntheoretical advances in inverse RL where the problem is formulated as\nidentifying the set of feasible reward functions. However, inverse RL for CURL\nproblems has not been considered previously. In this paper we show that most of\nthe standard IRL results do not apply to CURL in general, since CURL\ninvalidates the classical Bellman equations. This calls for a new theoretical\nframework for the inverse CURL problem. Using a recent equivalence result\nbetween CURL and Mean-field Games, we propose a new definition for the feasible\nrewards for I-CURL by proving that this problem is equivalent to an inverse\ngame theory problem in a subclass of mean-field games. We present initial query\nand sample complexity results for the I-CURL problem under assumptions such as\nLipschitz-continuity. Finally, we outline future directions and applications in\nhuman--AI collaboration enabled by our results.\n",
        "authors": "Mustafa Mert Çelikok; Frans A. Oliehoek; Jan-Willem van de Meent",
        "status": 0,
        "relevancy": 0.5083688591509455,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18741",
        "date": "2024-05-29",
        "title": "Genshin: General Shield for Natural Language Processing with Large\n  Language Models",
        "abstract": "  Large language models (LLMs) like ChatGPT, Gemini, or LLaMA have been\ntrending recently, demonstrating considerable advancement and generalizability\npower in countless domains. However, LLMs create an even bigger black box\nexacerbating opacity, with interpretability limited to few approaches. The\nuncertainty and opacity embedded in LLMs' nature restrict their application in\nhigh-stakes domains like financial fraud, phishing, etc. Current approaches\nmainly rely on traditional textual classification with posterior interpretable\nalgorithms, suffering from attackers who may create versatile adversarial\nsamples to break the system's defense, forcing users to make trade-offs between\nefficiency and robustness. To address this issue, we propose a novel cascading\nframework called Genshin (General Shield for Natural Language Processing with\nLarge Language Models), utilizing LLMs as defensive one-time plug-ins. Unlike\nmost applications of LLMs that try to transform text into something new or\nstructural, Genshin uses LLMs to recover text to its original state. Genshin\naims to combine the generalizability of the LLM, the discrimination of the\nmedian model, and the interpretability of the simple model. Our experiments on\nthe task of sentimental analysis and spam detection have shown fatal flaws of\nthe current median models and exhilarating results on LLMs' recovery ability,\ndemonstrating that Genshin is both effective and efficient. In our ablation\nstudy, we unearth several intriguing observations. Utilizing the LLM defender,\na tool derived from the 4th paradigm, we have reproduced BERT's 15% optimal\nmask rate results in the 3rd paradigm of NLP. Additionally, when employing the\nLLM as a potential adversarial tool, attackers are capable of executing\neffective attacks that are nearly semantically lossless.\n",
        "authors": "Xiao Peng; Tao Liu; Ying Wang",
        "status": 0,
        "relevancy": 0.5078287158605328,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19139",
        "date": "2024-05-29",
        "title": "DGRC: An Effective Fine-tuning Framework for Distractor Generation in\n  Chinese Multi-choice Reading Comprehension",
        "abstract": "  When evaluating a learner's knowledge proficiency, the multiple-choice\nquestion is an efficient and widely used format in standardized tests.\nNevertheless, generating these questions, particularly plausible distractors\n(incorrect options), poses a considerable challenge. Generally, the distractor\ngeneration can be classified into cloze-style distractor generation (CDG) and\nnatural questions distractor generation (NQDG). In contrast to the CDG,\nutilizing pre-trained language models (PLMs) for NQDG presents three primary\nchallenges: (1) PLMs are typically trained to generate ``correct'' content,\nlike answers, while rarely trained to generate ``plausible\" content, like\ndistractors; (2) PLMs often struggle to produce content that aligns well with\nspecific knowledge and the style of exams; (3) NQDG necessitates the model to\nproduce longer, context-sensitive, and question-relevant distractors. In this\nstudy, we introduce a fine-tuning framework named DGRC for NQDG in Chinese\nmulti-choice reading comprehension from authentic examinations. DGRC comprises\nthree major components: hard chain-of-thought, multi-task learning, and\ngeneration mask patterns. The experiment results demonstrate that DGRC\nsignificantly enhances generation performance, achieving a more than 2.5-fold\nimprovement in BLEU scores.\n",
        "authors": "Runfeng Lin; Dacheng Xu; Huijiang Wang; Zebiao Chen; Yating Wang; Shouqiang Liu",
        "status": 0,
        "relevancy": 0.5060433283611545,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18669",
        "date": "2024-05-29",
        "title": "Zipper: A Multi-Tower Decoder Architecture for Fusing Modalities",
        "abstract": "  Integrating multiple generative foundation models, especially those trained\non different modalities, into something greater than the sum of its parts poses\nsignificant challenges. Two key hurdles are the availability of aligned data\n(concepts that contain similar meaning but is expressed differently in\ndifferent modalities), and effectively leveraging unimodal representations in\ncross-domain generative tasks, without compromising their original unimodal\ncapabilities.\n  We propose Zipper, a multi-tower decoder architecture that addresses these\nconcerns by using cross-attention to flexibly compose multimodal generative\nmodels from independently pre-trained unimodal decoders. In our experiments\nfusing speech and text modalities, we show the proposed architecture performs\nvery competitively in scenarios with limited aligned text-speech data. We also\nshowcase the flexibility of our model to selectively maintain unimodal (e.g.,\ntext-to-text generation) generation performance by freezing the corresponding\nmodal tower (e.g. text). In cross-modal tasks such as automatic speech\nrecognition (ASR) where the output modality is text, we show that freezing the\ntext backbone results in negligible performance degradation. In cross-modal\ntasks such as text-to-speech generation (TTS) where the output modality is\nspeech, we show that using a pre-trained speech backbone results in superior\nperformance to the baseline.\n",
        "authors": "Vicky Zayats; Peter Chen; Melissa Merrari; Dirk Padfield",
        "status": 0,
        "relevancy": 0.5045697980937968,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18708",
        "date": "2024-05-29",
        "title": "Cognitive Evolutionary Learning to Select Feature Interactions for\n  Recommender Systems",
        "abstract": "  Feature interaction selection is a fundamental problem in commercial\nrecommender systems. Most approaches equally enumerate all features and\ninteractions by the same pre-defined operation under expert guidance. Their\nrecommendation is unsatisfactory sometimes due to the following issues:\n(1)~They cannot ensure the learning abilities of models because their\narchitectures are poorly adaptable to tasks and data; (2)~Useless features and\ninteractions can bring unnecessary noise and complicate the training process.\nIn this paper, we aim to adaptively evolve the model to select appropriate\noperations, features, and interactions under task guidance. Inspired by the\nevolution and functioning of natural organisms, we propose a novel\n\\textsl{Cognitive EvoLutionary Learning (CELL)} framework, where cognitive\nability refers to a property of organisms that allows them to react and survive\nin diverse environments. It consists of three stages, i.e., DNA search, genome\nsearch, and model functioning. Specifically, if we regard the relationship\nbetween models and tasks as the relationship between organisms and natural\nenvironments, interactions of feature pairs can be analogous to double-stranded\nDNA, of which relevant features and interactions can be analogous to genomes.\nAlong this line, we diagnose the fitness of the model on operations, features,\nand interactions to simulate the survival rates of organisms for natural\nselection. We show that CELL can adaptively evolve into different models for\ndifferent tasks and data, which enables practitioners to access off-the-shelf\nmodels. Extensive experiments on four real-world datasets demonstrate that CELL\nsignificantly outperforms state-of-the-art baselines. Also, we conduct\nsynthetic experiments to ascertain that CELL can consistently discover the\npre-defined interaction patterns for feature pairs.\n",
        "authors": "Runlong Yu; Qixiang Shao; Qi Liu; Huan Liu; Enhong Chen",
        "status": 0,
        "relevancy": 0.502107526650884,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19033",
        "date": "2024-05-29",
        "title": "CiliaGraph: Enabling Expression-enhanced Hyper-Dimensional Computation\n  in Ultra-Lightweight and One-Shot Graph Classification on Edge",
        "abstract": "  Graph Neural Networks (GNNs) are computationally demanding and inefficient\nwhen applied to graph classification tasks in resource-constrained edge\nscenarios due to their inherent process, involving multiple rounds of forward\nand backward propagation. As a lightweight alternative, Hyper-Dimensional\nComputing (HDC), which leverages high-dimensional vectors for data encoding and\nprocessing, offers a more efficient solution by addressing computational\nbottleneck. However, current HDC methods primarily focus on static graphs and\nneglect to effectively capture node attributes and structural information,\nwhich leads to poor accuracy. In this work, we propose CiliaGraph, an enhanced\nexpressive yet ultra-lightweight HDC model for graph classification. This model\nintroduces a novel node encoding strategy that preserves relative distance\nisomorphism for accurate node connection representation. In addition, node\ndistances are utilized as edge weights for information aggregation, and the\nencoded node attributes and structural information are concatenated to obtain a\ncomprehensive graph representation. Furthermore, we explore the relationship\nbetween orthogonality and dimensionality to reduce the dimensions, thereby\nfurther enhancing computational efficiency. Compared to the SOTA GNNs,\nextensive experiments show that CiliaGraph reduces memory usage and accelerates\ntraining speed by an average of 292 times(up to 2341 times) and 103 times(up to\n313 times) respectively while maintaining comparable accuracy.\n",
        "authors": "Yuxi Han; Jihe Wang; Danghui Wang",
        "status": 0,
        "relevancy": 0.49969572401070184,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18823",
        "date": "2024-05-29",
        "title": "Why Reinforcement Learning in Energy Systems Needs Explanations",
        "abstract": "  With economic development, the complexity of infrastructure has increased\ndrastically. Similarly, with the shift from fossil fuels to renewable sources\nof energy, there is a dire need for such systems that not only predict and\nforecast with accuracy but also help in understanding the process of\npredictions. Artificial intelligence and machine learning techniques have\nhelped in finding out wellperforming solutions to different problems in the\nenergy sector. However, the usage of state-of-the-art techniques like\nreinforcement learning is not surprisingly convincing. This paper discusses the\napplication of reinforcement techniques in energy systems and how explanations\nof these models can be helpful\n",
        "authors": "Hallah Shahid Butt; Benjamin Schäfer",
        "status": 0,
        "relevancy": 0.4986922627845327,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18729",
        "date": "2024-05-29",
        "title": "Preferred-Action-Optimized Diffusion Policies for Offline Reinforcement\n  Learning",
        "abstract": "  Offline reinforcement learning (RL) aims to learn optimal policies from\npreviously collected datasets. Recently, due to their powerful representational\ncapabilities, diffusion models have shown significant potential as policy\nmodels for offline RL issues. However, previous offline RL algorithms based on\ndiffusion policies generally adopt weighted regression to improve the policy.\nThis approach optimizes the policy only using the collected actions and is\nsensitive to Q-values, which limits the potential for further performance\nenhancement. To this end, we propose a novel preferred-action-optimized\ndiffusion policy for offline RL. In particular, an expressive conditional\ndiffusion model is utilized to represent the diverse distribution of a behavior\npolicy. Meanwhile, based on the diffusion model, preferred actions within the\nsame behavior distribution are automatically generated through the critic\nfunction. Moreover, an anti-noise preference optimization is designed to\nachieve policy improvement by using the preferred actions, which can adapt to\nnoise-preferred actions for stable training. Extensive experiments demonstrate\nthat the proposed method provides competitive or superior performance compared\nto previous state-of-the-art offline RL methods, particularly in sparse reward\ntasks such as Kitchen and AntMaze. Additionally, we empirically prove the\neffectiveness of anti-noise preference optimization.\n",
        "authors": "Tianle Zhang; Jiayi Guan; Lin Zhao; Yihang Li; Dongjiang Li; Zecui Zeng; Lei Sun; Yue Chen; Xuelong Wei; Lusong Li; Xiaodong He",
        "status": 0,
        "relevancy": 0.4974785576771925,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18867",
        "date": "2024-05-29",
        "title": "Topological Perspectives on Optimal Multimodal Embedding Spaces",
        "abstract": "  Recent strides in multimodal model development have ignited a paradigm shift\nin the realm of text-to-image generation. Among these advancements, CLIP stands\nout as a remarkable achievement which is a sophisticated autoencoder adept at\nencoding both textual and visual information within a unified latent space.\nThis paper delves into a comparative analysis between CLIP and its recent\ncounterpart, CLOOB. To unravel the intricate distinctions within the embedding\nspaces crafted by these models, we employ topological data analysis. Our\napproach encompasses a comprehensive examination of the modality gap drivers,\nthe clustering structures existing across both high and low dimensions, and the\npivotal role that dimension collapse plays in shaping their respective\nembedding spaces. Empirical experiments substantiate the implications of our\nanalyses on downstream performance across various contextual scenarios. Through\nthis investigation, we aim to shed light on the nuanced intricacies that\nunderlie the comparative efficacy of CLIP and CLOOB, offering insights into\ntheir respective strengths and weaknesses, and providing a foundation for\nfurther refinement and advancement in multimodal model research.\n",
        "authors": "Abdul Aziz A. B; A. B Abdul Rahim",
        "status": 0,
        "relevancy": 0.4972126720138256,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19519",
        "date": "2024-05-29",
        "title": "Two-layer retrieval augmented generation framework for low-resource\n  medical question-answering: proof of concept using Reddit data",
        "abstract": "  Retrieval augmented generation (RAG) provides the capability to constrain\ngenerative model outputs, and mitigate the possibility of hallucination, by\nproviding relevant in-context text. The number of tokens a generative large\nlanguage model (LLM) can incorporate as context is finite, thus limiting the\nvolume of knowledge from which to generate an answer. We propose a two-layer\nRAG framework for query-focused answer generation and evaluate a\nproof-of-concept for this framework in the context of query-focused summary\ngeneration from social media forums, focusing on emerging drug-related\ninformation. The evaluations demonstrate the effectiveness of the two-layer\nframework in resource constrained settings to enable researchers in obtaining\nnear real-time data from users.\n",
        "authors": "Sudeshna Das; Yao Ge; Yuting Guo; Swati Rajwal; JaMor Hairston; Jeanne Powell; Drew Walker; Snigdha Peddireddy; Sahithi Lakamana; Selen Bozkurt; Matthew Reyna; Reza Sameni; Yunyu Xiao; Sangmi Kim; Rasheeta Chandler; Natalie Hernandez; Danielle Mowery; Rachel Wightman; Jennifer Love; Anthony Spadaro; Jeanmarie Perrone; Abeed Sarker",
        "status": 0,
        "relevancy": 0.4936405808677772,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19261",
        "date": "2024-05-29",
        "title": "Faster Cascades via Speculative Decoding",
        "abstract": "  Cascades and speculative decoding are two common approaches to improving\nlanguage models' inference efficiency. Both approaches involve interleaving\nmodels of different sizes, but via fundamentally distinct mechanisms: cascades\nemploy a deferral rule that invokes the larger model only for \"hard\" inputs,\nwhile speculative decoding uses speculative execution to primarily invoke the\nlarger model in parallel verification mode. These mechanisms offer different\nbenefits: empirically, cascades are often capable of yielding better quality\nthan even the larger model, while theoretically, speculative decoding offers a\nguarantee of quality-neutrality. In this paper, we leverage the best of both\nthese approaches by designing new speculative cascading techniques that\nimplement their deferral rule through speculative execution. We characterize\nthe optimal deferral rule for our speculative cascades, and employ a plug-in\napproximation to the optimal rule. Through experiments with T5 models on\nbenchmark language tasks, we show that the proposed approach yields better\ncost-quality trade-offs than cascading and speculative decoding baselines.\n",
        "authors": "Harikrishna Narasimhan; Wittawat Jitkrittum; Ankit Singh Rawat; Seungyeon Kim; Neha Gupta; Aditya Krishna Menon; Sanjiv Kumar",
        "status": 0,
        "relevancy": 0.49014235973475473,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19047",
        "date": "2024-05-29",
        "title": "Statistical Context Detection for Deep Lifelong Reinforcement Learning",
        "abstract": "  Context detection involves labeling segments of an online stream of data as\nbelonging to different tasks. Task labels are used in lifelong learning\nalgorithms to perform consolidation or other procedures that prevent\ncatastrophic forgetting. Inferring task labels from online experiences remains\na challenging problem. Most approaches assume finite and low-dimension\nobservation spaces or a preliminary training phase during which task labels are\nlearned. Moreover, changes in the transition or reward functions can be\ndetected only in combination with a policy, and therefore are more difficult to\ndetect than changes in the input distribution. This paper presents an approach\nto learning both policies and labels in an online deep reinforcement learning\nsetting. The key idea is to use distance metrics, obtained via optimal\ntransport methods, i.e., Wasserstein distance, on suitable latent action-reward\nspaces to measure distances between sets of data points from past and current\nstreams. Such distances can then be used for statistical tests based on an\nadapted Kolmogorov-Smirnov calculation to assign labels to sequences of\nexperiences. A rollback procedure is introduced to learn multiple policies by\nensuring that only the appropriate data is used to train the corresponding\npolicy. The combination of task detection and policy deployment allows for the\noptimization of lifelong reinforcement learning agents without an oracle that\nprovides task labels. The approach is tested using two benchmarks and the\nresults show promising performance when compared with related context detection\nalgorithms. The results suggest that optimal transport statistical methods\nprovide an explainable and justifiable procedure for online context detection\nand reward optimization in lifelong reinforcement learning.\n",
        "authors": "Jeffery Dick; Saptarshi Nath; Christos Peridis; Eseoghene Benjamin; Soheil Kolouri; Andrea Soltoggio",
        "status": 0,
        "relevancy": 0.48755249325037087,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19153",
        "date": "2024-05-29",
        "title": "A Study of Plasticity Loss in On-Policy Deep Reinforcement Learning",
        "abstract": "  Continual learning with deep neural networks presents challenges distinct\nfrom both the fixed-dataset and convex continual learning regimes. One such\nchallenge is plasticity loss, wherein a neural network trained in an online\nfashion displays a degraded ability to fit new tasks. This problem has been\nextensively studied in both supervised learning and off-policy reinforcement\nlearning (RL), where a number of remedies have been proposed. Still, plasticity\nloss has received less attention in the on-policy deep RL setting. Here we\nperform an extensive set of experiments examining plasticity loss and a variety\nof mitigation methods in on-policy deep RL. We demonstrate that plasticity loss\nis pervasive under domain shift in this regime, and that a number of methods\ndeveloped to resolve it in other settings fail, sometimes even resulting in\nperformance that is worse than performing no intervention at all. In contrast,\nwe find that a class of ``regenerative'' methods are able to consistently\nmitigate plasticity loss in a variety of contexts, including in gridworld tasks\nand more challenging environments like Montezuma's Revenge and ProcGen.\n",
        "authors": "Arthur Juliani; Jordan T. Ash",
        "status": 0,
        "relevancy": 0.4851474332669473,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18792",
        "date": "2024-05-29",
        "title": "Kernel Metric Learning for In-Sample Off-Policy Evaluation of\n  Deterministic RL Policies",
        "abstract": "  We consider off-policy evaluation (OPE) of deterministic target policies for\nreinforcement learning (RL) in environments with continuous action spaces.\nWhile it is common to use importance sampling for OPE, it suffers from high\nvariance when the behavior policy deviates significantly from the target\npolicy. In order to address this issue, some recent works on OPE proposed\nin-sample learning with importance resampling. Yet, these approaches are not\napplicable to deterministic target policies for continuous action spaces. To\naddress this limitation, we propose to relax the deterministic target policy\nusing a kernel and learn the kernel metrics that minimize the overall mean\nsquared error of the estimated temporal difference update vector of an action\nvalue function, where the action value function is used for policy evaluation.\nWe derive the bias and variance of the estimation error due to this relaxation\nand provide analytic solutions for the optimal kernel metric. In empirical\nstudies using various test domains, we show that the OPE with in-sample\nlearning using the kernel with optimized metric achieves significantly improved\naccuracy than other baselines.\n",
        "authors": "Haanvid Lee; Tri Wahyu Guntara; Jongmin Lee; Yung-Kyun Noh; Kee-Eung Kim",
        "status": 0,
        "relevancy": 0.4828688850997147,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18780",
        "date": "2024-05-29",
        "title": "Quantitative Certification of Bias in Large Language Models",
        "abstract": "  Large Language Models (LLMs) can produce responses that exhibit social biases\nand support stereotypes. However, conventional benchmarking is insufficient to\nthoroughly evaluate LLM bias, as it can not scale to large sets of prompts and\nprovides no guarantees. Therefore, we propose a novel certification framework\nQuaCer-B (Quantitative Certification of Bias) that provides formal guarantees\non obtaining unbiased responses from target LLMs under large sets of prompts. A\ncertificate consists of high-confidence bounds on the probability of obtaining\nbiased responses from the LLM for any set of prompts containing sensitive\nattributes, sampled from a distribution. We illustrate the bias certification\nin LLMs for prompts with various prefixes drawn from given distributions. We\nconsider distributions of random token sequences, mixtures of manual\njailbreaks, and jailbreaks in the LLM's embedding space to certify its bias. We\ncertify popular LLMs with QuaCer-B and present novel insights into their\nbiases.\n",
        "authors": "Isha Chaudhary; Qian Hu; Manoj Kumar; Morteza Ziyadi; Rahul Gupta; Gagandeep Singh",
        "status": 0,
        "relevancy": 0.482455834813305,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19544",
        "date": "2024-05-29",
        "title": "One-Shot Safety Alignment for Large Language Models via Optimal\n  Dualization",
        "abstract": "  The growing safety concerns surrounding Large Language Models (LLMs) raise an\nurgent need to align them with diverse human preferences to simultaneously\nenhance their helpfulness and safety. A promising approach is to enforce safety\nconstraints through Reinforcement Learning from Human Feedback (RLHF). For such\nconstrained RLHF, common Lagrangian-based primal-dual policy optimization\nmethods are computationally expensive and often unstable. This paper presents a\ndualization perspective that reduces constrained alignment to an equivalent\nunconstrained alignment problem. We do so by pre-optimizing a smooth and convex\ndual function that has a closed form. This shortcut eliminates the need for\ncumbersome primal-dual policy iterations, thus greatly reducing the\ncomputational burden and improving training stability. Our strategy leads to\ntwo practical algorithms in model-based and preference-based scenarios (MoCAN\nand PeCAN, respectively). A broad range of experiments demonstrate the\neffectiveness of our methods.\n",
        "authors": "Xinmeng Huang; Shuo Li; Edgar Dobriban; Osbert Bastani; Hamed Hassani; Dongsheng Ding",
        "status": 0,
        "relevancy": 0.4803656048969728,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19534",
        "date": "2024-05-29",
        "title": "Preference Learning Algorithms Do Not Learn Preference Rankings",
        "abstract": "  Preference learning algorithms (e.g., RLHF and DPO) are frequently used to\nsteer LLMs to produce generations that are more preferred by humans, but our\nunderstanding of their inner workings is still limited. In this work, we study\nthe conventional wisdom that preference learning trains models to assign higher\nlikelihoods to more preferred outputs than less preferred outputs, measured via\n$\\textit{ranking accuracy}$. Surprisingly, we find that most state-of-the-art\npreference-tuned models achieve a ranking accuracy of less than 60% on common\npreference datasets. We furthermore derive the $\\textit{idealized ranking\naccuracy}$ that a preference-tuned LLM would achieve if it optimized the DPO or\nRLHF objective perfectly. We demonstrate that existing models exhibit a\nsignificant $\\textit{alignment gap}$ -- $\\textit{i.e.}$, a gap between the\nobserved and idealized ranking accuracies. We attribute this discrepancy to the\nDPO objective, which is empirically and theoretically ill-suited to fix even\nmild ranking errors in the reference model, and derive a simple and efficient\nformula for quantifying the difficulty of learning a given preference\ndatapoint. Finally, we demonstrate that ranking accuracy strongly correlates\nwith the empirically popular win rate metric when the model is close to the\nreference model used in the objective, shedding further light on the\ndifferences between on-policy (e.g., RLHF) and off-policy (e.g., DPO)\npreference learning algorithms.\n",
        "authors": "Angelica Chen; Sadhika Malladi; Lily H. Zhang; Xinyi Chen; Qiuyi Zhang; Rajesh Ranganath; Kyunghyun Cho",
        "status": 0,
        "relevancy": 0.4732342244423171,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19323",
        "date": "2024-05-29",
        "title": "Are Large Language Models Chameleons?",
        "abstract": "  Do large language models (LLMs) have their own worldviews and personality\ntendencies? Simulations in which an LLM was asked to answer subjective\nquestions were conducted more than 1 million times. Comparison of the responses\nfrom different LLMs with real data from the European Social Survey (ESS)\nsuggests that the effect of prompts on bias and variability is fundamental,\nhighlighting major cultural, age, and gender biases. Methods for measuring the\ndifference between LLMs and survey data are discussed, such as calculating\nweighted means and a new proposed measure inspired by Jaccard similarity. We\nconclude that it is important to analyze the robustness and variability of\nprompts before using LLMs to model individual decisions or collective behavior,\nas their imitation abilities are approximate at best.\n",
        "authors": "Mingmeng Geng; Sihong He; Roberto Trotta",
        "status": 0,
        "relevancy": 0.4695448291346914,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18719",
        "date": "2024-05-29",
        "title": "Contextual Position Encoding: Learning to Count What's Important",
        "abstract": "  The attention mechanism is a critical component of Large Language Models\n(LLMs) that allows tokens in a sequence to interact with each other, but is\norder-invariant. Incorporating position encoding (PE) makes it possible to\naddress by position, such as attending to the i-th token. However, current PE\nmethods use token counts to derive position, and thus cannot generalize to\nhigher levels of abstraction, such as attending to the i-th sentence. In this\npaper, we propose a new position encoding method, Contextual Position Encoding\n(CoPE), that allows positions to be conditioned on context by incrementing\nposition only on certain tokens determined by the model. This allows more\ngeneral position addressing such as attending to the $i$-th particular word,\nnoun, or sentence. We show that CoPE can solve the selective copy, counting and\nFlip-Flop tasks where popular position embeddings fail, and improves perplexity\non language modeling and coding tasks.\n",
        "authors": "Olga Golovneva; Tianlu Wang; Jason Weston; Sainbayar Sukhbaatar",
        "status": 0,
        "relevancy": 0.46879091917938376,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19458",
        "date": "2024-05-29",
        "title": "MemControl: Mitigating Memorization in Medical Diffusion Models via\n  Automated Parameter Selection",
        "abstract": "  Diffusion models show a remarkable ability in generating images that closely\nmirror the training distribution. However, these models are prone to training\ndata memorization, leading to significant privacy, ethical, and legal concerns,\nparticularly in sensitive fields such as medical imaging. We hypothesize that\nmemorization is driven by the overparameterization of deep models, suggesting\nthat regularizing model capacity during fine-tuning could be an effective\nmitigation strategy. Parameter-efficient fine-tuning (PEFT) methods offer a\npromising approach to capacity control by selectively updating specific\nparameters. However, finding the optimal subset of learnable parameters that\nbalances generation quality and memorization remains elusive. To address this\nchallenge, we propose a bi-level optimization framework that guides automated\nparameter selection by utilizing memorization and generation quality metrics as\nrewards. Our framework successfully identifies the optimal parameter set to be\nupdated to satisfy the generation-memorization tradeoff. We perform our\nexperiments for the specific task of medical image generation and outperform\nexisting state-of-the-art training-time mitigation strategies by fine-tuning as\nfew as 0.019% of model parameters. Furthermore, we show that the strategies\nlearned through our framework are transferable across different datasets and\ndomains. Our proposed framework is scalable to large datasets and agnostic to\nthe choice of reward functions. Finally, we show that our framework can be\ncombined with existing approaches for further memorization mitigation.\n",
        "authors": "Raman Dutt; Pedro Sanchez; Ondrej Bohdal; Sotirios A. Tsaftaris; Timothy Hospedales",
        "status": 0,
        "relevancy": 0.46231410262382755,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19032",
        "date": "2024-05-29",
        "title": "Large Language Models for Code Summarization",
        "abstract": "  Recently, there has been increasing activity in using deep learning for\nsoftware engineering, including tasks like code generation and summarization.\nIn particular, the most recent coding Large Language Models seem to perform\nwell on these problems. In this technical report, we aim to review how these\nmodels perform in code explanation/summarization, while also investigating\ntheir code generation capabilities (based on natural language descriptions).\n",
        "authors": "Balázs Szalontai; Gergő Szalay; Tamás Márton; Anna Sike; Balázs Pintér; Tibor Gregorics",
        "status": 0,
        "relevancy": 0.4602678976928025,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18693",
        "date": "2024-05-29",
        "title": "DeepHGNN: Study of Graph Neural Network based Forecasting Methods for\n  Hierarchically Related Multivariate Time Series",
        "abstract": "  Graph Neural Networks (GNN) have gained significant traction in the\nforecasting domain, especially for their capacity to simultaneously account for\nintra-series temporal correlations and inter-series relationships. This paper\nintroduces a novel Hierarchical GNN (DeepHGNN) framework, explicitly designed\nfor forecasting in complex hierarchical structures. The uniqueness of DeepHGNN\nlies in its innovative graph-based hierarchical interpolation and an end-to-end\nreconciliation mechanism. This approach ensures forecast accuracy and coherence\nacross various hierarchical levels while sharing signals across them,\naddressing a key challenge in hierarchical forecasting. A critical insight in\nhierarchical time series is the variance in forecastability across levels, with\nupper levels typically presenting more predictable components. DeepHGNN\ncapitalizes on this insight by pooling and leveraging knowledge from all\nhierarchy levels, thereby enhancing the overall forecast accuracy. Our\ncomprehensive evaluation set against several state-of-the-art models confirm\nthe superior performance of DeepHGNN. This research not only demonstrates\nDeepHGNN's effectiveness in achieving significantly improved forecast accuracy\nbut also contributes to the understanding of graph-based methods in\nhierarchical time series forecasting.\n",
        "authors": "Abishek Sriramulu; Nicolas Fourrier; Christoph Bergmeir",
        "status": 0,
        "relevancy": 0.4588965895437087,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19423",
        "date": "2024-05-29",
        "title": "Evaluating Vision-Language Models on Bistable Images",
        "abstract": "  Bistable images, also known as ambiguous or reversible images, present visual\nstimuli that can be seen in two distinct interpretations, though not\nsimultaneously by the observer. In this study, we conduct the most extensive\nexamination of vision-language models using bistable images to date. We\nmanually gathered a dataset of 29 bistable images, along with their associated\nlabels, and subjected them to 116 different manipulations in brightness, tint,\nand rotation. We evaluated twelve different models in both classification and\ngenerative tasks across six model architectures. Our findings reveal that, with\nthe exception of models from the Idefics family and LLaVA1.5-13b, there is a\npronounced preference for one interpretation over another among the models, and\nminimal variance under image manipulations, with few exceptions on image\nrotations. Additionally, we compared the model preferences with humans, noting\nthat the models do not exhibit the same continuity biases as humans and often\ndiverge from human initial interpretations. We also investigated the influence\nof variations in prompts and the use of synonymous labels, discovering that\nthese factors significantly affect model interpretations more than image\nmanipulations showing a higher influence of the language priors on bistable\nimage interpretations compared to image-text training data. All code and data\nis open sourced.\n",
        "authors": "Artemis Panagopoulou; Coby Melkin; Chris Callison-Burch",
        "status": 0,
        "relevancy": 0.4585280500520289,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19250",
        "date": "2024-05-29",
        "title": "Kotlin ML Pack: Technical Report",
        "abstract": "  In this technical report, we present three novel datasets of Kotlin code:\nKStack, KStack-clean, and KExercises. We also describe the results of\nfine-tuning CodeLlama and DeepSeek models on this data. Additionally, we\npresent a version of the HumanEval benchmark rewritten by human experts into\nKotlin - both the solutions and the tests. Our results demonstrate that small,\nhigh-quality datasets (KStack-clean and KExercises) can significantly improve\nmodel performance on code generation tasks, achieving up to a 16-point increase\nin pass rate on the HumanEval benchmark. Lastly, we discuss potential future\nwork in the field of improving language modeling for Kotlin, including the use\nof static analysis tools in the learning process and the introduction of more\nintricate and realistic benchmarks.\n",
        "authors": "Sergey Titov; Mikhail Evtikhiev; Anton Shapkin; Oleg Smirnov; Sergei Boytsov; Sergei Boytsov; Dariia Karaeva; Maksim Sheptyakov; Mikhail Arkhipov; Timofey Bryksin; Egor Bogomolov",
        "status": 0,
        "relevancy": 0.4559003778105136,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18875",
        "date": "2024-05-29",
        "title": "Counterfactual Metarules for Local and Global Recourse",
        "abstract": "  We introduce T-CREx, a novel model-agnostic method for local and global\ncounterfactual explanation (CE), which summarises recourse options for both\nindividuals and groups in the form of human-readable rules. It leverages\ntree-based surrogate models to learn the counterfactual rules, alongside\n'metarules' denoting their regions of optimality, providing both a global\nanalysis of model behaviour and diverse recourse options for users. Experiments\nindicate that T-CREx achieves superior aggregate performance over existing\nrule-based baselines on a range of CE desiderata, while being orders of\nmagnitude faster to run.\n",
        "authors": "Tom Bewley; Salim I. Amoukou; Saumitra Mishra; Daniele Magazzeni; Manuela Veloso",
        "status": 0,
        "relevancy": 0.45396323771383096,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19074",
        "date": "2024-05-29",
        "title": "Resurrecting Old Classes with New Data for Exemplar-Free Continual\n  Learning",
        "abstract": "  Continual learning methods are known to suffer from catastrophic forgetting,\na phenomenon that is particularly hard to counter for methods that do not store\nexemplars of previous tasks. Therefore, to reduce potential drift in the\nfeature extractor, existing exemplar-free methods are typically evaluated in\nsettings where the first task is significantly larger than subsequent tasks.\nTheir performance drops drastically in more challenging settings starting with\na smaller first task. To address this problem of feature drift estimation for\nexemplar-free methods, we propose to adversarially perturb the current samples\nsuch that their embeddings are close to the old class prototypes in the old\nmodel embedding space. We then estimate the drift in the embedding space from\nthe old to the new model using the perturbed images and compensate the\nprototypes accordingly. We exploit the fact that adversarial samples are\ntransferable from the old to the new feature space in a continual learning\nsetting. The generation of these images is simple and computationally cheap. We\ndemonstrate in our experiments that the proposed approach better tracks the\nmovement of prototypes in embedding space and outperforms existing methods on\nseveral standard continual learning benchmarks as well as on fine-grained\ndatasets. Code is available at https://github.com/dipamgoswami/ADC.\n",
        "authors": "Dipam Goswami; Albin Soutif--Cormerais; Yuyang Liu; Sandesh Kamath; Bartłomiej Twardowski; Joost van de Weijer",
        "status": 0,
        "relevancy": 0.45395732423525503,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19575",
        "date": "2024-05-29",
        "title": "A Deep Convolutional Neural Network-based Model for Aspect and Polarity\n  Classification in Hausa Movie Reviews",
        "abstract": "  Aspect-based Sentiment Analysis (ABSA) is crucial for understanding sentiment\nnuances in text, especially across diverse languages and cultures. This paper\nintroduces a novel Deep Convolutional Neural Network (CNN)-based model tailored\nfor aspect and polarity classification in Hausa movie reviews, an\nunderrepresented language in sentiment analysis research. A comprehensive Hausa\nABSA dataset is created, filling a significant gap in resource availability.\nThe dataset, preprocessed using sci-kit-learn for TF-IDF transformation,\nincludes manually annotated aspect-level feature ontology words and sentiment\npolarity assignments. The proposed model combines CNNs with attention\nmechanisms for aspect-word prediction, leveraging contextual information and\nsentiment polarities. With 91% accuracy on aspect term extraction and 92% on\nsentiment polarity classification, the model outperforms traditional machine\nmodels, offering insights into specific aspects and sentiments. This study\nadvances ABSA research, particularly in underrepresented languages, with\nimplications for cross-cultural linguistic research.\n",
        "authors": "Umar Ibrahim; Abubakar Yakubu Zandam; Fatima Muhammad Adam; Aminu Musa",
        "status": 0,
        "relevancy": 0.45257678300257476,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19420",
        "date": "2024-05-29",
        "title": "Using Contrastive Learning with Generative Similarity to Learn Spaces\n  that Capture Human Inductive Biases",
        "abstract": "  Humans rely on strong inductive biases to learn from few examples and\nabstract useful information from sensory data. Instilling such biases in\nmachine learning models has been shown to improve their performance on various\nbenchmarks including few-shot learning, robustness, and alignment. However,\nfinding effective training procedures to achieve that goal can be challenging\nas psychologically-rich training data such as human similarity judgments are\nexpensive to scale, and Bayesian models of human inductive biases are often\nintractable for complex, realistic domains. Here, we address this challenge by\nintroducing a Bayesian notion of generative similarity whereby two datapoints\nare considered similar if they are likely to have been sampled from the same\ndistribution. This measure can be applied to complex generative processes,\nincluding probabilistic programs. We show that generative similarity can be\nused to define a contrastive learning objective even when its exact form is\nintractable, enabling learning of spatial embeddings that express specific\ninductive biases. We demonstrate the utility of our approach by showing how it\ncan be used to capture human inductive biases for geometric shapes, and to\nbetter distinguish different abstract drawing styles that are parameterized by\nprobabilistic programs.\n",
        "authors": "Raja Marjieh; Sreejan Kumar; Declan Campbell; Liyi Zhang; Gianluca Bencomo; Jake Snell; Thomas L. Griffiths",
        "status": 0,
        "relevancy": 0.45076182816763066,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18724",
        "date": "2024-05-29",
        "title": "Adapting Differential Molecular Representation with Hierarchical Prompts\n  for Multi-label Property Prediction",
        "abstract": "  Accurate prediction of molecular properties is critical in the field of drug\ndiscovery. However, existing methods do not fully consider the fact that\nmolecules in the real world usually possess multiple property labels, and\ncomplex high-order relationships may exist among these labels. Therefore,\nmolecular representation learning models should generate differential molecular\nrepresentations that consider multi-granularity correlation information among\ntasks. To this end, our research introduces a Hierarchical Prompted Molecular\nRepresentation Learning Framework (HiPM), which enhances the differential\nexpression of tasks in molecular representations through task-aware prompts,\nand utilizes shared information among labels to mitigate negative transfer\nbetween different tasks. HiPM primarily consists of two core components: the\nMolecular Representation Encoder (MRE) and the Task-Aware Prompter (TAP). The\nMRE employs a hierarchical message-passing network architecture to capture\nmolecular features at both the atomic and motif levels, while the TAP uses\nagglomerative hierarchical clustering to build a prompt tree that reflects the\naffinity and distinctiveness of tasks, enabling the model to effectively handle\nthe complexity of multi-label property predictions. Extensive experiments\ndemonstrate that HiPM achieves state-of-the-art performance across various\nmulti-label datasets, offering a new perspective on multi-label molecular\nrepresentation learning.\n",
        "authors": "Linjia Kang; Songhua Zhou; Shuyan Fang; Shichao Liu; Wen Zhang",
        "status": 0,
        "relevancy": 0.44709170221701766,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18810",
        "date": "2024-05-29",
        "title": "UniPTS: A Unified Framework for Proficient Post-Training Sparsity",
        "abstract": "  Post-training Sparsity (PTS) is a recently emerged avenue that chases\nefficient network sparsity with limited data in need. Existing PTS methods,\nhowever, undergo significant performance degradation compared with traditional\nmethods that retrain the sparse networks via the whole dataset, especially at\nhigh sparsity ratios. In this paper, we attempt to reconcile this disparity by\ntransposing three cardinal factors that profoundly alter the performance of\nconventional sparsity into the context of PTS. Our endeavors particularly\ncomprise (1) A base-decayed sparsity objective that promotes efficient\nknowledge transferring from dense network to the sparse counterpart. (2) A\nreducing-regrowing search algorithm designed to ascertain the optimal sparsity\ndistribution while circumventing overfitting to the small calibration set in\nPTS. (3) The employment of dynamic sparse training predicated on the preceding\naspects, aimed at comprehensively optimizing the sparsity structure while\nensuring training stability. Our proposed framework, termed UniPTS, is\nvalidated to be much superior to existing PTS methods across extensive\nbenchmarks. As an illustration, it amplifies the performance of POT, a recently\nproposed recipe, from 3.9% to 68.6% when pruning ResNet-50 at 90% sparsity\nratio on ImageNet. We release the code of our paper at\nhttps://github.com/xjjxmu/UniPTS.\n",
        "authors": "Jingjing Xie; Yuxin Zhang; Mingbao Lin; Zhihang Lin; Liujuan Cao; Rongrong Ji",
        "status": 0,
        "relevancy": 0.447029926017696,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19026",
        "date": "2024-05-29",
        "title": "DiveR-CT: Diversity-enhanced Red Teaming with Relaxing Constraints",
        "abstract": "  Recent advances in large language models (LLMs) have made them indispensable,\nraising significant concerns over managing their safety. Automated red teaming\noffers a promising alternative to the labor-intensive and error-prone manual\nprobing for vulnerabilities, providing more consistent and scalable safety\nevaluations. However, existing approaches often compromise diversity by\nfocusing on maximizing attack success rate. Additionally, methods that decrease\nthe cosine similarity from historical embeddings with semantic diversity\nrewards lead to novelty stagnation as history grows. To address these issues,\nwe introduce DiveR-CT, which relaxes conventional constraints on the objective\nand semantic reward, granting greater freedom for the policy to enhance\ndiversity. Our experiments demonstrate DiveR-CT's marked superiority over\nbaselines by 1) generating data that perform better in various diversity\nmetrics across different attack success rate levels, 2) better-enhancing\nresiliency in blue team models through safety tuning based on collected data,\n3) allowing dynamic control of objective weights for reliable and controllable\nattack success rates, and 4) reducing susceptibility to reward\noveroptimization. Project details and code can be found at\nhttps://andrewzh112.github.io/#diverct.\n",
        "authors": "Andrew Zhao; Quentin Xu; Matthieu Lin; Shenzhi Wang; Yong-jin Liu; Zilong Zheng; Gao Huang",
        "status": 0,
        "relevancy": 0.4464088830842974,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18758",
        "date": "2024-05-29",
        "title": "Learning to Continually Learn with the Bayesian Principle",
        "abstract": "  In the present era of deep learning, continual learning research is mainly\nfocused on mitigating forgetting when training a neural network with stochastic\ngradient descent on a non-stationary stream of data. On the other hand, in the\nmore classical literature of statistical machine learning, many models have\nsequential Bayesian update rules that yield the same learning outcome as the\nbatch training, i.e., they are completely immune to catastrophic forgetting.\nHowever, they are often overly simple to model complex real-world data. In this\nwork, we adopt the meta-learning paradigm to combine the strong\nrepresentational power of neural networks and simple statistical models'\nrobustness to forgetting. In our novel meta-continual learning framework,\ncontinual learning takes place only in statistical models via ideal sequential\nBayesian update rules, while neural networks are meta-learned to bridge the raw\ndata and the statistical models. Since the neural networks remain fixed during\ncontinual learning, they are protected from catastrophic forgetting. This\napproach not only achieves significantly improved performance but also exhibits\nexcellent scalability. Since our approach is domain-agnostic and\nmodel-agnostic, it can be applied to a wide range of problems and easily\nintegrated with existing model architectures.\n",
        "authors": "Soochan Lee; Hyeonseong Jeon; Jaehyeon Son; Gunhee Kim",
        "status": 0,
        "relevancy": 0.445099674002285,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18770",
        "date": "2024-05-29",
        "title": "Leveraging Many-To-Many Relationships for Defending Against\n  Visual-Language Adversarial Attacks",
        "abstract": "  Recent studies have revealed that vision-language (VL) models are vulnerable\nto adversarial attacks for image-text retrieval (ITR). However, existing\ndefense strategies for VL models primarily focus on zero-shot image\nclassification, which do not consider the simultaneous manipulation of image\nand text, as well as the inherent many-to-many (N:N) nature of ITR, where a\nsingle image can be described in numerous ways, and vice versa. To this end,\nthis paper studies defense strategies against adversarial attacks on VL models\nfor ITR for the first time. Particularly, we focus on how to leverage the N:N\nrelationship in ITR to enhance adversarial robustness. We found that, although\nadversarial training easily overfits to specific one-to-one (1:1) image-text\npairs in the train data, diverse augmentation techniques to create one-to-many\n(1:N) / many-to-one (N:1) image-text pairs can significantly improve\nadversarial robustness in VL models. Additionally, we show that the alignment\nof the augmented image-text pairs is crucial for the effectiveness of the\ndefense strategy, and that inappropriate augmentations can even degrade the\nmodel's performance. Based on these findings, we propose a novel defense\nstrategy that leverages the N:N relationship in ITR, which effectively\ngenerates diverse yet highly-aligned N:N pairs using basic augmentations and\ngenerative model-based augmentations. This work provides a novel perspective on\ndefending against adversarial attacks in VL tasks and opens up new research\ndirections for future work.\n",
        "authors": "Futa Waseda; Antonio Tejero-de-Pablos",
        "status": 0,
        "relevancy": 0.44258475393659946,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18710",
        "date": "2024-05-29",
        "title": "To FP8 and Back Again: Quantifying the Effects of Reducing Precision on\n  LLM Training Stability",
        "abstract": "  The massive computational costs associated with large language model (LLM)\npretraining have spurred great interest in reduced-precision floating-point\nrepresentations to accelerate the process. As a result, the BrainFloat16 (BF16)\nprecision has become the de facto standard for LLM training, with hardware\nsupport included in recent accelerators. This trend has gone even further in\nthe latest processors, where FP8 has recently been introduced. However, prior\nexperience with FP16, which was found to be less stable than BF16, raises\nconcerns as to whether FP8, with even fewer bits than FP16, can be a\ncost-effective option for LLM training. We argue that reduced-precision\ntraining schemes must have similar training stability and hyperparameter\nsensitivities to their higher-precision counterparts in order to be\ncost-effective. However, we find that currently available methods for FP8\ntraining are not robust enough to allow their use as economical replacements.\nThis prompts us to investigate the stability of reduced-precision LLM training\nin terms of robustness across random seeds and learning rates. To this end, we\npropose new evaluation techniques and a new metric for quantifying loss\nlandscape sharpness in autoregressive language models. By simulating\nincremental bit reductions in floating-point representations, we analyze the\nrelationship between representational power and training stability with the\nintent of aiding future research into the field.\n",
        "authors": "Joonhyung Lee; Jeongin Bae; Byeongwook Kim; Se Jung Kwon; Dongsoo Lee",
        "status": 0,
        "relevancy": 0.4413392843518984,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18881",
        "date": "2024-05-29",
        "title": "Tuning-Free Alignment of Diffusion Models with Direct Noise Optimization",
        "abstract": "  In this work, we focus on the alignment problem of diffusion models with a\ncontinuous reward function, which represents specific objectives for downstream\ntasks, such as improving human preference. The central goal of the alignment\nproblem is to adjust the distribution learned by diffusion models such that the\ngenerated samples maximize the target reward function. We propose a novel\nalignment approach, named Direct Noise Optimization (DNO), that optimizes the\ninjected noise during the sampling process of diffusion models. By design, DNO\nis tuning-free and prompt-agnostic, as the alignment occurs in an online\nfashion during generation. We rigorously study the theoretical properties of\nDNO and also propose variants to deal with non-differentiable reward functions.\nFurthermore, we identify that naive implementation of DNO occasionally suffers\nfrom the out-of-distribution reward hacking problem, where optimized samples\nhave high rewards but are no longer in the support of the pretrained\ndistribution. To remedy this issue, we leverage classical high-dimensional\nstatistics theory and propose to augment the DNO loss with certain probability\nregularization. We conduct extensive experiments on several popular reward\nfunctions trained on human feedback data and demonstrate that the proposed DNO\napproach achieves state-of-the-art reward scores as well as high image quality,\nall within a reasonable time budget for generation.\n",
        "authors": "Zhiwei Tang; Jiangweizhi Peng; Jiasheng Tang; Mingyi Hong; Fan Wang; Tsung-Hui Chang",
        "status": 0,
        "relevancy": 0.4371682751270487,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18832",
        "date": "2024-05-29",
        "title": "MoNDE: Mixture of Near-Data Experts for Large-Scale Sparse Models",
        "abstract": "  Mixture-of-Experts (MoE) large language models (LLM) have memory requirements\nthat often exceed the GPU memory capacity, requiring costly parameter movement\nfrom secondary memories to the GPU for expert computation. In this work, we\npresent Mixture of Near-Data Experts (MoNDE), a near-data computing solution\nthat efficiently enables MoE LLM inference. MoNDE reduces the volume of MoE\nparameter movement by transferring only the $\\textit{hot}$ experts to the GPU,\nwhile computing the remaining $\\textit{cold}$ experts inside the host memory\ndevice. By replacing the transfers of massive expert parameters with the ones\nof small activations, MoNDE enables far more communication-efficient MoE\ninference, thereby resulting in substantial speedups over the existing\nparameter offloading frameworks for both encoder and decoder operations.\n",
        "authors": "Taehyun Kim; Kwanseok Choi; Youngmock Cho; Jaehoon Cho; Hyuk-Jae Lee; Jaewoong Sim",
        "status": 0,
        "relevancy": 0.43558057637047565,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19132",
        "date": "2024-05-29",
        "title": "Analyzing Chat Protocols of Novice Programmers Solving Introductory\n  Programming Tasks with ChatGPT",
        "abstract": "  Large Language Models (LLMs) have taken the world by storm, and students are\nassumed to use related tools at a great scale. In this research paper we aim to\ngain an understanding of how introductory programming students chat with LLMs\nand related tools, e.g., ChatGPT-3.5. To address this goal, computing students\nat a large German university were motivated to solve programming exercises with\nthe assistance of ChatGPT as part of their weekly introductory course\nexercises. Then students (n=213) submitted their chat protocols (with 2335\nprompts in sum) as data basis for this analysis. The data was analyzed w.r.t.\nthe prompts, frequencies, the chats' progress, contents, and other use pattern,\nwhich revealed a great variety of interactions, both potentially supportive and\nconcerning. Learning about students' interactions with ChatGPT will help inform\nand align teaching practices and instructions for future introductory\nprogramming courses in higher education.\n",
        "authors": "Andreas Scholl; Daniel Schiffner; Natalie Kiesler",
        "status": 0,
        "relevancy": 0.4319753617315164,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19121",
        "date": "2024-05-29",
        "title": "Spatio-Spectral Graph Neural Networks",
        "abstract": "  Spatial Message Passing Graph Neural Networks (MPGNNs) are widely used for\nlearning on graph-structured data. However, key limitations of l-step MPGNNs\nare that their \"receptive field\" is typically limited to the l-hop neighborhood\nof a node and that information exchange between distant nodes is limited by\nover-squashing. Motivated by these limitations, we propose Spatio-Spectral\nGraph Neural Networks (S$^2$GNNs) -- a new modeling paradigm for Graph Neural\nNetworks (GNNs) that synergistically combines spatially and spectrally\nparametrized graph filters. Parameterizing filters partially in the frequency\ndomain enables global yet efficient information propagation. We show that\nS$^2$GNNs vanquish over-squashing and yield strictly tighter\napproximation-theoretic error bounds than MPGNNs. Further, rethinking graph\nconvolutions at a fundamental level unlocks new design spaces. For example,\nS$^2$GNNs allow for free positional encodings that make them strictly more\nexpressive than the 1-Weisfeiler-Lehman (WL) test. Moreover, to obtain\ngeneral-purpose S$^2$GNNs, we propose spectrally parametrized filters for\ndirected graphs. S$^2$GNNs outperform spatial MPGNNs, graph transformers, and\ngraph rewirings, e.g., on the peptide long-range benchmark tasks, and are\ncompetitive with state-of-the-art sequence modeling. On a 40 GB GPU, S$^2$GNNs\nscale to millions of nodes.\n",
        "authors": "Simon Geisler; Arthur Kosmala; Daniel Herbst; Stephan Günnemann",
        "status": 0,
        "relevancy": 0.430269302084484,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19098",
        "date": "2024-05-29",
        "title": "Efficient Black-box Adversarial Attacks via Bayesian Optimization Guided\n  by a Function Prior",
        "abstract": "  This paper studies the challenging black-box adversarial attack that aims to\ngenerate adversarial examples against a black-box model by only using output\nfeedback of the model to input queries. Some previous methods improve the query\nefficiency by incorporating the gradient of a surrogate white-box model into\nquery-based attacks due to the adversarial transferability. However, the\nlocalized gradient is not informative enough, making these methods still\nquery-intensive. In this paper, we propose a Prior-guided Bayesian Optimization\n(P-BO) algorithm that leverages the surrogate model as a global function prior\nin black-box adversarial attacks. As the surrogate model contains rich prior\ninformation of the black-box one, P-BO models the attack objective with a\nGaussian process whose mean function is initialized as the surrogate model's\nloss. Our theoretical analysis on the regret bound indicates that the\nperformance of P-BO may be affected by a bad prior. Therefore, we further\npropose an adaptive integration strategy to automatically adjust a coefficient\non the function prior by minimizing the regret bound. Extensive experiments on\nimage classifiers and large vision-language models demonstrate the superiority\nof the proposed algorithm in reducing queries and improving attack success\nrates compared with the state-of-the-art black-box attacks. Code is available\nat https://github.com/yibo-miao/PBO-Attack.\n",
        "authors": "Shuyu Cheng; Yibo Miao; Yinpeng Dong; Xiao Yang; Xiao-Shan Gao; Jun Zhu",
        "status": 0,
        "relevancy": 0.4225890656422713,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18732",
        "date": "2024-05-29",
        "title": "Gemini & Physical World: Large Language Models Can Estimate the\n  Intensity of Earthquake Shaking from Multi-Modal Social Media Posts",
        "abstract": "  This paper presents a novel approach for estimating the ground shaking\nintensity using social media data and CCTV footage. Employing the Gemini Pro\n(Reid et al. 2024) model, a multi-modal language model, we demonstrate the\nability to extract relevant information from unstructured data utilizing\ngenerative AI and natural language processing. The model output, in the form of\nModified Mercalli Intensity (MMI) values, align well with independent\nobservational data. Furthermore, our results suggest that beyond its advanced\nvisual and auditory understanding abilities, Gemini appears to utilize\nadditional sources of knowledge, including a simplified understanding of the\ngeneral relationship between earthquake magnitude, distance, and MMI intensity,\nwhich it presumably acquired during its training, in its reasoning and\ndecision-making processes. These findings raise intriguing questions about the\nextent of Gemini's general understanding of the physical world and its\nphenomena. The ability of Gemini to generate results consistent with\nestablished scientific knowledge highlights the potential of LLMs like Gemini\nin augmenting our understanding of complex physical phenomena such as\nearthquakes. More specifically, the results of this study highlight the\npotential of LLMs like Gemini to revolutionize citizen seismology by enabling\nrapid, effective, and flexible analysis of crowdsourced data from eyewitness\naccounts for assessing earthquake impact and providing crisis situational\nawareness. This approach holds great promise for improving early warning\nsystems, disaster response, and overall resilience in earthquake-prone regions.\nThis study provides a significant step toward harnessing the power of social\nmedia and AI for earthquake disaster mitigation.\n",
        "authors": "S. Mostafa Mousavi; Marc Stogaitis; Tajinder Gadh; Richard M Allen; Alexei Barski; Robert Bosch; Patrick Robertson; Nivetha Thiruverahan; Youngmin Cho",
        "status": 0,
        "relevancy": 0.4221081965668697,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18902",
        "date": "2024-05-29",
        "title": "A Causal Framework for Evaluating Deferring Systems",
        "abstract": "  Deferring systems extend supervised Machine Learning (ML) models with the\npossibility to defer predictions to human experts. However, evaluating the\nimpact of a deferring strategy on system accuracy is still an overlooked area.\nThis paper fills this gap by evaluating deferring systems through a causal\nlens. We link the potential outcomes framework for causal inference with\ndeferring systems. This allows us to identify the causal impact of the\ndeferring strategy on predictive accuracy. We distinguish two scenarios. In the\nfirst one, we can access both the human and the ML model predictions for the\ndeferred instances. In such a case, we can identify the individual causal\neffects for deferred instances and aggregates of them. In the second scenario,\nonly human predictions are available for the deferred instances. In this case,\nwe can resort to regression discontinuity design to estimate a local causal\neffect. We empirically evaluate our approach on synthetic and real datasets for\nseven deferring systems from the literature.\n",
        "authors": "Filippo Palomba; Andrea Pugnana; José Manuel Alvarez; Salvatore Ruggieri",
        "status": 0,
        "relevancy": 0.42099516588555763,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18852",
        "date": "2024-05-29",
        "title": "LetsMap: Unsupervised Representation Learning for Semantic BEV Mapping",
        "abstract": "  Semantic Bird's Eye View (BEV) maps offer a rich representation with strong\nocclusion reasoning for various decision making tasks in autonomous driving.\nHowever, most BEV mapping approaches employ a fully supervised learning\nparadigm that relies on large amounts of human-annotated BEV ground truth data.\nIn this work, we address this limitation by proposing the first unsupervised\nrepresentation learning approach to generate semantic BEV maps from a monocular\nfrontal view (FV) image in a label-efficient manner. Our approach pretrains the\nnetwork to independently reason about scene geometry and scene semantics using\ntwo disjoint neural pathways in an unsupervised manner and then finetunes it\nfor the task of semantic BEV mapping using only a small fraction of labels in\nthe BEV. We achieve label-free pretraining by exploiting spatial and temporal\nconsistency of FV images to learn scene geometry while relying on a novel\ntemporal masked autoencoder formulation to encode the scene representation.\nExtensive evaluations on the KITTI-360 and nuScenes datasets demonstrate that\nour approach performs on par with the existing state-of-the-art approaches\nwhile using only 1% of BEV labels and no additional labeled data.\n",
        "authors": "Nikhil Gosala; Kürsat Petek; B Ravi Kiran; Senthil Yogamani; Paulo Drews-Jr; Wolfram Burgard; Abhinav Valada",
        "status": 0,
        "relevancy": 0.41065188419580223,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18931",
        "date": "2024-05-29",
        "title": "EntProp: High Entropy Propagation for Improving Accuracy and Robustness",
        "abstract": "  Deep neural networks (DNNs) struggle to generalize to out-of-distribution\ndomains that are different from those in training despite their impressive\nperformance. In practical applications, it is important for DNNs to have both\nhigh standard accuracy and robustness against out-of-distribution domains. One\ntechnique that achieves both of these improvements is disentangled learning\nwith mixture distribution via auxiliary batch normalization layers (ABNs). This\ntechnique treats clean and transformed samples as different domains, allowing a\nDNN to learn better features from mixed domains. However, if we distinguish the\ndomains of the samples based on entropy, we find that some transformed samples\nare drawn from the same domain as clean samples, and these samples are not\ncompletely different domains. To generate samples drawn from a completely\ndifferent domain than clean samples, we hypothesize that transforming clean\nhigh-entropy samples to further increase the entropy generates\nout-of-distribution samples that are much further away from the in-distribution\ndomain. On the basis of the hypothesis, we propose high entropy\npropagation~(EntProp), which feeds high-entropy samples to the network that\nuses ABNs. We introduce two techniques, data augmentation and free adversarial\ntraining, that increase entropy and bring the sample further away from the\nin-distribution domain. These techniques do not require additional training\ncosts. Our experimental results show that EntProp achieves higher standard\naccuracy and robustness with a lower training cost than the baseline methods.\nIn particular, EntProp is highly effective at training on small datasets.\n",
        "authors": "Shohei Enomoto",
        "status": 0,
        "relevancy": 0.4100677003887617,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19237",
        "date": "2024-05-29",
        "title": "ConceptPrune: Concept Editing in Diffusion Models via Skilled Neuron\n  Pruning",
        "abstract": "  While large-scale text-to-image diffusion models have demonstrated impressive\nimage-generation capabilities, there are significant concerns about their\npotential misuse for generating unsafe content, violating copyright, and\nperpetuating societal biases. Recently, the text-to-image generation community\nhas begun addressing these concerns by editing or unlearning undesired concepts\nfrom pre-trained models. However, these methods often involve data-intensive\nand inefficient fine-tuning or utilize various forms of token remapping,\nrendering them susceptible to adversarial jailbreaks. In this paper, we present\na simple and effective training-free approach, ConceptPrune, wherein we first\nidentify critical regions within pre-trained models responsible for generating\nundesirable concepts, thereby facilitating straightforward concept unlearning\nvia weight pruning. Experiments across a range of concepts including artistic\nstyles, nudity, object erasure, and gender debiasing demonstrate that target\nconcepts can be efficiently erased by pruning a tiny fraction, approximately\n0.12% of total weights, enabling multi-concept erasure and robustness against\nvarious white-box and black-box adversarial attacks.\n",
        "authors": "Ruchika Chavhan; Da Li; Timothy Hospedales",
        "status": 0,
        "relevancy": 0.40664847564041173,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19210",
        "date": "2024-05-29",
        "title": "Gradient Guided Hypotheses: A unified solution to enable machine\n  learning models on scarce and noisy data regimes",
        "abstract": "  Ensuring high-quality data is paramount for maximizing the performance of\nmachine learning models and business intelligence systems. However, challenges\nin data quality, including noise in data capture, missing records, limited data\nproduction, and confounding variables, significantly constrain the potential\nperformance of these systems. In this study, we propose an\narchitecture-agnostic algorithm, Gradient Guided Hypotheses (GGH), designed to\naddress these challenges. GGH analyses gradients from hypotheses as a proxy of\ndistinct and possibly contradictory patterns in the data. This framework\nentails an additional step in machine learning training, where gradients can be\nincluded or excluded from backpropagation. In this manner, missing and noisy\ndata are addressed through a unified solution that perceives both challenges as\nfacets of the same overarching issue: the propagation of erroneous information.\nExperimental validation of GGH is conducted using real-world open-source\ndatasets, where records with missing rates of up to 98.5% are simulated.\nComparative analysis with state-of-the-art imputation methods demonstrates a\nsubstantial improvement in model performance achieved by GGH. Specifically in\nvery high scarcity regimes, GGH was found to be the only viable solution.\nAdditionally, GGH's noise detection capabilities are showcased by introducing\nsimulated noise into the datasets and observing enhanced model performance\nafter filtering out the noisy data. This study presents GGH as a promising\nsolution for improving data quality and model performance in various\napplications.\n",
        "authors": "Paulo Neves; Joerg K. Wegner; Philippe Schwaller",
        "status": 0,
        "relevancy": 0.40663266762608186,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19238",
        "date": "2024-05-29",
        "title": "Explanation-based Belief Revision: Moving Beyond Minimalism to\n  Explanatory Understanding",
        "abstract": "  In belief revision, agents typically modify their beliefs when they receive\nsome new piece of information that is in conflict with them. The guiding\nprinciple behind most belief revision frameworks is that of minimalism, which\nadvocates minimal changes to existing beliefs. However, minimalism may not\nnecessarily capture the nuanced ways in which human agents reevaluate and\nmodify their beliefs. In contrast, the explanatory hypothesis indicates that\npeople are inherently driven to seek explanations for inconsistencies, thereby\nstriving for explanatory coherence rather than minimal changes when revising\nbeliefs. Our contribution in this paper is two-fold. Motivated by the\nexplanatory hypothesis, we first present a novel, yet simple belief revision\noperator that, given a belief base and an explanation for an explanandum, it\nrevises the belief bases in a manner that preserves the explanandum and is not\nnecessarily minimal. We call this operator explanation-based belief revision.\nSecond, we conduct two human-subject studies to empirically validate our\napproach and investigate belief revision behavior in real-world scenarios. Our\nfindings support the explanatory hypothesis and provide insights into the\nstrategies people employ when resolving inconsistencies.\n",
        "authors": "Stylianos Loukas Vasileiou; William Yeoh",
        "status": 0,
        "relevancy": 0.4043755067873307,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18942",
        "date": "2024-05-29",
        "title": "Verifiably Robust Conformal Prediction",
        "abstract": "  Conformal Prediction (CP) is a popular uncertainty quantification method that\nprovides distribution-free, statistically valid prediction sets, assuming that\ntraining and test data are exchangeable. In such a case, CP's prediction sets\nare guaranteed to cover the (unknown) true test output with a user-specified\nprobability. Nevertheless, this guarantee is violated when the data is\nsubjected to adversarial attacks, which often result in a significant loss of\ncoverage. Recently, several approaches have been put forward to recover CP\nguarantees in this setting. These approaches leverage variations of randomised\nsmoothing to produce conservative sets which account for the effect of the\nadversarial perturbations. They are, however, limited in that they only support\n$\\ell^2$-bounded perturbations and classification tasks. This paper introduces\n\\emph{VRCP (Verifiably Robust Conformal Prediction)}, a new framework that\nleverages recent neural network verification methods to recover coverage\nguarantees under adversarial attacks. Our VRCP method is the first to support\nperturbations bounded by arbitrary norms including $\\ell^1$, $\\ell^2$, and\n$\\ell^\\infty$, as well as regression tasks. We evaluate and compare our\napproach on image classification tasks (CIFAR10, CIFAR100, and TinyImageNet)\nand regression tasks for deep reinforcement learning environments. In every\ncase, VRCP achieves above nominal coverage and yields significantly more\nefficient and informative prediction regions than the SotA.\n",
        "authors": "Linus Jeary; Tom Kuipers; Mehran Hosseini; Nicola Paoletti",
        "status": 0,
        "relevancy": 0.4022948920414964,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19501",
        "date": "2024-05-29",
        "title": "MDS-ViTNet: Improving saliency prediction for Eye-Tracking with Vision\n  Transformer",
        "abstract": "  In this paper, we present a novel methodology we call MDS-ViTNet (Multi\nDecoder Saliency by Vision Transformer Network) for enhancing visual saliency\nprediction or eye-tracking. This approach holds significant potential for\ndiverse fields, including marketing, medicine, robotics, and retail. We propose\na network architecture that leverages the Vision Transformer, moving beyond the\nconventional ImageNet backbone. The framework adopts an encoder-decoder\nstructure, with the encoder utilizing a Swin transformer to efficiently embed\nmost important features. This process involves a Transfer Learning method,\nwherein layers from the Vision Transformer are converted by the Encoder\nTransformer and seamlessly integrated into a CNN Decoder. This methodology\nensures minimal information loss from the original input image. The decoder\nemploys a multi-decoding technique, utilizing dual decoders to generate two\ndistinct attention maps. These maps are subsequently combined into a singular\noutput via an additional CNN model. Our trained model MDS-ViTNet achieves\nstate-of-the-art results across several benchmarks. Committed to fostering\nfurther collaboration, we intend to make our code, models, and datasets\naccessible to the public.\n",
        "authors": "Polezhaev Ignat; Goncharenko Igor; Iurina Natalya",
        "status": 0,
        "relevancy": 0.40135242063673715,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18762",
        "date": "2024-05-29",
        "title": "Inpaint Biases: A Pathway to Accurate and Unbiased Image Generation",
        "abstract": "  This paper examines the limitations of advanced text-to-image models in\naccurately rendering unconventional concepts which are scarcely represented or\nabsent in their training datasets. We identify how these limitations not only\nconfine the creative potential of these models but also pose risks of\nreinforcing stereotypes. To address these challenges, we introduce the Inpaint\nBiases framework, which employs user-defined masks and inpainting techniques to\nenhance the accuracy of image generation, particularly for novel or\ninaccurately rendered objects. Through experimental validation, we demonstrate\nhow this framework significantly improves the fidelity of generated images to\nthe user's intent, thereby expanding the models' creative capabilities and\nmitigating the risk of perpetuating biases. Our study contributes to the\nadvancement of text-to-image models as unbiased, versatile tools for creative\nexpression.\n",
        "authors": "Jiyoon Myung; Jihyeon Park",
        "status": 0,
        "relevancy": 0.4006091752668067,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18698",
        "date": "2024-05-29",
        "title": "Spectral-Risk Safe Reinforcement Learning with Convergence Guarantees",
        "abstract": "  The field of risk-constrained reinforcement learning (RCRL) has been\ndeveloped to effectively reduce the likelihood of worst-case scenarios by\nexplicitly handling risk-measure-based constraints. However, the nonlinearity\nof risk measures makes it challenging to achieve convergence and optimality. To\novercome the difficulties posed by the nonlinearity, we propose a spectral risk\nmeasure-constrained RL algorithm, spectral-risk-constrained policy optimization\n(SRCPO), a bilevel optimization approach that utilizes the duality of spectral\nrisk measures. In the bilevel optimization structure, the outer problem\ninvolves optimizing dual variables derived from the risk measures, while the\ninner problem involves finding an optimal policy given these dual variables.\nThe proposed method, to the best of our knowledge, is the first to guarantee\nconvergence to an optimum in the tabular setting. Furthermore, the proposed\nmethod has been evaluated on continuous control tasks and showed the best\nperformance among other RCRL algorithms satisfying the constraints.\n",
        "authors": "Dohyeong Kim; Taehyun Cho; Seungyub Han; Hojun Chung; Kyungjae Lee; Songhwai Oh",
        "status": 0,
        "relevancy": 0.3956661895746282,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18848",
        "date": "2024-05-29",
        "title": "Anomaly Detection by Context Contrasting",
        "abstract": "  Anomaly Detection focuses on identifying samples that deviate from the norm.\nWhen working with high-dimensional data such as images, a crucial requirement\nfor detecting anomalous patterns is learning lower-dimensional representations\nthat capture normal concepts seen during training. Recent advances in\nself-supervised learning have shown great promise in this regard. However, many\nof the most successful self-supervised anomaly detection methods assume prior\nknowledge about the structure of anomalies and leverage synthetic anomalies\nduring training. Yet, in many real-world applications, we do not know what to\nexpect from unseen data, and we can solely leverage knowledge about normal\ndata. In this work, we propose Con2, which addresses this problem by setting\nnormal training data into distinct contexts while preserving its normal\nproperties, letting us observe the data from different perspectives. Unseen\nnormal data consequently adheres to learned context representations while\nanomalies fail to do so, letting us detect them without any knowledge about\nanomalies during training. Our experiments demonstrate that our approach\nachieves state-of-the-art performance on various benchmarks while exhibiting\nsuperior performance in a more realistic healthcare setting, where knowledge\nabout potential anomalies is often scarce.\n",
        "authors": "Alain Ryser; Thomas M. Sutter; Alexander Marx; Julia E. Vogt",
        "status": 0,
        "relevancy": 0.39473001712551403,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19456",
        "date": "2024-05-29",
        "title": "An Automated Startup Evaluation Pipeline: Startup Success Forecasting\n  Framework (SSFF)",
        "abstract": "  Evaluating startups in their early stages is a complex task that requires\ndetailed analysis by experts. While automating this process on a large scale\ncan significantly impact businesses, the inherent complexity poses challenges.\nThis paper addresses this challenge by introducing the Startup Success\nForecasting Framework (SSFF), a new automated system that combines traditional\nmachine learning with advanced language models. This intelligent agent-based\narchitecture is designed to reason, act, synthesize, and decide like a venture\ncapitalist to perform the analysis end-to-end. The SSFF is made up of three\nmain parts: - Prediction Block: Uses random forests and neural networks to make\npredictions. - Analyst Block: Simulates VC analysis scenario and uses SOTA\nprompting techniques - External Knowledge Block: Gathers real-time information\nfrom external sources. This framework requires minimal input data about the\nfounder and startup description, enhances it with additional data from external\nresources, and performs a detailed analysis with high accuracy, all in an\nautomated manner\n",
        "authors": "Xisen Wang; Yigit Ihlamur",
        "status": 0,
        "relevancy": 0.39271458087525835,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19522",
        "date": "2024-05-29",
        "title": "Artificial Intelligence Index Report 2024",
        "abstract": "  The 2024 Index is our most comprehensive to date and arrives at an important\nmoment when AI's influence on society has never been more pronounced. This\nyear, we have broadened our scope to more extensively cover essential trends\nsuch as technical advancements in AI, public perceptions of the technology, and\nthe geopolitical dynamics surrounding its development. Featuring more original\ndata than ever before, this edition introduces new estimates on AI training\ncosts, detailed analyses of the responsible AI landscape, and an entirely new\nchapter dedicated to AI's impact on science and medicine. The AI Index report\ntracks, collates, distills, and visualizes data related to artificial\nintelligence (AI). Our mission is to provide unbiased, rigorously vetted,\nbroadly sourced data in order for policymakers, researchers, executives,\njournalists, and the general public to develop a more thorough and nuanced\nunderstanding of the complex field of AI. The AI Index is recognized globally\nas one of the most credible and authoritative sources for data and insights on\nartificial intelligence. Previous editions have been cited in major newspapers,\nincluding the The New York Times, Bloomberg, and The Guardian, have amassed\nhundreds of academic citations, and been referenced by high-level policymakers\nin the United States, the United Kingdom, and the European Union, among other\nplaces. This year's edition surpasses all previous ones in size, scale, and\nscope, reflecting the growing significance that AI is coming to hold in all of\nour lives.\n",
        "authors": "Nestor Maslej; Loredana Fattorini; Raymond Perrault; Vanessa Parli; Anka Reuel; Erik Brynjolfsson; John Etchemendy; Katrina Ligett; Terah Lyons; James Manyika; Juan Carlos Niebles; Yoav Shoham; Russell Wald; Jack Clark",
        "status": 0,
        "relevancy": 0.3904021519416203,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19524",
        "date": "2024-05-29",
        "title": "AI Risk Management Should Incorporate Both Safety and Security",
        "abstract": "  The exposure of security vulnerabilities in safety-aligned language models,\ne.g., susceptibility to adversarial attacks, has shed light on the intricate\ninterplay between AI safety and AI security. Although the two disciplines now\ncome together under the overarching goal of AI risk management, they have\nhistorically evolved separately, giving rise to differing perspectives.\nTherefore, in this paper, we advocate that stakeholders in AI risk management\nshould be aware of the nuances, synergies, and interplay between safety and\nsecurity, and unambiguously take into account the perspectives of both\ndisciplines in order to devise mostly effective and holistic risk mitigation\napproaches. Unfortunately, this vision is often obfuscated, as the definitions\nof the basic concepts of \"safety\" and \"security\" themselves are often\ninconsistent and lack consensus across communities. With AI risk management\nbeing increasingly cross-disciplinary, this issue is particularly salient. In\nlight of this conceptual challenge, we introduce a unified reference framework\nto clarify the differences and interplay between AI safety and AI security,\naiming to facilitate a shared understanding and effective collaboration across\ncommunities.\n",
        "authors": "Xiangyu Qi; Yangsibo Huang; Yi Zeng; Edoardo Debenedetti; Jonas Geiping; Luxi He; Kaixuan Huang; Udari Madhushani; Vikash Sehwag; Weijia Shi; Boyi Wei; Tinghao Xie; Danqi Chen; Pin-Yu Chen; Jeffrey Ding; Ruoxi Jia; Jiaqi Ma; Arvind Narayanan; Weijie J Su; Mengdi Wang; Chaowei Xiao; Bo Li; Dawn Song; Peter Henderson; Prateek Mittal",
        "status": 0,
        "relevancy": 0.3873078006450864,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19296",
        "date": "2024-05-29",
        "title": "Neural Isometries: Taming Transformations for Equivariant ML",
        "abstract": "  Real-world geometry and 3D vision tasks are replete with challenging\nsymmetries that defy tractable analytical expression. In this paper, we\nintroduce Neural Isometries, an autoencoder framework which learns to map the\nobservation space to a general-purpose latent space wherein encodings are\nrelated by isometries whenever their corresponding observations are\ngeometrically related in world space. Specifically, we regularize the latent\nspace such that maps between encodings preserve a learned inner product and\ncommute with a learned functional operator, in the same manner as rigid-body\ntransformations commute with the Laplacian. This approach forms an effective\nbackbone for self-supervised representation learning, and we demonstrate that a\nsimple off-the-shelf equivariant network operating in the pre-trained latent\nspace can achieve results on par with meticulously-engineered, handcrafted\nnetworks designed to handle complex, nonlinear symmetries. Furthermore,\nisometric maps capture information about the respective transformations in\nworld space, and we show that this allows us to regress camera poses directly\nfrom the coefficients of the maps between encodings of adjacent views of a\nscene.\n",
        "authors": "Thomas W. Mitchel; Michael Taylor; Vincent Sitzmann",
        "status": 0,
        "relevancy": 0.3838432644456644,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18910",
        "date": "2024-05-29",
        "title": "Predicting Parking Availability in Singapore with Cross-Domain Data: A\n  New Dataset and A Data-Driven Approach",
        "abstract": "  The increasing number of vehicles highlights the need for efficient parking\nspace management. Predicting real-time Parking Availability (PA) can help\nmitigate traffic congestion and the corresponding social problems, which is a\npressing issue in densely populated cities like Singapore. In this study, we\naim to collectively predict future PA across Singapore with complex factors\nfrom various domains. The contributions in this paper are listed as follows:\n(1) A New Dataset: We introduce the \\texttt{SINPA} dataset, containing a year's\nworth of PA data from 1,687 parking lots in Singapore, enriched with various\nspatial and temporal factors. (2) A Data-Driven Approach: We present DeepPA, a\nnovel deep-learning framework, to collectively and efficiently predict future\nPA across thousands of parking lots. (3) Extensive Experiments and Deployment:\nDeepPA demonstrates a 9.2% reduction in prediction error for up to 3-hour\nforecasts compared to existing advanced models. Furthermore, we implement\nDeepPA in a practical web-based platform to provide real-time PA predictions to\naid drivers and inform urban planning for the governors in Singapore. We\nrelease the dataset and source code at https://github.com/yoshall/SINPA.\n",
        "authors": "Huaiwu Zhang; Yutong Xia; Siru Zhong; Kun Wang; Zekun Tong; Qingsong Wen; Roger Zimmermann; Yuxuan Liang",
        "status": 0,
        "relevancy": 0.38236117955777016,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18756",
        "date": "2024-05-29",
        "title": "Provable Contrastive Continual Learning",
        "abstract": "  Continual learning requires learning incremental tasks with dynamic data\ndistributions. So far, it has been observed that employing a combination of\ncontrastive loss and distillation loss for training in continual learning\nyields strong performance. To the best of our knowledge, however, this\ncontrastive continual learning framework lacks convincing theoretical\nexplanations. In this work, we fill this gap by establishing theoretical\nperformance guarantees, which reveal how the performance of the model is\nbounded by training losses of previous tasks in the contrastive continual\nlearning framework. Our theoretical explanations further support the idea that\npre-training can benefit continual learning. Inspired by our theoretical\nanalysis of these guarantees, we propose a novel contrastive continual learning\nalgorithm called CILA, which uses adaptive distillation coefficients for\ndifferent tasks. These distillation coefficients are easily computed by the\nratio between average distillation losses and average contrastive losses from\nprevious tasks. Our method shows great improvement on standard benchmarks and\nachieves new state-of-the-art performance.\n",
        "authors": "Yichen Wen; Zhiquan Tan; Kaipeng Zheng; Chuanlong Xie; Weiran Huang",
        "status": 0,
        "relevancy": 0.38203618582803467,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19538",
        "date": "2024-05-29",
        "title": "CheXpert Plus: Hundreds of Thousands of Aligned Radiology Texts, Images\n  and Patients",
        "abstract": "  Since the release of the original CheXpert paper five years ago, CheXpert has\nbecome one of the most widely used and cited clinical AI datasets. The\nemergence of vision language models has sparked an increase in demands for\nsharing reports linked to CheXpert images, along with a growing interest among\nAI fairness researchers in obtaining demographic data. To address this,\nCheXpert Plus serves as a new collection of radiology data sources, made\npublicly available to enhance the scaling, performance, robustness, and\nfairness of models for all subsequent machine learning tasks in the field of\nradiology. CheXpert Plus is the largest text dataset publicly released in\nradiology, with a total of 36 million text tokens, including 13 million\nimpression tokens. To the best of our knowledge, it represents the largest text\nde-identification effort in radiology, with almost 1 million PHI spans\nanonymized. It is only the second time that a large-scale English paired\ndataset has been released in radiology, thereby enabling, for the first time,\ncross-institution training at scale. All reports are paired with high-quality\nimages in DICOM format, along with numerous image and patient metadata covering\nvarious clinical and socio-economic groups, as well as many pathology labels\nand RadGraph annotations. We hope this dataset will boost research for AI\nmodels that can further assist radiologists and help improve medical care. Data\nis available at the following URL:\nhttps://stanfordaimi.azurewebsites.net/datasets/5158c524-d3ab-4e02-96e9-6ee9efc110a1\nModels are available at the following URL:\nhttps://github.com/Stanford-AIMI/chexpert-plus\n",
        "authors": "Pierre Chambon; Jean-Benoit Delbrouck; Thomas Sounack; Shih-Cheng Huang; Zhihong Chen; Maya Varma; Steven QH Truong; Chu The Chuong; Curtis P. Langlotz",
        "status": 0,
        "relevancy": 0.37835273214981524,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18845",
        "date": "2024-05-29",
        "title": "Simulation, Modelling and Classification of Wiki Contributors: Spotting\n  The Good, The Bad, and The Ugly",
        "abstract": "  Data crowdsourcing is a data acquisition process where groups of voluntary\ncontributors feed platforms with highly relevant data ranging from news,\ncomments, and media to knowledge and classifications. It typically processes\nuser-generated data streams to provide and refine popular services such as\nwikis, collaborative maps, e-commerce sites, and social networks. Nevertheless,\nthis modus operandi raises severe concerns regarding ill-intentioned data\nmanipulation in adversarial environments. This paper presents a simulation,\nmodelling, and classification approach to automatically identify human and\nnon-human (bots) as well as benign and malign contributors by using data\nfabrication to balance classes within experimental data sets, data stream\nmodelling to build and update contributor profiles and, finally, autonomic data\nstream classification. By employing WikiVoyage - a free worldwide wiki travel\nguide open to contribution from the general public - as a testbed, our approach\nproves to significantly boost the confidence and quality of the classifier by\nusing a class-balanced data stream, comprising both real and synthetic data.\nOur empirical results show that the proposed method distinguishes between\nbenign and malign bots as well as human contributors with a classification\naccuracy of up to 92 %.\n",
        "authors": "Silvia García Méndez; Fátima Leal; Benedita Malheiro; Juan Carlos Burguillo Rial; Bruno Veloso; Adriana E. Chis; Horacio González Vélez",
        "status": 0,
        "relevancy": 0.3771270497721225,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19464",
        "date": "2024-05-29",
        "title": "Leveraging Generative AI for Smart City Digital Twins: A Survey on the\n  Autonomous Generation of Data, Scenarios, 3D City Models, and Urban Designs",
        "abstract": "  The digital transformation of modern cities by integrating advanced\ninformation, communication, and computing technologies has marked the epoch of\ndata-driven smart city applications for efficient and sustainable urban\nmanagement. Despite their effectiveness, these applications often rely on\nmassive amounts of high-dimensional and multi-domain data for monitoring and\ncharacterizing different urban sub-systems, presenting challenges in\napplication areas that are limited by data quality and availability, as well as\ncostly efforts for generating urban scenarios and design alternatives. As an\nemerging research area in deep learning, Generative Artificial Intelligence\n(AI) models have demonstrated their unique values in data and code generation.\nThis survey paper aims to explore the innovative integration of generative AI\ntechniques and urban digital twins to address challenges in the realm of smart\ncities in various urban sectors, such as transportation and mobility\nmanagement, energy system operations, building and infrastructure management,\nand urban design. The survey starts with the introduction of popular generative\nAI models with their application areas, followed by a structured review of the\nexisting urban science applications that leverage the autonomous capability of\nthe generative AI techniques to facilitate (a) data augmentation for promoting\nurban monitoring and predictive analytics, (b) synthetic data and scenario\ngeneration, (c) automated 3D city modeling, and (d) generative urban design and\noptimization. Based on the review, this survey discusses potential\nopportunities and technical strategies that integrate generative AI models into\nthe next-generation urban digital twins for more reliable, scalable, and\nautomated management of smart cities.\n",
        "authors": "Haowen Xu; Femi Omitaomu; Soheil Sabri; Xiao Li; Yongze Song",
        "status": 0,
        "relevancy": 0.3769032798310912,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19201",
        "date": "2024-05-29",
        "title": "Going beyond compositional generalization, DDPMs can produce zero-shot\n  interpolation",
        "abstract": "  Denoising Diffusion Probabilistic Models (DDPMs) exhibit remarkable\ncapabilities in image generation, with studies suggesting that they can\ngeneralize by composing latent factors learned from the training data. In this\nwork, we go further and study DDPMs trained on strictly separate subsets of the\ndata distribution with large gaps on the support of the latent factors. We show\nthat such a model can effectively generate images in the unexplored,\nintermediate regions of the distribution. For instance, when trained on clearly\nsmiling and non-smiling faces, we demonstrate a sampling procedure which can\ngenerate slightly smiling faces without reference images (zero-shot\ninterpolation). We replicate these findings for other attributes as well as\nother datasets.\n$\\href{https://github.com/jdeschena/ddpm-zero-shot-interpolation}{\\text{Our\ncode is available on GitHub.}}$\n",
        "authors": "Justin Deschenaux; Igor Krawczuk; Grigorios Chrysos; Volkan Cevher",
        "status": 0,
        "relevancy": 0.37528768841224847,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18968",
        "date": "2024-05-29",
        "title": "UniIF: Unified Molecule Inverse Folding",
        "abstract": "  Molecule inverse folding has been a long-standing challenge in chemistry and\nbiology, with the potential to revolutionize drug discovery and material\nscience. Despite specified models have been proposed for different small- or\nmacro-molecules, few have attempted to unify the learning process, resulting in\nredundant efforts. Complementary to recent advancements in molecular structure\nprediction, such as RoseTTAFold All-Atom and AlphaFold3, we propose the unified\nmodel UniIF for the inverse folding of all molecules. We do such unification in\ntwo levels: 1) Data-Level: We propose a unified block graph data form for all\nmolecules, including the local frame building and geometric feature\ninitialization. 2) Model-Level: We introduce a geometric block attention\nnetwork, comprising a geometric interaction, interactive attention and virtual\nlong-term dependency modules, to capture the 3D interactions of all molecules.\nThrough comprehensive evaluations across various tasks such as protein design,\nRNA design, and material design, we demonstrate that our proposed method\nsurpasses state-of-the-art methods on all tasks. UniIF offers a versatile and\neffective solution for general molecule inverse folding.\n",
        "authors": "Zhangyang Gao; Jue Wang; Cheng Tan; Lirong Wu; Yufei Huang; Siyuan Li; Zhirui Ye; Stan Z. Li",
        "status": 0,
        "relevancy": 0.37069833497965055,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19331",
        "date": "2024-05-29",
        "title": "NPGA: Neural Parametric Gaussian Avatars",
        "abstract": "  The creation of high-fidelity, digital versions of human heads is an\nimportant stepping stone in the process of further integrating virtual\ncomponents into our everyday lives. Constructing such avatars is a challenging\nresearch problem, due to a high demand for photo-realism and real-time\nrendering performance. In this work, we propose Neural Parametric Gaussian\nAvatars (NPGA), a data-driven approach to create high-fidelity, controllable\navatars from multi-view video recordings. We build our method around 3D\nGaussian Splatting for its highly efficient rendering and to inherit the\ntopological flexibility of point clouds. In contrast to previous work, we\ncondition our avatars' dynamics on the rich expression space of neural\nparametric head models (NPHM), instead of mesh-based 3DMMs. To this end, we\ndistill the backward deformation field of our underlying NPHM into forward\ndeformations which are compatible with rasterization-based rendering. All\nremaining fine-scale, expression-dependent details are learned from the\nmulti-view videos. To increase the representational capacity of our avatars, we\naugment the canonical Gaussian point cloud using per-primitive latent features\nwhich govern its dynamic behavior. To regularize this increased dynamic\nexpressivity, we propose Laplacian terms on the latent features and predicted\ndynamics. We evaluate our method on the public NeRSemble dataset, demonstrating\nthat NPGA significantly outperforms the previous state-of-the-art avatars on\nthe self-reenactment task by 2.6 PSNR. Furthermore, we demonstrate accurate\nanimation capabilities from real-world monocular videos.\n",
        "authors": "Simon Giebenhain; Tobias Kirschstein; Martin Rünz; Lourdes Agapito; Matthias Nießner",
        "status": 0,
        "relevancy": 0.3698521178439419,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19317",
        "date": "2024-05-29",
        "title": "Adaptive Generalized Neyman Allocation: Local Asymptotic Minimax Optimal\n  Best Arm Identification",
        "abstract": "  This study investigates a local asymptotic minimax optimal strategy for\nfixed-budget best arm identification (BAI). We propose the Adaptive Generalized\nNeyman Allocation (AGNA) strategy and show that its worst-case upper bound of\nthe probability of misidentifying the best arm aligns with the worst-case lower\nbound under the small-gap regime, where the gap between the expected outcomes\nof the best and suboptimal arms is small. Our strategy corresponds to a\ngeneralization of the Neyman allocation for two-armed bandits (Neyman, 1934;\nKaufmann et al., 2016) and a refinement of existing strategies such as the ones\nproposed by Glynn & Juneja (2004) and Shin et al. (2018). Compared to Komiyama\net al. (2022), which proposes a minimax rate-optimal strategy, our proposed\nstrategy has a tighter upper bound that exactly matches the lower bound,\nincluding the constant terms, by restricting the class of distributions to the\nclass of small-gap distributions. Our result contributes to the longstanding\nopen issue about the existence of asymptotically optimal strategies in\nfixed-budget BAI, by presenting the local asymptotic minimax optimal strategy.\n",
        "authors": "Masahiro Kato",
        "status": 0,
        "relevancy": 0.3631625035025057,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19176",
        "date": "2024-05-29",
        "title": "The ethical situation of DALL-E 2",
        "abstract": "  A hot topic of Artificial Intelligence right now is image generation from\nprompts. DALL-E 2 is one of the biggest names in this domain, as it allows\npeople to create images from simple text inputs, to even more complicated ones.\nThe company that made this possible, OpenAI, has assured everyone that visited\ntheir website that their mission is to ensure that artificial general\nintelligence benefits all humanity. A noble idea in our opinion, that also\nstood as the motive behind us choosing this subject. This paper analyzes the\nethical implications of an AI image generative system, with an emphasis on how\nsociety is responding to it, how it probably will and how it should if all the\nright measures are taken.\n",
        "authors": "Eduard Hogea; Josem Rocafortf",
        "status": 0,
        "relevancy": 0.35870291508335583,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19284",
        "date": "2024-05-29",
        "title": "Optimizing Foundation Model Inference on a Many-tiny-core Open-source\n  RISC-V Platform",
        "abstract": "  Transformer-based foundation models have become crucial for various domains,\nmost notably natural language processing (NLP) or computer vision (CV). These\nmodels are predominantly deployed on high-performance GPUs or hardwired\naccelerators with highly customized, proprietary instruction sets. Until now,\nlimited attention has been given to RISC-V-based general-purpose platforms. In\nour work, we present the first end-to-end inference results of transformer\nmodels on an open-source many-tiny-core RISC-V platform implementing\ndistributed Softmax primitives and leveraging ISA extensions for SIMD\nfloating-point operand streaming and instruction repetition, as well as\nspecialized DMA engines to minimize costly main memory accesses and to tolerate\ntheir latency. We focus on two foundational transformer topologies,\nencoder-only and decoder-only models. For encoder-only models, we demonstrate a\nspeedup of up to 12.8x between the most optimized implementation and the\nbaseline version. We reach over 79% FPU utilization and 294 GFLOPS/W,\noutperforming State-of-the-Art (SoA) accelerators by more than 2x utilizing the\nHW platform while achieving comparable throughput per computational unit. For\ndecoder-only topologies, we achieve 16.1x speedup in the Non-Autoregressive\n(NAR) mode and up to 35.6x speedup in the Autoregressive (AR) mode compared to\nthe baseline implementation. Compared to the best SoA dedicated accelerator, we\nachieve 2.04x higher FPU utilization.\n",
        "authors": "Viviane Potocnik; Luca Colagrande; Tim Fischer; Luca Bertaccini; Daniele Jahier Pagliari; Alessio Burrello; Luca Benini",
        "status": 0,
        "relevancy": 0.3535956017607178,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18707",
        "date": "2024-05-29",
        "title": "Adaptive and Parallel Split Federated Learning in Vehicular Edge\n  Computing",
        "abstract": "  Vehicular edge intelligence (VEI) is a promising paradigm for enabling future\nintelligent transportation systems by accommodating artificial intelligence\n(AI) at the vehicular edge computing (VEC) system. Federated learning (FL)\nstands as one of the fundamental technologies facilitating collaborative model\ntraining locally and aggregation, while safeguarding the privacy of vehicle\ndata in VEI. However, traditional FL faces challenges in adapting to vehicle\nheterogeneity, training large models on resource-constrained vehicles, and\nremaining susceptible to model weight privacy leakage. Meanwhile, split\nlearning (SL) is proposed as a promising collaborative learning framework which\ncan mitigate the risk of model wights leakage, and release the training\nworkload on vehicles. SL sequentially trains a model between a vehicle and an\nedge cloud (EC) by dividing the entire model into a vehicle-side model and an\nEC-side model at a given cut layer. In this work, we combine the advantages of\nSL and FL to develop an Adaptive Split Federated Learning scheme for Vehicular\nEdge Computing (ASFV). The ASFV scheme adaptively splits the model and\nparallelizes the training process, taking into account mobile vehicle selection\nand resource allocation. Our extensive simulations, conducted on\nnon-independent and identically distributed data, demonstrate that the proposed\nASFV solution significantly reduces training latency compared to existing\nbenchmarks, while adapting to network dynamics and vehicles' mobility.\n",
        "authors": "Xianke Qiang; Zheng Chang; Yun Hu; Lei Liu; Timo Hamalainen",
        "status": 0,
        "relevancy": 0.35243586623531886,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19243",
        "date": "2024-05-29",
        "title": "Challenge-Device-Synthesis: A multi-disciplinary approach for the\n  development of social innovation competences for students of Artificial\n  Intelligence",
        "abstract": "  The advent of Artificial Intelligence is expected to imply profound changes\nin the short-term. It is therefore imperative for Academia, and particularly\nfor the Computer Science scope, to develop cross-disciplinary tools that bond\nAI developments to their social dimension. To this aim, we introduce the\nChallenge-Device-Synthesis methodology (CDS), in which a specific challenge is\npresented to the students of AI, who are required to develop a device as a\nsolution for the challenge. The device becomes the object of study for the\ndifferent dimensions of social transformation, and the conclusions addressed by\nthe students during the discussion around the device are presented in a\nsynthesis piece in the shape of a 10-page scientific paper. The latter is\nevaluated taking into account both the depth of analysis and the level to which\nit genuinely reflects the social transformations associated with the proposed\nAI-based device. We provide data obtained during the pilot for the\nimplementation phase of CDS within the subject of Social Innovation, a 6-ECTS\nsubject from the 6th semester of the Degree of Artificial Intelligence,\nUAB-Barcelona. We provide details on temporalisation, task distribution,\nmethodological tools used and assessment delivery procedure, as well as\nqualitative analysis of the results obtained.\n",
        "authors": "Matías Bilkis; Joan Moya Kohler; Fernando Vilariño",
        "status": 0,
        "relevancy": 0.35169060506191663,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18820",
        "date": "2024-05-29",
        "title": "Diffeomorphic interpolation for efficient persistence-based topological\n  optimization",
        "abstract": "  Topological Data Analysis (TDA) provides a pipeline to extract quantitative\ntopological descriptors from structured objects. This enables the definition of\ntopological loss functions, which assert to what extent a given object exhibits\nsome topological properties. These losses can then be used to perform\ntopological optimizationvia gradient descent routines. While theoretically\nsounded, topological optimization faces an important challenge: gradients tend\nto be extremely sparse, in the sense that the loss function typically depends\non only very few coordinates of the input object, yielding dramatically slow\noptimization schemes in practice.Focusing on the central case of topological\noptimization for point clouds, we propose in this work to overcome this\nlimitation using diffeomorphic interpolation, turning sparse gradients into\nsmooth vector fields defined on the whole space, with quantifiable Lipschitz\nconstants. In particular, we show that our approach combines efficiently with\nsubsampling techniques routinely used in TDA, as the diffeomorphism derived\nfrom the gradient computed on a subsample can be used to update the coordinates\nof the full input object, allowing us to perform topological optimization on\npoint clouds at an unprecedented scale. Finally, we also showcase the relevance\nof our approach for black-box autoencoder (AE) regularization, where we aim at\nenforcing topological priors on the latent spaces associated to fixed,\npre-trained, black-box AE models, and where we show thatlearning a\ndiffeomorphic flow can be done once and then re-applied to new data in linear\ntime (while vanilla topological optimization has to be re-run from scratch).\nMoreover, reverting the flow allows us to generate data by sampling the\ntopologically-optimized latent space directly, yielding better interpretability\nof the model.\n",
        "authors": "Mathieu Carriere; Marc Theveneau; Théo Lacombe",
        "status": 0,
        "relevancy": 0.34661584343309726,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18723",
        "date": "2024-05-29",
        "title": "Conformal Depression Prediction",
        "abstract": "  While existing depression recognition methods based on deep learning show\npromise, their practical application is hindered by the lack of\ntrustworthiness, as these deep models are often deployed as \\textit{black box}\nmodels, leaving us uncertain about the confidence of the model predictions. For\nhigh-risk clinical applications like depression recognition, uncertainty\nquantification is essential in decision-making. In this paper, we introduce\nconformal depression prediction (CDP), a depression recognition method with\nuncertainty quantification based on conformal prediction (CP), giving valid\nconfidence intervals with theoretical coverage guarantees for the model\npredictions. CDP is a plug-and-play module that requires neither model\nretraining nor an assumption about the depression data distribution. As CDP\nprovides only an average performance guarantee across all inputs rather than\nper-input performance guarantee, we propose CDP-ACC, an improved conformal\nprediction with approximate conditional coverage. CDP-ACC firstly estimates the\nprediction distribution through neighborhood relaxation, and then introduces a\nconformal score function by constructing nested sequences, so as to provide\ntighter prediction interval for each specific input. We empirically demonstrate\nthe application of uncertainty quantification in depression recognition, and\nthe effectiveness and superiority of CDP and CDP-ACC on the AVEC 2013 and AVEC\n2014 datasets\n",
        "authors": "Yonghong Li; Shan Qu; Xiuzhuang Zhou",
        "status": 0,
        "relevancy": 0.340765280481393,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18877",
        "date": "2024-05-29",
        "title": "Continuous Product Graph Neural Networks",
        "abstract": "  Processing multidomain data defined on multiple graphs holds significant\npotential in various practical applications in computer science. However,\ncurrent methods are mostly limited to discrete graph filtering operations.\nTensorial partial differential equations on graphs (TPDEGs) provide a\nprincipled framework for modeling structured data across multiple interacting\ngraphs, addressing the limitations of the existing discrete methodologies. In\nthis paper, we introduce Continuous Product Graph Neural Networks (CITRUS) that\nemerge as a natural solution to the TPDEG. CITRUS leverages the separability of\ncontinuous heat kernels from Cartesian graph products to efficiently implement\ngraph spectral decomposition. We conduct thorough theoretical analyses of the\nstability and over-smoothing properties of CITRUS in response to\ndomain-specific graph perturbations and graph spectra effects on the\nperformance. We evaluate CITRUS on well-known traffic and weather\nspatiotemporal forecasting datasets, demonstrating superior performance over\nexisting approaches.\n",
        "authors": "Aref Einizade; Fragkiskos D. Malliaros; Jhony H. Giraldo",
        "status": 0,
        "relevancy": 0.33932337406366275,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19495",
        "date": "2024-05-29",
        "title": "Qiskit Code Assistant: Training LLMs for generating Quantum Computing\n  Code",
        "abstract": "  Code Large Language Models (Code LLMs) have emerged as powerful tools,\nrevolutionizing the software development landscape by automating the coding\nprocess and reducing time and effort required to build applications. This paper\nfocuses on training Code LLMs to specialize in the field of quantum computing.\nWe begin by discussing the unique needs of quantum computing programming, which\ndiffer significantly from classical programming approaches or languages. A Code\nLLM specializing in quantum computing requires a foundational understanding of\nquantum computing and quantum information theory. However, the scarcity of\navailable quantum code examples and the rapidly evolving field, which\nnecessitates continuous dataset updates, present significant challenges.\nMoreover, we discuss our work on training Code LLMs to produce high-quality\nquantum code using the Qiskit library. This work includes an examination of the\nvarious aspects of the LLMs used for training and the specific training\nconditions, as well as the results obtained with our current models. To\nevaluate our models, we have developed a custom benchmark, similar to\nHumanEval, which includes a set of tests specifically designed for the field of\nquantum computing programming using Qiskit. Our findings indicate that our\nmodel outperforms existing state-of-the-art models in quantum computing tasks.\nWe also provide examples of code suggestions, comparing our model to other\nrelevant code LLMs. Finally, we introduce a discussion on the potential\nbenefits of Code LLMs for quantum computing computational scientists,\nresearchers, and practitioners. We also explore various features and future\nwork that could be relevant in this context.\n",
        "authors": "Nicolas Dupuis; Luca Buratti; Sanjay Vishwakarma; Aitana Viudes Forrat; David Kremer; Ismael Faro; Ruchir Puri; Juan Cruz-Benito",
        "status": 0,
        "relevancy": 0.33826390050958177,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19053",
        "date": "2024-05-29",
        "title": "Multiscale Spatio-Temporal Enhanced Short-term Load Forecasting of\n  Electric Vehicle Charging Stations",
        "abstract": "  The rapid expansion of electric vehicles (EVs) has rendered the load\nforecasting of electric vehicle charging stations (EVCS) increasingly critical.\nThe primary challenge in achieving precise load forecasting for EVCS lies in\naccounting for the nonlinear of charging behaviors, the spatial interactions\namong different stations, and the intricate temporal variations in usage\npatterns. To address these challenges, we propose a Multiscale Spatio-Temporal\nEnhanced Model (MSTEM) for effective load forecasting at EVCS. MSTEM\nincorporates a multiscale graph neural network to discern hierarchical\nnonlinear temporal dependencies across various time scales. Besides, it also\nintegrates a recurrent learning component and a residual fusion mechanism,\nenhancing its capability to accurately capture spatial and temporal variations\nin charging patterns. The effectiveness of the proposed MSTEM has been\nvalidated through comparative analysis with six baseline models using three\nevaluation metrics. The case studies utilize real-world datasets for both fast\nand slow charging loads at EVCS in Perth, UK. The experimental results\ndemonstrate the superiority of MSTEM in short-term continuous load forecasting\nfor EVCS.\n",
        "authors": "Zongbao Zhang; Jiao Hao; Wenmeng Zhao; Yan Liu; Yaohui Huang; Xinhang Luo",
        "status": 0,
        "relevancy": 0.3376575572574454,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18984",
        "date": "2024-05-29",
        "title": "Optimizing Vehicular Networks with Variational Quantum Circuits-based\n  Reinforcement Learning",
        "abstract": "  In vehicular networks (VNets), ensuring both road safety and dependable\nnetwork connectivity is of utmost importance. Achieving this necessitates the\ncreation of resilient and efficient decision-making policies that prioritize\nmultiple objectives. In this paper, we develop a Variational Quantum Circuit\n(VQC)-based multi-objective reinforcement learning (MORL) framework to\ncharacterize efficient network selection and autonomous driving policies in a\nvehicular network (VNet). Numerical results showcase notable enhancements in\nboth convergence rates and rewards when compared to conventional deep-Q\nnetworks (DQNs), validating the efficacy of the VQC-MORL solution.\n",
        "authors": "Zijiang Yan; Ramsundar Tanikella; Hina Tabassum",
        "status": 0,
        "relevancy": 0.3370702903778152,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18681",
        "date": "2024-05-29",
        "title": "A random-key GRASP for combinatorial optimization",
        "abstract": "  This paper proposes a problem-independent GRASP metaheuristic using the\nrandom-key optimizer (RKO) paradigm. GRASP (greedy randomized adaptive search\nprocedure) is a metaheuristic for combinatorial optimization that repeatedly\napplies a semi-greedy construction procedure followed by a local search\nprocedure. The best solution found over all iterations is returned as the\nsolution of the GRASP. Continuous GRASP (C-GRASP) is an extension of GRASP for\ncontinuous optimization in the unit hypercube. A random-key optimizer (RKO)\nuses a vector of random keys to encode a solution to a combinatorial\noptimization problem. It uses a decoder to evaluate a solution encoded by the\nvector of random keys. A random-key GRASP is a C-GRASP where points in the unit\nhypercube are evaluated employing a decoder. We describe random key GRASP\nconsisting of a problem-independent component and a problem-dependent decoder.\nAs a proof of concept, the random-key GRASP is tested on five NP-hard\ncombinatorial optimization problems: traveling salesman problem, tree of hubs\nlocation problem, Steiner triple covering problem, node capacitated graph\npartitioning problem, and job sequencing and tool switching problem.\n",
        "authors": "Antonio A. Chaves; Mauricio G. C. Resende; Ricardo M. A. Silva",
        "status": 0,
        "relevancy": 0.33583722498065316,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19202",
        "date": "2024-05-29",
        "title": "Vulnerable Road User Detection and Safety Enhancement: A Comprehensive\n  Survey",
        "abstract": "  Traffic incidents involving vulnerable road users (VRUs) constitute a\nsignificant proportion of global road accidents. Advances in traffic\ncommunication ecosystems, coupled with sophisticated signal processing and\nmachine learning techniques, have facilitated the utilization of data from\ndiverse sensors. Despite these advancements and the availability of extensive\ndatasets, substantial progress is required to mitigate traffic casualties. This\npaper provides a comprehensive survey of state-of-the-art technologies and\nmethodologies to enhance the safety of VRUs. The study delves into the\ncommunication networks between vehicles and VRUs, emphasizing the integration\nof advanced sensors and the availability of relevant datasets. It explores\npreprocessing techniques and data fusion methods to enhance sensor data\nquality. Furthermore, our study assesses critical simulation environments\nessential for developing and testing VRU safety systems. Our research also\nhighlights recent advances in VRU detection and classification algorithms,\naddressing challenges such as variable environmental conditions. Additionally,\nwe cover cutting-edge research in predicting VRU intentions and behaviors,\nwhich is crucial for proactive collision avoidance strategies. Through this\nsurvey, we aim to provide a comprehensive understanding of the current\nlandscape of VRU safety technologies, identifying areas of progress and areas\nneeding further research and development.\n",
        "authors": "Renato M. Silva; Gregório F. Azevedo; Matheus V. V. Berto; Jean R. Rocha; Eduardo C. Fidelis; Matheus V. Nogueira; Pedro H. Lisboa; Tiago A. Almeida",
        "status": 0,
        "relevancy": 0.33476239158703225,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18742",
        "date": "2024-05-29",
        "title": "Musical Phrase Segmentation via Grammatical Induction",
        "abstract": "  We outline a solution to the challenge of musical phrase segmentation that\nuses grammatical induction algorithms, a class of algorithms which infer a\ncontext-free grammar from an input sequence. We analyze the performance of five\ngrammatical induction algorithms on three datasets using various musical\nviewpoint combinations. Our experiments show that the LONGESTFIRST algorithm\nachieves the best F1 scores across all three datasets and that input encodings\nthat include the duration viewpoint result in the best performance.\n",
        "authors": "Reed Perkins; Dan Ventura",
        "status": 0,
        "relevancy": 0.3340359364976775,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19213",
        "date": "2024-05-29",
        "title": "HawkVision: Low-Latency Modeless Edge AI Serving",
        "abstract": "  The trend of modeless ML inference is increasingly growing in popularity as\nit hides the complexity of model inference from users and caters to diverse\nuser and application accuracy requirements. Previous work mostly focuses on\nmodeless inference in data centers. To provide low-latency inference, in this\npaper, we promote modeless inference at the edge. The edge environment\nintroduces additional challenges related to low power consumption, limited\ndevice memory, and volatile network environments.\n  To address these challenges, we propose HawkVision, which provides\nlow-latency modeless serving of vision DNNs. HawkVision leverages a two-layer\nedge-DC architecture that employs confidence scaling to reduce the number of\nmodel options while meeting diverse accuracy requirements. It also supports\nlossy inference under volatile network environments. Our experimental results\nshow that HawkVision outperforms current serving systems by up to 1.6X in P99\nlatency for providing modeless service. Our FPGA prototype demonstrates similar\nperformance at certain accuracy levels with up to a 3.34X reduction in power\nconsumption.\n",
        "authors": "ChonLam Lao; Jiaqi Gao; Ganesh Ananthanarayanan; Aditya Akella; Minlan Yu",
        "status": 0,
        "relevancy": 0.3337253868241944,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18802",
        "date": "2024-05-29",
        "title": "Enhancing Security and Privacy in Federated Learning using Update\n  Digests and Voting-Based Defense",
        "abstract": "  Federated Learning (FL) is a promising privacy-preserving machine learning\nparadigm that allows data owners to collaboratively train models while keeping\ntheir data localized. Despite its potential, FL faces challenges related to the\ntrustworthiness of both clients and servers, especially in the presence of\ncurious or malicious adversaries. In this paper, we introduce a novel framework\nnamed \\underline{\\textbf{F}}ederated \\underline{\\textbf{L}}earning with\n\\underline{\\textbf{U}}pdate \\underline{\\textbf{D}}igest (FLUD), which addresses\nthe critical issues of privacy preservation and resistance to Byzantine attacks\nwithin distributed learning environments. FLUD utilizes an innovative approach,\nthe $\\mathsf{LinfSample}$ method, allowing clients to compute the $l_{\\infty}$\nnorm across sliding windows of updates as an update digest. This digest enables\nthe server to calculate a shared distance matrix, significantly reducing the\noverhead associated with Secure Multi-Party Computation (SMPC) by three orders\nof magnitude while effectively distinguishing between benign and malicious\nupdates. Additionally, FLUD integrates a privacy-preserving, voting-based\ndefense mechanism that employs optimized SMPC protocols to minimize\ncommunication rounds. Our comprehensive experiments demonstrate FLUD's\neffectiveness in countering Byzantine adversaries while incurring low\ncommunication and runtime overhead. FLUD offers a scalable framework for secure\nand reliable FL in distributed environments, facilitating its application in\nscenarios requiring robust data management and security.\n",
        "authors": "Wenjie Li; Kai Fan; Jingyuan Zhang; Hui Li; Wei Yang Bryan Lim; Qiang Yang",
        "status": 0,
        "relevancy": 0.3293751801649848,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18929",
        "date": "2024-05-29",
        "title": "Deep Positive-Unlabeled Anomaly Detection for Contaminated Unlabeled\n  Data",
        "abstract": "  Semi-supervised anomaly detection, which aims to improve the performance of\nthe anomaly detector by using a small amount of anomaly data in addition to\nunlabeled data, has attracted attention. Existing semi-supervised approaches\nassume that unlabeled data are mostly normal. They train the anomaly detector\nto minimize the anomaly scores for the unlabeled data, and to maximize those\nfor the anomaly data. However, in practice, the unlabeled data are often\ncontaminated with anomalies. This weakens the effect of maximizing the anomaly\nscores for anomalies, and prevents us from improving the detection performance.\nTo solve this problem, we propose the positive-unlabeled autoencoder, which is\nbased on positive-unlabeled learning and the anomaly detector such as the\nautoencoder. With our approach, we can approximate the anomaly scores for\nnormal data using the unlabeled and anomaly data. Therefore, without the\nlabeled normal data, we can train the anomaly detector to minimize the anomaly\nscores for normal data, and to maximize those for the anomaly data. In\naddition, our approach is applicable to various anomaly detectors such as the\nDeepSVDD. Experiments on various datasets show that our approach achieves\nbetter detection performance than existing approaches.\n",
        "authors": "Hiroshi Takahashi; Tomoharu Iwata; Atsutoshi Kumagai; Yuuki Yamanaka",
        "status": 0,
        "relevancy": 0.3222058537326241,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19236",
        "date": "2024-05-29",
        "title": "Exploring the impact of traffic signal control and connected and\n  automated vehicles on intersections safety: A deep reinforcement learning\n  approach",
        "abstract": "  In transportation networks, intersections pose significant risks of\ncollisions due to conflicting movements of vehicles approaching from different\ndirections. To address this issue, various tools can exert influence on traffic\nsafety both directly and indirectly. This study focuses on investigating the\nimpact of adaptive signal control and connected and automated vehicles (CAVs)\non intersection safety using a deep reinforcement learning approach. The\nobjective is to assess the individual and combined effects of CAVs and adaptive\ntraffic signal control on traffic safety, considering rear-end and crossing\nconflicts. The study employs a Deep Q Network (DQN) to regulate traffic signals\nand driving behaviors of both CAVs and Human Drive Vehicles (HDVs), and uses\nTime To Collision (TTC) metric to evaluate safety. The findings demonstrate a\nsignificant reduction in rear-end and crossing conflicts through the combined\nimplementation of CAVs and DQNs-based traffic signal control. Additionally, the\nlong-term positive effects of CAVs on safety are similar to the short-term\neffects of combined CAVs and DQNs-based traffic signal control. Overall, the\nstudy emphasizes the potential benefits of integrating CAVs and adaptive\ntraffic signal control approaches in order to enhance traffic safety. The\nfindings of this study could provide valuable insights for city officials and\ntransportation authorities in developing effective strategies to improve safety\nat signalized intersections.\n",
        "authors": "Amir Hossein Karbasi; Hao Yang; Saiedeh Razavi",
        "status": 0,
        "relevancy": 0.32070303691652524,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19453",
        "date": "2024-05-29",
        "title": "Optimizing Split Points for Error-Resilient SplitFed Learning",
        "abstract": "  Recent advancements in decentralized learning, such as Federated Learning\n(FL), Split Learning (SL), and Split Federated Learning (SplitFed), have\nexpanded the potentials of machine learning. SplitFed aims to minimize the\ncomputational burden on individual clients in FL and parallelize SL while\nmaintaining privacy. This study investigates the resilience of SplitFed to\npacket loss at model split points. It explores various parameter aggregation\nstrategies of SplitFed by examining the impact of splitting the model at\ndifferent points-either shallow split or deep split-on the final global model\nperformance. The experiments, conducted on a human embryo image segmentation\ntask, reveal a statistically significant advantage of a deeper split point.\n",
        "authors": "Chamani Shiranthika; Parvaneh Saeedi; Ivan V. Bajić",
        "status": 0,
        "relevancy": 0.3192607615605515,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19300",
        "date": "2024-05-29",
        "title": "Measuring and Mitigating Bias for Tabular Datasets with Multiple\n  Protected Attributes",
        "abstract": "  Motivated by the recital (67) of the current corrigendum of the AI Act in the\nEuropean Union, we propose and present measures and mitigation strategies for\ndiscrimination in tabular datasets. We specifically focus on datasets that\ncontain multiple protected attributes, such as nationality, age, and sex. This\nmakes measuring and mitigating bias more challenging, as many existing methods\nare designed for a single protected attribute. This paper comes with a twofold\ncontribution: Firstly, new discrimination measures are introduced. These\nmeasures are categorized in our framework along with existing ones, guiding\nresearchers and practitioners in choosing the right measure to assess the\nfairness of the underlying dataset. Secondly, a novel application of an\nexisting bias mitigation method, FairDo, is presented. We show that this\nstrategy can mitigate any type of discrimination, including intersectional\ndiscrimination, by transforming the dataset. By conducting experiments on\nreal-world datasets (Adult, Bank, Compas), we demonstrate that de-biasing\ndatasets with multiple protected attributes is achievable. Further, the\ntransformed fair datasets do not compromise any of the tested machine learning\nmodels' performances significantly when trained on these datasets compared to\nthe original datasets. Discrimination was reduced by up to 83% in our\nexperimentation. For most experiments, the disparity between protected groups\nwas reduced by at least 7% and 27% on average. Generally, the findings show\nthat the mitigation strategy used is effective, and this study contributes to\nthe ongoing discussion on the implementation of the European Union's AI Act.\n",
        "authors": "Manh Khoi Duong; Stefan Conrad",
        "status": 0,
        "relevancy": 0.3177973673221842,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18843",
        "date": "2024-05-29",
        "title": "Data-driven Machinery Fault Detection: A Comprehensive Review",
        "abstract": "  In this era of advanced manufacturing, it's now more crucial than ever to\ndiagnose machine faults as early as possible to guarantee their safe and\nefficient operation. With the massive surge in industrial big data and\nadvancement in sensing and computational technologies, data-driven Machinery\nFault Diagnosis (MFD) solutions based on machine/deep learning approaches have\nbeen used ubiquitously in manufacturing. Timely and accurately identifying\nfaulty machine signals is vital in industrial applications for which many\nrelevant solutions have been proposed and are reviewed in many articles.\nDespite the availability of numerous solutions and reviews on MFD, existing\nworks often lack several aspects. Most of the available literature has limited\napplicability in a wide range of manufacturing settings due to their\nconcentration on a particular type of equipment or method of analysis.\nAdditionally, discussions regarding the challenges associated with implementing\ndata-driven approaches, such as dealing with noisy data, selecting appropriate\nfeatures, and adapting models to accommodate new or unforeseen faults, are\noften superficial or completely overlooked. Thus, this survey provides a\ncomprehensive review of the articles using different types of machine learning\napproaches for the detection and diagnosis of various types of machinery\nfaults, highlights their strengths and limitations, provides a review of the\nmethods used for condition-based analyses, comprehensively discusses the\navailable machinery fault datasets, introduces future researchers to the\npossible challenges they have to encounter while using these approaches for MFD\nand recommends the probable solutions to mitigate those problems. The future\nresearch prospects are also pointed out for a better understanding of the\nfield. We believe this article will help researchers and contribute to the\nfurther development of the field.\n",
        "authors": "Dhiraj Neupane; Mohamed Reda Bouadjenek; Richard Dazeley; Sunil Aryal",
        "status": 0,
        "relevancy": 0.31612336870644375,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19166",
        "date": "2024-05-29",
        "title": "Transformers as Neural Operators for Solutions of Differential Equations\n  with Finite Regularity",
        "abstract": "  Neural operator learning models have emerged as very effective surrogates in\ndata-driven methods for partial differential equations (PDEs) across different\napplications from computational science and engineering. Such operator learning\nmodels not only predict particular instances of a physical or biological system\nin real-time but also forecast classes of solutions corresponding to a\ndistribution of initial and boundary conditions or forcing terms. % DeepONet is\nthe first neural operator model and has been tested extensively for a broad\nclass of solutions, including Riemann problems. Transformers have not been used\nin that capacity, and specifically, they have not been tested for solutions of\nPDEs with low regularity. %\n  In this work, we first establish the theoretical groundwork that transformers\npossess the universal approximation property as operator learning models.\n  We then apply transformers to forecast solutions of diverse dynamical systems\nwith solutions of finite regularity for a plurality of initial conditions and\nforcing terms. In particular, we consider three examples: the Izhikevich neuron\nmodel, the tempered fractional-order Leaky Integrate-and-Fire (LIF) model, and\nthe one-dimensional Euler equation Riemann problem. For the latter problem, we\nalso compare with variants of DeepONet, and we find that transformers\noutperform DeepONet in accuracy but they are computationally more expensive.\n",
        "authors": "Benjamin Shih; Ahmad Peyvan; Zhongqiang Zhang; George Em Karniadakis",
        "status": 0,
        "relevancy": 0.31378908612081013,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19029",
        "date": "2024-05-29",
        "title": "Convex neural network synthesis for robustness in the 1-norm",
        "abstract": "  With neural networks being used to control safety-critical systems, they\nincreasingly have to be both accurate (in the sense of matching inputs to\noutputs) and robust. However, these two properties are often at odds with each\nother and a trade-off has to be navigated. To address this issue, this paper\nproposes a method to generate an approximation of a neural network which is\ncertifiably more robust. Crucially, the method is fully convex and posed as a\nsemi-definite programme. An application to robustifying model predictive\ncontrol is used to demonstrate the results. The aim of this work is to\nintroduce a method to navigate the neural network robustness/accuracy\ntrade-off.\n",
        "authors": "Ross Drummond; Chris Guiver; Matthew C. Turner",
        "status": 0,
        "relevancy": 0.3043396034245549,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18886",
        "date": "2024-05-29",
        "title": "Compressing Large Language Models using Low Rank and Low Precision\n  Decomposition",
        "abstract": "  The prohibitive sizes of Large Language Models (LLMs) today make it difficult\nto deploy them on memory-constrained edge devices. This work introduces $\\rm\nCALDERA$ -- a new post-training LLM compression algorithm that harnesses the\ninherent low-rank structure of a weight matrix $\\mathbf{W}$ by approximating it\nvia a low-rank, low-precision decomposition as $\\mathbf{W} \\approx \\mathbf{Q} +\n\\mathbf{L}\\mathbf{R}$. Here, $\\mathbf{L}$ and $\\mathbf{R}$ are low rank\nfactors, and the entries of $\\mathbf{Q}$, $\\mathbf{L}$ and $\\mathbf{R}$ are\nquantized. The model is compressed by substituting each layer with its\n$\\mathbf{Q} + \\mathbf{L}\\mathbf{R}$ decomposition, and the zero-shot\nperformance of the compressed model is evaluated. Additionally, $\\mathbf{L}$\nand $\\mathbf{R}$ are readily amenable to low-rank adaptation, consequently\nenhancing the zero-shot performance. $\\rm CALDERA$ obtains this decomposition\nby formulating it as an optimization problem\n$\\min_{\\mathbf{Q},\\mathbf{L},\\mathbf{R}}\\lVert(\\mathbf{Q} +\n\\mathbf{L}\\mathbf{R} - \\mathbf{W})\\mathbf{X}^\\top\\rVert_{\\rm F}^2$, where\n$\\mathbf{X}$ is the calibration data, and $\\mathbf{Q}, \\mathbf{L}, \\mathbf{R}$\nare constrained to be representable using low-precision formats. Theoretical\nupper bounds on the approximation error of $\\rm CALDERA$ are established using\na rank-constrained regression framework, and the tradeoff between compression\nratio and model performance is studied by analyzing the impact of target rank\nand quantization bit budget. Results illustrate that compressing LlaMa-$2$\n$7$B/$70$B and LlaMa-$3$ $8$B models obtained using $\\rm CALDERA$ outperforms\nexisting post-training LLM compression techniques in the regime of less than\n$2.5$ bits per parameter. The implementation is available at:\n\\href{https://github.com/pilancilab/caldera}{https://github.com/pilancilab/caldera}.\n",
        "authors": "Rajarshi Saha; Naomi Sagan; Varun Srivastava; Andrea J. Goldsmith; Mert Pilanci",
        "status": 0,
        "relevancy": 0.2960778544824819,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19479",
        "date": "2024-05-29",
        "title": "Participation in the age of foundation models",
        "abstract": "  Growing interest and investment in the capabilities of foundation models has\npositioned such systems to impact a wide array of public services. Alongside\nthese opportunities is the risk that these systems reify existing power\nimbalances and cause disproportionate harm to marginalized communities.\nParticipatory approaches hold promise to instead lend agency and\ndecision-making power to marginalized stakeholders. But existing approaches in\nparticipatory AI/ML are typically deeply grounded in context - how do we apply\nthese approaches to foundation models, which are, by design, disconnected from\ncontext? Our paper interrogates this question.\n  First, we examine existing attempts at incorporating participation into\nfoundation models. We highlight the tension between participation and scale,\ndemonstrating that it is intractable for impacted communities to meaningfully\nshape a foundation model that is intended to be universally applicable. In\nresponse, we develop a blueprint for participatory foundation models that\nidentifies more local, application-oriented opportunities for meaningful\nparticipation. In addition to the \"foundation\" layer, our framework proposes\nthe \"subfloor'' layer, in which stakeholders develop shared technical\ninfrastructure, norms and governance for a grounded domain, and the \"surface''\nlayer, in which affected communities shape the use of a foundation model for a\nspecific downstream task. The intermediate \"subfloor'' layer scopes the range\nof potential harms to consider, and affords communities more concrete avenues\nfor deliberation and intervention. At the same time, it avoids duplicative\neffort by scaling input across relevant use cases. Through three case studies\nin clinical care, financial services, and journalism, we illustrate how this\nmulti-layer model can create more meaningful opportunities for participation\nthan solely intervening at the foundation layer.\n",
        "authors": "Harini Suresh; Emily Tseng; Meg Young; Mary L. Gray; Emma Pierson; Karen Levy",
        "status": 0,
        "relevancy": 0.2838741916613018,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19212",
        "date": "2024-05-29",
        "title": "Partial Information Decomposition for Data Interpretability and Feature\n  Selection",
        "abstract": "  In this paper, we introduce Partial Information Decomposition of Features\n(PIDF), a new paradigm for simultaneous data interpretability and feature\nselection. Contrary to traditional methods that assign a single importance\nvalue, our approach is based on three metrics per feature: the mutual\ninformation shared with the target variable, the feature's contribution to\nsynergistic information, and the amount of this information that is redundant.\nIn particular, we develop a novel procedure based on these three metrics, which\nreveals not only how features are correlated with the target but also the\nadditional and overlapping information provided by considering them in\ncombination with other features. We extensively evaluate PIDF using both\nsynthetic and real-world data, demonstrating its potential applications and\neffectiveness, by considering case studies from genetics and neuroscience.\n",
        "authors": "Charles Westphal; Stephen Hailes; Mirco Musolesi",
        "status": 0,
        "relevancy": 0.28308530850550995,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18894",
        "date": "2024-05-29",
        "title": "Few-Shot Testing: Estimating Uncertainty of Memristive Deep Neural\n  Networks Using One Bayesian Test Vector",
        "abstract": "  The performance of deep learning algorithms such as neural networks (NNs) has\nincreased tremendously recently, and they can achieve state-of-the-art\nperformance in many domains. However, due to memory and computation resource\nconstraints, implementing NNs on edge devices is a challenging task. Therefore,\nhardware accelerators such as computation-in-memory (CIM) with memristive\ndevices have been developed to accelerate the most common operations, i.e.,\nmatrix-vector multiplication. However, due to inherent device properties,\nexternal environmental factors such as temperature, and an immature fabrication\nprocess, memristors suffer from various non-idealities, including defects and\nvariations occurring during manufacturing and runtime. Consequently, there is a\nlack of complete confidence in the predictions made by the model. To improve\nconfidence in NN predictions made by hardware accelerators in the presence of\ndevice non-idealities, in this paper, we propose a Bayesian test vector\ngeneration framework that can estimate the model uncertainty of NNs implemented\non memristor-based CIM hardware. Compared to the conventional point estimate\ntest vector generation method, our method is more generalizable across\ndifferent model dimensions and requires storing only one test Bayesian vector\nin the hardware. Our method is evaluated on different model dimensions, tasks,\nfault rates, and variation noise to show that it can consistently achieve\n$100\\%$ coverage with only $0.024$ MB of memory overhead.\n",
        "authors": "Soyed Tuhin Ahmed; Mehdi Tahoori",
        "status": 0,
        "relevancy": 0.2822313482469797,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19471",
        "date": "2024-05-29",
        "title": "The Data Minimization Principle in Machine Learning",
        "abstract": "  The principle of data minimization aims to reduce the amount of data\ncollected, processed or retained to minimize the potential for misuse,\nunauthorized access, or data breaches. Rooted in privacy-by-design principles,\ndata minimization has been endorsed by various global data protection\nregulations. However, its practical implementation remains a challenge due to\nthe lack of a rigorous formulation. This paper addresses this gap and\nintroduces an optimization framework for data minimization based on its legal\ndefinitions. It then adapts several optimization algorithms to perform data\nminimization and conducts a comprehensive evaluation in terms of their\ncompliance with minimization objectives as well as their impact on user\nprivacy. Our analysis underscores the mismatch between the privacy expectations\nof data minimization and the actual privacy benefits, emphasizing the need for\napproaches that account for multiple facets of real-world privacy risks.\n",
        "authors": "Prakhar Ganesh; Cuong Tran; Reza Shokri; Ferdinando Fioretto",
        "status": 0,
        "relevancy": 0.24154683442099745,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18999",
        "date": "2024-05-29",
        "title": "Continuously Optimizing Radar Placement with Model Predictive Path\n  Integrals",
        "abstract": "  Continuously optimizing sensor placement is essential for precise target\nlocalization in various military and civilian applications. While information\ntheory has shown promise in optimizing sensor placement, many studies\noversimplify sensor measurement models or neglect dynamic constraints of mobile\nsensors. To address these challenges, we employ a range measurement model that\nincorporates radar parameters and radar-target distance, coupled with Model\nPredictive Path Integral (MPPI) control to manage complex environmental\nobstacles and dynamic constraints. We compare the proposed approach against\nstationary radars or simplified range measurement models based on the root mean\nsquared error (RMSE) of the Cubature Kalman Filter (CKF) estimator for the\ntargets' state. Additionally, we visualize the evolving geometry of radars and\ntargets over time, highlighting areas of highest measurement information gain,\ndemonstrating the strengths of the approach. The proposed strategy outperforms\nstationary radars and simplified range measurement models in target\nlocalization, achieving a 38-74% reduction in mean RMSE and a 33-79% reduction\nin the upper tail of the 90% Highest Density Interval (HDI) over 500 Monte Carl\n(MC) trials across all time steps.\n  Code will be made publicly available upon acceptance.\n",
        "authors": "Michael Potter; Shuo Tang; Paul Ghanem; Milica Stojanovic; Pau Closas; Murat Akcakaya; Ben Wright; Marius Necsoiu; Deniz Erdogmus; Michael Everett; Tales Imbiriba",
        "status": 0,
        "relevancy": 0.23836429077249166,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19184",
        "date": "2024-05-29",
        "title": "Promoting Two-sided Fairness in Dynamic Vehicle Routing Problem",
        "abstract": "  Dynamic Vehicle Routing Problem (DVRP), is an extension of the classic\nVehicle Routing Problem (VRP), which is a fundamental problem in logistics and\ntransportation. Typically, DVRPs involve two stakeholders: service providers\nthat deliver services to customers and customers who raise requests from\ndifferent locations. Many real-world applications can be formulated as DVRP\nsuch as ridesharing and non-compliance capture. Apart from original objectives\nlike optimising total utility or efficiency, DVRP should also consider fairness\nfor all parties. Unfairness can induce service providers and customers to give\nup on the systems, leading to negative financial and social impacts. However,\nmost existing DVRP-related applications focus on improving fairness from a\nsingle side, and there have been few works considering two-sided fairness and\nutility optimisation concurrently. To this end, we propose a novel framework, a\nTwo-sided Fairness-aware Genetic Algorithm (named 2FairGA), which expands the\ngenetic algorithm from the original objective solely focusing on utility to\nmulti-objectives that incorporate two-sided fairness. Subsequently, the impact\nof injecting two fairness definitions into the utility-focused model and the\ncorrelation between any pair of the three objectives are explored. Extensive\nexperiments demonstrate the superiority of our proposed framework compared to\nthe state-of-the-art.\n",
        "authors": "Yufan Kang; Rongsheng Zhang; Wei Shao; Flora D. Salim; Jeffrey Chan",
        "status": 0,
        "relevancy": 0.22907416774040323,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18731",
        "date": "2024-05-29",
        "title": "VBIM-Net: Variational Born Iterative Network for Inverse Scattering\n  Problems",
        "abstract": "  Recently, studies have shown the potential of integrating field-type\niterative methods with deep learning (DL) techniques in solving inverse\nscattering problems (ISPs). In this article, we propose a novel Variational\nBorn Iterative Network, namely, VBIM-Net, to solve the full-wave ISPs with\nsignificantly improved flexibility and inversion quality. The proposed VBIM-Net\nemulates the alternating updates of the total electric field and the contrast\nin the variational Born iterative method (VBIM) by multiple layers of\nsubnetworks. We embed the calculation of the contrast variation into each of\nthe subnetworks, converting the scattered field residual into an approximate\ncontrast variation and then enhancing it by a U-Net, thus avoiding the\nrequirement of matched measurement dimension and grid resolution as in existing\napproaches. The total field and contrast of each layer's output is supervised\nin the loss function of VBIM-Net, which guarantees the physical\ninterpretability of variables of the subnetworks. In addition, we design a\ntraining scheme with extra noise to enhance the model's stability. Extensive\nnumerical results on synthetic and experimental data both verify the inversion\nquality, generalization ability, and robustness of the proposed VBIM-Net. This\nwork may provide some new inspiration for the design of efficient field-type DL\nschemes.\n",
        "authors": "Ziqing Xing; Zhaoyang Zhang; Zirui Chen; Yusong Wang; Haoran Ma; Zhun Wei; Gang Bao",
        "status": 0,
        "relevancy": 0.22405573259782163,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19012",
        "date": "2024-05-29",
        "title": "Implicit Neural Image Field for Biological Microscopy Image Compression",
        "abstract": "  The rapid pace of innovation in biological microscopy imaging has led to\nlarge images, putting pressure on data storage and impeding efficient sharing,\nmanagement, and visualization. This necessitates the development of efficient\ncompression solutions. Traditional CODEC methods struggle to adapt to the\ndiverse bioimaging data and often suffer from sub-optimal compression. In this\nstudy, we propose an adaptive compression workflow based on Implicit Neural\nRepresentation (INR). This approach permits application-specific compression\nobjectives, capable of compressing images of any shape and arbitrary pixel-wise\ndecompression. We demonstrated on a wide range of microscopy images from real\napplications that our workflow not only achieved high, controllable compression\nratios (e.g., 512x) but also preserved detailed information critical for\ndownstream analysis.\n",
        "authors": "Gaole Dai; Cheng-Ching Tseng; Qingpo Wuwu; Rongyu Zhang; Shaokang Wang; Ming Lu; Tiejun Huang; Yu Zhou; Ali Ata Tuz; Matthias Gunzer; Jianxu Chen; Shanghang Zhang",
        "status": 0,
        "relevancy": 0.22247836646075891,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19413",
        "date": "2024-05-29",
        "title": "VisTA-SR: Improving the Accuracy and Resolution of Low-Cost Thermal\n  Imaging Cameras for Agriculture",
        "abstract": "  Thermal cameras are an important tool for agricultural research because they\nallow for non-invasive measurement of plant temperature, which relates to\nimportant photochemical, hydraulic, and agronomic traits. Utilizing low-cost\nthermal cameras can lower the barrier to introducing thermal imaging in\nagricultural research and production. This paper presents an approach to\nimprove the temperature accuracy and image quality of low-cost thermal imaging\ncameras for agricultural applications. Leveraging advancements in computer\nvision techniques, particularly deep learning networks, we propose a method,\ncalled $\\textbf{VisTA-SR}$ ($\\textbf{Vis}$ual \\& $\\textbf{T}$hermal\n$\\textbf{A}$lignment and $\\textbf{S}$uper-$\\textbf{R}$esolution Enhancement)\nthat combines RGB and thermal images to enhance the capabilities of\nlow-resolution thermal cameras. The research includes calibration and\nvalidation of temperature measurements, acquisition of paired image datasets,\nand the development of a deep learning network tailored for agricultural\nthermal imaging. Our study addresses the challenges of image enhancement in the\nagricultural domain and explores the potential of low-cost thermal cameras to\nreplace high-resolution industrial cameras. Experimental results demonstrate\nthe effectiveness of our approach in enhancing temperature accuracy and image\nsharpness, paving the way for more accessible and efficient thermal imaging\nsolutions in agriculture.\n",
        "authors": "Heesup Yun; Sassoum Lo; Christine H. Diepenbrock; Brian N. Bailey; J. Mason Earles",
        "status": 0,
        "relevancy": 0.2125032929335794,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.18889",
        "date": "2024-05-29",
        "title": "On Perception of Prevalence of Cheating and Usage of Generative AI",
        "abstract": "  This report investigates the perceptions of teaching staff on the prevalence\nof student cheating and the impact of Generative AI on academic integrity. Data\nwas collected via an anonymous survey of teachers at the Department of\nInformation Technology at Uppsala University and analyzed alongside\ninstitutional statistics on cheating investigations from 2004 to 2023. The\nresults indicate that while teachers generally do not view cheating as highly\nprevalent, there is a strong belief that its incidence is increasing,\npotentially due to the accessibility of Generative AI. Most teachers do not\nequate AI usage with cheating but acknowledge its widespread use among\nstudents. Furthermore, teachers' perceptions align with objective data on\ncheating trends, highlighting their awareness of the evolving landscape of\nacademic dishonesty.\n",
        "authors": "Roman Denkin",
        "status": 0,
        "relevancy": 0.2014656036339435,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      },
      {
        "id": "2405.19085",
        "date": "2024-05-29",
        "title": "Patch-enhanced Mask Encoder Prompt Image Generation",
        "abstract": "  Artificial Intelligence Generated Content(AIGC), known for its superior\nvisual results, represents a promising mitigation method for high-cost\nadvertising applications. Numerous approaches have been developed to manipulate\ngenerated content under different conditions. However, a crucial limitation\nlies in the accurate description of products in advertising applications.\nApplying previous methods directly may lead to considerable distortion and\ndeformation of advertised products, primarily due to oversimplified content\ncontrol conditions. Hence, in this work, we propose a patch-enhanced mask\nencoder approach to ensure accurate product descriptions while preserving\ndiverse backgrounds. Our approach consists of three components Patch Flexible\nVisibility, Mask Encoder Prompt Adapter and an image Foundation Model. Patch\nFlexible Visibility is used for generating a more reasonable background image.\nMask Encoder Prompt Adapter enables region-controlled fusion. We also conduct\nan analysis of the structure and operational mechanisms of the Generation\nModule. Experimental results show our method can achieve the highest visual\nresults and FID scores compared with other methods.\n",
        "authors": "Shusong Xu; Peiye Liu",
        "status": 0,
        "relevancy": 0.19786574989094752,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T05:21:04.773Z",
        "updatedAt": "2024-05-31T05:21:04.773Z",
        "DatesTable": {
          "value": "2024-05-29",
          "status": "complete",
          "count": 133,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T05:21:04.775Z"
        }
      }
    ]
  },
  {
    "date": {
      "value": "2024-05-28",
      "status": "complete",
      "count": 161,
      "createdAt": "2024-05-31 00:09:48.114 +00:00",
      "updatedAt": "2024-05-31 04:51:45.389 +00:00"
    },
    "papers": [
      {
        "id": "2405.17950",
        "date": "2024-05-28",
        "title": "Self-Guiding Exploration for Combinatorial Problems",
        "abstract": "  Large Language Models (LLMs) have become pivotal in addressing reasoning\ntasks across diverse domains, including arithmetic, commonsense, and symbolic\nreasoning. They utilize prompting techniques such as Exploration-of-Thought,\nDecomposition, and Refinement to effectively navigate and solve intricate\ntasks. Despite these advancements, the application of LLMs to Combinatorial\nProblems (CPs), known for their NP-hardness and critical roles in logistics and\nresource management remains underexplored. To address this gap, we introduce a\nnovel prompting strategy: Self-Guiding Exploration (SGE), designed to enhance\nthe performance of solving CPs. SGE operates autonomously, generating multiple\nthought trajectories for each CP task. It then breaks these trajectories down\ninto actionable subtasks, executes them sequentially, and refines the results\nto ensure optimal outcomes. We present our research as the first to apply LLMs\nto a broad range of CPs and demonstrate that SGE outperforms existing prompting\nstrategies by over 27.84% in CP optimization performance. Additionally, SGE\nachieves a 2.46% higher accuracy over the best existing results in other\nreasoning tasks (arithmetic, commonsense, and symbolic).\n",
        "authors": "Zangir Iklassov; Yali Du; Farkhad Akimov; Martin Takac",
        "status": 0,
        "relevancy": 0.6772564044041381,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18208",
        "date": "2024-05-28",
        "title": "A Human-Like Reasoning Framework for Multi-Phases Planning Task with\n  Large Language Models",
        "abstract": "  Recent studies have highlighted their proficiency in some simple tasks like\nwriting and coding through various reasoning strategies. However, LLM agents\nstill struggle with tasks that require comprehensive planning, a process that\nchallenges current models and remains a critical research issue. In this study,\nwe concentrate on travel planning, a Multi-Phases planning problem, that\ninvolves multiple interconnected stages, such as outlining, information\ngathering, and planning, often characterized by the need to manage various\nconstraints and uncertainties. Existing reasoning approaches have struggled to\neffectively address this complex task. Our research aims to address this\nchallenge by developing a human-like planning framework for LLM agents, i.e.,\nguiding the LLM agent to simulate various steps that humans take when solving\nMulti-Phases problems. Specifically, we implement several strategies to enable\nLLM agents to generate a coherent outline for each travel query, mirroring\nhuman planning patterns. Additionally, we integrate Strategy Block and\nKnowledge Block into our framework: Strategy Block facilitates information\ncollection, while Knowledge Block provides essential information for detailed\nplanning. Through our extensive experiments, we demonstrate that our framework\nsignificantly improves the planning capabilities of LLM agents, enabling them\nto tackle the travel planning task with improved efficiency and effectiveness.\nOur experimental results showcase the exceptional performance of the proposed\nframework; when combined with GPT-4-Turbo, it attains $10\\times$ the\nperformance gains in comparison to the baseline framework deployed on\nGPT-4-Turbo.\n",
        "authors": "Chengxing Xie; Difan Zou",
        "status": 0,
        "relevancy": 0.6687598875397698,
        "isStarred": true,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:52:20.960Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17974",
        "date": "2024-05-28",
        "title": "Recent Trends in Personalized Dialogue Generation: A Review of Datasets,\n  Methodologies, and Evaluations",
        "abstract": "  Enhancing user engagement through personalization in conversational agents\nhas gained significance, especially with the advent of large language models\nthat generate fluent responses. Personalized dialogue generation, however, is\nmultifaceted and varies in its definition -- ranging from instilling a persona\nin the agent to capturing users' explicit and implicit cues. This paper seeks\nto systemically survey the recent landscape of personalized dialogue\ngeneration, including the datasets employed, methodologies developed, and\nevaluation metrics applied. Covering 22 datasets, we highlight benchmark\ndatasets and newer ones enriched with additional features. We further analyze\n17 seminal works from top conferences between 2021-2023 and identify five\ndistinct types of problems. We also shed light on recent progress by LLMs in\npersonalized dialogue generation. Our evaluation section offers a comprehensive\nsummary of assessment facets and metrics utilized in these works. In\nconclusion, we discuss prevailing challenges and envision prospect directions\nfor future research in personalized dialogue generation.\n",
        "authors": "Yi-Pei Chen; Noriki Nishida; Hideki Nakayama; Yuji Matsumoto",
        "status": 0,
        "relevancy": 0.658808673281338,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:52:09.160Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18581",
        "date": "2024-05-28",
        "title": "Unleashing the Potential of Text-attributed Graphs: Automatic Relation\n  Decomposition via Large Language Models",
        "abstract": "  Recent advancements in text-attributed graphs (TAGs) have significantly\nimproved the quality of node features by using the textual modeling\ncapabilities of language models. Despite this success, utilizing text\nattributes to enhance the predefined graph structure remains largely\nunexplored. Our extensive analysis reveals that conventional edges on TAGs,\ntreated as a single relation (e.g., hyperlinks) in previous literature,\nactually encompass mixed semantics (e.g., \"advised by\" and \"participates in\").\nThis simplification hinders the representation learning process of Graph Neural\nNetworks (GNNs) on downstream tasks, even when integrated with advanced node\nfeatures. In contrast, we discover that decomposing these edges into distinct\nsemantic relations significantly enhances the performance of GNNs. Despite\nthis, manually identifying and labeling of edges to corresponding semantic\nrelations is labor-intensive, often requiring domain expertise. To this end, we\nintroduce RoSE (Relation-oriented Semantic Edge-decomposition), a novel\nframework that leverages the capability of Large Language Models (LLMs) to\ndecompose the graph structure by analyzing raw text attributes - in a fully\nautomated manner. RoSE operates in two stages: (1) identifying meaningful\nrelations using an LLM-based generator and discriminator, and (2) categorizing\neach edge into corresponding relations by analyzing textual contents associated\nwith connected nodes via an LLM-based decomposer. Extensive experiments\ndemonstrate that our model-agnostic framework significantly enhances node\nclassification performance across various datasets, with improvements of up to\n16% on the Wisconsin dataset.\n",
        "authors": "Hyunjin Seo; Taewon Kim; June Yong Yang; Eunho Yang",
        "status": 0,
        "relevancy": 0.625058710296175,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18369",
        "date": "2024-05-28",
        "title": "PromptWizard: Task-Aware Agent-driven Prompt Optimization Framework",
        "abstract": "  Large language models (LLMs) have revolutionized AI across diverse domains,\nshowcasing remarkable capabilities. Central to their success is the concept of\nprompting, which guides model output generation. However, manual prompt\nengineering is labor-intensive and domain-specific, necessitating automated\nsolutions. This paper introduces PromptWizard, a novel framework leveraging\nLLMs to iteratively synthesize and refine prompts tailored to specific tasks.\nUnlike existing approaches, PromptWizard optimizes both prompt instructions and\nin-context examples, maximizing model performance. The framework iteratively\nrefines prompts by mutating instructions and incorporating negative examples to\ndeepen understanding and ensure diversity. It further enhances both\ninstructions and examples with the aid of a critic, synthesizing new\ninstructions and examples enriched with detailed reasoning steps for optimal\nperformance. PromptWizard offers several key features and capabilities,\nincluding computational efficiency compared to state-of-the-art approaches,\nadaptability to scenarios with varying amounts of training data, and\neffectiveness with smaller LLMs. Rigorous evaluation across 35 tasks on 8\ndatasets demonstrates PromptWizard's superiority over existing prompt\nstrategies, showcasing its efficacy and scalability in prompt optimization.\n",
        "authors": "Eshaan Agarwal; Vivek Dani; Tanuja Ganu; Akshay Nambi",
        "status": 0,
        "relevancy": 0.6224390267317457,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18110",
        "date": "2024-05-28",
        "title": "Individual Contributions as Intrinsic Exploration Scaffolds for\n  Multi-agent Reinforcement Learning",
        "abstract": "  In multi-agent reinforcement learning (MARL), effective exploration is\ncritical, especially in sparse reward environments. Although introducing global\nintrinsic rewards can foster exploration in such settings, it often complicates\ncredit assignment among agents. To address this difficulty, we propose\nIndividual Contributions as intrinsic Exploration Scaffolds (ICES), a novel\napproach to motivate exploration by assessing each agent's contribution from a\nglobal view. In particular, ICES constructs exploration scaffolds with Bayesian\nsurprise, leveraging global transition information during centralized training.\nThese scaffolds, used only in training, help to guide individual agents towards\nactions that significantly impact the global latent state transitions.\nAdditionally, ICES separates exploration policies from exploitation policies,\nenabling the former to utilize privileged global information during training.\nExtensive experiments on cooperative benchmark tasks with sparse rewards,\nincluding Google Research Football (GRF) and StarCraft Multi-agent Challenge\n(SMAC), demonstrate that ICES exhibits superior exploration capabilities\ncompared with baselines. The code is publicly available at\nhttps://github.com/LXXXXR/ICES.\n",
        "authors": "Xinran Li; Zifan Liu; Shibo Chen; Jun Zhang",
        "status": 0,
        "relevancy": 0.610816543969512,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18118",
        "date": "2024-05-28",
        "title": "An approach to improve agent learning via guaranteeing goal reaching in\n  all episodes",
        "abstract": "  Reinforcement learning is commonly concerned with problems of maximizing\naccumulated rewards in Markov decision processes. Oftentimes, a certain goal\nstate or a subset of the state space attain maximal reward. In such a case, the\nenvironment may be considered solved when the goal is reached. Whereas numerous\ntechniques, learning or non-learning based, exist for solving environments,\ndoing so optimally is the biggest challenge. Say, one may choose a reward rate\nwhich penalizes the action effort. Reinforcement learning is currently among\nthe most actively developed frameworks for solving environments optimally by\nvirtue of maximizing accumulated reward, in other words, returns. Yet, tuning\nagents is a notoriously hard task as reported in a series of works. Our aim\nhere is to help the agent learn a near-optimal policy efficiently while\nensuring a goal reaching property of some basis policy that merely solves the\nenvironment. We suggest an algorithm, which is fairly flexible, and can be used\nto augment practically any agent as long as it comprises of a critic. A formal\nproof of a goal reaching property is provided. Simulation experiments on six\nproblems under five agents, including the benchmarked one, provided an\nempirical evidence that the learning can indeed be boosted while ensuring goal\nreaching property.\n",
        "authors": "Pavel Osinenko; Grigory Yaremenko; Georgiy Malaniya; Anton Bolychev",
        "status": 0,
        "relevancy": 0.599505902476585,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18359",
        "date": "2024-05-28",
        "title": "Bridging the Gap: Dynamic Learning Strategies for Improving Multilingual\n  Performance in LLMs",
        "abstract": "  Large language models (LLMs) are at the forefront of transforming numerous\ndomains globally. However, their inclusivity and effectiveness remain limited\nfor non-Latin scripts and low-resource languages. This paper tackles the\nimperative challenge of enhancing the multilingual performance of LLMs without\nextensive training or fine-tuning. Through systematic investigation and\nevaluation of diverse languages using popular question-answering (QA) datasets,\nwe present novel techniques that unlock the true potential of LLMs in a\npolyglot landscape. Our approach encompasses three key strategies that yield\nsignificant improvements in multilingual proficiency. First, by meticulously\noptimizing prompts tailored for polyglot LLMs, we unlock their latent\ncapabilities, resulting in substantial performance boosts across languages.\nSecond, we introduce a new hybrid approach that synergizes LLM Retrieval\nAugmented Generation (RAG) with multilingual embeddings and achieves improved\nmultilingual task performance. Finally, we introduce a novel learning approach\nthat dynamically selects the optimal prompt strategy, LLM model, and embedding\nmodel per query at run-time. This dynamic adaptation maximizes the efficacy of\nLLMs across languages, outperforming best static and random strategies.\nAdditionally, our approach adapts configurations in both offline and online\nsettings, and can seamlessly adapt to new languages and datasets, leading to\nsubstantial advancements in multilingual understanding and generation across\ndiverse languages.\n",
        "authors": "Somnath Kumar; Vaibhav Balloli; Mercy Ranjit; Kabir Ahuja; Tanuja Ganu; Sunayana Sitaram; Kalika Bali; Akshay Nambi",
        "status": 0,
        "relevancy": 0.591437679750576,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17822",
        "date": "2024-05-28",
        "title": "Conv-CoA: Improving Open-domain Question Answering in Large Language\n  Models via Conversational Chain-of-Action",
        "abstract": "  We present a Conversational Chain-of-Action (Conv-CoA) framework for\nOpen-domain Conversational Question Answering (OCQA). Compared with literature,\nConv-CoA addresses three major challenges: (i) unfaithful hallucination that is\ninconsistent with real-time or domain facts, (ii) weak reasoning performance in\nconversational scenarios, and (iii) unsatisfying performance in conversational\ninformation retrieval. Our key contribution is a dynamic reasoning-retrieval\nmechanism that extracts the intent of the question and decomposes it into a\nreasoning chain to be solved via systematic prompting, pre-designed actions,\nupdating the Contextual Knowledge Set (CKS), and a novel Hopfield-based\nretriever. Methodologically, we propose a resource-efficiency Hopfield\nretriever to enhance the efficiency and accuracy of conversational information\nretrieval within our actions. Additionally, we propose a\nconversational-multi-reference faith score (Conv-MRFS) to verify and resolve\nconflicts between retrieved knowledge and answers in conversations.\nEmpirically, we conduct comparisons between our framework and 23\nstate-of-the-art methods across five different research directions and two\npublic benchmarks. These comparisons demonstrate that our Conv-CoA outperforms\nother methods in both the accuracy and efficiency dimensions.\n",
        "authors": "Zhenyu Pan; Haozheng Luo; Manling Li; Han Liu",
        "status": 0,
        "relevancy": 0.5879060542498787,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18414",
        "date": "2024-05-28",
        "title": "Don't Forget to Connect! Improving RAG with Graph-based Reranking",
        "abstract": "  Retrieval Augmented Generation (RAG) has greatly improved the performance of\nLarge Language Model (LLM) responses by grounding generation with context from\nexisting documents. These systems work well when documents are clearly relevant\nto a question context. But what about when a document has partial information,\nor less obvious connections to the context? And how should we reason about\nconnections between documents? In this work, we seek to answer these two core\nquestions about RAG generation. We introduce G-RAG, a reranker based on graph\nneural networks (GNNs) between the retriever and reader in RAG. Our method\ncombines both connections between documents and semantic information (via\nAbstract Meaning Representation graphs) to provide a context-informed ranker\nfor RAG. G-RAG outperforms state-of-the-art approaches while having smaller\ncomputational footprint. Additionally, we assess the performance of PaLM 2 as a\nreranker and find it to significantly underperform G-RAG. This result\nemphasizes the importance of reranking for RAG even when using Large Language\nModels.\n",
        "authors": "Jialin Dong; Bahare Fatemi; Bryan Perozzi; Lin F. Yang; Anton Tsitsulin",
        "status": 0,
        "relevancy": 0.5847993182247199,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17888",
        "date": "2024-05-28",
        "title": "Getting More Juice Out of the SFT Data: Reward Learning from Human\n  Demonstration Improves SFT for LLM Alignment",
        "abstract": "  Aligning human preference and value is an important requirement for\ncontemporary foundation models. State-of-the-art techniques such as\nReinforcement Learning from Human Feedback (RLHF) often consist of two stages:\n1) supervised fine-tuning (SFT), where the model is fine-tuned by learning from\nhuman demonstration data; 2) Preference learning, where preference data is used\nto learn a reward model, which is in turn used by a reinforcement learning (RL)\nstep to fine-tune the model. Such reward model serves as a proxy to human\npreference, and it is critical to guide the RL step towards improving the model\nquality. In this work, we argue that the SFT stage significantly benefits from\nlearning a reward model as well. Instead of using the human demonstration data\ndirectly via supervised learning, we propose to leverage an Inverse\nReinforcement Learning (IRL) technique to (explicitly or implicitly) build an\nreward model, while learning the policy model. This approach leads to new SFT\nalgorithms that are not only efficient to implement, but also promote the\nability to distinguish between the preferred and non-preferred continuations.\nMoreover, we identify a connection between the proposed IRL based approach, and\ncertain self-play approach proposed recently, and showed that self-play is a\nspecial case of modeling a reward-learning agent. Theoretically, we show that\nthe proposed algorithms converge to the stationary solutions of the IRL\nproblem. Empirically, we align 1B and 7B models using proposed methods and\nevaluate them on a reward benchmark model and the HuggingFace Open LLM\nLeaderboard. The proposed methods show significant performance improvement over\nexisting SFT approaches. Our results indicate that it is beneficial to\nexplicitly or implicitly leverage reward learning throughout the entire\nalignment process.\n",
        "authors": "Jiaxiang Li; Siliang Zeng; Hoi-To Wai; Chenliang Li; Alfredo Garcia; Mingyi Hong",
        "status": 0,
        "relevancy": 0.5838876694831042,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18289",
        "date": "2024-05-28",
        "title": "Highway Reinforcement Learning",
        "abstract": "  Learning from multi-step off-policy data collected by a set of policies is a\ncore problem of reinforcement learning (RL). Approaches based on importance\nsampling (IS) often suffer from large variances due to products of IS ratios.\nTypical IS-free methods, such as $n$-step Q-learning, look ahead for $n$ time\nsteps along the trajectory of actions (where $n$ is called the lookahead depth)\nand utilize off-policy data directly without any additional adjustment. They\nwork well for proper choices of $n$. We show, however, that such IS-free\nmethods underestimate the optimal value function (VF), especially for large\n$n$, restricting their capacity to efficiently utilize information from distant\nfuture time steps. To overcome this problem, we introduce a novel, IS-free,\nmulti-step off-policy method that avoids the underestimation issue and\nconverges to the optimal VF. At its core lies a simple but non-trivial\n\\emph{highway gate}, which controls the information flow from the distant\nfuture by comparing it to a threshold. The highway gate guarantees convergence\nto the optimal VF for arbitrary $n$ and arbitrary behavioral policies. It gives\nrise to a novel family of off-policy RL algorithms that safely learn even when\n$n$ is very large, facilitating rapid credit assignment from the far future to\nthe past. On tasks with greatly delayed rewards, including video games where\nthe reward is given only at the end of the game, our new methods outperform\nmany existing multi-step off-policy algorithms.\n",
        "authors": "Yuhui Wang; Miroslav Strupl; Francesco Faccio; Qingyuan Wu; Haozhe Liu; Michał Grudzień; Xiaoyang Tan; Jürgen Schmidhuber",
        "status": 0,
        "relevancy": 0.5819882330995535,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18344",
        "date": "2024-05-28",
        "title": "The Battle of LLMs: A Comparative Study in Conversational QA Tasks",
        "abstract": "  Large language models have gained considerable interest for their impressive\nperformance on various tasks. Within this domain, ChatGPT and GPT-4, developed\nby OpenAI, and the Gemini, developed by Google, have emerged as particularly\npopular among early adopters. Additionally, Mixtral by Mistral AI and Claude by\nAnthropic are newly released, further expanding the landscape of advanced\nlanguage models. These models are viewed as disruptive technologies with\napplications spanning customer service, education, healthcare, and finance.\nMore recently, Mistral has entered the scene, captivating users with its unique\nability to generate creative content. Understanding the perspectives of these\nusers is crucial, as they can offer valuable insights into the potential\nstrengths, weaknesses, and overall success or failure of these technologies in\nvarious domains. This research delves into the responses generated by ChatGPT,\nGPT-4, Gemini, Mixtral and Claude across different Conversational QA corpora.\nEvaluation scores were meticulously computed and subsequently compared to\nascertain the overall performance of these models. Our study pinpointed\ninstances where these models provided inaccurate answers to questions, offering\ninsights into potential areas where they might be susceptible to errors. In\nessence, this research provides a comprehensive comparison and evaluation of\nthese state of-the-art language models, shedding light on their capabilities\nwhile also highlighting potential areas for improvement\n",
        "authors": "Aryan Rangapur; Aman Rangapur",
        "status": 0,
        "relevancy": 0.5813454744354037,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17935",
        "date": "2024-05-28",
        "title": "Tool Learning with Large Language Models: A Survey",
        "abstract": "  Recently, tool learning with large language models (LLMs) has emerged as a\npromising paradigm for augmenting the capabilities of LLMs to tackle highly\ncomplex problems. Despite growing attention and rapid advancements in this\nfield, the existing literature remains fragmented and lacks systematic\norganization, posing barriers to entry for newcomers. This gap motivates us to\nconduct a comprehensive survey of existing works on tool learning with LLMs. In\nthis survey, we focus on reviewing existing literature from the two primary\naspects (1) why tool learning is beneficial and (2) how tool learning is\nimplemented, enabling a comprehensive understanding of tool learning with LLMs.\nWe first explore the \"why\" by reviewing both the benefits of tool integration\nand the inherent benefits of the tool learning paradigm from six specific\naspects. In terms of \"how\", we systematically review the literature according\nto a taxonomy of four key stages in the tool learning workflow: task planning,\ntool selection, tool calling, and response generation. Additionally, we provide\na detailed summary of existing benchmarks and evaluation methods, categorizing\nthem according to their relevance to different stages. Finally, we discuss\ncurrent challenges and outline potential future directions, aiming to inspire\nboth researchers and industrial developers to further explore this emerging and\npromising area. We also maintain a GitHub repository to continually keep track\nof the relevant papers and resources in this rising area at\n\\url{https://github.com/quchangle1/LLM-Tool-Survey}.\n",
        "authors": "Changle Qu; Sunhao Dai; Xiaochi Wei; Hengyi Cai; Shuaiqiang Wang; Dawei Yin; Jun Xu; Ji-Rong Wen",
        "status": 0,
        "relevancy": 0.5772621332788771,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18358",
        "date": "2024-05-28",
        "title": "MMCTAgent: Multi-modal Critical Thinking Agent Framework for Complex\n  Visual Reasoning",
        "abstract": "  Recent advancements in Multi-modal Large Language Models (MLLMs) have\nsignificantly improved their performance in tasks combining vision and\nlanguage. However, challenges persist in detailed multi-modal understanding,\ncomprehension of complex tasks, and reasoning over multi-modal information.\nThis paper introduces MMCTAgent, a novel multi-modal critical thinking agent\nframework designed to address the inherent limitations of current MLLMs in\ncomplex visual reasoning tasks. Inspired by human cognitive processes and\ncritical thinking, MMCTAgent iteratively analyzes multi-modal information,\ndecomposes queries, plans strategies, and dynamically evolves its reasoning.\nAdditionally, MMCTAgent incorporates critical thinking elements such as\nverification of final answers and self-reflection through a novel approach that\ndefines a vision-based critic and identifies task-specific evaluation criteria,\nthereby enhancing its decision-making abilities. Through rigorous evaluations\nacross various image and video understanding benchmarks, we demonstrate that\nMMCTAgent (with and without the critic) outperforms both foundational MLLMs and\nother tool-augmented pipelines.\n",
        "authors": "Somnath Kumar; Yash Gadhia; Tanuja Ganu; Akshay Nambi",
        "status": 0,
        "relevancy": 0.5743416288656753,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18520",
        "date": "2024-05-28",
        "title": "Offline-Boosted Actor-Critic: Adaptively Blending Optimal Historical\n  Behaviors in Deep Off-Policy RL",
        "abstract": "  Off-policy reinforcement learning (RL) has achieved notable success in\ntackling many complex real-world tasks, by leveraging previously collected data\nfor policy learning. However, most existing off-policy RL algorithms fail to\nmaximally exploit the information in the replay buffer, limiting sample\nefficiency and policy performance. In this work, we discover that concurrently\ntraining an offline RL policy based on the shared online replay buffer can\nsometimes outperform the original online learning policy, though the occurrence\nof such performance gains remains uncertain. This motivates a new possibility\nof harnessing the emergent outperforming offline optimal policy to improve\nonline policy learning. Based on this insight, we present Offline-Boosted\nActor-Critic (OBAC), a model-free online RL framework that elegantly identifies\nthe outperforming offline policy through value comparison, and uses it as an\nadaptive constraint to guarantee stronger policy learning performance. Our\nexperiments demonstrate that OBAC outperforms other popular model-free RL\nbaselines and rivals advanced model-based RL methods in terms of sample\nefficiency and asymptotic performance across 53 tasks spanning 6 task suites.\n",
        "authors": "Yu Luo; Tianying Ji; Fuchun Sun; Jianwei Zhang; Huazhe Xu; Xianyuan Zhan",
        "status": 0,
        "relevancy": 0.5705726677815043,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18123",
        "date": "2024-05-28",
        "title": "PyTAG: Tabletop Games for Multi-Agent Reinforcement Learning",
        "abstract": "  Modern Tabletop Games present various interesting challenges for Multi-agent\nReinforcement Learning. In this paper, we introduce PyTAG, a new framework that\nsupports interacting with a large collection of games implemented in the\nTabletop Games framework. In this work we highlight the challenges tabletop\ngames provide, from a game-playing agent perspective, along with the\nopportunities they provide for future research. Additionally, we highlight the\ntechnical challenges that involve training Reinforcement Learning agents on\nthese games. To explore the Multi-agent setting provided by PyTAG we train the\npopular Proximal Policy Optimisation Reinforcement Learning algorithm using\nself-play on a subset of games and evaluate the trained policies against some\nsimple agents and Monte-Carlo Tree Search implemented in the Tabletop Games\nframework.\n",
        "authors": "Martin Balla; George E. M. Long; James Goodman; Raluca D. Gaina; Diego Perez-Liebana",
        "status": 0,
        "relevancy": 0.5615817257458973,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18380",
        "date": "2024-05-28",
        "title": "OwLore: Outlier-weighed Layerwise Sampled Low-Rank Projection for\n  Memory-Efficient LLM Fine-tuning",
        "abstract": "  The rapid advancements in Large Language Models (LLMs) have revolutionized\nvarious natural language processing tasks. However, the substantial size of\nLLMs presents significant challenges in training or fine-tuning. While\nparameter-efficient approaches such as low-rank adaptation (LoRA) have gained\npopularity, they often compromise performance compared to full-rank\nfine-tuning. In this paper, we propose Outlier-weighed Layerwise Sampled\nLow-Rank Projection (OwLore), a new memory-efficient fine-tuning approach,\ninspired by the layerwise outlier distribution of LLMs, which dynamically\nsamples pre-trained layers to fine-tune instead of adding additional adaptors.\nWe first interpret the outlier phenomenon through the lens of Heavy-Tailed\nSelf-Regularization theory (HT-SR), discovering that layers with more outliers\ntend to be more heavy-tailed and consequently better trained. Inspired by this\nfinding, OwLore strategically assigns higher sampling probabilities to layers\nwith more outliers to better leverage the knowledge stored in pre-trained LLMs.\nTo further mitigate the memory demands of fine-tuning, we integrate gradient\nlow-rank projection into our approach, which facilitates each layer to be\nefficiently trained in a low-rank manner. By incorporating the efficient\ncharacteristics of low-rank and optimal layerwise sampling, OwLore\nsignificantly improves the memory-performance trade-off in LLM pruning. Our\nextensive experiments across various architectures, including LLaMa2, LLaMa3,\nand Mistral, demonstrate that OwLore consistently outperforms baseline\napproaches, including full fine-tuning. Specifically, it achieves up to a 1.1%\naverage accuracy gain on the Commonsense Reasoning benchmark, a 3.0%\nimprovement on MMLU, and a notable 10% boost on MT-Bench, while being more\nmemory efficient. OwLore allows us to fine-tune LLaMa2-7B with only 21GB of\nmemory.\n",
        "authors": "Pengxiang Li; Lu Yin; Xiaowei Gao; Shiwei Liu",
        "status": 0,
        "relevancy": 0.5533503896343944,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18248",
        "date": "2024-05-28",
        "title": "Extreme Value Monte Carlo Tree Search",
        "abstract": "  Despite being successful in board games and reinforcement learning (RL), UCT,\na Monte-Carlo Tree Search (MCTS) combined with UCB1 Multi-Armed Bandit (MAB),\nhas had limited success in domain-independent planning until recently. Previous\nwork showed that UCB1, designed for $[0,1]$-bounded rewards, is not appropriate\nfor estimating the distance-to-go which are potentially unbounded in\n$\\mathbb{R}$, such as heuristic functions used in classical planning, then\nproposed combining MCTS with MABs designed for Gaussian reward distributions\nand successfully improved the performance. In this paper, we further sharpen\nour understanding of ideal bandits for planning tasks. Existing work has two\nissues: First, while Gaussian MABs no longer over-specify the distances as\n$h\\in [0,1]$, they under-specify them as $h\\in [-\\infty,\\infty]$ while they are\nnon-negative and can be further bounded in some cases. Second, there is no\ntheoretical justifications for Full-Bellman backup (Schulte & Keller, 2014)\nthat backpropagates minimum/maximum of samples. We identified \\emph{extreme\nvalue} statistics as a theoretical framework that resolves both issues at once\nand propose two bandits, UCB1-Uniform/Power, and apply them to MCTS for\nclassical planning. We formally prove their regret bounds and empirically\ndemonstrate their performance in classical planning.\n",
        "authors": "Masataro Asai; Stephen Wissow",
        "status": 0,
        "relevancy": 0.5518046770472743,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18028",
        "date": "2024-05-28",
        "title": "Edinburgh Clinical NLP at MEDIQA-CORR 2024: Guiding Large Language\n  Models with Hints",
        "abstract": "  The MEDIQA-CORR 2024 shared task aims to assess the ability of Large Language\nModels (LLMs) to identify and correct medical errors in clinical notes. In this\nstudy, we evaluate the capability of general LLMs, specifically GPT-3.5 and\nGPT-4, to identify and correct medical errors with multiple prompting\nstrategies. Recognising the limitation of LLMs in generating accurate\ncorrections only via prompting strategies, we propose incorporating error-span\npredictions from a smaller, fine-tuned model in two ways: 1) by presenting it\nas a hint in the prompt and 2) by framing it as multiple-choice questions from\nwhich the LLM can choose the best correction. We found that our proposed\nprompting strategies significantly improve the LLM's ability to generate\ncorrections. Our best-performing solution with 8-shot + CoT + hints ranked\nsixth in the shared task leaderboard. Additionally, our comprehensive analyses\nshow the impact of the location of the error sentence, the prompted role, and\nthe position of the multiple-choice option on the accuracy of the LLM. This\nprompts further questions about the readiness of LLM to be implemented in\nreal-world clinical settings.\n",
        "authors": "Aryo Pradipta Gema; Chaeeun Lee; Pasquale Minervini; Luke Daines; T. Ian Simpson; Beatrice Alex",
        "status": 0,
        "relevancy": 0.5509592100176375,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18649",
        "date": "2024-05-28",
        "title": "Training LLMs to Better Self-Debug and Explain Code",
        "abstract": "  In the domain of code generation, self-debugging is crucial. It allows LLMs\nto refine their generated code based on execution feedback. This is\nparticularly important because generating correct solutions in one attempt\nproves challenging for complex tasks. Prior works on self-debugging mostly\nfocus on prompting methods by providing LLMs with few-shot examples, which work\npoorly on small open-sourced LLMs. In this work, we propose a training\nframework that significantly improves self-debugging capability of LLMs.\nIntuitively, we observe that a chain of explanations on the wrong code followed\nby code refinement helps LLMs better analyze the wrong code and do refinement.\nWe thus propose an automated pipeline to collect a high-quality dataset for\ncode explanation and refinement by generating a number of explanations and\nrefinement trajectories and filtering via execution verification. We perform\nsupervised fine-tuning (SFT) and further reinforcement learning (RL) on both\nsuccess and failure trajectories with a novel reward design considering code\nexplanation and refinement quality. SFT improves the pass@1 by up to 15.92% and\npass@10 by 9.30% over four benchmarks. RL training brings additional up to\n3.54% improvement on pass@1 and 2.55% improvement on pass@10. The trained LLMs\nshow iterative refinement ability, and can keep refining code continuously.\nLastly, our human evaluation shows that the LLMs trained with our framework\ngenerate more useful code explanations and help developers better understand\nbugs in source code.\n",
        "authors": "Nan Jiang; Xiaopeng Li; Shiqi Wang; Qiang Zhou; Soneya Binta Hossain; Baishakhi Ray; Varun Kumar; Xiaofei Ma; Anoop Deoras",
        "status": 0,
        "relevancy": 0.5490521632445885,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18650",
        "date": "2024-05-28",
        "title": "Approximating Human Models During Argumentation-based Dialogues",
        "abstract": "  Explainable AI Planning (XAIP) aims to develop AI agents that can effectively\nexplain their decisions and actions to human users, fostering trust and\nfacilitating human-AI collaboration. A key challenge in XAIP is model\nreconciliation, which seeks to align the mental models of AI agents and humans.\nWhile existing approaches often assume a known and deterministic human model,\nthis simplification may not capture the complexities and uncertainties of\nreal-world interactions. In this paper, we propose a novel framework that\nenables AI agents to learn and update a probabilistic human model through\nargumentation-based dialogues. Our approach incorporates trust-based and\ncertainty-based update mechanisms, allowing the agent to refine its\nunderstanding of the human's mental state based on the human's expressed trust\nin the agent's arguments and certainty in their own arguments. We employ a\nprobability weighting function inspired by prospect theory to capture the\nrelationship between trust and perceived probability, and use a Bayesian\napproach to update the agent's probability distribution over possible human\nmodels. We conduct a human-subject study to empirically evaluate the\neffectiveness of our approach in an argumentation scenario, demonstrating its\nability to capture the dynamics of human belief formation and adaptation.\n",
        "authors": "Yinxu Tang; Stylianos Loukas Vasileiou; William Yeoh",
        "status": 0,
        "relevancy": 0.5392468235525845,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18512",
        "date": "2024-05-28",
        "title": "Understanding Transformer Reasoning Capabilities via Graph Algorithms",
        "abstract": "  Which transformer scaling regimes are able to perfectly solve different\nclasses of algorithmic problems? While tremendous empirical advances have been\nattained by transformer-based neural networks, a theoretical understanding of\ntheir algorithmic reasoning capabilities in realistic parameter regimes is\nlacking. We investigate this question in terms of the network's depth, width,\nand number of extra tokens for algorithm execution. Our novel representational\nhierarchy separates 9 algorithmic reasoning problems into classes solvable by\ntransformers in different realistic parameter scaling regimes. We prove that\nlogarithmic depth is necessary and sufficient for tasks like graph\nconnectivity, while single-layer transformers with small embedding dimensions\ncan solve contextual retrieval tasks. We also support our theoretical analysis\nwith ample empirical evidence using the GraphQA benchmark. These results show\nthat transformers excel at many graph reasoning tasks, even outperforming\nspecialized graph neural networks.\n",
        "authors": "Clayton Sanford; Bahare Fatemi; Ethan Hall; Anton Tsitsulin; Mehran Kazemi; Jonathan Halcrow; Bryan Perozzi; Vahab Mirrokni",
        "status": 0,
        "relevancy": 0.5381364633905632,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18073",
        "date": "2024-05-28",
        "title": "Towards Dialogues for Joint Human-AI Reasoning and Value Alignment",
        "abstract": "  We argue that enabling human-AI dialogue, purposed to support joint reasoning\n(i.e., 'inquiry'), is important for ensuring that AI decision making is aligned\nwith human values and preferences. In particular, we point to logic-based\nmodels of argumentation and dialogue, and suggest that the traditional focus on\npersuasion dialogues be replaced by a focus on inquiry dialogues, and the\ndistinct challenges that joint inquiry raises. Given recent dramatic advances\nin the performance of large language models (LLMs), and the anticipated\nincrease in their use for decision making, we provide a roadmap for research\ninto inquiry dialogues for supporting joint human-LLM reasoning tasks that are\nethically salient, and that thereby require that decisions are value aligned.\n",
        "authors": "Elfia Bezou-Vrakatseli; Oana Cocarascu; Sanjay Modgil",
        "status": 0,
        "relevancy": 0.537977847914832,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18092",
        "date": "2024-05-28",
        "title": "LLM experiments with simulation: Large Language Model Multi-Agent System\n  for Process Simulation Parametrization in Digital Twins",
        "abstract": "  This paper presents a novel design of a multi-agent system framework that\napplies a large language model (LLM) to automate the parametrization of process\nsimulations in digital twins. We propose a multi-agent framework that includes\nfour types of agents: observation, reasoning, decision and summarization. By\nenabling dynamic interaction between LLM agents and simulation model, the\ndeveloped system can automatically explore the parametrization of the\nsimulation and use heuristic reasoning to determine a set of parameters to\ncontrol the simulation to achieve an objective. The proposed approach enhances\nthe simulation model by infusing it with heuristics from LLM and enables\nautonomous search for feasible parametrization to solve a user task.\nFurthermore, the system has the potential to increase user-friendliness and\nreduce the cognitive load on human users by assisting in complex\ndecision-making processes. The effectiveness and functionality of the system\nare demonstrated through a case study, and the visualized demos are available\nat a GitHub Repository: https://github.com/YuchenXia/LLMDrivenSimulation\n",
        "authors": "Yuchen Xia; Daniel Dittler; Nasser Jazdi; Haonan Chen; Michael Weyrich",
        "status": 0,
        "relevancy": 0.5365061176244996,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17846",
        "date": "2024-05-28",
        "title": "Safety Control of Service Robots with LLMs and Embodied Knowledge Graphs",
        "abstract": "  Safety limitations in service robotics across various industries have raised\nsignificant concerns about the need for robust mechanisms ensuring that robots\nadhere to safe practices, thereby preventing actions that might harm humans or\ncause property damage. Despite advances, including the integration of Knowledge\nGraphs (KGs) with Large Language Models (LLMs), challenges in ensuring\nconsistent safety in autonomous robot actions persist. In this paper, we\npropose a novel integration of Large Language Models with Embodied Robotic\nControl Prompts (ERCPs) and Embodied Knowledge Graphs (EKGs) to enhance the\nsafety framework for service robots. ERCPs are designed as predefined\ninstructions that ensure LLMs generate safe and precise responses. These\nresponses are subsequently validated by EKGs, which provide a comprehensive\nknowledge base ensuring that the actions of the robot are continuously aligned\nwith safety protocols, thereby promoting safer operational practices in varied\ncontexts. Our experimental setup involved diverse real-world tasks, where\nrobots equipped with our framework demonstrated significantly higher compliance\nwith safety standards compared to traditional methods. This integration fosters\nsecure human-robot interactions and positions our methodology at the forefront\nof AI-driven safety innovations in service robotics.\n",
        "authors": "Yong Qi; Gabriel Kyebambo; Siyuan Xie; Wei Shen; Shenghui Wang; Bitao Xie; Bin He; Zhipeng Wang; Shuo Jiang",
        "status": 0,
        "relevancy": 0.5361101468889371,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17956",
        "date": "2024-05-28",
        "title": "Hybrid Preference Optimization: Augmenting Direct Preference\n  Optimization with Auxiliary Objectives",
        "abstract": "  For aligning large language models (LLMs), prior work has leveraged\nreinforcement learning via human feedback (RLHF) or variations of direct\npreference optimization (DPO). While DPO offers a simpler framework based on\nmaximum likelihood estimation, it compromises on the ability to tune language\nmodels to easily maximize non-differentiable and non-binary objectives\naccording to the LLM designer's preferences (e.g., using simpler language or\nminimizing specific kinds of harmful content). These may neither align with\nuser preferences nor even be able to be captured tractably by binary preference\ndata. To leverage the simplicity and performance of DPO with the\ngeneralizability of RL, we propose a hybrid approach between DPO and RLHF. With\na simple augmentation to the implicit reward decomposition of DPO, we allow for\ntuning LLMs to maximize a set of arbitrary auxiliary rewards using offline RL.\nThe proposed method, Hybrid Preference Optimization (HPO), shows the ability to\neffectively generalize to both user preferences and auxiliary designer\nobjectives, while preserving alignment performance across a range of\nchallenging benchmarks and model sizes.\n",
        "authors": "Anirudhan Badrinath; Prabhat Agarwal; Jiajing Xu",
        "status": 0,
        "relevancy": 0.5283808724778053,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17755",
        "date": "2024-05-28",
        "title": "XL3M: A Training-free Framework for LLM Length Extension Based on\n  Segment-wise Inference",
        "abstract": "  Length generalization failure problem, namely the large language model (LLM)\nfails to generalize to texts longer than its maximum training length, greatly\nrestricts the application of LLM in the scenarios with streaming long inputs.\nTo address this problem, the existing methods either require substantial costs\nor introduce precision loss. In this paper, we empirically find that the\naccuracy of the LLM's prediction is highly correlated to its certainty. Based\non this, we propose an efficient training free framework, named XL3M (it means\nextra-long large language model), which enables the LLMs trained on short\nsequences to reason extremely long sequence without any further training or\nfine-tuning. Under the XL3M framework, the input context will be firstly\ndecomposed into multiple short sub-contexts, where each sub-context contains an\nindependent segment and a common ``question'' which is a few tokens from the\nend of the original context. Then XL3M gives a method to measure the relevance\nbetween each segment and the ``question'', and constructs a concise key context\nby splicing all the relevant segments in chronological order. The key context\nis further used instead of the original context to complete the inference task.\nEvaluations on comprehensive benchmarks show the superiority of XL3M. Using our\nframework, a Llama2-7B model is able to reason 20M long sequences on an 8-card\nHuawei Ascend 910B NPU machine with 64GB memory per card.\n",
        "authors": "Shengnan Wang; Youhui Bai; Lin Zhang; Pingyi Zhou; Shixiong Zhao; Gong Zhang; Sen Wang; Renhai Chen; Hua Xu; Hongwei Sun",
        "status": 0,
        "relevancy": 0.5271678320189086,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17743",
        "date": "2024-05-28",
        "title": "ORLM: Training Large Language Models for Optimization Modeling",
        "abstract": "  Large Language Models (LLMs) have emerged as powerful tools for tackling\ncomplex Operations Research (OR) problem by providing the capacity in\nautomating optimization modeling. However, current methodologies heavily rely\non prompt engineering (e.g., multi-agent cooperation) with proprietary LLMs,\nraising data privacy concerns that could be prohibitive in industry\napplications. To tackle this issue, we propose training open-source LLMs for\noptimization modeling. We identify four critical requirements for the training\ndataset of OR LLMs, design and implement OR-Instruct, a semi-automated process\nfor creating synthetic data tailored to specific requirements. We also\nintroduce the IndustryOR benchmark, the first industrial benchmark for testing\nLLMs on solving real-world OR problems. We apply the data from OR-Instruct to\nvarious open-source LLMs of 7b size (termed as ORLMs), resulting in a\nsignificantly improved capability for optimization modeling. Our\nbest-performing ORLM achieves state-of-the-art performance on the NL4OPT, MAMO,\nand IndustryOR benchmarks. Our code and data are available at\n\\url{https://github.com/Cardinal-Operations/ORLM}.\n",
        "authors": "Zhengyang Tang; Chenyu Huang; Xin Zheng; Shixi Hu; Zizhuo Wang; Dongdong Ge; Benyou Wang",
        "status": 0,
        "relevancy": 0.5236272328810484,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17893",
        "date": "2024-05-28",
        "title": "Arithmetic Reasoning with LLM: Prolog Generation & Permutation",
        "abstract": "  Instructing large language models (LLMs) to solve elementary school math\nproblems has shown great success using Chain of Thought (CoT). However, the CoT\napproach relies on an LLM to generate a sequence of arithmetic calculations\nwhich can be prone to cascaded calculation errors. We hypothesize that an LLM\nshould focus on extracting predicates and generating symbolic formulas from the\nmath problem description so that the underlying calculation can be done via an\nexternal code interpreter. We investigate using LLM to generate Prolog programs\nto solve mathematical questions. Experimental results show that our\nProlog-based arithmetic problem-solving outperforms CoT generation in the GSM8K\nbenchmark across three distinct LLMs. In addition, given the insensitive\nordering of predicates and symbolic formulas in Prolog, we propose to permute\nthe ground truth predicates for more robust LLM training via data augmentation.\n",
        "authors": "Xiaocheng Yang; Bingsen Chen; Yik-Cheung Tam",
        "status": 0,
        "relevancy": 0.5213901825067223,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18542",
        "date": "2024-05-28",
        "title": "Automatic detection of cognitive impairment in elderly people using an\n  entertainment chatbot with Natural Language Processing capabilities",
        "abstract": "  Previous researchers have proposed intelligent systems for therapeutic\nmonitoring of cognitive impairments. However, most existing practical\napproaches for this purpose are based on manual tests. This raises issues such\nas excessive caretaking effort and the white-coat effect. To avoid these\nissues, we present an intelligent conversational system for entertaining\nelderly people with news of their interest that monitors cognitive impairment\ntransparently. Automatic chatbot dialogue stages allow assessing content\ndescription skills and detecting cognitive impairment with Machine Learning\nalgorithms. We create these dialogue flows automatically from updated news\nitems using Natural Language Generation techniques. The system also infers the\ngold standard of the answers to the questions, so it can assess cognitive\ncapabilities automatically by comparing these answers with the user responses.\nIt employs a similarity metric with values in [0, 1], in increasing level of\nsimilarity. To evaluate the performance and usability of our approach, we have\nconducted field tests with a test group of 30 elderly people in the earliest\nstages of dementia, under the supervision of gerontologists. In the\nexperiments, we have analysed the effect of stress and concentration in these\nusers. Those without cognitive impairment performed up to five times better. In\nparticular, the similarity metric varied between 0.03, for stressed and\nunfocused participants, and 0.36, for relaxed and focused users. Finally, we\ndeveloped a Machine Learning algorithm based on textual analysis features for\nautomatic cognitive impairment detection, which attained accuracy, F-measure\nand recall levels above 80%. We have thus validated the automatic approach to\ndetect cognitive impairment in elderly people based on entertainment content.\n",
        "authors": "Francisco de Arriba-Pérez; Silvia García-Méndez; Francisco J. González-Castaño; Enrique Costa-Montenegro",
        "status": 0,
        "relevancy": 0.5193799491103603,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18377",
        "date": "2024-05-28",
        "title": "LLaMA-NAS: Efficient Neural Architecture Search for Large Language\n  Models",
        "abstract": "  The abilities of modern large language models (LLMs) in solving natural\nlanguage processing, complex reasoning, sentiment analysis and other tasks have\nbeen extraordinary which has prompted their extensive adoption. Unfortunately,\nthese abilities come with very high memory and computational costs which\nprecludes the use of LLMs on most hardware platforms. To mitigate this, we\npropose an effective method of finding Pareto-optimal network architectures\nbased on LLaMA2-7B using one-shot NAS. In particular, we fine-tune LLaMA2-7B\nonly once and then apply genetic algorithm-based search to find smaller, less\ncomputationally complex network architectures. We show that, for certain\nstandard benchmark tasks, the pre-trained LLaMA2-7B network is unnecessarily\nlarge and complex. More specifically, we demonstrate a 1.5x reduction in model\nsize and 1.3x speedup in throughput for certain tasks with negligible drop in\naccuracy. In addition to finding smaller, higher-performing network\narchitectures, our method does so more effectively and efficiently than certain\npruning or sparsification techniques. Finally, we demonstrate how quantization\nis complementary to our method and that the size and complexity of the networks\nwe find can be further decreased using quantization. We believe that our work\nprovides a way to automatically create LLMs which can be used on less expensive\nand more readily available hardware platforms.\n",
        "authors": "Anthony Sarah; Sharath Nittur Sridhar; Maciej Szankin; Sairam Sundaresan",
        "status": 0,
        "relevancy": 0.5188820875193044,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17764",
        "date": "2024-05-28",
        "title": "On the Sequence Evaluation based on Stochastic Processes",
        "abstract": "  Modeling and analyzing long sequences of text is an essential task for\nNatural Language Processing. Success in capturing long text dynamics using\nneural language models will facilitate many downstream tasks such as coherence\nevaluation, text generation, machine translation and so on. This paper presents\na novel approach to model sequences through a stochastic process. We introduce\na likelihood-based training objective for the text encoder and design a more\nthorough measurement (score) for long text evaluation compared to the previous\napproach. The proposed training objective effectively preserves the sequence\ncoherence, while the new score comprehensively captures both temporal and\nspatial dependencies. Theoretical properties of our new score show its\nadvantages in sequence evaluation. Experimental results show superior\nperformance in various sequence evaluation tasks, including global and local\ndiscrimination within and between documents of different lengths. We also\ndemonstrate the encoder achieves competitive results on discriminating human\nand AI written text.\n",
        "authors": "Tianhao Zhang; Zhexiao Lin; Zhecheng Sheng; Chen Jiang; Dongyeop Kang",
        "status": 0,
        "relevancy": 0.5167412359666395,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17739",
        "date": "2024-05-28",
        "title": "The Widening Gap: The Benefits and Harms of Generative AI for Novice\n  Programmers",
        "abstract": "  Novice programmers often struggle through programming problem solving due to\na lack of metacognitive awareness and strategies. Previous research has shown\nthat novices can encounter multiple metacognitive difficulties while\nprogramming. Novices are typically unaware of how these difficulties are\nhindering their progress. Meanwhile, many novices are now programming with\ngenerative AI (GenAI), which can provide complete solutions to most\nintroductory programming problems, code suggestions, hints for next steps when\nstuck, and explain cryptic error messages. Its impact on novice metacognition\nhas only started to be explored. Here we replicate a previous study that\nexamined novice programming problem solving behavior and extend it by\nincorporating GenAI tools. Through 21 lab sessions consisting of participant\nobservation, interview, and eye tracking, we explore how novices are coding\nwith GenAI tools. Although 20 of 21 students completed the assigned programming\nproblem, our findings show an unfortunate divide in the use of GenAI tools\nbetween students who accelerated and students who struggled. Students who\naccelerated were able to use GenAI to create code they already intended to make\nand were able to ignore unhelpful or incorrect inline code suggestions. But for\nstudents who struggled, our findings indicate that previously known\nmetacognitive difficulties persist, and that GenAI unfortunately can compound\nthem and even introduce new metacognitive difficulties. Furthermore, struggling\nstudents often expressed cognitive dissonance about their problem solving\nability, thought they performed better than they did, and finished with an\nillusion of competence. Based on our observations from both groups, we propose\nways to scaffold the novice GenAI experience and make suggestions for future\nwork.\n",
        "authors": "James Prather; Brent Reeves; Juho Leinonen; Stephen MacNeil; Arisoa S. Randrianasolo; Brett Becker; Bailey Kimmel; Jared Wright; Ben Briggs",
        "status": 0,
        "relevancy": 0.5159764894068817,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17879",
        "date": "2024-05-28",
        "title": "Resisting Stochastic Risks in Diffusion Planners with the Trajectory\n  Aggregation Tree",
        "abstract": "  Diffusion planners have shown promise in handling long-horizon and\nsparse-reward tasks due to the non-autoregressive plan generation. However,\ntheir inherent stochastic risk of generating infeasible trajectories presents\nsignificant challenges to their reliability and stability. We introduce a novel\napproach, the Trajectory Aggregation Tree (TAT), to address this issue in\ndiffusion planners. Compared to prior methods that rely solely on raw\ntrajectory predictions, TAT aggregates information from both historical and\ncurrent trajectories, forming a dynamic tree-like structure. Each trajectory is\nconceptualized as a branch and individual states as nodes. As the structure\nevolves with the integration of new trajectories, unreliable states are\nmarginalized, and the most impactful nodes are prioritized for decision-making.\nTAT can be deployed without modifying the original training and sampling\npipelines of diffusion planners, making it a training-free, ready-to-deploy\nsolution. We provide both theoretical analysis and empirical evidence to\nsupport TAT's effectiveness. Our results highlight its remarkable ability to\nresist the risk from unreliable trajectories, guarantee the performance\nboosting of diffusion planners in $100\\%$ of tasks, and exhibit an appreciable\ntolerance margin for sample quality, thereby enabling planning with a more than\n$3\\times$ acceleration.\n",
        "authors": "Lang Feng; Pengjie Gu; Bo An; Gang Pan",
        "status": 0,
        "relevancy": 0.5152195033933369,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18553",
        "date": "2024-05-28",
        "title": "The FAIIR Tool: A Conversational AI Agent Assistant for Youth Mental\n  Health Service Provision",
        "abstract": "  World's healthcare systems and mental health agencies face both a growing\ndemand for youth mental health services, alongside a simultaneous challenge of\nlimited resources. Given these constraints, this work presents our experience\nin the creation and evaluation of the FAIIR (Frontline Assistant: Issue\nIdentification and Recommendation) tool, an ensemble of domain-adapted and\nfine-tuned transformer models, leveraging natural language processing to\nidentify issues that youth may be experiencing. We explore the technical\ndevelopment, performance, and validation processes leveraged for the FAIIR tool\nin application to situations of frontline crisis response via Kids Help Phone.\nFrontline Crisis Responders assign an issue tag from a defined list following\neach conversation. Assisting with the identification of issues of relevance\nhelps reduce the burden on CRs, ensuring that appropriate resources can be\nprovided and that active rescues and mandatory reporting can take place in\ncritical situations requiring immediate de-escalation.\n",
        "authors": "Stephen Obadinma; Alia Lachana; Maia Norman; Jocelyn Rankin; Joanna Yu; Xiaodan Zhu; Darren Mastropaolo; Deval Pandya; Roxana Sultan; Elham Dolatabadi",
        "status": 0,
        "relevancy": 0.5151707121878215,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18626",
        "date": "2024-05-28",
        "title": "Causal Contextual Bandits with Adaptive Context",
        "abstract": "  We study a variant of causal contextual bandits where the context is chosen\nbased on an initial intervention chosen by the learner. At the beginning of\neach round, the learner selects an initial action, depending on which a\nstochastic context is revealed by the environment. Following this, the learner\nthen selects a final action and receives a reward. Given $T$ rounds of\ninteractions with the environment, the objective of the learner is to learn a\npolicy (of selecting the initial and the final action) with maximum expected\nreward. In this paper we study the specific situation where every action\ncorresponds to intervening on a node in some known causal graph. We extend\nprior work from the deterministic context setting to obtain simple regret\nminimization guarantees. This is achieved through an instance-dependent causal\nparameter, $\\lambda$, which characterizes our upper bound. Furthermore, we\nprove that our simple regret is essentially tight for a large class of\ninstances. A key feature of our work is that we use convex optimization to\naddress the bandit exploration problem. We also conduct experiments to validate\nour theoretical results, and release our code at our project GitHub repository:\nhttps://github.com/adaptiveContextualCausalBandits/aCCB.\n",
        "authors": "Rahul Madhavan; Aurghya Maiti; Gaurav Sinha; Siddharth Barman",
        "status": 0,
        "relevancy": 0.5139517434237361,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17991",
        "date": "2024-05-28",
        "title": "VeLoRA: Memory Efficient Training using Rank-1 Sub-Token Projections",
        "abstract": "  Large language models (LLMs) have recently emerged as powerful tools for\ntackling many language-processing tasks. Despite their success, training and\nfine-tuning these models is still far too computationally and memory intensive.\nIn this paper, we identify and characterise the important components needed for\neffective model convergence using gradient descent. In doing so we find that\nthe intermediate activations used to implement backpropagation can be\nexcessively compressed without incurring any degradation in performance. This\nresult leads us to a cheap and memory-efficient algorithm for both fine-tuning\nand pre-training LLMs. The proposed algorithm simply divides the tokens up into\nsmaller sub-tokens before projecting them onto a fixed 1-dimensional subspace\nduring the forward pass. These features are then coarsely reconstructed during\nthe backward pass to implement the update rules. We confirm the effectiveness\nof our algorithm as being complimentary to many state-of-the-art PEFT methods\non the VTAB-1k fine-tuning benchmark. Furthermore, we outperform QLoRA for\nfine-tuning LLaMA and show competitive performance against other\nmemory-efficient pre-training methods on the large-scale C4 dataset.\n",
        "authors": "Roy Miles; Pradyumna Reddy; Ismail Elezi; Jiankang Deng",
        "status": 0,
        "relevancy": 0.5129212230701997,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18272",
        "date": "2024-05-28",
        "title": "Metaheuristics and Large Language Models Join Forces: Towards an\n  Integrated Optimization Approach",
        "abstract": "  Since the rise of Large Language Models (LLMs) a couple of years ago,\nresearchers in metaheuristics (MHs) have wondered how to use their power in a\nbeneficial way within their algorithms. This paper introduces a novel approach\nthat leverages LLMs as pattern recognition tools to improve MHs. The resulting\nhybrid method, tested in the context of a social network-based combinatorial\noptimization problem, outperforms existing state-of-the-art approaches that\ncombine machine learning with MHs regarding the obtained solution quality. By\ncarefully designing prompts, we demonstrate that the output obtained from LLMs\ncan be used as problem knowledge, leading to improved results. Lastly, we\nacknowledge LLMs' potential drawbacks and limitations and consider it essential\nto examine them to advance this type of research further.\n",
        "authors": "Camilo Chacón Sartori; Christian Blum; Filippo Bistaffa; Guillem Rodríguez Corominas",
        "status": 0,
        "relevancy": 0.5074855790680858,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17998",
        "date": "2024-05-28",
        "title": "Source Echo Chamber: Exploring the Escalation of Source Bias in User,\n  Data, and Recommender System Feedback Loop",
        "abstract": "  Recently, researchers have uncovered that neural retrieval models prefer\nAI-generated content (AIGC), called source bias. Compared to active search\nbehavior, recommendation represents another important means of information\nacquisition, where users are more prone to source bias. Furthermore, delving\ninto the recommendation scenario, as AIGC becomes integrated within the\nfeedback loop involving users, data, and the recommender system, it\nprogressively contaminates the candidate items, the user interaction history,\nand ultimately, the data used to train the recommendation models. How and to\nwhat extent the source bias affects the neural recommendation models within\nfeedback loop remains unknown. In this study, we extend the investigation of\nsource bias into the realm of recommender systems, specifically examining its\nimpact across different phases of the feedback loop. We conceptualize the\nprogression of AIGC integration into the recommendation content ecosystem in\nthree distinct phases-HGC dominate, HGC-AIGC coexist, and AIGC dominance-each\nrepresenting past, present, and future states, respectively. Through extensive\nexperiments across three datasets from diverse domains, we demonstrate the\nprevalence of source bias and reveal a potential digital echo chamber with\nsource bias amplification throughout the feedback loop. This trend risks\ncreating a recommender ecosystem with limited information source, such as AIGC,\nbeing disproportionately recommended. To counteract this bias and prevent its\nescalation in the feedback loop, we introduce a black-box debiasing method that\nmaintains model impartiality towards both HGC and AIGC. Our experimental\nresults validate the effectiveness of the proposed debiasing method, confirming\nits potential to disrupt the feedback loop.\n",
        "authors": "Yuqi Zhou; Sunhao Dai; Liang Pang; Gang Wang; Zhenhua Dong; Jun Xu; Ji-Rong Wen",
        "status": 0,
        "relevancy": 0.5068231599869906,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18180",
        "date": "2024-05-28",
        "title": "Safe Reinforcement Learning in Black-Box Environments via Adaptive\n  Shielding",
        "abstract": "  Empowering safe exploration of reinforcement learning (RL) agents during\ntraining is a critical impediment towards deploying RL agents in many\nreal-world scenarios. Training RL agents in unknown, black-box environments\nposes an even greater safety risk when prior knowledge of the domain/task is\nunavailable. We introduce ADVICE (Adaptive Shielding with a Contrastive\nAutoencoder), a novel post-shielding technique that distinguishes safe and\nunsafe features of state-action pairs during training, thus protecting the RL\nagent from executing actions that yield potentially hazardous outcomes. Our\ncomprehensive experimental evaluation against state-of-the-art safe RL\nexploration techniques demonstrates how ADVICE can significantly reduce safety\nviolations during training while maintaining a competitive outcome reward.\n",
        "authors": "Daniel Bethell; Simos Gerasimou; Radu Calinescu; Calum Imrie",
        "status": 0,
        "relevancy": 0.5066017536340098,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17969",
        "date": "2024-05-28",
        "title": "Knowledge Circuits in Pretrained Transformers",
        "abstract": "  The remarkable capabilities of modern large language models are rooted in\ntheir vast repositories of knowledge encoded within their parameters, enabling\nthem to perceive the world and engage in reasoning. The inner workings of how\nthese models store knowledge have long been a subject of intense interest and\ninvestigation among researchers. To date, most studies have concentrated on\nisolated components within these models, such as the Multilayer Perceptrons and\nattention head. In this paper, we delve into the computation graph of the\nlanguage model to uncover the knowledge circuits that are instrumental in\narticulating specific knowledge. The experiments, conducted with GPT2 and\nTinyLLAMA, has allowed us to observe how certain information heads, relation\nheads, and Multilayer Perceptrons collaboratively encode knowledge within the\nmodel. Moreover, we evaluate the impact of current knowledge editing techniques\non these knowledge circuits, providing deeper insights into the functioning and\nconstraints of these editing methodologies. Finally, we utilize knowledge\ncircuits to analyze and interpret language model behaviors such as\nhallucinations and in-context learning. We believe the knowledge circuit holds\npotential for advancing our understanding of Transformers and guiding the\nimproved design of knowledge editing. Code and data are available in\nhttps://github.com/zjunlp/KnowledgeCircuits.\n",
        "authors": "Yunzhi Yao; Ningyu Zhang; Zekun Xi; Mengru Wang; Ziwen Xu; Shumin Deng; Huajun Chen",
        "status": 0,
        "relevancy": 0.4996402280743558,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18241",
        "date": "2024-05-28",
        "title": "Active Use of Latent Constituency Representation in both Humans and\n  Large Language Models",
        "abstract": "  Understanding how sentences are internally represented in the human brain, as\nwell as in large language models (LLMs) such as ChatGPT, is a major challenge\nfor cognitive science. Classic linguistic theories propose that the brain\nrepresents a sentence by parsing it into hierarchically organized constituents.\nIn contrast, LLMs do not explicitly parse linguistic constituents and their\nlatent representations remains poorly explained. Here, we demonstrate that\nhumans and LLMs construct similar latent representations of hierarchical\nlinguistic constituents by analyzing their behaviors during a novel one-shot\nlearning task, in which they infer which words should be deleted from a\nsentence. Both humans and LLMs tend to delete a constituent, instead of a\nnonconstituent word string. In contrast, a naive sequence processing model that\nhas access to word properties and ordinal positions does not show this\nproperty. Based on the word deletion behaviors, we can reconstruct the latent\nconstituency tree representation of a sentence for both humans and LLMs. These\nresults demonstrate that a latent tree-structured constituency representation\ncan emerge in both the human brain and LLMs.\n",
        "authors": "Wei Liu; Ming Xiang; Nai Ding",
        "status": 0,
        "relevancy": 0.4970011354378443,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17820",
        "date": "2024-05-28",
        "title": "Don't Miss the Forest for the Trees: Attentional Vision Calibration for\n  Large Vision Language Models",
        "abstract": "  This study addresses the issue observed in Large Vision Language Models\n(LVLMs), where excessive attention on a few image tokens, referred to as blind\ntokens, leads to hallucinatory responses in tasks requiring fine-grained\nunderstanding of visual objects. We found that tokens receiving lower attention\nweights often hold essential information for identifying nuanced object details\n-- ranging from merely recognizing object existence to identifying their\nattributes (color, position, etc.) and understanding their relationships. To\ncounteract the over-emphasis on blind tokens and to accurately respond to user\nqueries, we introduce a technique called Attentional Vision Calibration (AVC).\nDuring the decoding phase, AVC identifies blind tokens by analyzing the\nimage-related attention distribution. It then dynamically adjusts the logits\nfor the next token prediction by contrasting the logits conditioned on the\noriginal visual tokens with those conditioned on the blind tokens. This\neffectively lowers the dependency on blind tokens and promotes a more balanced\nconsideration of all tokens. We validate AVC on benchmarks such as POPE, MME,\nand AMBER, where it consistently outperforms existing decoding techniques in\nmitigating object hallucinations in LVLMs.\n",
        "authors": "Sangmin Woo; Donguk Kim; Jaehyuk Jang; Yubin Choi; Changick Kim",
        "status": 0,
        "relevancy": 0.4958776841847703,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18572",
        "date": "2024-05-28",
        "title": "Low-rank finetuning for LLMs: A fairness perspective",
        "abstract": "  Low-rank approximation techniques have become the de facto standard for\nfine-tuning Large Language Models (LLMs) due to their reduced computational and\nmemory requirements. This paper investigates the effectiveness of these methods\nin capturing the shift of fine-tuning datasets from the initial pre-trained\ndata distribution. Our findings reveal that there are cases in which low-rank\nfine-tuning falls short in learning such shifts. This, in turn, produces\nnon-negligible side effects, especially when fine-tuning is adopted for\ntoxicity mitigation in pre-trained models, or in scenarios where it is\nimportant to provide fair models. Through comprehensive empirical evidence on\nseveral models, datasets, and tasks, we show that low-rank fine-tuning\ninadvertently preserves undesirable biases and toxic behaviors. We also show\nthat this extends to sequential decision-making tasks, emphasizing the need for\ncareful evaluation to promote responsible LLMs development.\n",
        "authors": "Saswat Das; Marco Romanelli; Cuong Tran; Zarreen Reza; Bhavya Kailkhura; Ferdinando Fioretto",
        "status": 0,
        "relevancy": 0.4944283926549484,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17809",
        "date": "2024-05-28",
        "title": "TransVIP: Speech to Speech Translation System with Voice and Isochrony\n  Preservation",
        "abstract": "  There is a rising interest and trend in research towards directly translating\nspeech from one language to another, known as end-to-end speech-to-speech\ntranslation. However, most end-to-end models struggle to outperform cascade\nmodels, i.e., a pipeline framework by concatenating speech recognition, machine\ntranslation and text-to-speech models. The primary challenges stem from the\ninherent complexities involved in direct translation tasks and the scarcity of\ndata. In this study, we introduce a novel model framework TransVIP that\nleverages diverse datasets in a cascade fashion yet facilitates end-to-end\ninference through joint probability. Furthermore, we propose two separated\nencoders to preserve the speaker's voice characteristics and isochrony from the\nsource speech during the translation process, making it highly suitable for\nscenarios such as video dubbing. Our experiments on the French-English language\npair demonstrate that our model outperforms the current state-of-the-art\nspeech-to-speech translation model.\n",
        "authors": "Chenyang Le; Yao Qian; Dongmei Wang; Long Zhou; Shujie Liu; Xiaofei Wang; Midia Yousefi; Yanmin Qian; Jinyu Li; Sheng Zhao; Michael Zeng",
        "status": 0,
        "relevancy": 0.4942942352267037,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18346",
        "date": "2024-05-28",
        "title": "Intelligent Clinical Documentation: Harnessing Generative AI for\n  Patient-Centric Clinical Note Generation",
        "abstract": "  Comprehensive clinical documentation is crucial for effective healthcare\ndelivery, yet it poses a significant burden on healthcare professionals,\nleading to burnout, increased medical errors, and compromised patient safety.\nThis paper explores the potential of generative AI (Artificial Intelligence) to\nstreamline the clinical documentation process, specifically focusing on\ngenerating SOAP (Subjective, Objective, Assessment, Plan) and BIRP (Behavior,\nIntervention, Response, Plan) notes. We present a case study demonstrating the\napplication of natural language processing (NLP) and automatic speech\nrecognition (ASR) technologies to transcribe patient-clinician interactions,\ncoupled with advanced prompting techniques to generate draft clinical notes\nusing large language models (LLMs). The study highlights the benefits of this\napproach, including time savings, improved documentation quality, and enhanced\npatient-centered care. Additionally, we discuss ethical considerations, such as\nmaintaining patient confidentiality and addressing model biases, underscoring\nthe need for responsible deployment of generative AI in healthcare settings.\nThe findings suggest that generative AI has the potential to revolutionize\nclinical documentation practices, alleviating administrative burdens and\nenabling healthcare professionals to focus more on direct patient care.\n",
        "authors": "Anjanava Biswas; Wrick Talukdar",
        "status": 0,
        "relevancy": 0.4910412988786512,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17959",
        "date": "2024-05-28",
        "title": "Attention-based sequential recommendation system using multimodal data",
        "abstract": "  Sequential recommendation systems that model dynamic preferences based on a\nuse's past behavior are crucial to e-commerce. Recent studies on these systems\nhave considered various types of information such as images and texts. However,\nmultimodal data have not yet been utilized directly to recommend products to\nusers. In this study, we propose an attention-based sequential recommendation\nmethod that employs multimodal data of items such as images, texts, and\ncategories. First, we extract image and text features from pre-trained VGG and\nBERT and convert categories into multi-labeled forms. Subsequently, attention\noperations are performed independent of the item sequence and multimodal\nrepresentations. Finally, the individual attention information is integrated\nthrough an attention fusion function. In addition, we apply multitask learning\nloss for each modality to improve the generalization performance. The\nexperimental results obtained from the Amazon datasets show that the proposed\nmethod outperforms those of conventional sequential recommendation systems.\n",
        "authors": "Hyungtaik Oh; Wonkeun Jo; Dongil Kim",
        "status": 0,
        "relevancy": 0.4898352172466597,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18638",
        "date": "2024-05-28",
        "title": "ConSiDERS-The-Human Evaluation Framework: Rethinking Human Evaluation\n  for Generative Large Language Models",
        "abstract": "  In this position paper, we argue that human evaluation of generative large\nlanguage models (LLMs) should be a multidisciplinary undertaking that draws\nupon insights from disciplines such as user experience research and human\nbehavioral psychology to ensure that the experimental design and results are\nreliable. The conclusions from these evaluations, thus, must consider factors\nsuch as usability, aesthetics, and cognitive biases. We highlight how cognitive\nbiases can conflate fluent information and truthfulness, and how cognitive\nuncertainty affects the reliability of rating scores such as Likert.\nFurthermore, the evaluation should differentiate the capabilities and\nweaknesses of increasingly powerful large language models -- which requires\neffective test sets. The scalability of human evaluation is also crucial to\nwider adoption. Hence, to design an effective human evaluation system in the\nage of generative NLP, we propose the ConSiDERS-The-Human evaluation framework\nconsisting of 6 pillars --Consistency, Scoring Critera, Differentiating, User\nExperience, Responsible, and Scalability.\n",
        "authors": "Aparna Elangovan; Ling Liu; Lei Xu; Sravan Bodapati; Dan Roth",
        "status": 0,
        "relevancy": 0.4888812049931227,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18258",
        "date": "2024-05-28",
        "title": "Text-only Synthesis for Image Captioning",
        "abstract": "  From paired image-text training to text-only training for image captioning,\nthe pursuit of relaxing the requirements for high-cost and large-scale\nannotation of good quality data remains consistent. In this paper, we propose\nText-only Synthesis for Image Captioning (ToCa), which further advances this\nrelaxation with fewer human labor and less computing time. Specifically, we\ndeconstruct caption text into structures and lexical words, which serve as the\nfundamental components of the caption. By combining different structures and\nlexical words as inputs to the large language model, massive captions that\ncontain various patterns of lexical words are generated. This method not only\napproaches the target domain but also surpasses it by generating new captions,\nthereby enhancing the zero-shot generalization ability of the model.\nConsidering the different levels of data access in the real world, we define\nthree synthesis scenarios: cross-domain synthesis, in-domain synthesis, and\ndata-efficient synthesis. Experiments in these scenarios demonstrate the\ngeneralizability, transferability and practicability of ToCa with a nearly 5\nCIDEr improvement for zero-shot cross-domain captioning and a maximum increase\nof over 20 CIDEr for data-efficient captioning.\n",
        "authors": "Qing Zhou; Junlin Huang; Qiang Li; Junyu Gao; Qi Wang",
        "status": 0,
        "relevancy": 0.48785918089931724,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18106",
        "date": "2024-05-28",
        "title": "A Unified Temporal Knowledge Graph Reasoning Model Towards Interpolation\n  and Extrapolation",
        "abstract": "  Temporal knowledge graph (TKG) reasoning has two settings: interpolation\nreasoning and extrapolation reasoning. Both of them draw plenty of research\ninterest and have great significance. Methods of the former de-emphasize the\ntemporal correlations among facts sequences, while methods of the latter\nrequire strict chronological order of knowledge and ignore inferring clues\nprovided by missing facts of the past. These limit the practicability of TKG\napplications as almost all of the existing TKG reasoning methods are designed\nspecifically to address either one setting. To this end, this paper proposes an\noriginal Temporal PAth-based Reasoning (TPAR) model for both the interpolation\nand extrapolation reasoning. TPAR performs a neural-driven symbolic reasoning\nfashion that is robust to ambiguous and noisy temporal data and with fine\ninterpretability as well. Comprehensive experiments show that TPAR outperforms\nSOTA methods on the link prediction task for both the interpolation and the\nextrapolation settings. A novel pipeline experimental setting is designed to\nevaluate the performances of SOTA combinations and the proposed TPAR towards\ninterpolation and extrapolation reasoning. More diverse experiments are\nconducted to show the robustness and interpretability of TPAR.\n",
        "authors": "Kai Chen; Ye Wang; Yitong Li; Aiping Li; Han Yu; Xin Song",
        "status": 0,
        "relevancy": 0.48525179207716307,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17730",
        "date": "2024-05-28",
        "title": "MMPareto: Boosting Multimodal Learning with Innocent Unimodal Assistance",
        "abstract": "  Multimodal learning methods with targeted unimodal learning objectives have\nexhibited their superior efficacy in alleviating the imbalanced multimodal\nlearning problem. However, in this paper, we identify the previously ignored\ngradient conflict between multimodal and unimodal learning objectives,\npotentially misleading the unimodal encoder optimization. To well diminish\nthese conflicts, we observe the discrepancy between multimodal loss and\nunimodal loss, where both gradient magnitude and covariance of the\neasier-to-learn multimodal loss are smaller than the unimodal one. With this\nproperty, we analyze Pareto integration under our multimodal scenario and\npropose MMPareto algorithm, which could ensure a final gradient with direction\nthat is common to all learning objectives and enhanced magnitude to improve\ngeneralization, providing innocent unimodal assistance. Finally, experiments\nacross multiple types of modalities and frameworks with dense cross-modal\ninteraction indicate our superior and extendable method performance. Our method\nis also expected to facilitate multi-task cases with a clear discrepancy in\ntask difficulty, demonstrating its ideal scalability. The source code and\ndataset are available at https://github.com/GeWu-Lab/MMPareto_ICML2024.\n",
        "authors": "Yake Wei; Di Hu",
        "status": 0,
        "relevancy": 0.48349556893841217,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18068",
        "date": "2024-05-28",
        "title": "A Survey of Latent Factor Models in Recommender Systems",
        "abstract": "  Recommender systems are essential tools in the digital era, providing\npersonalized content to users in areas like e-commerce, entertainment, and\nsocial media. Among the many approaches developed to create these systems,\nlatent factor models have proven particularly effective. This survey\nsystematically reviews latent factor models in recommender systems, focusing on\ntheir core principles, methodologies, and recent advancements. The literature\nis examined through a structured framework covering learning data, model\narchitecture, learning strategies, and optimization techniques. The analysis\nincludes a taxonomy of contributions and detailed discussions on the types of\nlearning data used, such as implicit feedback, trust, and content data, various\nmodels such as probabilistic, nonlinear, and neural models, and an exploration\nof diverse learning strategies like online learning, transfer learning, and\nactive learning. Furthermore, the survey addresses the optimization strategies\nused to train latent factor models, improving their performance and\nscalability. By identifying trends, gaps, and potential research directions,\nthis survey aims to provide valuable insights for researchers and practitioners\nlooking to advance the field of recommender systems.\n",
        "authors": "Hind I. Alshbanat; Hafida Benhidour; Said Kerrache",
        "status": 0,
        "relevancy": 0.48248742690915747,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18642",
        "date": "2024-05-28",
        "title": "JADS: A Framework for Self-supervised Joint Aspect Discovery and\n  Summarization",
        "abstract": "  To generate summaries that include multiple aspects or topics for text\ndocuments, most approaches use clustering or topic modeling to group relevant\nsentences and then generate a summary for each group. These approaches struggle\nto optimize the summarization and clustering algorithms jointly. On the other\nhand, aspect-based summarization requires known aspects. Our solution\nintegrates topic discovery and summarization into a single step. Given text\ndata, our Joint Aspect Discovery and Summarization algorithm (JADS) discovers\naspects from the input and generates a summary of the topics, in one step. We\npropose a self-supervised framework that creates a labeled dataset by first\nmixing sentences from multiple documents (e.g., CNN/DailyMail articles) as the\ninput and then uses the article summaries from the mixture as the labels. The\nJADS model outperforms the two-step baselines. With pretraining, the model\nachieves better performance and stability. Furthermore, embeddings derived from\nJADS exhibit superior clustering capabilities. Our proposed method achieves\nhigher semantic alignment with ground truth and is factual.\n",
        "authors": "Xiaobo Guo; Jay Desai; Srinivasan H. Sengamedu",
        "status": 0,
        "relevancy": 0.4766947271742752,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18161",
        "date": "2024-05-28",
        "title": "Back to the Drawing Board for Fair Representation Learning",
        "abstract": "  The goal of Fair Representation Learning (FRL) is to mitigate biases in\nmachine learning models by learning data representations that enable high\naccuracy on downstream tasks while minimizing discrimination based on sensitive\nattributes. The evaluation of FRL methods in many recent works primarily\nfocuses on the tradeoff between downstream fairness and accuracy with respect\nto a single task that was used to approximate the utility of representations\nduring training (proxy task). This incentivizes retaining only features\nrelevant to the proxy task while discarding all other information. In extreme\ncases, this can cause the learned representations to collapse to a trivial,\nbinary value, rendering them unusable in transfer settings. In this work, we\nargue that this approach is fundamentally mismatched with the original\nmotivation of FRL, which arises from settings with many downstream tasks\nunknown at training time (transfer tasks). To remedy this, we propose to\nrefocus the evaluation protocol of FRL methods primarily around the performance\non transfer tasks. A key challenge when conducting such an evaluation is the\nlack of adequate benchmarks. We address this by formulating four criteria that\na suitable evaluation procedure should fulfill. Based on these, we propose\nTransFair, a benchmark that satisfies these criteria, consisting of novel\nvariations of popular FRL datasets with carefully calibrated transfer tasks. In\nthis setting, we reevaluate state-of-the-art FRL methods, observing that they\noften overfit to the proxy task, which causes them to underperform on certain\ntransfer tasks. We further highlight the importance of task-agnostic learning\nsignals for FRL methods, as they can lead to more transferrable\nrepresentations.\n",
        "authors": "Angéline Pouget; Nikola Jovanović; Mark Vero; Robin Staab; Martin Vechev",
        "status": 0,
        "relevancy": 0.476540623175971,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17978",
        "date": "2024-05-28",
        "title": "FASTopic: A Fast, Adaptive, Stable, and Transferable Topic Modeling\n  Paradigm",
        "abstract": "  Topic models have been evolving rapidly over the years, from conventional to\nrecent neural models. However, existing topic models generally struggle with\neither effectiveness, efficiency, or stability, highly impeding their practical\napplications. In this paper, we propose FASTopic, a fast, adaptive, stable, and\ntransferable topic model. FASTopic follows a new paradigm: Dual\nSemantic-relation Reconstruction (DSR). Instead of previous conventional,\nneural VAE-based or clustering-based methods, DSR discovers latent topics by\nreconstruction through modeling the semantic relations among document, topic,\nand word embeddings. This brings about a neat and efficient topic modeling\nframework. We further propose a novel Embedding Transport Plan (ETP) method.\nRather than early straightforward approaches, ETP explicitly regularizes the\nsemantic relations as optimal transport plans. This addresses the relation bias\nissue and thus leads to effective topic modeling. Extensive experiments on\nbenchmark datasets demonstrate that our FASTopic shows superior effectiveness,\nefficiency, adaptivity, stability, and transferability, compared to\nstate-of-the-art baselines across various scenarios. Our code is available at\nhttps://github.com/bobxwu/FASTopic .\n",
        "authors": "Xiaobao Wu; Thong Nguyen; Delvin Ce Zhang; William Yang Wang; Anh Tuan Luu",
        "status": 0,
        "relevancy": 0.4762399963696454,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18330",
        "date": "2024-05-28",
        "title": "Frustratingly Easy Test-Time Adaptation of Vision-Language Models",
        "abstract": "  Vision-Language Models seamlessly discriminate among arbitrary semantic\ncategories, yet they still suffer from poor generalization when presented with\nchallenging examples. For this reason, Episodic Test-Time Adaptation (TTA)\nstrategies have recently emerged as powerful techniques to adapt VLMs in the\npresence of a single unlabeled image. The recent literature on TTA is dominated\nby the paradigm of prompt tuning by Marginal Entropy Minimization, which,\nrelying on online backpropagation, inevitably slows down inference while\nincreasing memory. In this work, we theoretically investigate the properties of\nthis approach and unveil that a surprisingly strong TTA method lies dormant and\nhidden within it. We term this approach ZERO (TTA with \"zero\" temperature),\nwhose design is both incredibly effective and frustratingly simple: augment N\ntimes, predict, retain the most confident predictions, and marginalize after\nsetting the Softmax temperature to zero. Remarkably, ZERO requires a single\nbatched forward pass through the vision encoder only and no backward passes. We\nthoroughly evaluate our approach following the experimental protocol\nestablished in the literature and show that ZERO largely surpasses or compares\nfavorably w.r.t. the state-of-the-art while being almost 10x faster and 13x\nmore memory-friendly than standard Test-Time Prompt Tuning. Thanks to its\nsimplicity and comparatively negligible computation, ZERO can serve as a strong\nbaseline for future work in this field. The code is available at\nhttps://github.com/FarinaMatteo/zero.\n",
        "authors": "Matteo Farina; Gianni Franchi; Giovanni Iacca; Massimiliano Mancini; Elisa Ricci",
        "status": 0,
        "relevancy": 0.4753889689512445,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18523",
        "date": "2024-05-28",
        "title": "TripletMix: Triplet Data Augmentation for 3D Understanding",
        "abstract": "  Data augmentation has proven to be a vital tool for enhancing the\ngeneralization capabilities of deep learning models, especially in the context\nof 3D vision where traditional datasets are often limited. Despite previous\nadvancements, existing methods primarily cater to unimodal data scenarios,\nleaving a gap in the augmentation of multimodal triplet data, which integrates\ntext, images, and point clouds. Simultaneously augmenting all three modalities\nenhances diversity and improves alignment across modalities, resulting in more\ncomprehensive and robust 3D representations. To address this gap, we propose\nTripletMix, a novel approach to address the previously unexplored issue of\nmultimodal data augmentation in 3D understanding. TripletMix innovatively\napplies the principles of mixed-based augmentation to multimodal triplet data,\nallowing for the preservation and optimization of cross-modal connections. Our\nproposed TripletMix combines feature-level and input-level augmentations to\nachieve dual enhancement between raw data and latent features, significantly\nimproving the model's cross-modal understanding and generalization capabilities\nby ensuring feature consistency and providing diverse and realistic training\nsamples. We demonstrate that TripletMix not only improves the baseline\nperformance of models in various learning scenarios including zero-shot and\nlinear probing classification but also significantly enhances model\ngeneralizability. Notably, we improved the zero-shot classification accuracy on\nScanObjectNN from 51.3 percent to 61.9 percent, and on Objaverse-LVIS from 46.8\npercent to 51.4 percent. Our findings highlight the potential of multimodal\ndata augmentation to significantly advance 3D object recognition and\nunderstanding.\n",
        "authors": "Jiaze Wang; Yi Wang; Ziyu Guo; Renrui Zhang; Donghao Zhou; Guangyong Chen; Anfeng Liu; Pheng-Ann Heng",
        "status": 0,
        "relevancy": 0.47330038070319025,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17832",
        "date": "2024-05-28",
        "title": "Mollification Effects of Policy Gradient Methods",
        "abstract": "  Policy gradient methods have enabled deep reinforcement learning (RL) to\napproach challenging continuous control problems, even when the underlying\nsystems involve highly nonlinear dynamics that generate complex non-smooth\noptimization landscapes. We develop a rigorous framework for understanding how\npolicy gradient methods mollify non-smooth optimization landscapes to enable\neffective policy search, as well as the downside of it: while making the\nobjective function smoother and easier to optimize, the stochastic objective\ndeviates further from the original problem. We demonstrate the equivalence\nbetween policy gradient methods and solving backward heat equations. Following\nthe ill-posedness of backward heat equations from PDE theory, we present a\nfundamental challenge to the use of policy gradient under stochasticity.\nMoreover, we make the connection between this limitation and the uncertainty\nprinciple in harmonic analysis to understand the effects of exploration with\nstochastic policies in RL. We also provide experimental results to illustrate\nboth the positive and negative aspects of mollification effects in practice.\n",
        "authors": "Tao Wang; Sylvia Herbert; Sicun Gao",
        "status": 0,
        "relevancy": 0.4731394987063351,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18139",
        "date": "2024-05-28",
        "title": "Unlocking Futures: A Natural Language Driven Career Prediction System\n  for Computer Science and Software Engineering Students",
        "abstract": "  A career is a crucial aspect for any person to fulfill their desires through\nhard work. During their studies, students cannot find the best career\nsuggestions unless they receive meaningful guidance tailored to their skills.\nTherefore, we developed an AI-assisted model for early prediction to provide\nbetter career suggestions. Although the task is difficult, proper guidance can\nmake it easier. Effective career guidance requires understanding a student's\nacademic skills, interests, and skill-related activities. In this research, we\ncollected essential information from Computer Science (CS) and Software\nEngineering (SWE) students to train a machine learning (ML) model that predicts\ncareer paths based on students' career-related information. To adequately train\nthe models, we applied Natural Language Processing (NLP) techniques and\ncompleted dataset pre-processing. For comparative analysis, we utilized\nmultiple classification ML algorithms and deep learning (DL) algorithms. This\nstudy contributes valuable insights to educational advising by providing\nspecific career suggestions based on the unique features of CS and SWE\nstudents. Additionally, the research helps individual CS and SWE students find\nsuitable jobs that match their skills, interests, and skill-related activities.\n",
        "authors": "Sakir Hossain Faruque; Sharun Akter Khushbu; Sharmin Akter",
        "status": 0,
        "relevancy": 0.4721310304102726,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17995",
        "date": "2024-05-28",
        "title": "DMT-JEPA: Discriminative Masked Targets for Joint-Embedding Predictive\n  Architecture",
        "abstract": "  The joint-embedding predictive architecture (JEPA) recently has shown\nimpressive results in extracting visual representations from unlabeled imagery\nunder a masking strategy. However, we reveal its disadvantages, notably its\ninsufficient understanding of local semantics. This deficiency originates from\nmasked modeling in the embedding space, resulting in a reduction of\ndiscriminative power and can even lead to the neglect of critical local\nsemantics. To bridge this gap, we introduce DMT-JEPA, a novel masked modeling\nobjective rooted in JEPA, specifically designed to generate discriminative\nlatent targets from neighboring information. Our key idea is simple: we\nconsider a set of semantically similar neighboring patches as a target of a\nmasked patch. To be specific, the proposed DMT-JEPA (a) computes feature\nsimilarities between each masked patch and its corresponding neighboring\npatches to select patches having semantically meaningful relations, and (b)\nemploys lightweight cross-attention heads to aggregate features of neighboring\npatches as the masked targets. Consequently, DMT-JEPA demonstrates strong\ndiscriminative power, offering benefits across a diverse spectrum of downstream\ntasks. Through extensive experiments, we demonstrate our effectiveness across\nvarious visual benchmarks, including ImageNet-1K image classification, ADE20K\nsemantic segmentation, and COCO object detection tasks. Code is available at:\n\\url{https://github.com/DMTJEPA/DMTJEPA}.\n",
        "authors": "Shentong Mo; Sukmin Yun",
        "status": 0,
        "relevancy": 0.4692978572429557,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17913",
        "date": "2024-05-28",
        "title": "OV-DQUO: Open-Vocabulary DETR with Denoising Text Query Training and\n  Open-World Unknown Objects Supervision",
        "abstract": "  Open-Vocabulary Detection (OVD) aims to detect objects from novel categories\nbeyond the base categories on which the detector is trained. However, existing\nopen-vocabulary detectors trained on known category data tend to assign higher\nconfidence to trained categories and confuse novel categories with background.\nTo resolve this, we propose OV-DQUO, an \\textbf{O}pen-\\textbf{V}ocabulary DETR\nwith \\textbf{D}enoising text \\textbf{Q}uery training and open-world\n\\textbf{U}nknown \\textbf{O}bjects supervision. Specifically, we introduce a\nwildcard matching method that enables the detector to learn from pairs of\nunknown objects recognized by the open-world detector and text embeddings with\ngeneral semantics, mitigating the confidence bias between base and novel\ncategories. Additionally, we propose a denoising text query training strategy\nthat synthesizes additional noisy query-box pairs from open-world unknown\nobjects to trains the detector through contrastive learning, enhancing its\nability to distinguish novel objects from the background. We conducted\nextensive experiments on the challenging OV-COCO and OV-LVIS benchmarks,\nachieving new state-of-the-art results of 45.6 AP50 and 39.3 mAP on novel\ncategories respectively, without the need for additional training data. Models\nand code are released at https://github.com/xiaomoguhz/OV-DQUO\n",
        "authors": "Junjie Wang; Bin Chen; Bin Kang; Yulin Li; YiChi Chen; Weizhi Xian; Huifeng Chang",
        "status": 0,
        "relevancy": 0.4671651657710123,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18113",
        "date": "2024-05-28",
        "title": "Facilitating Multi-Role and Multi-Behavior Collaboration of Large\n  Language Models for Online Job Seeking and Recruiting",
        "abstract": "  The emergence of online recruitment services has revolutionized the\ntraditional landscape of job seeking and recruitment, necessitating the\ndevelopment of high-quality industrial applications to improve person-job\nfitting. Existing methods generally rely on modeling the latent semantics of\nresumes and job descriptions and learning a matching function between them.\nInspired by the powerful role-playing capabilities of Large Language Models\n(LLMs), we propose to introduce a mock interview process between LLM-played\ninterviewers and candidates. The mock interview conversations can provide\nadditional evidence for candidate evaluation, thereby augmenting traditional\nperson-job fitting based solely on resumes and job descriptions. However,\ncharacterizing these two roles in online recruitment still presents several\nchallenges, such as developing the skills to raise interview questions,\nformulating appropriate answers, and evaluating two-sided fitness. To this end,\nwe propose MockLLM, a novel applicable framework that divides the person-job\nmatching process into two modules: mock interview generation and two-sided\nevaluation in handshake protocol, jointly enhancing their performance through\ncollaborative behaviors between interviewers and candidates. We design a\nrole-playing framework as a multi-role and multi-behavior paradigm to enable a\nsingle LLM agent to effectively behave with multiple functions for both\nparties. Moreover, we propose reflection memory generation and dynamic prompt\nmodification techniques to refine the behaviors of both sides, enabling\ncontinuous optimization of the augmented additional evidence. Extensive\nexperimental results show that MockLLM can achieve the best performance on\nperson-job matching accompanied by high mock interview quality, envisioning its\nemerging application in real online recruitment in the future.\n",
        "authors": "Hongda Sun; Hongzhan Lin; Haiyu Yan; Chen Zhu; Yang Song; Xin Gao; Shuo Shang; Rui Yan",
        "status": 0,
        "relevancy": 0.4671475609579421,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18050",
        "date": "2024-05-28",
        "title": "Learning-Based Link Anomaly Detection in Continuous-Time Dynamic Graphs",
        "abstract": "  Anomaly detection in continuous-time dynamic graphs is an emerging field yet\nunder-explored in the context of learning-based approaches. In this paper, we\npioneer structured analyses of link-level anomalies and graph representation\nlearning for identifying anomalous links in these graphs. First, we introduce a\nfine-grain taxonomy for edge-level anomalies leveraging structural, temporal,\nand contextual graph properties. We present a method for generating and\ninjecting such typed anomalies into graphs. Next, we introduce a novel method\nto generate continuous-time dynamic graphs with consistent patterns across\ntime, structure, and context. To allow temporal graph methods to learn the link\nanomaly detection task, we extend the generic link prediction setting by: (1)\nconditioning link existence on contextual edge attributes; and (2) refining the\ntraining regime to accommodate diverse perturbations in the negative edge\nsampler. Building on this, we benchmark methods for anomaly detection.\nComprehensive experiments on synthetic and real-world datasets -- featuring\nsynthetic and labeled organic anomalies and employing six state-of-the-art\nlearning methods -- validate our taxonomy and generation processes for\nanomalies and benign graphs, as well as our approach to adapting link\nprediction methods for anomaly detection. Our results further reveal that\ndifferent learning methods excel in capturing different aspects of graph\nnormality and detecting different types of anomalies. We conclude with a\ncomprehensive list of findings highlighting opportunities for future research.\n",
        "authors": "Tim Poštuvan; Claas Grohnfeldt; Michele Russo; Giulio Lovisotto",
        "status": 0,
        "relevancy": 0.4669409562930932,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18044",
        "date": "2024-05-28",
        "title": "Cognitive Insights and Stable Coalition Matching for Fostering\n  Multi-Agent Cooperation",
        "abstract": "  Cognitive abilities, such as Theory of Mind (ToM), play a vital role in\nfacilitating cooperation in human social interactions. However, our study\nreveals that agents with higher ToM abilities may not necessarily exhibit\nbetter cooperative behavior compared to those with lower ToM abilities. To\naddress this challenge, we propose a novel matching coalition mechanism that\nleverages the strengths of agents with different ToM levels by explicitly\nconsidering belief alignment and specialized abilities when forming coalitions.\nOur proposed matching algorithm seeks to find stable coalitions that maximize\nthe potential for cooperative behavior and ensure long-term viability. By\nincorporating cognitive insights into the design of multi-agent systems, our\nwork demonstrates the potential of leveraging ToM to create more sophisticated\nand human-like coordination strategies that foster cooperation and improve\noverall system performance.\n",
        "authors": "Jiaqi Shao; Tianjun Yuan; Tao Lin; Xuanyu Cao; Bing Luo",
        "status": 0,
        "relevancy": 0.46599837101190855,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17713",
        "date": "2024-05-28",
        "title": "AI Alignment with Changing and Influenceable Reward Functions",
        "abstract": "  Existing AI alignment approaches assume that preferences are static, which is\nunrealistic: our preferences change, and may even be influenced by our\ninteractions with AI systems themselves. To clarify the consequences of\nincorrectly assuming static preferences, we introduce Dynamic Reward Markov\nDecision Processes (DR-MDPs), which explicitly model preference changes and the\nAI's influence on them. We show that despite its convenience, the\nstatic-preference assumption may undermine the soundness of existing alignment\ntechniques, leading them to implicitly reward AI systems for influencing user\npreferences in ways users may not truly want. We then explore potential\nsolutions. First, we offer a unifying perspective on how an agent's\noptimization horizon may partially help reduce undesirable AI influence. Then,\nwe formalize different notions of AI alignment that account for preference\nchange from the outset. Comparing the strengths and limitations of 8 such\nnotions of alignment, we find that they all either err towards causing\nundesirable AI influence, or are overly risk-averse, suggesting that a\nstraightforward solution to the problems of changing preferences may not exist.\nAs there is no avoiding grappling with changing preferences in real-world\nsettings, this makes it all the more important to handle these issues with\ncare, balancing risks and capabilities. We hope our work can provide conceptual\nclarity and constitute a first step towards AI alignment practices which\nexplicitly account for (and contend with) the changing and influenceable nature\nof human preferences.\n",
        "authors": "Micah Carroll; Davis Foote; Anand Siththaranjan; Stuart Russell; Anca Dragan",
        "status": 0,
        "relevancy": 0.4646108229816245,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18405",
        "date": "2024-05-28",
        "title": "WIDIn: Wording Image for Domain-Invariant Representation in\n  Single-Source Domain Generalization",
        "abstract": "  Language has been useful in extending the vision encoder to data from diverse\ndistributions without empirical discovery in training domains. However, as the\nimage description is mostly at coarse-grained level and ignores visual details,\nthe resulted embeddings are still ineffective in overcoming complexity of\ndomains at inference time. We present a self-supervision framework WIDIn,\nWording Images for Domain-Invariant representation, to disentangle\ndiscriminative visual representation, by only leveraging data in a single\ndomain and without any test prior. Specifically, for each image, we first\nestimate the language embedding with fine-grained alignment, which can be\nconsequently used to adaptively identify and then remove domain-specific\ncounterpart from the raw visual embedding. WIDIn can be applied to both\npretrained vision-language models like CLIP, and separately trained uni-modal\nmodels like MoCo and BERT. Experimental studies on three domain generalization\ndatasets demonstrate the effectiveness of our approach.\n",
        "authors": "Jiawei Ma; Yulei Niu; Shiyuan Huang; Guangxing Han; Shih-Fu Chang",
        "status": 0,
        "relevancy": 0.4629400786649298,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17902",
        "date": "2024-05-28",
        "title": "Boosting Protein Language Models with Negative Sample Mining",
        "abstract": "  We introduce a pioneering methodology for boosting large language models in\nthe domain of protein representation learning. Our primary contribution lies in\nthe refinement process for correlating the over-reliance on co-evolution\nknowledge, in a way that networks are trained to distill invaluable insights\nfrom negative samples, constituted by protein pairs sourced from disparate\ncategories. By capitalizing on this novel approach, our technique steers the\ntraining of transformer-based models within the attention score space. This\nadvanced strategy not only amplifies performance but also reflects the nuanced\nbiological behaviors exhibited by proteins, offering aligned evidence with\ntraditional biological mechanisms such as protein-protein interaction. We\nexperimentally observed improved performance on various tasks over datasets, on\ntop of several well-established large protein models. This innovative paradigm\nopens up promising horizons for further progress in the realms of protein\nresearch and computational biology.\n",
        "authors": "Yaoyao Xu; Xinjian Zhao; Xiaozhuang Song; Benyou Wang; Tianshu Yu",
        "status": 0,
        "relevancy": 0.4612553321497934,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18196",
        "date": "2024-05-28",
        "title": "Render and Diffuse: Aligning Image and Action Spaces for Diffusion-based\n  Behaviour Cloning",
        "abstract": "  In the field of Robot Learning, the complex mapping between high-dimensional\nobservations such as RGB images and low-level robotic actions, two inherently\nvery different spaces, constitutes a complex learning problem, especially with\nlimited amounts of data. In this work, we introduce Render and Diffuse (R&D) a\nmethod that unifies low-level robot actions and RGB observations within the\nimage space using virtual renders of the 3D model of the robot. Using this\njoint observation-action representation it computes low-level robot actions\nusing a learnt diffusion process that iteratively updates the virtual renders\nof the robot. This space unification simplifies the learning problem and\nintroduces inductive biases that are crucial for sample efficiency and spatial\ngeneralisation. We thoroughly evaluate several variants of R&D in simulation\nand showcase their applicability on six everyday tasks in the real world. Our\nresults show that R&D exhibits strong spatial generalisation capabilities and\nis more sample efficient than more common image-to-action methods.\n",
        "authors": "Vitalis Vosylius; Younggyo Seo; Jafar Uruç; Stephen James",
        "status": 0,
        "relevancy": 0.4608678641104317,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17821",
        "date": "2024-05-28",
        "title": "RITUAL: Random Image Transformations as a Universal Anti-hallucination\n  Lever in LVLMs",
        "abstract": "  Recent advancements in Large Vision Language Models (LVLMs) have\nrevolutionized how machines understand and generate textual responses based on\nvisual inputs. Despite their impressive capabilities, they often produce\n\"hallucinatory\" outputs that do not accurately reflect the visual information,\nposing challenges in reliability and trustworthiness. Current methods such as\ncontrastive decoding have made strides in addressing these issues by\ncontrasting the original probability distribution of generated tokens with\ndistorted counterparts; yet, generating visually-faithful outputs remains a\nchallenge. In this work, we shift our focus to the opposite: What could serve\nas a complementary enhancement to the original probability distribution? We\npropose a simple, training-free method termed RITUAL to enhance robustness\nagainst hallucinations in LVLMs. Our approach employs random image\ntransformations as complements to the original probability distribution, aiming\nto mitigate the likelihood of hallucinatory visual explanations by enriching\nthe model's exposure to varied visual scenarios. Our empirical results show\nthat while the isolated use of transformed images initially degrades\nperformance, strategic implementation of these transformations can indeed serve\nas effective complements. Notably, our method is compatible with current\ncontrastive decoding methods and does not require external models or costly\nself-feedback mechanisms, making it a practical addition. In experiments,\nRITUAL significantly outperforms existing contrastive decoding methods across\nseveral object hallucination benchmarks, including POPE, CHAIR, and MME.\n",
        "authors": "Sangmin Woo; Jaehyuk Jang; Donguk Kim; Yubin Choi; Changick Kim",
        "status": 0,
        "relevancy": 0.45838152955094225,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18281",
        "date": "2024-05-28",
        "title": "MODL: Multilearner Online Deep Learning",
        "abstract": "  Online deep learning solves the problem of learning from streams of data,\nreconciling two opposing objectives: learn fast and learn deep. Existing work\nfocuses almost exclusively on exploring pure deep learning solutions, which are\nmuch better suited to handle the \"deep\" than the \"fast\" part of the online\nlearning equation. In our work, we propose a different paradigm, based on a\nhybrid multilearner approach. First, we develop a fast online logistic\nregression learner. This learner does not rely on backpropagation. Instead, it\nuses closed form recursive updates of model parameters, handling the fast\nlearning part of the online learning problem. We then analyze the existing\nonline deep learning theory and show that the widespread ODL approach,\ncurrently operating at complexity $O(L^2)$ in terms of the number of layers\n$L$, can be equivalently implemented in $O(L)$ complexity. This further leads\nus to the cascaded multilearner design, in which multiple shallow and deep\nlearners are co-trained to solve the online learning problem in a cooperative,\nsynergistic fashion. We show that this approach achieves state-of-the-art\nresults on common online learning datasets, while also being able to handle\nmissing features gracefully. Our code is publicly available at\nhttps://github.com/AntonValk/MODL.\n",
        "authors": "Antonios Valkanas; Boris N. Oreshkin; Mark Coates",
        "status": 0,
        "relevancy": 0.4573266022847642,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18350",
        "date": "2024-05-28",
        "title": "A System for Automatic English Text Expansion",
        "abstract": "  We present an automatic text expansion system to generate English sentences,\nwhich performs automatic Natural Language Generation (NLG) by combining\nlinguistic rules with statistical approaches. Here, \"automatic\" means that the\nsystem can generate coherent and correct sentences from a minimum set of words.\nFrom its inception, the design is modular and adaptable to other languages.\nThis adaptability is one of its greatest advantages. For English, we have\ncreated the highly precise aLexiE lexicon with wide coverage, which represents\na contribution on its own. We have evaluated the resulting NLG library in an\nAugmentative and Alternative Communication (AAC) proof of concept, both\ndirectly (by regenerating corpus sentences) and manually (from annotations)\nusing a popular corpus in the NLG field. We performed a second analysis by\ncomparing the quality of text expansion in English to Spanish, using an ad-hoc\nSpanish-English parallel corpus. The system might also be applied to other\ndomains such as report and news generation.\n",
        "authors": "Silvia García Méndez; Milagros Fernández Gavilanes; Enrique Costa Montenegro; Jonathan Juncal Martínez; Francisco Javier González Castaño; Ehud Reiter",
        "status": 0,
        "relevancy": 0.4530532782297587,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18315",
        "date": "2024-05-28",
        "title": "DSDL: Data Set Description Language for Bridging Modalities and Tasks in\n  AI Data",
        "abstract": "  In the era of artificial intelligence, the diversity of data modalities and\nannotation formats often renders data unusable directly, requiring\nunderstanding and format conversion before it can be used by researchers or\ndevelopers with different needs. To tackle this problem, this article\nintroduces a framework called Dataset Description Language (DSDL) that aims to\nsimplify dataset processing by providing a unified standard for AI datasets.\nDSDL adheres to the three basic practical principles of generic, portable, and\nextensible, using a unified standard to express data of different modalities\nand structures, facilitating the dissemination of AI data, and easily extending\nto new modalities and tasks. The standardized specifications of DSDL reduce the\nworkload for users in data dissemination, processing, and usage. To further\nimprove user convenience, we provide predefined DSDL templates for various\ntasks, convert mainstream datasets to comply with DSDL specifications, and\nprovide comprehensive documentation and DSDL tools. These efforts aim to\nsimplify the use of AI data, thereby improving the efficiency of AI\ndevelopment.\n",
        "authors": "Bin Wang; Linke Ouyang; Fan Wu; Wenchang Ning; Xiao Han; Zhiyuan Zhao; Jiahui Peng; Yiying Jiang; Dahua Lin; Conghui He",
        "status": 0,
        "relevancy": 0.4509819666706769,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18560",
        "date": "2024-05-28",
        "title": "Potential Field Based Deep Metric Learning",
        "abstract": "  Deep metric learning (DML) involves training a network to learn a\nsemantically meaningful representation space. Many current approaches mine\nn-tuples of examples and model interactions within each tuplets. We present a\nnovel, compositional DML model, inspired by electrostatic fields in physics\nthat, instead of in tuples, represents the influence of each example\n(embedding) by a continuous potential field, and superposes the fields to\nobtain their combined global potential field. We use attractive/repulsive\npotential fields to represent interactions among embeddings from images of the\nsame/different classes. Contrary to typical learning methods, where mutual\ninfluence of samples is proportional to their distance, we enforce reduction in\nsuch influence with distance, leading to a decaying field. We show that such\ndecay helps improve performance on real world datasets with large intra-class\nvariations and label noise. Like other proxy-based methods, we also use proxies\nto succinctly represent sub-populations of examples. We evaluate our method on\nthree standard DML benchmarks- Cars-196, CUB-200-2011, and SOP datasets where\nit outperforms state-of-the-art baselines.\n",
        "authors": "Shubhang Bhatnagar; Narendra Ahuja",
        "status": 0,
        "relevancy": 0.4499224271124421,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17825",
        "date": "2024-05-28",
        "title": "Diffusion Model Patching via Mixture-of-Prompts",
        "abstract": "  We present Diffusion Model Patching (DMP), a simple method to boost the\nperformance of pre-trained diffusion models that have already reached\nconvergence, with a negligible increase in parameters. DMP inserts a small,\nlearnable set of prompts into the model's input space while keeping the\noriginal model frozen. The effectiveness of DMP is not merely due to the\naddition of parameters but stems from its dynamic gating mechanism, which\nselects and combines a subset of learnable prompts at every step of the\ngenerative process (e.g., reverse denoising steps). This strategy, which we\nterm \"mixture-of-prompts\", enables the model to draw on the distinct expertise\nof each prompt, essentially \"patching\" the model's functionality at every step\nwith minimal yet specialized parameters. Uniquely, DMP enhances the model by\nfurther training on the same dataset on which it was originally trained, even\nin a scenario where significant improvements are typically not expected due to\nmodel convergence. Experiments show that DMP significantly enhances the\nconverged FID of DiT-L/2 on FFHQ 256x256 by 10.38%, achieved with only a 1.43%\nparameter increase and 50K additional training iterations.\n",
        "authors": "Seokil Ham; Sangmin Woo; Jin-Young Kim; Hyojun Go; Byeongjun Park; Changick Kim",
        "status": 0,
        "relevancy": 0.44975087428677474,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17784",
        "date": "2024-05-28",
        "title": "Adaptive Horizon Actor-Critic for Policy Learning in Contact-Rich\n  Differentiable Simulation",
        "abstract": "  Model-Free Reinforcement Learning~(MFRL), leveraging the policy gradient\ntheorem, has demonstrated considerable success in continuous control tasks.\nHowever, these approaches are plagued by high gradient variance due to\nzeroth-order gradient estimation, resulting in suboptimal policies. Conversely,\nFirst-Order Model-Based Reinforcement Learning~(FO-MBRL) methods, employing\ndifferentiable simulation, provide gradients with reduced variance but are\nsusceptible to sampling error in scenarios involving stiff dynamics, such as\nphysical contact. This paper investigates the source of this error and\nintroduces Adaptive Horizon Actor-Critic (AHAC), an FO-MBRL algorithm that\nreduces gradient error by adapting the model-based horizon to avoid stiff\ndynamics. Empirical findings reveal that AHAC outperforms MFRL baselines,\nattaining 40\\% more reward across a set of locomotion tasks, and efficiently\nscaling to high-dimensional control environments with improved wall-clock-time\nefficiency.\n",
        "authors": "Ignat Georgiev; Krishnan Srinivasan; Jie Xu; Eric Heiden; Animesh Garg",
        "status": 0,
        "relevancy": 0.4491718861360514,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18406",
        "date": "2024-05-28",
        "title": "RACCooN: Remove, Add, and Change Video Content with Auto-Generated\n  Narratives",
        "abstract": "  Recent video generative models primarily rely on carefully written text\nprompts for specific tasks, like inpainting or style editing. They require\nlabor-intensive textual descriptions for input videos, hindering their\nflexibility to adapt personal/raw videos to user specifications. This paper\nproposes RACCooN, a versatile and user-friendly video-to-paragraph-to-video\ngenerative framework that supports multiple video editing capabilities such as\nremoval, addition, and modification, through a unified pipeline. RACCooN\nconsists of two principal stages: Video-to-Paragraph (V2P) and\nParagraph-to-Video (P2V). In the V2P stage, we automatically describe video\nscenes in well-structured natural language, capturing both the holistic context\nand focused object details. Subsequently, in the P2V stage, users can\noptionally refine these descriptions to guide the video diffusion model,\nenabling various modifications to the input video, such as removing, changing\nsubjects, and/or adding new objects. The proposed approach stands out from\nother methods through several significant contributions: (1) RACCooN suggests a\nmulti-granular spatiotemporal pooling strategy to generate well-structured\nvideo descriptions, capturing both the broad context and object details without\nrequiring complex human annotations, simplifying precise video content editing\nbased on text for users. (2) Our video generative model incorporates\nauto-generated narratives or instructions to enhance the quality and accuracy\nof the generated content. It supports the addition of video objects,\ninpainting, and attribute modification within a unified framework, surpassing\nexisting video editing and inpainting benchmarks. The proposed framework\ndemonstrates impressive versatile capabilities in video-to-paragraph\ngeneration, video content editing, and can be incorporated into other SoTA\nvideo generative models for further enhancement.\n",
        "authors": "Jaehong Yoon; Shoubin Yu; Mohit Bansal",
        "status": 0,
        "relevancy": 0.44877581009015877,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18610",
        "date": "2024-05-28",
        "title": "DTR-Bench: An in silico Environment and Benchmark Platform for\n  Reinforcement Learning Based Dynamic Treatment Regime",
        "abstract": "  Reinforcement learning (RL) has garnered increasing recognition for its\npotential to optimise dynamic treatment regimes (DTRs) in personalised\nmedicine, particularly for drug dosage prescriptions and medication\nrecommendations. However, a significant challenge persists: the absence of a\nunified framework for simulating diverse healthcare scenarios and a\ncomprehensive analysis to benchmark the effectiveness of RL algorithms within\nthese contexts. To address this gap, we introduce \\textit{DTR-Bench}, a\nbenchmarking platform comprising four distinct simulation environments tailored\nto common DTR applications, including cancer chemotherapy, radiotherapy,\nglucose management in diabetes, and sepsis treatment. We evaluate various\nstate-of-the-art RL algorithms across these settings, particularly highlighting\ntheir performance amidst real-world challenges such as\npharmacokinetic/pharmacodynamic (PK/PD) variability, noise, and missing data.\nOur experiments reveal varying degrees of performance degradation among RL\nalgorithms in the presence of noise and patient variability, with some\nalgorithms failing to converge. Additionally, we observe that using temporal\nobservation representations does not consistently lead to improved performance\nin DTR settings. Our findings underscore the necessity of developing robust,\nadaptive RL algorithms capable of effectively managing these complexities to\nenhance patient-specific healthcare. We have open-sourced our benchmark and\ncode at https://github.com/GilesLuo/DTR-Bench.\n",
        "authors": "Zhiyao Luo; Mingcheng Zhu; Fenglin Liu; Jiali Li; Yangchen Pan; Jiandong Zhou; Tingting Zhu",
        "status": 0,
        "relevancy": 0.448666604338693,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17927",
        "date": "2024-05-28",
        "title": "The Evolution of Multimodal Model Architectures",
        "abstract": "  This work uniquely identifies and characterizes four prevalent multimodal\nmodel architectural patterns in the contemporary multimodal landscape.\nSystematically categorizing models by architecture type facilitates monitoring\nof developments in the multimodal domain. Distinct from recent survey papers\nthat present general information on multimodal architectures, this research\nconducts a comprehensive exploration of architectural details and identifies\nfour specific architectural types. The types are distinguished by their\nrespective methodologies for integrating multimodal inputs into the deep neural\nnetwork model. The first two types (Type A and B) deeply fuses multimodal\ninputs within the internal layers of the model, whereas the following two types\n(Type C and D) facilitate early fusion at the input stage. Type-A employs\nstandard cross-attention, whereas Type-B utilizes custom-designed layers for\nmodality fusion within the internal layers. On the other hand, Type-C utilizes\nmodality-specific encoders, while Type-D leverages tokenizers to process the\nmodalities at the model's input stage. The identified architecture types aid\nthe monitoring of any-to-any multimodal model development. Notably, Type-C and\nType-D are currently favored in the construction of any-to-any multimodal\nmodels. Type-C, distinguished by its non-tokenizing multimodal model\narchitecture, is emerging as a viable alternative to Type-D, which utilizes\ninput-tokenizing techniques. To assist in model selection, this work highlights\nthe advantages and disadvantages of each architecture type based on data and\ncompute requirements, architecture complexity, scalability, simplification of\nadding modalities, training objectives, and any-to-any multimodal generation\ncapability.\n",
        "authors": "Shakti N. Wadekar; Abhishek Chaurasia; Aman Chadha; Eugenio Culurciello",
        "status": 0,
        "relevancy": 0.44795431593343815,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17724",
        "date": "2024-05-28",
        "title": "ClavaDDPM: Multi-relational Data Synthesis with Cluster-guided Diffusion\n  Models",
        "abstract": "  Recent research in tabular data synthesis has focused on single tables,\nwhereas real-world applications often involve complex data with tens or\nhundreds of interconnected tables. Previous approaches to synthesizing\nmulti-relational (multi-table) data fall short in two key aspects: scalability\nfor larger datasets and capturing long-range dependencies, such as correlations\nbetween attributes spread across different tables. Inspired by the success of\ndiffusion models in tabular data modeling, we introduce\n  $\\textbf{C}luster$ $\\textbf{La}tent$ $\\textbf{Va}riable$ $guided$\n$\\textbf{D}enoising$ $\\textbf{D}iffusion$ $\\textbf{P}robabilistic$\n$\\textbf{M}odels$ (ClavaDDPM). This novel approach leverages clustering labels\nas intermediaries to model relationships between tables, specifically focusing\non foreign key constraints. ClavaDDPM leverages the robust generation\ncapabilities of diffusion models while incorporating efficient algorithms to\npropagate the learned latent variables across tables. This enables ClavaDDPM to\ncapture long-range dependencies effectively.\n  Extensive evaluations on multi-table datasets of varying sizes show that\nClavaDDPM significantly outperforms existing methods for these long-range\ndependencies while remaining competitive on utility metrics for single-table\ndata.\n",
        "authors": "Wei Pang; Masoumeh Shafieinejad; Lucy Liu; Xi He",
        "status": 0,
        "relevancy": 0.44540486209067287,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18025",
        "date": "2024-05-28",
        "title": "Unveiling the Power of Diffusion Features For Personalized Segmentation\n  and Retrieval",
        "abstract": "  Personalized retrieval and segmentation aim to locate specific instances\nwithin a dataset based on an input image and a short description of the\nreference instance. While supervised methods are effective, they require\nextensive labeled data for training. Recently, self-supervised foundation\nmodels have been introduced to these tasks showing comparable results to\nsupervised methods. However, a significant flaw in these models is evident:\nthey struggle to locate a desired instance when other instances within the same\nclass are presented. In this paper, we explore text-to-image diffusion models\nfor these tasks. Specifically, we propose a novel approach called PDM for\nPersonalized Features Diffusion Matching, that leverages intermediate features\nof pre-trained text-to-image models for personalization tasks without any\nadditional training. PDM demonstrates superior performance on popular retrieval\nand segmentation benchmarks, outperforming even supervised methods. We also\nhighlight notable shortcomings in current instance and segmentation datasets\nand propose new benchmarks for these tasks.\n",
        "authors": "Dvir Samuel; Rami Ben-Ari; Matan Levy; Nir Darshan; Gal Chechik",
        "status": 0,
        "relevancy": 0.444737569088822,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18415",
        "date": "2024-05-28",
        "title": "Why are Visually-Grounded Language Models Bad at Image Classification?",
        "abstract": "  Image classification is one of the most fundamental capabilities of machine\nvision intelligence. In this work, we revisit the image classification task\nusing visually-grounded language models (VLMs) such as GPT-4V and LLaVA. We\nfind that existing proprietary and public VLMs, despite often using CLIP as a\nvision encoder and having many more parameters, significantly underperform CLIP\non standard image classification benchmarks like ImageNet. To understand the\nreason, we explore several hypotheses concerning the inference algorithms,\ntraining objectives, and data processing in VLMs. Our analysis reveals that the\nprimary cause is data-related: critical information for image classification is\nencoded in the VLM's latent space but can only be effectively decoded with\nenough training data. Specifically, there is a strong correlation between the\nfrequency of class exposure during VLM training and instruction-tuning and the\nVLM's performance in those classes; when trained with sufficient data, VLMs can\nmatch the accuracy of state-of-the-art classification models. Based on these\nfindings, we enhance a VLM by integrating classification-focused datasets into\nits training, and demonstrate that the enhanced classification performance of\nthe VLM transfers to its general capabilities, resulting in an improvement of\n11.8% on the newly collected ImageWikiQA dataset.\n",
        "authors": "Yuhui Zhang; Alyssa Unell; Xiaohan Wang; Dhruba Ghosh; Yuchang Su; Ludwig Schmidt; Serena Yeung-Levy",
        "status": 0,
        "relevancy": 0.43976592749373355,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18556",
        "date": "2024-05-28",
        "title": "Reinforcement Learning in Dynamic Treatment Regimes Needs Critical\n  Reexamination",
        "abstract": "  In the rapidly changing healthcare landscape, the implementation of offline\nreinforcement learning (RL) in dynamic treatment regimes (DTRs) presents a mix\nof unprecedented opportunities and challenges. This position paper offers a\ncritical examination of the current status of offline RL in the context of\nDTRs. We argue for a reassessment of applying RL in DTRs, citing concerns such\nas inconsistent and potentially inconclusive evaluation metrics, the absence of\nnaive and supervised learning baselines, and the diverse choice of RL\nformulation in existing research. Through a case study with more than 17,000\nevaluation experiments using a publicly available Sepsis dataset, we\ndemonstrate that the performance of RL algorithms can significantly vary with\nchanges in evaluation metrics and Markov Decision Process (MDP) formulations.\nSurprisingly, it is observed that in some instances, RL algorithms can be\nsurpassed by random baselines subjected to policy evaluation methods and reward\ndesign. This calls for more careful policy evaluation and algorithm development\nin future DTR works. Additionally, we discussed potential enhancements toward\nmore reliable development of RL-based dynamic treatment regimes and invited\nfurther discussion within the community. Code is available at\nhttps://github.com/GilesLuo/ReassessDTR.\n",
        "authors": "Zhiyao Luo; Yangchen Pan; Peter Watkinson; Tingting Zhu",
        "status": 0,
        "relevancy": 0.4370009931794995,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17871",
        "date": "2024-05-28",
        "title": "Seeing the Image: Prioritizing Visual Correlation by Contrastive\n  Alignment",
        "abstract": "  Existing image-text modality alignment in Vision Language Models (VLMs)\ntreats each text token equally in an autoregressive manner. Despite being\nsimple and effective, this method results in sub-optimal cross-modal alignment\nby over-emphasizing the text tokens that are less correlated with or even\ncontradictory with the input images. In this paper, we advocate for assigning\ndistinct contributions for each text token based on its visual correlation.\nSpecifically, we present by contrasting image inputs, the difference in\nprediction logits on each text token provides strong guidance of visual\ncorrelation. We therefore introduce Contrastive ALignment (CAL), a simple yet\neffective re-weighting strategy that prioritizes training visually correlated\ntokens. Our experimental results demonstrate that CAL consistently improves\ndifferent types of VLMs across different resolutions and model sizes on various\nbenchmark datasets. Importantly, our method incurs minimal additional\ncomputational overhead, rendering it highly efficient compared to alternative\ndata scaling strategies. Codes are available at\nhttps://github.com/foundation-multimodal-models/CAL.\n",
        "authors": "Xin Xiao; Bohong Wu; Jiacong Wang; Chunyuan Li; Xun Zhou; Haoyuan Guo",
        "status": 0,
        "relevancy": 0.43597643397719865,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17878",
        "date": "2024-05-28",
        "title": "An Information Theoretic Metric for Evaluating Unlearning Models",
        "abstract": "  Machine unlearning (MU) addresses privacy concerns by removing information of\n`forgetting data' samples from trained models. Typically, evaluating MU methods\ninvolves comparing unlearned models to those retrained from scratch without\nforgetting data, using metrics such as membership inference attacks (MIA) and\naccuracy measurements. These evaluations implicitly assume that if the output\nlogits of the unlearned and retrained models are similar, the unlearned model\nhas successfully forgotten the data. Here, we challenge if this assumption is\nvalid. In particular, we conduct a simple experiment of training only the last\nlayer of a given original model using a novel masked-distillation technique\nwhile keeping the rest fixed. Surprisingly, simply altering the last layer\nyields favorable outcomes in the existing evaluation metrics, while the model\ndoes not successfully unlearn the samples or classes. For better evaluating the\nMU methods, we propose a metric that quantifies the residual information about\nforgetting data samples in intermediate features using mutual information,\ncalled information difference index or IDI for short. The IDI provides a\ncomprehensive evaluation of MU methods by efficiently analyzing the internal\nstructure of DNNs. Our metric is scalable to large datasets and adaptable to\nvarious model architectures. Additionally, we present COLapse-and-Align (COLA),\na simple contrastive-based method that effectively unlearns intermediate\nfeatures.\n",
        "authors": "Dongjae Jeon; Wonje Jeung; Taeheon Kim; Albert No; Jonghyun Choi",
        "status": 0,
        "relevancy": 0.4325258785364253,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17829",
        "date": "2024-05-28",
        "title": "LDMol: Text-Conditioned Molecule Diffusion Model Leveraging Chemically\n  Informative Latent Space",
        "abstract": "  With the emergence of diffusion models as the frontline of generative models,\nmany researchers have proposed molecule generation techniques using conditional\ndiffusion models. However, due to the fundamental nature of a molecule, which\ncarries highly entangled correlations within a small number of atoms and bonds,\nit becomes difficult for a model to connect raw data with the conditions when\nthe conditions become more complex as natural language. To address this, here\nwe present a novel latent diffusion model dubbed LDMol, which enables a natural\ntext-conditioned molecule generation. Specifically, LDMol is composed of three\nbuilding blocks: a molecule encoder that produces a chemically informative\nfeature space, a natural language-conditioned latent diffusion model using a\nDiffusion Transformer (DiT), and an autoregressive decoder for molecule re. In\nparticular, recognizing that multiple SMILES notations can represent the same\nmolecule, we employ a contrastive learning strategy to extract the chemical\ninformative feature space. LDMol not only beats the existing baselines on the\ntext-to-molecule generation benchmark but is also capable of zero-shot\ninference with unseen scenarios. Furthermore, we show that LDMol can be applied\nto downstream tasks such as molecule-to-text retrieval and text-driven molecule\nediting, demonstrating its versatility as a diffusion model.\n",
        "authors": "Jinho Chang; Jong Chul Ye",
        "status": 0,
        "relevancy": 0.43248361742376906,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18510",
        "date": "2024-05-28",
        "title": "Improved Emotional Alignment of AI and Humans: Human Ratings of Emotions\n  Expressed by Stable Diffusion v1, DALL-E 2, and DALL-E 3",
        "abstract": "  Generative AI systems are increasingly capable of expressing emotions via\ntext and imagery. Effective emotional expression will likely play a major role\nin the efficacy of AI systems -- particularly those designed to support human\nmental health and wellbeing. This motivates our present research to better\nunderstand the alignment of AI expressed emotions with the human perception of\nemotions. When AI tries to express a particular emotion, how might we assess\nwhether they are successful? To answer this question, we designed a survey to\nmeasure the alignment between emotions expressed by generative AI and human\nperceptions. Three generative image models (DALL-E 2, DALL-E 3 and Stable\nDiffusion v1) were used to generate 240 examples of images, each of which was\nbased on a prompt designed to express five positive and five negative emotions\nacross both humans and robots. 24 participants recruited from the Prolific\nwebsite rated the alignment of AI-generated emotional expressions with a text\nprompt used to generate the emotion (i.e., \"A robot expressing the emotion\namusement\"). The results of our evaluation suggest that generative AI models\nare indeed capable of producing emotional expressions that are well-aligned\nwith a range of human emotions; however, we show that the alignment\nsignificantly depends upon the AI model used and the emotion itself. We analyze\nvariations in the performance of these systems to identify gaps for future\nimprovement. We conclude with a discussion of the implications for future AI\nsystems designed to support mental health and wellbeing.\n",
        "authors": "James Derek Lomas; Willem van der Maden; Sohhom Bandyopadhyay; Giovanni Lion; Nirmal Patel; Gyanesh Jain; Yanna Litowsky; Haian Xue; Pieter Desmet",
        "status": 0,
        "relevancy": 0.432431378752716,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18166",
        "date": "2024-05-28",
        "title": "Defending Large Language Models Against Jailbreak Attacks via\n  Layer-specific Editing",
        "abstract": "  Large language models (LLMs) are increasingly being adopted in a wide range\nof real-world applications. Despite their impressive performance, recent\nstudies have shown that LLMs are vulnerable to deliberately crafted adversarial\nprompts even when aligned via Reinforcement Learning from Human Feedback or\nsupervised fine-tuning. While existing defense methods focus on either\ndetecting harmful prompts or reducing the likelihood of harmful responses\nthrough various means, defending LLMs against jailbreak attacks based on the\ninner mechanisms of LLMs remains largely unexplored. In this work, we\ninvestigate how LLMs response to harmful prompts and propose a novel defense\nmethod termed \\textbf{L}ayer-specific \\textbf{Ed}iting (LED) to enhance the\nresilience of LLMs against jailbreak attacks. Through LED, we reveal that\nseveral critical \\textit{safety layers} exist among the early layers of LLMs.\nWe then show that realigning these safety layers (and some selected additional\nlayers) with the decoded safe response from selected target layers can\nsignificantly improve the alignment of LLMs against jailbreak attacks.\nExtensive experiments across various LLMs (e.g., Llama2, Mistral) show the\neffectiveness of LED, which effectively defends against jailbreak attacks while\nmaintaining performance on benign prompts. Our code is available at\n\\url{https://github.com/ledllm/ledllm}.\n",
        "authors": "Wei Zhao; Zhe Li; Yige Li; Ye Zhang; Jun Sun",
        "status": 0,
        "relevancy": 0.43063009002870933,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17741",
        "date": "2024-05-28",
        "title": "LoRA-Switch: Boosting the Efficiency of Dynamic LLM Adapters via\n  System-Algorithm Co-design",
        "abstract": "  Recent literature has found that an effective method to customize or further\nimprove large language models (LLMs) is to add dynamic adapters, such as\nlow-rank adapters (LoRA) with Mixture-of-Experts (MoE) structures. Though such\ndynamic adapters incur modest computational complexity, they surprisingly lead\nto huge inference latency overhead, slowing down the decoding speed by 2.5+\ntimes. In this paper, we analyze the fine-grained costs of the dynamic adapters\nand find that the fragmented CUDA kernel calls are the root cause. Therefore,\nwe propose LoRA-Switch, a system-algorithm co-designed architecture for\nefficient dynamic adapters. Unlike most existing dynamic structures that adopt\nlayer-wise or block-wise dynamic routing, LoRA-Switch introduces a token-wise\nrouting mechanism. It switches the LoRA adapters and weights for each token and\nmerges them into the backbone for inference. For efficiency, this switching is\nimplemented with an optimized CUDA kernel, which fuses the merging operations\nfor all LoRA adapters at once. Based on experiments with popular open-source\nLLMs on common benchmarks, our approach has demonstrated similar accuracy\nimprovement as existing dynamic adapters, while reducing the decoding latency\nby more than 2.4 times.\n",
        "authors": "Rui Kong; Qiyang Li; Xinyu Fang; Qingtian Feng; Qingfeng He; Yazhu Dong; Weijun Wang; Yuanchun Li; Linghe Kong; Yunxin Liu",
        "status": 0,
        "relevancy": 0.4301885317883706,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17728",
        "date": "2024-05-28",
        "title": "Facilitating Holistic Evaluations with LLMs: Insights from\n  Scenario-Based Experiments",
        "abstract": "  Workshop courses designed to foster creativity are gaining popularity.\nHowever, achieving a holistic evaluation that accommodates diverse perspectives\nis challenging, even for experienced faculty teams. Adequate discussion is\nessential to integrate varied assessments, but faculty often lack the time for\nsuch deliberations. Deriving an average score without discussion undermines the\npurpose of a holistic evaluation. This paper explores the use of a Large\nLanguage Model (LLM) as a facilitator to integrate diverse faculty assessments.\nScenario-based experiments were conducted to determine if the LLM could\nsynthesize diverse evaluations and explain the underlying theories to faculty.\nThe results were noteworthy, showing that the LLM effectively facilitated\nfaculty discussions. Additionally, the LLM demonstrated the capability to\ngeneralize and create evaluation criteria from a single scenario based on its\nlearned domain knowledge.\n",
        "authors": "Toru Ishida",
        "status": 0,
        "relevancy": 0.42996538011129903,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18291",
        "date": "2024-05-28",
        "title": "FedSAC: Dynamic Submodel Allocation for Collaborative Fairness in\n  Federated Learning",
        "abstract": "  Collaborative fairness stands as an essential element in federated learning\nto encourage client participation by equitably distributing rewards based on\nindividual contributions. Existing methods primarily focus on adjusting\ngradient allocations among clients to achieve collaborative fairness. However,\nthey frequently overlook crucial factors such as maintaining consistency across\nlocal models and catering to the diverse requirements of high-contributing\nclients. This oversight inevitably decreases both fairness and model accuracy\nin practice. To address these issues, we propose FedSAC, a novel Federated\nlearning framework with dynamic Submodel Allocation for Collaborative fairness,\nbacked by a theoretical convergence guarantee. First, we present the concept of\n\"bounded collaborative fairness (BCF)\", which ensures fairness by tailoring\nrewards to individual clients based on their contributions. Second, to\nimplement the BCF, we design a submodel allocation module with a theoretical\nguarantee of fairness. This module incentivizes high-contributing clients with\nhigh-performance submodels containing a diverse range of crucial neurons,\nthereby preserving consistency across local models. Third, we further develop a\ndynamic aggregation module to adaptively aggregate submodels, ensuring the\nequitable treatment of low-frequency neurons and consequently enhancing overall\nmodel accuracy. Extensive experiments conducted on three public benchmarks\ndemonstrate that FedSAC outperforms all baseline methods in both fairness and\nmodel accuracy. We see this work as a significant step towards incentivizing\nbroader client participation in federated learning. The source code is\navailable at https://github.com/wangzihuixmu/FedSAC.\n",
        "authors": "Zihui Wang; Zheng Wang; Lingjuan Lyu; Zhaopeng Peng; Zhicheng Yang; Chenglu Wen; Rongshan Yu; Cheng Wang; Xiaoliang Fan",
        "status": 0,
        "relevancy": 0.4289100644033852,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18620",
        "date": "2024-05-28",
        "title": "RealitySummary: On-Demand Mixed Reality Document Enhancement using Large\n  Language Models",
        "abstract": "  We introduce RealitySummary, a mixed reality reading assistant that can\nenhance any printed or digital document using on-demand text extraction,\nsummarization, and augmentation. While augmented reading tools promise to\nenhance physical reading experiences with overlaid digital content, prior\nsystems have typically required pre-processed documents, which limits their\ngeneralizability and real-world use cases. In this paper, we explore on-demand\ndocument augmentation by leveraging large language models. To understand\ngeneralizable techniques for diverse documents, we first conducted an\nexploratory design study which identified five categories of document\nenhancements (summarization, augmentation, navigation, comparison, and\nextraction). Based on this, we developed a proof-of-concept system that can\nautomatically extract and summarize text using Google Cloud OCR and GPT-4, then\nembed information around documents using a Microsoft Hololens 2 and Apple\nVision Pro. We demonstrate real-time examples of six specific document\naugmentations: 1) summaries, 2) comparison tables, 3) timelines, 4) keyword\nlists, 5) summary highlighting, and 6) information cards. Results from a\nusability study (N=12) and in-the-wild study (N=11) highlight the potential\nbenefits of on-demand MR document enhancement and opportunities for future\nresearch.\n",
        "authors": "Aditya Gunturu; Shivesh Jadon; Nandi Zhang; Jarin Thundathil; Wesley Willett; Ryo Suzuki",
        "status": 0,
        "relevancy": 0.42877027919261557,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18386",
        "date": "2024-05-28",
        "title": "Instruct-MusicGen: Unlocking Text-to-Music Editing for Music Language\n  Models via Instruction Tuning",
        "abstract": "  Recent advances in text-to-music editing, which employ text queries to modify\nmusic (e.g.\\ by changing its style or adjusting instrumental components),\npresent unique challenges and opportunities for AI-assisted music creation.\nPrevious approaches in this domain have been constrained by the necessity to\ntrain specific editing models from scratch, which is both resource-intensive\nand inefficient; other research uses large language models to predict edited\nmusic, resulting in imprecise audio reconstruction. To Combine the strengths\nand address these limitations, we introduce Instruct-MusicGen, a novel approach\nthat finetunes a pretrained MusicGen model to efficiently follow editing\ninstructions such as adding, removing, or separating stems. Our approach\ninvolves a modification of the original MusicGen architecture by incorporating\na text fusion module and an audio fusion module, which allow the model to\nprocess instruction texts and audio inputs concurrently and yield the desired\nedited music. Remarkably, Instruct-MusicGen only introduces 8% new parameters\nto the original MusicGen model and only trains for 5K steps, yet it achieves\nsuperior performance across all tasks compared to existing baselines, and\ndemonstrates performance comparable to the models trained for specific tasks.\nThis advancement not only enhances the efficiency of text-to-music editing but\nalso broadens the applicability of music language models in dynamic music\nproduction environments.\n",
        "authors": "Yixiao Zhang; Yukara Ikemiya; Woosung Choi; Naoki Murata; Marco A. Martínez-Ramírez; Liwei Lin; Gus Xia; Wei-Hsiang Liao; Yuki Mitsufuji; Simon Dixon",
        "status": 0,
        "relevancy": 0.4275335455986071,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18065",
        "date": "2024-05-28",
        "title": "EffoVPR: Effective Foundation Model Utilization for Visual Place\n  Recognition",
        "abstract": "  The task of Visual Place Recognition (VPR) is to predict the location of a\nquery image from a database of geo-tagged images. Recent studies in VPR have\nhighlighted the significant advantage of employing pre-trained foundation\nmodels like DINOv2 for the VPR task. However, these models are often deemed\ninadequate for VPR without further fine-tuning on task-specific data. In this\npaper, we propose a simple yet powerful approach to better exploit the\npotential of a foundation model for VPR. We first demonstrate that features\nextracted from self-attention layers can serve as a powerful re-ranker for VPR.\nUtilizing these features in a zero-shot manner, our method surpasses previous\nzero-shot methods and achieves competitive results compared to supervised\nmethods across multiple datasets. Subsequently, we demonstrate that a\nsingle-stage method leveraging internal ViT layers for pooling can generate\nglobal features that achieve state-of-the-art results, even when reduced to a\ndimensionality as low as 128D. Nevertheless, incorporating our local foundation\nfeatures for re-ranking, expands this gap. Our approach further demonstrates\nremarkable robustness and generalization, achieving state-of-the-art results,\nwith a significant gap, in challenging scenarios, involving occlusion,\nday-night variations, and seasonal changes.\n",
        "authors": "Issar Tzachor; Boaz Lerner; Matan Levy; Michael Green; Tal Berkovitz Shalev; Gavriel Habib; Dvir Samuel; Noam Korngut Zailer; Or Shimshi; Nir Darshan; Rami Ben-Ari",
        "status": 0,
        "relevancy": 0.4274677593901701,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18507",
        "date": "2024-05-28",
        "title": "Injecting Hierarchical Biological Priors into Graph Neural Networks for\n  Flow Cytometry Prediction",
        "abstract": "  In the complex landscape of hematologic samples such as peripheral blood or\nbone marrow derived from flow cytometry (FC) data, cell-level prediction\npresents profound challenges. This work explores injecting hierarchical prior\nknowledge into graph neural networks (GNNs) for single-cell multi-class\nclassification of tabular cellular data. By representing the data as graphs and\nencoding hierarchical relationships between classes, we propose our\nhierarchical plug-in method to be applied to several GNN models, namely,\nFCHC-GNN, and effectively designed to capture neighborhood information crucial\nfor single-cell FC domain. Extensive experiments on our cohort of 19 distinct\npatients, demonstrate that incorporating hierarchical biological constraints\nboosts performance significantly across multiple metrics compared to baseline\nGNNs without such priors. The proposed approach highlights the importance of\nstructured inductive biases for gaining improved generalization in complex\nbiological prediction tasks.\n",
        "authors": "Fatemeh Nassajian Mojarrad; Lorenzo Bini; Thomas Matthes; Stéphane Marchand-Maillet",
        "status": 0,
        "relevancy": 0.426226112603169,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18632",
        "date": "2024-05-28",
        "title": "Large Language Models as Partners in Student Essay Evaluation",
        "abstract": "  As the importance of comprehensive evaluation in workshop courses increases,\nthere is a growing demand for efficient and fair assessment methods that reduce\nthe workload for faculty members. This paper presents an evaluation conducted\nwith Large Language Models (LLMs) using actual student essays in three\nscenarios: 1) without providing guidance such as rubrics, 2) with pre-specified\nrubrics, and 3) through pairwise comparison of essays. Quantitative analysis of\nthe results revealed a strong correlation between LLM and faculty member\nassessments in the pairwise comparison scenario with pre-specified rubrics,\nalthough concerns about the quality and stability of evaluations remained.\nTherefore, we conducted a qualitative analysis of LLM assessment comments,\nshowing that: 1) LLMs can match the assessment capabilities of faculty members,\n2) variations in LLM assessments should be interpreted as diversity rather than\nconfusion, and 3) assessments by humans and LLMs can differ and complement each\nother. In conclusion, this paper suggests that LLMs should not be seen merely\nas assistants to faculty members but as partners in evaluation committees and\noutlines directions for further research.\n",
        "authors": "Toru Ishida; Tongxi Liu; Hailong Wang; William K. Cheung",
        "status": 0,
        "relevancy": 0.4238266887285501,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18165",
        "date": "2024-05-28",
        "title": "Time Series Representation Models",
        "abstract": "  Time series analysis remains a major challenge due to its sparse\ncharacteristics, high dimensionality, and inconsistent data quality. Recent\nadvancements in transformer-based techniques have enhanced capabilities in\nforecasting and imputation; however, these methods are still resource-heavy,\nlack adaptability, and face difficulties in integrating both local and global\nattributes of time series. To tackle these challenges, we propose a new\narchitectural concept for time series analysis based on introspection. Central\nto this concept is the self-supervised pretraining of Time Series\nRepresentation Models (TSRMs), which once learned can be easily tailored and\nfine-tuned for specific tasks, such as forecasting and imputation, in an\nautomated and resource-efficient manner. Our architecture is equipped with a\nflexible and hierarchical representation learning process, which is robust\nagainst missing data and outliers. It can capture and learn both local and\nglobal features of the structure, semantics, and crucial patterns of a given\ntime series category, such as heart rate data. Our learned time series\nrepresentation models can be efficiently adapted to a specific task, such as\nforecasting or imputation, without manual intervention. Furthermore, our\narchitecture's design supports explainability by highlighting the significance\nof each input value for the task at hand. Our empirical study using four\nbenchmark datasets shows that, compared to investigated state-of-the-art\nbaseline methods, our architecture improves imputation and forecasting errors\nby up to 90.34% and 71.54%, respectively, while reducing the required trainable\nparameters by up to 92.43%. The source code is available at\nhttps://github.com/RobertLeppich/TSRM.\n",
        "authors": "Robert Leppich; Vanessa Borst; Veronika Lesch; Samuel Kounev",
        "status": 0,
        "relevancy": 0.41983046121433154,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17918",
        "date": "2024-05-28",
        "title": "Cost-Sensitive Multi-Fidelity Bayesian Optimization with Transfer of\n  Learning Curve Extrapolation",
        "abstract": "  In this paper, we address the problem of cost-sensitive multi-fidelity\nBayesian Optimization (BO) for efficient hyperparameter optimization (HPO).\nSpecifically, we assume a scenario where users want to early-stop the BO when\nthe performance improvement is not satisfactory with respect to the required\ncomputational cost. Motivated by this scenario, we introduce utility, which is\na function predefined by each user and describes the trade-off between cost and\nperformance of BO. This utility function, combined with our novel acquisition\nfunction and stopping criterion, allows us to dynamically choose for each BO\nstep the best configuration that we expect to maximally improve the utility in\nfuture, and also automatically stop the BO around the maximum utility. Further,\nwe improve the sample efficiency of existing learning curve (LC) extrapolation\nmethods with transfer learning, while successfully capturing the correlations\nbetween different configurations to develop a sensible surrogate function for\nmulti-fidelity BO. We validate our algorithm on various LC datasets and found\nit outperform all the previous multi-fidelity BO and transfer-BO baselines we\nconsider, achieving significantly better trade-off between cost and performance\nof BO.\n",
        "authors": "Dong Bok Lee; Aoxuan Silvia Zhang; Byungjoo Kim; Junhyeon Park; Juho Lee; Sung Ju Hwang; Hae Beom Lee",
        "status": 0,
        "relevancy": 0.4133124845818694,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17924",
        "date": "2024-05-28",
        "title": "Generative AI Enhances Team Performance and Reduces Need for Traditional\n  Teams",
        "abstract": "  Recent advancements in generative artificial intelligence (AI) have\ntransformed collaborative work processes, yet the impact on team performance\nremains underexplored. Here we examine the role of generative AI in enhancing\nor replacing traditional team dynamics using a randomized controlled experiment\nwith 435 participants across 122 teams. We show that teams augmented with\ngenerative AI significantly outperformed those relying solely on human\ncollaboration across various performance measures. Interestingly, teams with\nmultiple AIs did not exhibit further gains, indicating diminishing returns with\nincreased AI integration. Our analysis suggests that centralized AI usage by a\nfew team members is more effective than distributed engagement. Additionally,\nindividual-AI pairs matched the performance of conventional teams, suggesting a\nreduced need for traditional team structures in some contexts. However, despite\nthis capability, individual-AI pairs still fell short of the performance levels\nachieved by AI-assisted teams. These findings underscore that while generative\nAI can replace some traditional team functions, more comprehensively\nintegrating AI within team structures provides superior benefits, enhancing\noverall effectiveness beyond individual efforts.\n",
        "authors": "Ning Li; Huaikang Zhou; Kris Mikel-Hong",
        "status": 0,
        "relevancy": 0.4115967548791559,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18040",
        "date": "2024-05-28",
        "title": "Fast-FedUL: A Training-Free Federated Unlearning with Provable Skew\n  Resilience",
        "abstract": "  Federated learning (FL) has recently emerged as a compelling machine learning\nparadigm, prioritizing the protection of privacy for training data. The\nincreasing demand to address issues such as ``the right to be forgotten'' and\ncombat data poisoning attacks highlights the importance of techniques, known as\n\\textit{unlearning}, which facilitate the removal of specific training data\nfrom trained FL models. Despite numerous unlearning methods proposed for\ncentralized learning, they often prove inapplicable to FL due to fundamental\ndifferences in the operation of the two learning paradigms. Consequently,\nunlearning in FL remains in its early stages, presenting several challenges.\nMany existing unlearning solutions in FL require a costly retraining process,\nwhich can be burdensome for clients. Moreover, these methods are primarily\nvalidated through experiments, lacking theoretical assurances. In this study,\nwe introduce Fast-FedUL, a tailored unlearning method for FL, which eliminates\nthe need for retraining entirely. Through meticulous analysis of the target\nclient's influence on the global model in each round, we develop an algorithm\nto systematically remove the impact of the target client from the trained\nmodel. In addition to presenting empirical findings, we offer a theoretical\nanalysis delineating the upper bound of our unlearned model and the exact\nretrained model (the one obtained through retraining using untargeted clients).\nExperimental results with backdoor attack scenarios indicate that Fast-FedUL\neffectively removes almost all traces of the target client, while retaining the\nknowledge of untargeted clients (obtaining a high accuracy of up to 98\\% on the\nmain task). Significantly, Fast-FedUL attains the lowest time complexity,\nproviding a speed that is 1000 times faster than retraining. Our source code is\npublicly available at \\url{https://github.com/thanhtrunghuynh93/fastFedUL}.\n",
        "authors": "Thanh Trung Huynh; Trong Bang Nguyen; Phi Le Nguyen; Thanh Tam Nguyen; Matthias Weidlich; Quoc Viet Hung Nguyen; Karl Aberer",
        "status": 0,
        "relevancy": 0.40989976161506747,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17814",
        "date": "2024-05-28",
        "title": "FAIntbench: A Holistic and Precise Benchmark for Bias Evaluation in\n  Text-to-Image Models",
        "abstract": "  The rapid development and reduced barriers to entry for Text-to-Image (T2I)\nmodels have raised concerns about the biases in their outputs, but existing\nresearch lacks a holistic definition and evaluation framework of biases,\nlimiting the enhancement of debiasing techniques. To address this issue, we\nintroduce FAIntbench, a holistic and precise benchmark for biases in T2I\nmodels. In contrast to existing benchmarks that evaluate bias in limited\naspects, FAIntbench evaluate biases from four dimensions: manifestation of\nbias, visibility of bias, acquired attributes, and protected attributes. We\napplied FAIntbench to evaluate seven recent large-scale T2I models and\nconducted human evaluation, whose results demonstrated the effectiveness of\nFAIntbench in identifying various biases. Our study also revealed new research\nquestions about biases, including the side-effect of distillation. The findings\npresented here are preliminary, highlighting the potential of FAIntbench to\nadvance future research aimed at mitigating the biases in T2I models. Our\nbenchmark is publicly available to ensure the reproducibility.\n",
        "authors": "Hanjun Luo; Ziye Deng; Ruizhe Chen; Zuozhu Liu",
        "status": 0,
        "relevancy": 0.40739744638283404,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18327",
        "date": "2024-05-28",
        "title": "Histopathology Based AI Model Predicts Anti-Angiogenic Therapy Response\n  in Renal Cancer Clinical Trial",
        "abstract": "  Predictive biomarkers of treatment response are lacking for metastatic clear\ncell renal cell carcinoma (ccRCC), a tumor type that is treated with\nangiogenesis inhibitors, immune checkpoint inhibitors, mTOR inhibitors and a\nHIF2 inhibitor. The Angioscore, an RNA-based quantification of angiogenesis, is\narguably the best candidate to predict anti-angiogenic (AA) response. However,\nthe clinical adoption of transcriptomic assays faces several challenges\nincluding standardization, time delay, and high cost. Further, ccRCC tumors are\nhighly heterogenous, and sampling multiple areas for sequencing is impractical.\nHere we present a novel deep learning (DL) approach to predict the Angioscore\nfrom ubiquitous histopathology slides. To overcome the lack of\ninterpretability, one of the biggest limitations of typical DL models, our\nmodel produces a visual vascular network which is the basis of the model's\nprediction. To test its reliability, we applied this model to multiple cohorts\nincluding a clinical trial dataset. Our model accurately predicts the RNA-based\nAngioscore on multiple independent cohorts (spearman correlations of 0.77 and\n0.73). Further, the predictions help unravel meaningful biology such as\nassociation of angiogenesis with grade, stage, and driver mutation status.\nFinally, we find our model can predict response to AA therapy, in both a\nreal-world cohort and the IMmotion150 clinical trial. The predictive power of\nour model vastly exceeds that of CD31, a marker of vasculature, and nearly\nrivals the performance (c-index 0.66 vs 0.67) of the ground truth RNA-based\nAngioscore at a fraction of the cost. By providing a robust yet interpretable\nprediction of the Angioscore from histopathology slides alone, our approach\noffers insights into angiogenesis biology and AA treatment response.\n",
        "authors": "Jay Jasti; Hua Zhong; Vandana Panwar; Vipul Jarmale; Jeffrey Miyata; Deyssy Carrillo; Alana Christie; Dinesh Rakheja; Zora Modrusan; Edward Ernest Kadel III; Niha Beig; Mahrukh Huseni; James Brugarolas; Payal Kapur; Satwik Rajaram",
        "status": 0,
        "relevancy": 0.40642693768662375,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18148",
        "date": "2024-05-28",
        "title": "Learning to Detour: Shortcut Mitigating Augmentation for Weakly\n  Supervised Semantic Segmentation",
        "abstract": "  Weakly supervised semantic segmentation (WSSS) employing weak forms of labels\nhas been actively studied to alleviate the annotation cost of acquiring\npixel-level labels. However, classifiers trained on biased datasets tend to\nexploit shortcut features and make predictions based on spurious correlations\nbetween certain backgrounds and objects, leading to a poor generalization\nperformance. In this paper, we propose shortcut mitigating augmentation (SMA)\nfor WSSS, which generates synthetic representations of object-background\ncombinations not seen in the training data to reduce the use of shortcut\nfeatures. Our approach disentangles the object-relevant and background\nfeatures. We then shuffle and combine the disentangled representations to\ncreate synthetic features of diverse object-background combinations.\nSMA-trained classifier depends less on contexts and focuses more on the target\nobject when making predictions. In addition, we analyzed the behavior of the\nclassifier on shortcut usage after applying our augmentation using an\nattribution method-based metric. The proposed method achieved the improved\nperformance of semantic segmentation result on PASCAL VOC 2012 and MS COCO 2014\ndatasets.\n",
        "authors": "JuneHyoung Kwon; Eunju Lee; Yunsung Cho; YoungBin Kim",
        "status": 0,
        "relevancy": 0.40573900463812274,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18322",
        "date": "2024-05-28",
        "title": "SCE-MAE: Selective Correspondence Enhancement with Masked Autoencoder\n  for Self-Supervised Landmark Estimation",
        "abstract": "  Self-supervised landmark estimation is a challenging task that demands the\nformation of locally distinct feature representations to identify sparse facial\nlandmarks in the absence of annotated data. To tackle this task, existing\nstate-of-the-art (SOTA) methods (1) extract coarse features from backbones that\nare trained with instance-level self-supervised learning (SSL) paradigms, which\nneglect the dense prediction nature of the task, (2) aggregate them into\nmemory-intensive hypercolumn formations, and (3) supervise lightweight\nprojector networks to naively establish full local correspondences among all\npairs of spatial features. In this paper, we introduce SCE-MAE, a framework\nthat (1) leverages the MAE, a region-level SSL method that naturally better\nsuits the landmark prediction task, (2) operates on the vanilla feature map\ninstead of on expensive hypercolumns, and (3) employs a Correspondence\nApproximation and Refinement Block (CARB) that utilizes a simple density peak\nclustering algorithm and our proposed Locality-Constrained Repellence Loss to\ndirectly hone only select local correspondences. We demonstrate through\nextensive experiments that SCE-MAE is highly effective and robust,\noutperforming existing SOTA methods by large margins of approximately 20%-44%\non the landmark matching and approximately 9%-15% on the landmark detection\ntasks.\n",
        "authors": "Kejia Yin; Varshanth R. Rao; Ruowei Jiang; Xudong Liu; Parham Aarabi; David B. Lindell",
        "status": 0,
        "relevancy": 0.40572639872939775,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18425",
        "date": "2024-05-28",
        "title": "ViG: Linear-complexity Visual Sequence Learning with Gated Linear\n  Attention",
        "abstract": "  Recently, linear complexity sequence modeling networks have achieved modeling\ncapabilities similar to Vision Transformers on a variety of computer vision\ntasks, while using fewer FLOPs and less memory. However, their advantage in\nterms of actual runtime speed is not significant. To address this issue, we\nintroduce Gated Linear Attention (GLA) for vision, leveraging its superior\nhardware-awareness and efficiency. We propose direction-wise gating to capture\n1D global context through bidirectional modeling and a 2D gating locality\ninjection to adaptively inject 2D local details into 1D global context. Our\nhardware-aware implementation further merges forward and backward scanning into\na single kernel, enhancing parallelism and reducing memory cost and latency.\nThe proposed model, ViG, offers a favorable trade-off in accuracy, parameters,\nand FLOPs on ImageNet and downstream tasks, outperforming popular Transformer\nand CNN-based models. Notably, ViG-S matches DeiT-B's accuracy while using only\n27% of the parameters and 20% of the FLOPs, running 2$\\times$ faster on\n$224\\times224$ images. At $1024\\times1024$ resolution, ViG-T uses 5.2$\\times$\nfewer FLOPs, saves 90% GPU memory, runs 4.8$\\times$ faster, and achieves 20.7%\nhigher top-1 accuracy than DeiT-T. These results position ViG as an efficient\nand scalable solution for visual representation learning. Code is available at\n\\url{https://github.com/hustvl/ViG}.\n",
        "authors": "Bencheng Liao; Xinggang Wang; Lianghui Zhu; Qian Zhang; Chang Huang",
        "status": 0,
        "relevancy": 0.40567791159791344,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17894",
        "date": "2024-05-28",
        "title": "White-box Multimodal Jailbreaks Against Large Vision-Language Models",
        "abstract": "  Recent advancements in Large Vision-Language Models (VLMs) have underscored\ntheir superiority in various multimodal tasks. However, the adversarial\nrobustness of VLMs has not been fully explored. Existing methods mainly assess\nrobustness through unimodal adversarial attacks that perturb images, while\nassuming inherent resilience against text-based attacks. Different from\nexisting attacks, in this work we propose a more comprehensive strategy that\njointly attacks both text and image modalities to exploit a broader spectrum of\nvulnerability within VLMs. Specifically, we propose a dual optimization\nobjective aimed at guiding the model to generate affirmative responses with\nhigh toxicity. Our attack method begins by optimizing an adversarial image\nprefix from random noise to generate diverse harmful responses in the absence\nof text input, thus imbuing the image with toxic semantics. Subsequently, an\nadversarial text suffix is integrated and co-optimized with the adversarial\nimage prefix to maximize the probability of eliciting affirmative responses to\nvarious harmful instructions. The discovered adversarial image prefix and text\nsuffix are collectively denoted as a Universal Master Key (UMK). When\nintegrated into various malicious queries, UMK can circumvent the alignment\ndefenses of VLMs and lead to the generation of objectionable content, known as\njailbreaks. The experimental results demonstrate that our universal attack\nstrategy can effectively jailbreak MiniGPT-4 with a 96% success rate,\nhighlighting the vulnerability of VLMs and the urgent need for new alignment\nstrategies.\n",
        "authors": "Ruofan Wang; Xingjun Ma; Hanxu Zhou; Chuanjun Ji; Guangnan Ye; Yu-Gang Jiang",
        "status": 0,
        "relevancy": 0.40417267133145773,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18335",
        "date": "2024-05-28",
        "title": "Interpretable classification of wiki-review streams",
        "abstract": "  Wiki articles are created and maintained by a crowd of editors, producing a\ncontinuous stream of reviews. Reviews can take the form of additions, reverts,\nor both. This crowdsourcing model is exposed to manipulation since neither\nreviews nor editors are automatically screened and purged. To protect articles\nagainst vandalism or damage, the stream of reviews can be mined to classify\nreviews and profile editors in real-time. The goal of this work is to\nanticipate and explain which reviews to revert. This way, editors are informed\nwhy their edits will be reverted. The proposed method employs stream-based\nprocessing, updating the profiling and classification models on each incoming\nevent. The profiling uses side and content-based features employing Natural\nLanguage Processing, and editor profiles are incrementally updated based on\ntheir reviews. Since the proposed method relies on self-explainable\nclassification algorithms, it is possible to understand why a review has been\nclassified as a revert or a non-revert. In addition, this work contributes an\nalgorithm for generating synthetic data for class balancing, making the final\nclassification fairer. The proposed online method was tested with a real data\nset from Wikivoyage, which was balanced through the aforementioned synthetic\ndata generation. The results attained near-90 % values for all evaluation\nmetrics (accuracy, precision, recall, and F-measure).\n",
        "authors": "Silvia García Méndez; Fátima Leal; Benedita Malheiro; Juan Carlos Burguillo Rial",
        "status": 0,
        "relevancy": 0.4038534301778801,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17957",
        "date": "2024-05-28",
        "title": "Modeling Dynamic Topics in Chain-Free Fashion by Evolution-Tracking\n  Contrastive Learning and Unassociated Word Exclusion",
        "abstract": "  Dynamic topic models track the evolution of topics in sequential documents,\nwhich have derived various applications like trend analysis and opinion mining.\nHowever, existing models suffer from repetitive topic and unassociated topic\nissues, failing to reveal the evolution and hindering further applications. To\naddress these issues, we break the tradition of simply chaining topics in\nexisting work and propose a novel neural \\modelfullname. We introduce a new\nevolution-tracking contrastive learning method that builds the similarity\nrelations among dynamic topics. This not only tracks topic evolution but also\nmaintains topic diversity, mitigating the repetitive topic issue. To avoid\nunassociated topics, we further present an unassociated word exclusion method\nthat consistently excludes unassociated words from discovered topics. Extensive\nexperiments demonstrate our model significantly outperforms state-of-the-art\nbaselines, tracking topic evolution with high-quality topics, showing better\nperformance on downstream tasks, and remaining robust to the hyperparameter for\nevolution intensities. Our code is available at https://github.com/bobxwu/CFDTM .\n",
        "authors": "Xiaobao Wu; Xinshuai Dong; Liangming Pan; Thong Nguyen; Anh Tuan Luu",
        "status": 0,
        "relevancy": 0.40346648234587934,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18003",
        "date": "2024-05-28",
        "title": "MAVIN: Multi-Action Video Generation with Diffusion Models via\n  Transition Video Infilling",
        "abstract": "  Diffusion-based video generation has achieved significant progress, yet\ngenerating multiple actions that occur sequentially remains a formidable task.\nDirectly generating a video with sequential actions can be extremely\nchallenging due to the scarcity of fine-grained action annotations and the\ndifficulty in establishing temporal semantic correspondences and maintaining\nlong-term consistency. To tackle this, we propose an intuitive and\nstraightforward solution: splicing multiple single-action video segments\nsequentially. The core challenge lies in generating smooth and natural\ntransitions between these segments given the inherent complexity and\nvariability of action transitions. We introduce MAVIN (Multi-Action Video\nINfilling model), designed to generate transition videos that seamlessly\nconnect two given videos, forming a cohesive integrated sequence. MAVIN\nincorporates several innovative techniques to address challenges in the\ntransition video infilling task. Firstly, a consecutive noising strategy\ncoupled with variable-length sampling is employed to handle large infilling\ngaps and varied generation lengths. Secondly, boundary frame guidance (BFG) is\nproposed to address the lack of semantic guidance during transition generation.\nLastly, a Gaussian filter mixer (GFM) dynamically manages noise initialization\nduring inference, mitigating train-test discrepancy while preserving generation\nflexibility. Additionally, we introduce a new metric, CLIP-RS (CLIP Relative\nSmoothness), to evaluate temporal coherence and smoothness, complementing\ntraditional quality-based metrics. Experimental results on horse and tiger\nscenarios demonstrate MAVIN's superior performance in generating smooth and\ncoherent video transitions compared to existing methods.\n",
        "authors": "Bowen Zhang; Xiaofei Xie; Haotian Lu; Na Ma; Tianlin Li; Qing Guo",
        "status": 0,
        "relevancy": 0.4032169511470619,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17874",
        "date": "2024-05-28",
        "title": "NUTS, NARS, and Speech",
        "abstract": "  To investigate whether \"Intelligence is the capacity of an\ninformation-processing system to adapt to its environment while operating with\ninsufficient knowledge and resources\", we look at utilising the non axiomatic\nreasoning system (NARS) for speech recognition. This article presents NUTS:\nraNdom dimensionality redUction non axiomaTic reasoning few Shot learner for\nperception. NUTS consists of naive dimensionality reduction, some\npre-processing, and then non axiomatic reasoning (NARS). With only 2 training\nexamples NUTS performs similarly to the Whisper Tiny model for discrete word\nidentification.\n",
        "authors": "D. van der Sluis",
        "status": 0,
        "relevancy": 0.4030182594399745,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17940",
        "date": "2024-05-28",
        "title": "World Models for General Surgical Grasping",
        "abstract": "  Intelligent vision control systems for surgical robots should adapt to\nunknown and diverse objects while being robust to system disturbances. Previous\nmethods did not meet these requirements due to mainly relying on pose\nestimation and feature tracking. We propose a world-model-based deep\nreinforcement learning framework \"Grasp Anything for Surgery\" (GAS), that\nlearns a pixel-level visuomotor policy for surgical grasping, enhancing both\ngenerality and robustness. In particular, a novel method is proposed to\nestimate the values and uncertainties of depth pixels for a rigid-link object's\ninaccurate region based on the empirical prior of the object's size; both depth\nand mask images of task objects are encoded to a single compact 3-channel image\n(size: 64x64x3) by dynamically zooming in the mask regions, minimizing the\ninformation loss. The learned controller's effectiveness is extensively\nevaluated in simulation and in a real robot. Our learned visuomotor policy\nhandles: i) unseen objects, including 5 types of target grasping objects and a\nrobot gripper, in unstructured real-world surgery environments, and ii)\ndisturbances in perception and control. Note that we are the first work to\nachieve a unified surgical control system that grasps diverse surgical objects\nusing different robot grippers on real robots in complex surgery scenes\n(average success rate: 69%). Our system also demonstrates significant\nrobustness across 6 conditions including background variation, target\ndisturbance, camera pose variation, kinematic control error, image noise, and\nre-grasping after the gripped target object drops from the gripper. Videos and\ncodes can be found on our project page: https://linhongbin.github.io/gas/.\n",
        "authors": "Hongbin Lin; Bin Li; Chun Wai Wong; Juan Rojas; Xiangyu Chu; Kwok Wai Samuel Au",
        "status": 0,
        "relevancy": 0.4002606149039689,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18663",
        "date": "2024-05-28",
        "title": "Lifelong Learning and Selective Forgetting via Contrastive Strategy",
        "abstract": "  Lifelong learning aims to train a model with good performance for new tasks\nwhile retaining the capacity of previous tasks. However, some practical\nscenarios require the system to forget undesirable knowledge due to privacy\nissues, which is called selective forgetting. The joint task of the two is\ndubbed Learning with Selective Forgetting (LSF). In this paper, we propose a\nnew framework based on contrastive strategy for LSF. Specifically, for the\npreserved classes (tasks), we make features extracted from different samples\nwithin a same class compacted. And for the deleted classes, we make the\nfeatures from different samples of a same class dispersed and irregular, i.e.,\nthe network does not have any regular response to samples from a specific\ndeleted class as if the network has no training at all. Through maintaining or\ndisturbing the feature distribution, the forgetting and memory of different\nclasses can be or independent of each other. Experiments are conducted on four\nbenchmark datasets, and our method acieves new state-of-the-art.\n",
        "authors": "Lianlei Shan; Wenzhang Zhou; Wei Li; Xingyu Ding",
        "status": 0,
        "relevancy": 0.3979575634270527,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17942",
        "date": "2024-05-28",
        "title": "Self-supervised Pre-training for Transferable Multi-modal Perception",
        "abstract": "  In autonomous driving, multi-modal perception models leveraging inputs from\nmultiple sensors exhibit strong robustness in degraded environments. However,\nthese models face challenges in efficiently and effectively transferring\nlearned representations across different modalities and tasks. This paper\npresents NeRF-Supervised Masked Auto Encoder (NS-MAE), a self-supervised\npre-training paradigm for transferable multi-modal representation learning.\nNS-MAE is designed to provide pre-trained model initializations for efficient\nand high-performance fine-tuning. Our approach uses masked multi-modal\nreconstruction in neural radiance fields (NeRF), training the model to\nreconstruct missing or corrupted input data across multiple modalities.\nSpecifically, multi-modal embeddings are extracted from corrupted LiDAR point\nclouds and images, conditioned on specific view directions and locations. These\nembeddings are then rendered into projected multi-modal feature maps using\nneural rendering techniques. The original multi-modal signals serve as\nreconstruction targets for the rendered feature maps, facilitating\nself-supervised representation learning. Extensive experiments demonstrate the\npromising transferability of NS-MAE representations across diverse multi-modal\nand single-modal perception models. This transferability is evaluated on\nvarious 3D perception downstream tasks, such as 3D object detection and BEV map\nsegmentation, using different amounts of fine-tuning labeled data. Our code\nwill be released to support the community.\n",
        "authors": "Xiaohao Xu; Tianyi Zhang; Jinrong Yang; Matthew Johnson-Roberson; Xiaonan Huang",
        "status": 0,
        "relevancy": 0.3967230227177043,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18014",
        "date": "2024-05-28",
        "title": "Coupled Mamba: Enhanced Multi-modal Fusion with Coupled State Space\n  Model",
        "abstract": "  The essence of multi-modal fusion lies in exploiting the complementary\ninformation inherent in diverse modalities. However, prevalent fusion methods\nrely on traditional neural architectures and are inadequately equipped to\ncapture the dynamics of interactions across modalities, particularly in\npresence of complex intra- and inter-modality correlations. Recent advancements\nin State Space Models (SSMs), notably exemplified by the Mamba model, have\nemerged as promising contenders. Particularly, its state evolving process\nimplies stronger modality fusion paradigm, making multi-modal fusion on SSMs an\nappealing direction. However, fusing multiple modalities is challenging for\nSSMs due to its hardware-aware parallelism designs. To this end, this paper\nproposes the Coupled SSM model, for coupling state chains of multiple\nmodalities while maintaining independence of intra-modality state processes.\nSpecifically, in our coupled scheme, we devise an inter-modal hidden states\ntransition scheme, in which the current state is dependent on the states of its\nown chain and that of the neighbouring chains at the previous time-step. To\nfully comply with the hardware-aware parallelism, we devise an expedite coupled\nstate transition scheme and derive its corresponding global convolution kernel\nfor parallelism. Extensive experiments on CMU-MOSEI, CH-SIMS, CH-SIMSV2 through\nmulti-domain input verify the effectiveness of our model compared to current\nstate-of-the-art methods, improved F1-Score by 0.4\\%, 0.9\\%, and 2.3\\% on the\nthree datasets respectively, 49\\% faster inference and 83.7\\% GPU memory save.\nThe results demonstrate that Coupled Mamba model is capable of enhanced\nmulti-modal fusion.\n",
        "authors": "Wenbing Li; Hang Zhou; Junqing Yu; Zikai Song; Wei Yang",
        "status": 0,
        "relevancy": 0.39009738529761795,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17766",
        "date": "2024-05-28",
        "title": "SleepFM: Multi-modal Representation Learning for Sleep Across Brain\n  Activity, ECG and Respiratory Signals",
        "abstract": "  Sleep is a complex physiological process evaluated through various modalities\nrecording electrical brain, cardiac, and respiratory activities. We curate a\nlarge polysomnography dataset from over 14,000 participants comprising over\n100,000 hours of multi-modal sleep recordings. Leveraging this extensive\ndataset, we developed SleepFM, the first multi-modal foundation model for sleep\nanalysis. We show that a novel leave-one-out approach for contrastive learning\nsignificantly improves downstream task performance compared to representations\nfrom standard pairwise contrastive learning. A logistic regression model\ntrained on SleepFM's learned embeddings outperforms an end-to-end trained\nconvolutional neural network (CNN) on sleep stage classification (macro AUROC\n0.88 vs 0.72 and macro AUPRC 0.72 vs 0.48) and sleep disordered breathing\ndetection (AUROC 0.85 vs 0.69 and AUPRC 0.77 vs 0.61). Notably, the learned\nembeddings achieve 48% top-1 average accuracy in retrieving the corresponding\nrecording clips of other modalities from 90,000 candidates. This work\ndemonstrates the value of holistic multi-modal sleep modeling to fully capture\nthe richness of sleep recordings. SleepFM is open source and available at\nhttps://github.com/rthapa84/sleepfm-codebase.\n",
        "authors": "Rahul Thapa; Bryan He; Magnus Ruud Kjaer; Hyatt Moore; Gauri Ganjoo; Emmanuel Mignot; James Zou",
        "status": 0,
        "relevancy": 0.3898255435339463,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17838",
        "date": "2024-05-28",
        "title": "Trust and Terror: Hazards in Text Reveal Negatively Biased Credulity and\n  Partisan Negativity Bias",
        "abstract": "  Socio-linguistic indicators of text, such as emotion or sentiment, are often\nextracted using neural networks in order to better understand features of\nsocial media. One indicator that is often overlooked, however, is the presence\nof hazards within text. Recent psychological research suggests that statements\nabout hazards are more believable than statements about benefits (a property\nknown as negatively biased credulity), and that political liberals and\nconservatives differ in how often they share hazards. Here, we develop a new\nmodel to detect information concerning hazards, trained on a new collection of\nannotated X posts, as well as urban legends annotated in previous work. We show\nthat not only does this model perform well (outperforming, e.g., zero-shot\nhuman annotator proxies, such as GPT-4) but that the hazard information it\nextracts is not strongly correlated with other indicators, namely moral\noutrage, sentiment, emotions, and threat words. (That said, consonant with\nexpectations, hazard information does correlate positively with such emotions\nas fear, and negatively with emotions like joy.) We then apply this model to\nthree datasets: X posts about COVID-19, X posts about the 2023 Hamas-Israel\nwar, and a new expanded collection of urban legends. From these data, we\nuncover words associated with hazards unique to each dataset as well as\ndifferences in this language between groups of users, such as conservatives and\nliberals, which informs what these groups perceive as hazards. We further show\nthat information about hazards peaks in frequency after major hazard events,\nand therefore acts as an automated indicator of such events. Finally, we find\nthat information about hazards is especially prevalent in urban legends, which\nis consistent with previous work that finds that reports of hazards are more\nlikely to be both believed and transmitted.\n",
        "authors": "Keith Burghardt; Daniel M. T. Fessler; Chyna Tang; Anne Pisor; Kristina Lerman",
        "status": 0,
        "relevancy": 0.3885782353072148,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17934",
        "date": "2024-05-28",
        "title": "Proof of Quality: A Costless Paradigm for Trustless Generative AI Model\n  Inference on Blockchains",
        "abstract": "  Generative AI models, such as GPT-4 and Stable Diffusion, have demonstrated\npowerful and disruptive capabilities in natural language and image tasks.\nHowever, deploying these models in decentralized environments remains\nchallenging. Unlike traditional centralized deployment, systematically\nguaranteeing the integrity of AI model services in fully decentralized\nenvironments, particularly on trustless blockchains, is both crucial and\ndifficult. In this paper, we present a new inference paradigm called\n\\emph{proof of quality} (PoQ) to enable the deployment of arbitrarily large\ngenerative models on blockchain architecture. Unlike traditional approaches\nbased on validating inference procedures, such as ZKML or OPML, our PoQ\nparadigm focuses on the outcome quality of model inference. Using lightweight\nBERT-based cross-encoders as our underlying quality evaluation model, we design\nand implement PQML, the first practical protocol for real-world NLP generative\nmodel inference on blockchains, tailored for popular open-source models such as\nLlama 3 and Mixtral. Our analysis demonstrates that our protocol is robust\nagainst adversarial but rational participants in ecosystems, where lazy or\ndishonest behavior results in fewer benefits compared to well-behaving\nparticipants. The computational overhead of validating the quality evaluation\nis minimal, allowing quality validators to complete the quality check within a\nsecond, even using only a CPU. Preliminary simulation results show that PoQ\nconsensus is generated in milliseconds, 1,000 times faster than any existing\nscheme.\n",
        "authors": "Zhenjie Zhang; Yuyang Rao; Hao Xiao; Xiaokui Xiao; Yin Yang",
        "status": 0,
        "relevancy": 0.38675751504487776,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17746",
        "date": "2024-05-28",
        "title": "Rethinking Pruning for Backdoor Mitigation: An Optimization Perspective",
        "abstract": "  Deep Neural Networks (DNNs) are known to be vulnerable to backdoor attacks,\nposing concerning threats to their reliable deployment. Recent research reveals\nthat backdoors can be erased from infected DNNs by pruning a specific group of\nneurons, while how to effectively identify and remove these backdoor-associated\nneurons remains an open challenge. Most of the existing defense methods rely on\ndefined rules and focus on neuron's local properties, ignoring the exploration\nand optimization of pruning policies. To address this gap, we propose an\nOptimized Neuron Pruning (ONP) method combined with Graph Neural Network (GNN)\nand Reinforcement Learning (RL) to repair backdoor models. Specifically, ONP\nfirst models the target DNN as graphs based on neuron connectivity, and then\nuses GNN-based RL agents to learn graph embeddings and find a suitable pruning\npolicy. To the best of our knowledge, this is the first attempt to employ GNN\nand RL for optimizing pruning policies in the field of backdoor defense.\nExperiments show, with a small amount of clean data, ONP can effectively prune\nthe backdoor neurons implanted by a set of backdoor attacks at the cost of\nnegligible performance degradation, achieving a new state-of-the-art\nperformance for backdoor mitigation.\n",
        "authors": "Nan Li; Haiyang Yu; Ping Yi",
        "status": 0,
        "relevancy": 0.3860347237446391,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17992",
        "date": "2024-05-28",
        "title": "fMRI predictors based on language models of increasing complexity\n  recover brain left lateralization",
        "abstract": "  Over the past decade, studies of naturalistic language processing where\nparticipants are scanned while listening to continuous text have flourished.\nUsing word embeddings at first, then large language models, researchers have\ncreated encoding models to analyze the brain signals. Presenting these models\nwith the same text as the participants allows to identify brain areas where\nthere is a significant correlation between the functional magnetic resonance\nimaging (fMRI) time series and the ones predicted by the models' artificial\nneurons. One intriguing finding from these studies is that they have revealed\nhighly symmetric bilateral activation patterns, somewhat at odds with the\nwell-known left lateralization of language processing. Here, we report analyses\nof an fMRI dataset where we manipulate the complexity of large language models,\ntesting 28 pretrained models from 8 different families, ranging from 124M to\n14.2B parameters. First, we observe that the performance of models in\npredicting brain responses follows a scaling law, where the fit with brain\nactivity increases linearly with the logarithm of the number of parameters of\nthe model (and its performance on natural language processing tasks). Second,\nwe show that a left-right asymmetry gradually appears as model size increases,\nand that the difference in left-right brain correlations also follows a scaling\nlaw. Whereas the smallest models show no asymmetry, larger models fit better\nand better left hemispheric activations than right hemispheric ones. This\nfinding reconciles computational analyses of brain activity using large\nlanguage models with the classic observation from aphasic patients showing left\nhemisphere dominance for language.\n",
        "authors": "Laurent Bonnasse-Gahot; Christophe Pallier",
        "status": 0,
        "relevancy": 0.380465478549635,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18636",
        "date": "2024-05-28",
        "title": "ChatGPT as the Marketplace of Ideas: Should Truth-Seeking Be the Goal of\n  AI Content Governance?",
        "abstract": "  As one of the most enduring metaphors within legal discourse, the marketplace\nof ideas has wielded considerable influence over the jurisprudential landscape\nfor decades. A century after the inception of this theory, ChatGPT emerged as a\nrevolutionary technological advancement in the twenty-first century. This\nresearch finds that ChatGPT effectively manifests the marketplace metaphor. It\nnot only instantiates the promises envisaged by generations of legal scholars\nbut also lays bare the perils discerned through sustained academic critique.\nSpecifically, the workings of ChatGPT and the marketplace of ideas theory\nexhibit at least four common features: arena, means, objectives, and flaws.\nThese shared attributes are sufficient to render ChatGPT historically the most\nqualified engine for actualizing the marketplace of ideas theory.\n  The comparison of the marketplace theory and ChatGPT merely marks a starting\npoint. A more meaningful undertaking entails reevaluating and reframing both\ninternal and external AI policies by referring to the accumulated experience,\ninsights, and suggestions researchers have raised to fix the marketplace\ntheory. Here, a pivotal issue is: should truth-seeking be set as the goal of AI\ncontent governance? Given the unattainability of the absolute truth-seeking\ngoal, I argue against adopting zero-risk policies. Instead, a more judicious\napproach would be to embrace a knowledge-based alternative wherein large\nlanguage models (LLMs) are trained to generate competing and divergent\nviewpoints based on sufficient justifications. This research also argues that\nso-called AI content risks are not created by AI companies but are inherent in\nthe entire information ecosystem. Thus, the burden of managing these risks\nshould be distributed among different social actors, rather than being solely\nshouldered by chatbot companies.\n",
        "authors": "Jiawei Zhang",
        "status": 0,
        "relevancy": 0.3804020367454448,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18428",
        "date": "2024-05-28",
        "title": "DiG: Scalable and Efficient Diffusion Models with Gated Linear Attention",
        "abstract": "  Diffusion models with large-scale pre-training have achieved significant\nsuccess in the field of visual content generation, particularly exemplified by\nDiffusion Transformers (DiT). However, DiT models have faced challenges with\nscalability and quadratic complexity efficiency. In this paper, we aim to\nleverage the long sequence modeling capability of Gated Linear Attention (GLA)\nTransformers, expanding its applicability to diffusion models. We introduce\nDiffusion Gated Linear Attention Transformers (DiG), a simple, adoptable\nsolution with minimal parameter overhead, following the DiT design, but\noffering superior efficiency and effectiveness. In addition to better\nperformance than DiT, DiG-S/2 exhibits $2.5\\times$ higher training speed than\nDiT-S/2 and saves $75.7\\%$ GPU memory at a resolution of $1792 \\times 1792$.\nMoreover, we analyze the scalability of DiG across a variety of computational\ncomplexity. DiG models, with increased depth/width or augmentation of input\ntokens, consistently exhibit decreasing FID. We further compare DiG with other\nsubquadratic-time diffusion models. With the same model size, DiG-XL/2 is\n$4.2\\times$ faster than the recent Mamba-based diffusion model at a $1024$\nresolution, and is $1.8\\times$ faster than DiT with CUDA-optimized\nFlashAttention-2 under the $2048$ resolution. All these results demonstrate its\nsuperior efficiency among the latest diffusion models. Code is released at\nhttps://github.com/hustvl/DiG.\n",
        "authors": "Lianghui Zhu; Zilong Huang; Bencheng Liao; Jun Hao Liew; Hanshu Yan; Jiashi Feng; Xinggang Wang",
        "status": 0,
        "relevancy": 0.378326993971983,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18602",
        "date": "2024-05-28",
        "title": "SST-GCN: The Sequential based Spatio-Temporal Graph Convolutional\n  networks for Minute-level and Road-level Traffic Accident Risk Predictio",
        "abstract": "  Traffic accidents are recognized as a major social issue worldwide, causing\nnumerous injuries and significant costs annually. Consequently, methods for\npredicting and preventing traffic accidents have been researched for many\nyears. With advancements in the field of artificial intelligence, various\nstudies have applied Machine Learning and Deep Learning techniques to traffic\naccident prediction. Modern traffic conditions change rapidly by the minute,\nand these changes vary significantly across different roads. In other words,\nthe risk of traffic accidents changes minute by minute in various patterns for\neach road. Therefore, it is desirable to predict traffic accident risk at the\nMinute-Level and Road-Level. However, because roads have close and complex\nrelationships with adjacent roads, research on predicting traffic accidents at\nthe Minute-Level and Road-Level is challenging. Thus, it is essential to build\na model that can reflect the spatial and temporal characteristics of roads for\ntraffic accident prediction. Consequently, recent attempts have been made to\nuse Graph Convolutional Networks to capture the spatial characteristics of\nroads and Recurrent Neural Networks to capture their temporal characteristics\nfor predicting traffic accident risk. This paper proposes the Sequential based\nSpatio-Temporal Graph Convolutional Networks (SST-GCN), which combines GCN and\nLSTM, to predict traffic accidents at the Minute-Level and Road-Level using a\nroad dataset constructed in Seoul, the capital of South Korea. Experiments have\ndemonstrated that SST-GCN outperforms other state-of-the-art models in\nMinute-Level predictions.\n",
        "authors": "Tae-wook Kim; Han-jin Lee; Hyeon-Jin Jung; Ji-Woong Yang; Ellen J. Hong",
        "status": 0,
        "relevancy": 0.3735551232509764,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18300",
        "date": "2024-05-28",
        "title": "CompetEvo: Towards Morphological Evolution from Competition",
        "abstract": "  Training an agent to adapt to specific tasks through co-optimization of\nmorphology and control has widely attracted attention. However, whether there\nexists an optimal configuration and tactics for agents in a multiagent\ncompetition scenario is still an issue that is challenging to definitively\nconclude. In this context, we propose competitive evolution (CompetEvo), which\nco-evolves agents' designs and tactics in confrontation. We build arenas\nconsisting of three animals and their evolved derivatives, placing agents with\ndifferent morphologies in direct competition with each other. The results\nreveal that our method enables agents to evolve a more suitable design and\nstrategy for fighting compared to fixed-morph agents, allowing them to obtain\nadvantages in combat scenarios. Moreover, we demonstrate the amazing and\nimpressive behaviors that emerge when confrontations are conducted under\nasymmetrical morphs.\n",
        "authors": "Kangyao Huang; Di Guo; Xinyu Zhang; Xiangyang Ji; Huaping Liu",
        "status": 0,
        "relevancy": 0.3731645532957174,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18064",
        "date": "2024-05-28",
        "title": "Automated Real-World Sustainability Data Generation from Images of\n  Buildings",
        "abstract": "  When data on building features is unavailable, the task of determining how to\nimprove that building in terms of carbon emissions becomes infeasible. We show\nthat from only a set of images, a Large Language Model with appropriate prompt\nengineering and domain knowledge can successfully estimate a range of building\nfeatures relevant for sustainability calculations. We compare our novel\nimage-to-data method with a ground truth comprising real building data for 47\napartments and achieve accuracy better than a human performing the same task.\nWe also demonstrate that the method can generate tailored recommendations to\nthe owner on how best to improve their properties and discuss methods to scale\nthe approach.\n",
        "authors": "Peter J Bentley; Soo Ling Lim; Rajat Mathur; Sid Narang",
        "status": 0,
        "relevancy": 0.37260089535019003,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18137",
        "date": "2024-05-28",
        "title": "Exploiting LLM Quantization",
        "abstract": "  Quantization leverages lower-precision weights to reduce the memory usage of\nlarge language models (LLMs) and is a key technique for enabling their\ndeployment on commodity hardware. While LLM quantization's impact on utility\nhas been extensively explored, this work for the first time studies its adverse\neffects from a security perspective. We reveal that widely used quantization\nmethods can be exploited to produce a harmful quantized LLM, even though the\nfull-precision counterpart appears benign, potentially tricking users into\ndeploying the malicious quantized model. We demonstrate this threat using a\nthree-staged attack framework: (i) first, we obtain a malicious LLM through\nfine-tuning on an adversarial task; (ii) next, we quantize the malicious model\nand calculate constraints that characterize all full-precision models that map\nto the same quantized model; (iii) finally, using projected gradient descent,\nwe tune out the poisoned behavior from the full-precision model while ensuring\nthat its weights satisfy the constraints computed in step (ii). This procedure\nresults in an LLM that exhibits benign behavior in full precision but when\nquantized, it follows the adversarial behavior injected in step (i). We\nexperimentally demonstrate the feasibility and severity of such an attack\nacross three diverse scenarios: vulnerable code generation, content injection,\nand over-refusal attack. In practice, the adversary could host the resulting\nfull-precision model on an LLM community hub such as Hugging Face, exposing\nmillions of users to the threat of deploying its malicious quantized version on\ntheir devices.\n",
        "authors": "Kazuki Egashira; Mark Vero; Robin Staab; Jingxuan He; Martin Vechev",
        "status": 0,
        "relevancy": 0.3688298202796041,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17898",
        "date": "2024-05-28",
        "title": "FlashST: A Simple and Universal Prompt-Tuning Framework for Traffic\n  Prediction",
        "abstract": "  The objective of traffic prediction is to accurately forecast and analyze the\ndynamics of transportation patterns, considering both space and time. However,\nthe presence of distribution shift poses a significant challenge in this field,\nas existing models struggle to generalize well when faced with test data that\nsignificantly differs from the training distribution. To tackle this issue,\nthis paper introduces a simple and universal spatio-temporal prompt-tuning\nframework-FlashST, which adapts pre-trained models to the specific\ncharacteristics of diverse downstream datasets, improving generalization in\ndiverse traffic prediction scenarios. Specifically, the FlashST framework\nemploys a lightweight spatio-temporal prompt network for in-context learning,\ncapturing spatio-temporal invariant knowledge and facilitating effective\nadaptation to diverse scenarios. Additionally, we incorporate a distribution\nmapping mechanism to align the data distributions of pre-training and\ndownstream data, facilitating effective knowledge transfer in spatio-temporal\nforecasting. Empirical evaluations demonstrate the effectiveness of our FlashST\nacross different spatio-temporal prediction tasks using diverse urban datasets.\nCode is available at https://github.com/HKUDS/FlashST.\n",
        "authors": "Zhonghang Li; Lianghao Xia; Yong Xu; Chao Huang",
        "status": 0,
        "relevancy": 0.3686578294078132,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17910",
        "date": "2024-05-28",
        "title": "Human-Cobot collaboration's impact on success, time completion, errors,\n  workload, gestures and acceptability during an assembly task",
        "abstract": "  The 5.0 industry promotes collaborative robots (cobots). This research\nstudies the impacts of cobot collaboration using an experimental setup. 120\nparticipants realized a simple and a complex assembly task. 50% collaborated\nwith another human (H/H) and 50% with a cobot (H/C). The workload and the\nacceptability of the cobotic collaboration were measured. Working with a cobot\ndecreases the effect of the task complexity on the human workload and on the\noutput quality. However, it increases the time completion and the number of\ngestures (while decreasing their frequency). The H/C couples have a higher\nchance of success but they take more time and more gestures to realize the\ntask. The results of this research could help developers and stakeholders to\nunderstand the impacts of implementing a cobot in production chains.\n",
        "authors": "Étienne Fournier; Christine Jeoffrion; Belal Hmedan; Damien Pellier; Humbert Fiorino; Aurélie Landry",
        "status": 0,
        "relevancy": 0.364853025509027,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17720",
        "date": "2024-05-28",
        "title": "MindFormer: A Transformer Architecture for Multi-Subject Brain Decoding\n  via fMRI",
        "abstract": "  Research efforts to understand neural signals have been ongoing for many\nyears, with visual decoding from fMRI signals attracting considerable\nattention. Particularly, the advent of image diffusion models has advanced the\nreconstruction of images from fMRI data significantly. However, existing\napproaches often introduce inter- and intra- subject variations in the\nreconstructed images, which can compromise accuracy. To address current\nlimitations in multi-subject brain decoding, we introduce a new Transformer\narchitecture called MindFormer. This model is specifically designed to generate\nfMRI-conditioned feature vectors that can be used for conditioning Stable\nDiffusion model. More specifically, MindFormer incorporates two key\ninnovations: 1) a novel training strategy based on the IP-Adapter to extract\nsemantically meaningful features from fMRI signals, and 2) a subject specific\ntoken and linear layer that effectively capture individual differences in fMRI\nsignals while synergistically combines multi subject fMRI data for training.\nOur experimental results demonstrate that Stable Diffusion, when integrated\nwith MindFormer, produces semantically consistent images across different\nsubjects. This capability significantly surpasses existing models in\nmulti-subject brain decoding. Such advancements not only improve the accuracy\nof our reconstructions but also deepen our understanding of neural processing\nvariations among individuals.\n",
        "authors": "Inhwa Han; Jaayeon Lee; Jong Chul Ye",
        "status": 0,
        "relevancy": 0.36230292825655397,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17849",
        "date": "2024-05-28",
        "title": "I-LLM: Efficient Integer-Only Inference for Fully-Quantized Low-Bit\n  Large Language Models",
        "abstract": "  Post-training quantization (PTQ) serves as a potent technique to accelerate\nthe inference of large language models (LLMs). Nonetheless, existing works\nstill necessitate a considerable number of floating-point (FP) operations\nduring inference, including additional quantization and de-quantization, as\nwell as non-linear operators such as RMSNorm and Softmax. This limitation\nhinders the deployment of LLMs on the edge and cloud devices. In this paper, we\nidentify the primary obstacle to integer-only quantization for LLMs lies in the\nlarge fluctuation of activations across channels and tokens in both linear and\nnon-linear operations. To address this issue, we propose I-LLM, a novel\ninteger-only fully-quantized PTQ framework tailored for LLMs. Specifically, (1)\nwe develop Fully-Smooth Block-Reconstruction (FSBR) to aggressively smooth\ninter-channel variations of all activations and weights. (2) to alleviate\ndegradation caused by inter-token variations, we introduce a novel approach\ncalled Dynamic Integer-only MatMul (DI-MatMul). This method enables dynamic\nquantization in full-integer matrix multiplication by dynamically quantizing\nthe input and outputs with integer-only operations. (3) we design\nDI-ClippedSoftmax, DI-Exp, and DI-Normalization, which utilize bit shift to\nexecute non-linear operators efficiently while maintaining accuracy. The\nexperiment shows that our I-LLM achieves comparable accuracy to the FP baseline\nand outperforms non-integer quantization methods. For example, I-LLM can\noperate at W4A4 with negligible loss of accuracy. To our knowledge, we are the\nfirst to bridge the gap between integer-only quantization and LLMs. We've\npublished our code on anonymous.4open.science, aiming to contribute to the\nadvancement of this field.\n",
        "authors": "Xing Hu; Yuan Chen; Dawei Yang; Sifan Zhou; Zhihang Yuan; Jiangyong Yu; Chen Xu",
        "status": 0,
        "relevancy": 0.3600921885200329,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18119",
        "date": "2024-05-28",
        "title": "Low-Resource Crop Classification from Multi-Spectral Time Series Using\n  Lossless Compressors",
        "abstract": "  Deep learning has significantly improved the accuracy of crop classification\nusing multispectral temporal data. However, these models have complex\nstructures with numerous parameters, requiring large amounts of data and costly\ntraining. In low-resource situations with fewer labeled samples, deep learning\nmodels perform poorly due to insufficient data. Conversely, compressors are\ndata-type agnostic, and non-parametric methods do not bring underlying\nassumptions. Inspired by this insight, we propose a non-training alternative to\ndeep learning models, aiming to address these situations. Specifically, the\nSymbolic Representation Module is proposed to convert the reflectivity into\nsymbolic representations. The symbolic representations are then\ncross-transformed in both the channel and time dimensions to generate symbolic\nembeddings. Next, the Multi-scale Normalised Compression Distance (MNCD) is\ndesigned to measure the correlation between any two symbolic embeddings.\nFinally, based on the MNCDs, high quality crop classification can be achieved\nusing only a k-nearest-neighbor classifier kNN. The entire framework is\nready-to-use and lightweight. Without any training, it outperformed, on\naverage, 7 advanced deep learning models trained at scale on three benchmark\ndatasets. It also outperforms more than half of these models in the few-shot\nsetting with sparse crop labels. Therefore, the high performance and robustness\nof our non-training framework makes it truly applicable to real-world crop\nmapping. Codes are available at:\nhttps://github.com/qinfengsama/Compressor-Based-Crop-Mapping.\n",
        "authors": "Wei Cheng; Hongrui Ye; Xiao Wen; Jiachen Zhang; Jiping Xu; Feifan Zhang",
        "status": 0,
        "relevancy": 0.3599758879307282,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17976",
        "date": "2024-05-28",
        "title": "Yuan 2.0-M32: Mixture of Experts with Attention Router",
        "abstract": "  Yuan 2.0-M32, with a similar base architecture as Yuan-2.0 2B, uses a\nmixture-of-experts architecture with 32 experts of which 2 experts are active.\nA new router network, Attention Router, is proposed and adopted for a more\nefficient selection of experts, which improves the accuracy compared to the\nmodel with classical router network. Yuan 2.0-M32 is trained with 2000B tokens\nfrom scratch, and the training computation consumption is only 9.25% of a dense\nmodel at the same parameter scale. Yuan 2.0-M32 demonstrates competitive\ncapability on coding, math, and various domains of expertise, with only 3.7B\nactive parameters of 40B in total, and 7.4 GFlops forward computation per\ntoken, both of which are only 1/19 of Llama3-70B. Yuan 2.0-M32 surpass\nLlama3-70B on MATH and ARC-Challenge benchmark, with accuracy of 55.89 and 95.8\nrespectively. The models and source codes of Yuan 2.0-M32 are released at\nGithub1.\n",
        "authors": "Shaohua Wu; Jiangang Luo; Xi Chen; Lingjun Li; Xudong Zhao; Tong Yu; Chao Wang; Yue Wang; Fei Wang; Weixu Qiao; Houbo He; Zeru Zhang; Zeyu Sun; Junxiong Mao; Chong Shen",
        "status": 0,
        "relevancy": 0.35573598707865905,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.19376",
        "date": "2024-05-28",
        "title": "PureEBM: Universal Poison Purification via Mid-Run Dynamics of\n  Energy-Based Models",
        "abstract": "  Data poisoning attacks pose a significant threat to the integrity of machine\nlearning models by leading to misclassification of target distribution test\ndata by injecting adversarial examples during training. Existing\nstate-of-the-art (SoTA) defense methods suffer from a variety of limitations,\nsuch as significantly reduced generalization performance, specificity to\nparticular attack types and classifiers, and significant overhead during\ntraining, making them impractical or limited for real-world applications. In\nresponse to this challenge, we introduce a universal data purification method\nthat defends naturally trained classifiers from malicious white-, gray-, and\nblack-box image poisons by applying a universal stochastic preprocessing step\n$\\Psi_{T}(x)$, realized by iterative Langevin sampling of a convergent Energy\nBased Model (EBM) initialized with an image $x.$ Mid-run dynamics of\n$\\Psi_{T}(x)$ purify poison information with minimal impact on features\nimportant to the generalization of a classifier network. We show that the\ncontrastive learning process of EBMs allows them to remain universal purifiers,\neven in the presence of poisoned EBM training data, and to achieve SoTA defense\non leading triggered poison Narcissus and triggerless poisons Gradient Matching\nand Bullseye Polytope. This work is a subset of a larger framework introduced\nin PureGen with a more detailed focus on EBM purification and poison defense.\n",
        "authors": "Omead Pooladzandi; Jeffrey Jiang; Sunay Bhat; Gregory Pottie",
        "status": 0,
        "relevancy": 0.35327272309902313,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18655",
        "date": "2024-05-28",
        "title": "CAVACHON: a hierarchical variational autoencoder to integrate\n  multi-modal single-cell data",
        "abstract": "  Paired single-cell sequencing technologies enable the simultaneous\nmeasurement of complementary modalities of molecular data at single-cell\nresolution. Along with the advances in these technologies, many methods based\non variational autoencoders have been developed to integrate these data.\nHowever, these methods do not explicitly incorporate prior biological\nrelationships between the data modalities, which could significantly enhance\nmodeling and interpretation. We propose a novel probabilistic learning\nframework that explicitly incorporates conditional independence relationships\nbetween multi-modal data as a directed acyclic graph using a generalized\nhierarchical variational autoencoder. We demonstrate the versatility of our\nframework across various applications pertinent to single-cell multi-omics data\nintegration. These include the isolation of common and distinct information\nfrom different modalities, modality-specific differential analysis, and\nintegrated cell clustering. We anticipate that the proposed framework can\nfacilitate the construction of highly flexible graphical models that can\ncapture the complexities of biological hypotheses and unravel the connections\nbetween different biological data types, such as different modalities of paired\nsingle-cell multi-omics data. The implementation of the proposed framework can\nbe found in the repository https://github.com/kuijjerlab/CAVACHON.\n",
        "authors": "Ping-Han Hsieh; Ru-Xiu Hsiao; Katalin Ferenc; Anthony Mathelier; Rebekka Burkholz; Chien-Yu Chen; Geir Kjetil Sandve; Tatiana Belova; Marieke Lydia Kuijjer",
        "status": 0,
        "relevancy": 0.35166433201430425,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18580",
        "date": "2024-05-28",
        "title": "Artificial Intelligence in Industry 4.0: A Review of Integration\n  Challenges for Industrial Systems",
        "abstract": "  In Industry 4.0, Cyber-Physical Systems (CPS) generate vast data sets that\ncan be leveraged by Artificial Intelligence (AI) for applications including\npredictive maintenance and production planning. However, despite the\ndemonstrated potential of AI, its widespread adoption in sectors like\nmanufacturing remains limited. Our comprehensive review of recent literature,\nincluding standards and reports, pinpoints key challenges: system integration,\ndata-related issues, managing workforce-related concerns and ensuring\ntrustworthy AI. A quantitative analysis highlights particular challenges and\ntopics that are important for practitioners but still need to be sufficiently\ninvestigated by academics. The paper briefly discusses existing solutions to\nthese challenges and proposes avenues for future research. We hope that this\nsurvey serves as a resource for practitioners evaluating the cost-benefit\nimplications of AI in CPS and for researchers aiming to address these urgent\nchallenges.\n",
        "authors": "Alexander Windmann; Philipp Wittenberg; Marvin Schieseck; Oliver Niggemann",
        "status": 0,
        "relevancy": 0.35158690085126376,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18320",
        "date": "2024-05-28",
        "title": "Self-Supervised Learning Based Handwriting Verification",
        "abstract": "  We present SSL-HV: Self-Supervised Learning approaches applied to the task of\nHandwriting Verification. This task involves determining whether a given pair\nof handwritten images originate from the same or different writer distribution.\nWe have compared the performance of multiple generative, contrastive SSL\napproaches against handcrafted feature extractors and supervised learning on\nCEDAR AND dataset. We show that ResNet based Variational Auto-Encoder (VAE)\noutperforms other generative approaches achieving 76.3% accuracy, while\nResNet-18 fine-tuned using Variance-Invariance-Covariance Regularization\n(VICReg) outperforms other contrastive approaches achieving 78% accuracy. Using\na pre-trained VAE and VICReg for the downstream task of writer verification we\nobserved a relative improvement in accuracy of 6.7% and 9% over ResNet-18\nsupervised baseline with 10% writer labels.\n",
        "authors": "Mihir Chauhan; Mohammad Abuzar Shaikh; Bina Ramamurthy; Mingchen Gao; Siwei Lyu; Sargur Srihari",
        "status": 0,
        "relevancy": 0.34925654159443875,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18246",
        "date": "2024-05-28",
        "title": "Utilitarian Algorithm Configuration for Infinite Parameter Spaces",
        "abstract": "  Utilitarian algorithm configuration is a general-purpose technique for\nautomatically searching the parameter space of a given algorithm to optimize\nits performance, as measured by a given utility function, on a given set of\ninputs. Recently introduced utilitarian configuration procedures offer\noptimality guarantees about the returned parameterization while provably\nadapting to the hardness of the underlying problem. However, the applicability\nof these approaches is severely limited by the fact that they only search a\nfinite, relatively small set of parameters. They cannot effectively search the\nconfiguration space of algorithms with continuous or uncountable parameters. In\nthis paper we introduce a new procedure, which we dub COUP (Continuous,\nOptimistic Utilitarian Procrastination). COUP is designed to search infinite\nparameter spaces efficiently to find good configurations quickly. Furthermore,\nCOUP maintains the theoretical benefits of previous utilitarian configuration\nprocedures when applied to finite parameter spaces but is significantly faster,\nboth provably and experimentally.\n",
        "authors": "Devon Graham; Kevin Leyton-Brown",
        "status": 0,
        "relevancy": 0.34869925130912893,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18492",
        "date": "2024-05-28",
        "title": "LLMs and Memorization: On Quality and Specificity of Copyright\n  Compliance",
        "abstract": "  Memorization in large language models (LLMs) is a growing concern. LLMs have\nbeen shown to easily reproduce parts of their training data, including\ncopyrighted work. This is an important problem to solve, as it may violate\nexisting copyright laws as well as the European AI Act. In this work, we\npropose a systematic analysis to quantify the extent of potential copyright\ninfringements in LLMs using European law as an example. Unlike previous work,\nwe evaluate instruction-finetuned models in a realistic end-user scenario. Our\nanalysis builds on a proposed threshold of 160 characters, which we borrow from\nthe German Copyright Service Provider Act and a fuzzy text matching algorithm\nto identify potentially copyright-infringing textual reproductions. The\nspecificity of countermeasures against copyright infringement is analyzed by\ncomparing model behavior on copyrighted and public domain data. We investigate\nwhat behaviors models show instead of producing protected text (such as refusal\nor hallucination) and provide a first legal assessment of these behaviors. We\nfind that there are huge differences in copyright compliance, specificity, and\nappropriate refusal among popular LLMs. Alpaca, GPT 4, GPT 3.5, and Luminous\nperform best in our comparison, with OpenGPT-X, Alpaca, and Luminous producing\na particularly low absolute number of potential copyright violations. Code will\nbe published soon.\n",
        "authors": "Felix B Mueller; Rebekka Görge; Anna K Bernzen; Janna C Pirk; Maximilian Poretschkin",
        "status": 0,
        "relevancy": 0.3367144131530433,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18548",
        "date": "2024-05-28",
        "title": "The Computational Complexity of Formal Reasoning for Encoder-Only\n  Transformers",
        "abstract": "  We investigate challenges and possibilities of formal reasoning for\nencoder-only transformers (EOT), meaning sound and complete methods for\nverifying or interpreting behaviour. In detail, we condense related formal\nreasoning tasks in the form of a naturally occurring satisfiability problem\n(SAT). We find that SAT is undecidable if we consider EOT, commonly considered\nin the expressiveness community. Furthermore, we identify practical scenarios\nwhere SAT is decidable and establish corresponding complexity bounds. Besides\ntrivial cases, we find that quantized EOT, namely those restricted by some\nfixed-width arithmetic, lead to the decidability of SAT due to their limited\nattention capabilities. However, the problem remains difficult, as we establish\nthose scenarios where SAT is NEXPTIME-hard and those where we can show that it\nis solvable in NEXPTIME for quantized EOT. To complement our theoretical\nresults, we put our findings and their implications in the overall perspective\nof formal reasoning.\n",
        "authors": "Marco Sälzer; Eric Alsmann; Martin Lange",
        "status": 0,
        "relevancy": 0.33240166909271296,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17802",
        "date": "2024-05-28",
        "title": "Multi-level Interaction Modeling for Protein Mutational Effect\n  Prediction",
        "abstract": "  Protein-protein interactions are central mediators in many biological\nprocesses. Accurately predicting the effects of mutations on interactions is\ncrucial for guiding the modulation of these interactions, thereby playing a\nsignificant role in therapeutic development and drug discovery. Mutations\ngenerally affect interactions hierarchically across three levels: mutated\nresidues exhibit different sidechain conformations, which lead to changes in\nthe backbone conformation, eventually affecting the binding affinity between\nproteins. However, existing methods typically focus only on sidechain-level\ninteraction modeling, resulting in suboptimal predictions. In this work, we\npropose a self-supervised multi-level pre-training framework, ProMIM, to fully\ncapture all three levels of interactions with well-designed pretraining\nobjectives. Experiments show ProMIM outperforms all the baselines on the\nstandard benchmark, especially on mutations where significant changes in\nbackbone conformations may occur. In addition, leading results from zero-shot\nevaluations for SARS-CoV-2 mutational effect prediction and antibody\noptimization underscore the potential of ProMIM as a powerful next-generation\ntool for developing novel therapeutic approaches and new drugs.\n",
        "authors": "Yuanle Mo; Xin Hong; Bowen Gao; Yinjun Jia; Yanyan Lan",
        "status": 0,
        "relevancy": 0.3319137877067708,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18172",
        "date": "2024-05-28",
        "title": "AnyFit: Controllable Virtual Try-on for Any Combination of Attire Across\n  Any Scenario",
        "abstract": "  While image-based virtual try-on has made significant strides, emerging\napproaches still fall short of delivering high-fidelity and robust fitting\nimages across various scenarios, as their models suffer from issues of\nill-fitted garment styles and quality degrading during the training process,\nnot to mention the lack of support for various combinations of attire.\nTherefore, we first propose a lightweight, scalable, operator known as Hydra\nBlock for attire combinations. This is achieved through a parallel attention\nmechanism that facilitates the feature injection of multiple garments from\nconditionally encoded branches into the main network. Secondly, to\nsignificantly enhance the model's robustness and expressiveness in real-world\nscenarios, we evolve its potential across diverse settings by synthesizing the\nresiduals of multiple models, as well as implementing a mask region boost\nstrategy to overcome the instability caused by information leakage in existing\nmodels. Equipped with the above design, AnyFit surpasses all baselines on\nhigh-resolution benchmarks and real-world data by a large gap, excelling in\nproducing well-fitting garments replete with photorealistic and rich details.\nFurthermore, AnyFit's impressive performance on high-fidelity virtual try-ons\nin any scenario from any image, paves a new path for future research within the\nfashion community.\n",
        "authors": "Yuhan Li; Hao Zhou; Wenxiang Shang; Ran Lin; Xuanhong Chen; Bingbing Ni",
        "status": 0,
        "relevancy": 0.3279623426657089,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17921",
        "date": "2024-05-28",
        "title": "Towards Clinical AI Fairness: Filling Gaps in the Puzzle",
        "abstract": "  The ethical integration of Artificial Intelligence (AI) in healthcare\nnecessitates addressing fairness-a concept that is highly context-specific\nacross medical fields. Extensive studies have been conducted to expand the\ntechnical components of AI fairness, while tremendous calls for AI fairness\nhave been raised from healthcare. Despite this, a significant disconnect\npersists between technical advancements and their practical clinical\napplications, resulting in a lack of contextualized discussion of AI fairness\nin clinical settings. Through a detailed evidence gap analysis, our review\nsystematically pinpoints several deficiencies concerning both healthcare data\nand the provided AI fairness solutions. We highlight the scarcity of research\non AI fairness in many medical domains where AI technology is increasingly\nutilized. Additionally, our analysis highlights a substantial reliance on group\nfairness, aiming to ensure equality among demographic groups from a macro\nhealthcare system perspective; in contrast, individual fairness, focusing on\nequity at a more granular level, is frequently overlooked. To bridge these\ngaps, our review advances actionable strategies for both the healthcare and AI\nresearch communities. Beyond applying existing AI fairness methods in\nhealthcare, we further emphasize the importance of involving healthcare\nprofessionals to refine AI fairness concepts and methods to ensure contextually\nrelevant and ethically sound AI applications in healthcare.\n",
        "authors": "Mingxuan Liu; Yilin Ning; Salinelat Teixayavong; Xiaoxuan Liu; Mayli Mertens; Yuqing Shang; Xin Li; Di Miao; Jie Xu; Daniel Shu Wei Ting; Lionel Tim-Ee Cheng; Jasmine Chiat Ling Ong; Zhen Ling Teo; Ting Fang Tan; Narrendar RaviChandran; Fei Wang; Leo Anthony Celi; Marcus Eng Hock Ong; Nan Liu",
        "status": 0,
        "relevancy": 0.32604417023489884,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18658",
        "date": "2024-05-28",
        "title": "D-CoRP: Differentiable Connectivity Refinement for Functional Brain\n  Networks",
        "abstract": "  Brain network is an important tool for understanding the brain, offering\ninsights for scientific research and clinical diagnosis. Existing models for\nbrain networks typically primarily focus on brain regions or overlook the\ncomplexity of brain connectivities. MRI-derived brain network data is commonly\nsusceptible to connectivity noise, underscoring the necessity of incorporating\nconnectivities into the modeling of brain networks. To address this gap, we\nintroduce a differentiable module for refining brain connectivity. We develop\nthe multivariate optimization based on information bottleneck theory to address\nthe complexity of the brain network and filter noisy or redundant connections.\nAlso, our method functions as a flexible plugin that is adaptable to most graph\nneural networks. Our extensive experimental results show that the proposed\nmethod can significantly improve the performance of various baseline models and\noutperform other state-of-the-art methods, indicating the effectiveness and\ngeneralizability of the proposed method in refining brain network connectivity.\nThe code will be released for public availability.\n",
        "authors": "Haoyu Hu; Hongrun Zhang; Chao Li",
        "status": 0,
        "relevancy": 0.32580228008524625,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18387",
        "date": "2024-05-28",
        "title": "A Review and Implementation of Object Detection Models and Optimizations\n  for Real-time Medical Mask Detection during the COVID-19 Pandemic",
        "abstract": "  Convolutional Neural Networks (CNN) are commonly used for the problem of\nobject detection thanks to their increased accuracy. Nevertheless, the\nperformance of CNN-based detection models is ambiguous when detection speed is\nconsidered. To the best of our knowledge, there has not been sufficient\nevaluation of the available methods in terms of the speed/accuracy trade-off in\nrelated literature. This work assesses the most fundamental object detection\nmodels on the Common Objects in Context (COCO) dataset with respect to this\ntrade-off, their memory consumption, and computational and storage cost. Next,\nwe select a highly efficient model called YOLOv5 to train on the topical and\nunexplored dataset of human faces with medical masks, the Properly-Wearing\nMasked Faces Dataset (PWMFD), and analyze the benefits of specific optimization\ntechniques for real-time medical mask detection: transfer learning, data\naugmentations, and a Squeeze-and-Excitation attention mechanism. Using our\nfindings in the context of the COVID-19 pandemic, we propose an optimized model\nbased on YOLOv5s using transfer learning for the detection of correctly and\nincorrectly worn medical masks that surpassed more than two times in speed (69\nframes per second) the state-of-the-art model SE-YOLOv3 on the PWMFD dataset\nwhile maintaining the same level of mean Average Precision (67%).\n",
        "authors": "Ioanna Gogou; Dimitrios Koutsomitropoulos",
        "status": 0,
        "relevancy": 0.32400493530131347,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18426",
        "date": "2024-05-28",
        "title": "GFlow: Recovering 4D World from Monocular Video",
        "abstract": "  Reconstructing 4D scenes from video inputs is a crucial yet challenging task.\nConventional methods usually rely on the assumptions of multi-view video\ninputs, known camera parameters, or static scenes, all of which are typically\nabsent under in-the-wild scenarios. In this paper, we relax all these\nconstraints and tackle a highly ambitious but practical task, which we termed\nas AnyV4D: we assume only one monocular video is available without any camera\nparameters as input, and we aim to recover the dynamic 4D world alongside the\ncamera poses. To this end, we introduce GFlow, a new framework that utilizes\nonly 2D priors (depth and optical flow) to lift a video (3D) to a 4D explicit\nrepresentation, entailing a flow of Gaussian splatting through space and time.\nGFlow first clusters the scene into still and moving parts, then applies a\nsequential optimization process that optimizes camera poses and the dynamics of\n3D Gaussian points based on 2D priors and scene clustering, ensuring fidelity\namong neighboring points and smooth movement across frames. Since dynamic\nscenes always introduce new content, we also propose a new pixel-wise\ndensification strategy for Gaussian points to integrate new visual content.\nMoreover, GFlow transcends the boundaries of mere 4D reconstruction; it also\nenables tracking of any points across frames without the need for prior\ntraining and segments moving objects from the scene in an unsupervised way.\nAdditionally, the camera poses of each frame can be derived from GFlow,\nallowing for rendering novel views of a video scene through changing camera\npose. By employing the explicit representation, we may readily conduct\nscene-level or object-level editing as desired, underscoring its versatility\nand power. Visit our project website at: https://littlepure2333.github.io/GFlow\n",
        "authors": "Shizun Wang; Xingyi Yang; Qiuhong Shen; Zhenxiang Jiang; Xinchao Wang",
        "status": 0,
        "relevancy": 0.3188414046306072,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18077",
        "date": "2024-05-28",
        "title": "Design Principles for Falsifiable, Replicable and Reproducible Empirical\n  ML Research",
        "abstract": "  Empirical research plays a fundamental role in the machine learning domain.\nAt the heart of impactful empirical research lies the development of clear\nresearch hypotheses, which then shape the design of experiments. The execution\nof experiments must be carried out with precision to ensure reliable results,\nfollowed by statistical analysis to interpret these outcomes. This process is\nkey to either supporting or refuting initial hypotheses. Despite its\nimportance, there is a high variability in research practices across the\nmachine learning community and no uniform understanding of quality criteria for\nempirical research. To address this gap, we propose a model for the empirical\nresearch process, accompanied by guidelines to uphold the validity of empirical\nresearch. By embracing these recommendations, greater consistency, enhanced\nreliability and increased impact can be achieved.\n",
        "authors": "Daniel Vranješ; Oliver Niggemann",
        "status": 0,
        "relevancy": 0.3180171849494975,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18627",
        "date": "2024-05-28",
        "title": "PureGen: Universal Data Purification for Train-Time Poison Defense via\n  Generative Model Dynamics",
        "abstract": "  Train-time data poisoning attacks threaten machine learning models by\nintroducing adversarial examples during training, leading to misclassification.\nCurrent defense methods often reduce generalization performance, are\nattack-specific, and impose significant training overhead. To address this, we\nintroduce a set of universal data purification methods using a stochastic\ntransform, $\\Psi(x)$, realized via iterative Langevin dynamics of Energy-Based\nModels (EBMs), Denoising Diffusion Probabilistic Models (DDPMs), or both. These\napproaches purify poisoned data with minimal impact on classifier\ngeneralization. Our specially trained EBMs and DDPMs provide state-of-the-art\ndefense against various attacks (including Narcissus, Bullseye Polytope,\nGradient Matching) on CIFAR-10, Tiny-ImageNet, and CINIC-10, without needing\nattack or classifier-specific information. We discuss performance trade-offs\nand show that our methods remain highly effective even with poisoned or\ndistributionally shifted generative model training data.\n",
        "authors": "Sunay Bhat; Jeffrey Jiang; Omead Pooladzandi; Alexander Branch; Gregory Pottie",
        "status": 0,
        "relevancy": 0.317629100171516,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18016",
        "date": "2024-05-28",
        "title": "On Creativity and Open-Endedness",
        "abstract": "  Artificial Life (ALife) as an interdisciplinary field draws inspiration and\ninfluence from a variety of perspectives. Scientific progress crucially\ndepends, then, on concerted efforts to invite cross-disciplinary dialogue. The\ngoal of this paper is to revitalize discussions of potential connections\nbetween the fields of Computational Creativity (CC) and ALife, focusing\nspecifically on the concept of Open-Endedness (OE); the primary goal of CC is\nto endow artificial systems with creativity, and ALife has dedicated much\nresearch effort into studying and synthesizing OE and artificial innovation.\nHowever, despite the close proximity of these concepts, their use so far\nremains confined to their respective communities, and their relationship is\nlargely unclear. We provide historical context for research in both domains,\nand review the limited work connecting research on creativity and OE\nexplicitly. We then highlight specific questions to be considered, with the\neventual goals of (i) decreasing conceptual ambiguity by highlighting\nsimilarities and differences between the concepts of OE, (ii) identifying\nsynergy effects of a research agenda that encompasses both OE and creativity,\nand (iii) establishing a dialogue between ALife and CC research.\n",
        "authors": "Lisa Soros; Alyssa Adams; Stefano Kalonaris; Olaf Witkowski; Christian Guckelsberger",
        "status": 0,
        "relevancy": 0.31665143342258717,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18427",
        "date": "2024-05-28",
        "title": "Classifying Overlapping Gaussian Mixtures in High Dimensions: From\n  Optimal Classifiers to Neural Nets",
        "abstract": "  We derive closed-form expressions for the Bayes optimal decision boundaries\nin binary classification of high dimensional overlapping Gaussian mixture model\n(GMM) data, and show how they depend on the eigenstructure of the class\ncovariances, for particularly interesting structured data. We empirically\ndemonstrate, through experiments on synthetic GMMs inspired by real-world data,\nthat deep neural networks trained for classification, learn predictors which\napproximate the derived optimal classifiers. We further extend our study to\nnetworks trained on authentic data, observing that decision thresholds\ncorrelate with the covariance eigenvectors rather than the eigenvalues,\nmirroring our GMM analysis. This provides theoretical insights regarding neural\nnetworks' ability to perform probabilistic inference and distill statistical\npatterns from intricate distributions.\n",
        "authors": "Khen Cohen; Noam Levi; Yaron Oz",
        "status": 0,
        "relevancy": 0.30853721631054176,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17839",
        "date": "2024-05-28",
        "title": "PeerFL: A Simulator for Peer-to-Peer Federated Learning at Scale",
        "abstract": "  This work integrates peer-to-peer federated learning tools with NS3, a widely\nused network simulator, to create a novel simulator designed to allow\nheterogeneous device experiments in federated learning. This cross-platform\nadaptability addresses a critical gap in existing simulation tools, enhancing\nthe overall utility and user experience. NS3 is leveraged to simulate WiFi\ndynamics to facilitate federated learning experiments with participants that\nmove around physically during training, leading to dynamic network\ncharacteristics. Our experiments showcase the simulator's efficiency in\ncomputational resource utilization at scale, with a maximum of 450\nheterogeneous devices modelled as participants in federated learning. This\npositions it as a valuable tool for simulation-based investigations in\npeer-to-peer federated learning. The framework is open source and available for\nuse and extension to the community.\n",
        "authors": "Alka Luqman; Shivanshu Shekhar; Anupam Chattopadhyay",
        "status": 0,
        "relevancy": 0.30535233545839,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18047",
        "date": "2024-05-28",
        "title": "2BP: 2-Stage Backpropagation",
        "abstract": "  As Deep Neural Networks (DNNs) grow in size and complexity, they often exceed\nthe memory capacity of a single accelerator, necessitating the sharding of\nmodel parameters across multiple accelerators. Pipeline parallelism is a\ncommonly used sharding strategy for training large DNNs. However, current\nimplementations of pipeline parallelism are being unintentionally bottlenecked\nby the automatic differentiation tools provided by ML frameworks. This paper\nintroduces 2-stage backpropagation (2BP). By splitting the backward propagation\nstep into two separate stages, we can reduce idle compute time. We tested 2BP\non various model architectures and pipelining schedules, achieving increases in\nthroughput in all cases. Using 2BP, we were able to achieve a 1.70x increase in\nthroughput compared to traditional methods when training a LLaMa-like\ntransformer with 7 billion parameters across 4 GPUs.\n",
        "authors": "Christopher Rae; Joseph K. L. Lee; James Richings",
        "status": 0,
        "relevancy": 0.3050124597543611,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18624",
        "date": "2024-05-28",
        "title": "Enhancing IoT Security with CNN and LSTM-Based Intrusion Detection\n  Systems",
        "abstract": "  Protecting Internet of things (IoT) devices against cyber attacks is\nimperative owing to inherent security vulnerabilities. These vulnerabilities\ncan include a spectrum of sophisticated attacks that pose significant damage to\nboth individuals and organizations. Employing robust security measures like\nintrusion detection systems (IDSs) is essential to solve these problems and\nprotect IoT systems from such attacks. In this context, our proposed IDS model\nconsists on a combination of convolutional neural network (CNN) and long\nshort-term memory (LSTM) deep learning (DL) models. This fusion facilitates the\ndetection and classification of IoT traffic into binary categories, benign and\nmalicious activities by leveraging the spatial feature extraction capabilities\nof CNN for pattern recognition and the sequential memory retention of LSTM for\ndiscerning complex temporal dependencies in achieving enhanced accuracy and\nefficiency. In assessing the performance of our proposed model, the authors\nemployed the new CICIoT2023 dataset for both training and final testing, while\nfurther validating the model's performance through a conclusive testing phase\nutilizing the CICIDS2017 dataset. Our proposed model achieves an accuracy rate\nof 98.42%, accompanied by a minimal loss of 0.0275. False positive rate(FPR) is\nequally important, reaching 9.17% with an F1-score of 98.57%. These results\ndemonstrate the effectiveness of our proposed CNN-LSTM IDS model in fortifying\nIoT environments against potential cyber threats.\n",
        "authors": "Afrah Gueriani; Hamza Kheddar; Ahmed Cherif Mazari",
        "status": 0,
        "relevancy": 0.2970899930717883,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18395",
        "date": "2024-05-28",
        "title": "MC-GTA: Metric-Constrained Model-Based Clustering using Goodness-of-fit\n  Tests with Autocorrelations",
        "abstract": "  A wide range of (multivariate) temporal (1D) and spatial (2D) data analysis\ntasks, such as grouping vehicle sensor trajectories, can be formulated as\nclustering with given metric constraints. Existing metric-constrained\nclustering algorithms overlook the rich correlation between feature similarity\nand metric distance, i.e., metric autocorrelation. The model-based variations\nof these clustering algorithms (e.g. TICC and STICC) achieve SOTA performance,\nyet suffer from computational instability and complexity by using a\nmetric-constrained Expectation-Maximization procedure. In order to address\nthese two problems, we propose a novel clustering algorithm, MC-GTA\n(Model-based Clustering via Goodness-of-fit Tests with Autocorrelations). Its\nobjective is only composed of pairwise weighted sums of feature similarity\nterms (square Wasserstein-2 distance) and metric autocorrelation terms (a novel\nmultivariate generalization of classic semivariogram). We show that MC-GTA is\neffectively minimizing the total hinge loss for intra-cluster observation pairs\nnot passing goodness-of-fit tests, i.e., statistically not originating from the\nsame distribution. Experiments on 1D/2D synthetic and real-world datasets\ndemonstrate that MC-GTA successfully incorporates metric autocorrelation. It\noutperforms strong baselines by large margins (up to 14.3% in ARI and 32.1% in\nNMI) with faster and stabler optimization (>10x speedup).\n",
        "authors": "Zhangyu Wang; Gengchen Mai; Krzysztof Janowicz; Ni Lao",
        "status": 0,
        "relevancy": 0.29563656452996523,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17873",
        "date": "2024-05-28",
        "title": "MixDQ: Memory-Efficient Few-Step Text-to-Image Diffusion Models with\n  Metric-Decoupled Mixed Precision Quantization",
        "abstract": "  Diffusion models have achieved significant visual generation quality.\nHowever, their significant computational and memory costs pose challenge for\ntheir application on resource-constrained mobile devices or even desktop GPUs.\nRecent few-step diffusion models reduces the inference time by reducing the\ndenoising steps. However, their memory consumptions are still excessive. The\nPost Training Quantization (PTQ) replaces high bit-width FP representation with\nlow-bit integer values (INT4/8) , which is an effective and efficient technique\nto reduce the memory cost. However, when applying to few-step diffusion models,\nexisting quantization methods face challenges in preserving both the image\nquality and text alignment. To address this issue, we propose an\nmixed-precision quantization framework - MixDQ. Firstly, We design specialized\nBOS-aware quantization method for highly sensitive text embedding quantization.\nThen, we conduct metric-decoupled sensitivity analysis to measure the\nsensitivity of each layer. Finally, we develop an integer-programming-based\nmethod to conduct bit-width allocation. While existing quantization methods\nfall short at W8A8, MixDQ could achieve W8A8 without performance loss, and W4A8\nwith negligible visual degradation. Compared with FP16, we achieve 3-4x\nreduction in model size and memory cost, and 1.45x latency speedup.\n",
        "authors": "Tianchen Zhao; Xuefei Ning; Tongcheng Fang; Enshu Liu; Guyue Huang; Zinan Lin; Shengen Yan; Guohao Dai; Yu Wang",
        "status": 0,
        "relevancy": 0.295624977623422,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17750",
        "date": "2024-05-28",
        "title": "Magnitude-based Neuron Pruning for Backdoor Defens",
        "abstract": "  Deep Neural Networks (DNNs) are known to be vulnerable to backdoor attacks,\nposing concerning threats to their reliable deployment. Recent research reveals\nthat backdoors can be erased from infected DNNs by pruning a specific group of\nneurons, while how to effectively identify and remove these backdoor-associated\nneurons remains an open challenge. In this paper, we investigate the\ncorrelation between backdoor behavior and neuron magnitude, and find that\nbackdoor neurons deviate from the magnitude-saliency correlation of the model.\nThe deviation inspires us to propose a Magnitude-based Neuron Pruning (MNP)\nmethod to detect and prune backdoor neurons. Specifically, MNP uses three\nmagnitude-guided objective functions to manipulate the magnitude-saliency\ncorrelation of backdoor neurons, thus achieving the purpose of exposing\nbackdoor behavior, eliminating backdoor neurons and preserving clean neurons,\nrespectively. Experiments show our pruning strategy achieves state-of-the-art\nbackdoor defense performance against a variety of backdoor attacks with a\nlimited amount of clean data, demonstrating the crucial role of magnitude for\nguiding backdoor defenses.\n",
        "authors": "Nan Li; Haoyu Jiang; Ping Yi",
        "status": 0,
        "relevancy": 0.2891580497427574,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18459",
        "date": "2024-05-28",
        "title": "Probing the Information Theoretical Roots of Spatial Dependence Measures",
        "abstract": "  Intuitively, there is a relation between measures of spatial dependence and\ninformation theoretical measures of entropy. For instance, we can provide an\nintuition of why spatial data is special by stating that, on average, spatial\ndata samples contain less than expected information. Similarly, spatial data,\ne.g., remotely sensed imagery, that is easy to compress is also likely to show\nsignificant spatial autocorrelation. Formulating our (highly specific) core\nconcepts of spatial information theory in the widely used language of\ninformation theory opens new perspectives on their differences and similarities\nand also fosters cross-disciplinary collaboration, e.g., with the broader AI/ML\ncommunities. Interestingly, however, this intuitive relation is challenging to\nformalize and generalize, leading prior work to rely mostly on experimental\nresults, e.g., for describing landscape patterns. In this work, we will explore\nthe information theoretical roots of spatial autocorrelation, more specifically\nMoran's I, through the lens of self-information (also known as surprisal) and\nprovide both formal proofs and experiments.\n",
        "authors": "Zhangyu Wang; Krzysztof Janowicz; Gengchen Mai; Ivan Majic",
        "status": 0,
        "relevancy": 0.2801216544419354,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18144",
        "date": "2024-05-28",
        "title": "4-bit Shampoo for Memory-Efficient Network Training",
        "abstract": "  Second-order optimizers, maintaining a matrix termed a preconditioner, are\nsuperior to first-order optimizers in both theory and practice. The states\nforming the preconditioner and its inverse root restrict the maximum size of\nmodels trained by second-order optimizers. To address this, compressing 32-bit\noptimizer states to lower bitwidths has shown promise in reducing memory usage.\nHowever, current approaches only pertain to first-order optimizers. In this\npaper, we propose the first 4-bit second-order optimizers, exemplified by 4-bit\nShampoo, maintaining performance similar to that of 32-bit ones. We show that\nquantizing the eigenvector matrix of the preconditioner in 4-bit Shampoo is\nremarkably better than quantizing the preconditioner itself both theoretically\nand experimentally. By rectifying the orthogonality of the quantized\neigenvector matrix, we enhance the approximation of the preconditioner's\neigenvector matrix, which also benefits the computation of its inverse 4-th\nroot. Besides, we find that linear square quantization slightly outperforms\ndynamic tree quantization when quantizing second-order optimizer states.\nEvaluation on various networks for image classification demonstrates that our\n4-bit Shampoo achieves comparable test accuracy to its 32-bit counterpart while\nbeing more memory-efficient. The source code will be made available.\n",
        "authors": "Sike Wang; Jia Li; Pan Zhou; Hua Huang",
        "status": 0,
        "relevancy": 0.2794414385924491,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17901",
        "date": "2024-05-28",
        "title": "Near-Infrared and Low-Rank Adaptation of Vision Transformers in Remote\n  Sensing",
        "abstract": "  Plant health can be monitored dynamically using multispectral sensors that\nmeasure Near-Infrared reflectance (NIR). Despite this potential, obtaining and\nannotating high-resolution NIR images poses a significant challenge for\ntraining deep neural networks. Typically, large networks pre-trained on the RGB\ndomain are utilized to fine-tune infrared images. This practice introduces a\ndomain shift issue because of the differing visual traits between RGB and NIR\nimages.As an alternative to fine-tuning, a method called low-rank adaptation\n(LoRA) enables more efficient training by optimizing rank-decomposition\nmatrices while keeping the original network weights frozen. However, existing\nparameter-efficient adaptation strategies for remote sensing images focus on\nRGB images and overlook domain shift issues in the NIR domain. Therefore, this\nstudy investigates the potential benefits of using vision transformer (ViT)\nbackbones pre-trained in the RGB domain, with low-rank adaptation for\ndownstream tasks in the NIR domain. Extensive experiments demonstrate that\nemploying LoRA with pre-trained ViT backbones yields the best performance for\ndownstream tasks applied to NIR images.\n",
        "authors": "Irem Ulku; O. Ozgur Tanriover; Erdem Akagündüz",
        "status": 0,
        "relevancy": 0.27293085219579494,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18471",
        "date": "2024-05-28",
        "title": "Symbolic Regression for Beyond the Standard Model Physics",
        "abstract": "  We propose symbolic regression as a powerful tool for studying Beyond the\nStandard Model physics. As a benchmark model, we consider the so-called\nConstrained Minimal Supersymmetric Standard Model, which has a four-dimensional\nparameter space defined at the GUT scale. We provide a set of analytical\nexpressions that reproduce three low-energy observables of interest in terms of\nthe parameters of the theory: the Higgs mass, the contribution to the anomalous\nmagnetic moment of the muon, and the cold dark matter relic density. To\ndemonstrate the power of the approach, we employ the symbolic expressions in a\nglobal fits analysis to derive the posterior probability densities of the\nparameters, which are obtained extremely rapidly in comparison with\nconventional methods.\n",
        "authors": "Shehu AbdusSalam; Steve Abel; Miguel Crispim Romao",
        "status": 0,
        "relevancy": 0.23516579085256617,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.17905",
        "date": "2024-05-28",
        "title": "Cycle-YOLO: A Efficient and Robust Framework for Pavement Damage\n  Detection",
        "abstract": "  With the development of modern society, traffic volume continues to increase\nin most countries worldwide, leading to an increase in the rate of pavement\ndamage Therefore, the real-time and highly accurate pavement damage detection\nand maintenance have become the current need. In this paper, an enhanced\npavement damage detection method with CycleGAN and improved YOLOv5 algorithm is\npresented. We selected 7644 self-collected images of pavement damage samples as\nthe initial dataset and augmented it by CycleGAN. Due to a substantial\ndifference between the images generated by CycleGAN and real road images, we\nproposed a data enhancement method based on an improved Scharr filter,\nCycleGAN, and Laplacian pyramid. To improve the target recognition effect on a\ncomplex background and solve the problem that the spatial pyramid pooling-fast\nmodule in the YOLOv5 network cannot handle multiscale targets, we introduced\nthe convolutional block attention module attention mechanism and proposed the\natrous spatial pyramid pooling with squeeze-and-excitation structure. In\naddition, we optimized the loss function of YOLOv5 by replacing the CIoU with\nEIoU. The experimental results showed that our algorithm achieved a precision\nof 0.872, recall of 0.854, and mean average precision@0.5 of 0.882 in detecting\nthree main types of pavement damage: cracks, potholes, and patching. On the\nGPU, its frames per second reached 68, meeting the requirements for real-time\ndetection. Its overall performance even exceeded the current more advanced\nYOLOv7 and achieved good results in practical applications, providing a basis\nfor decision-making in pavement damage detection and prevention.\n",
        "authors": "Zhengji Li; Xi Xiao; Jiacheng Xie; Yuxiao Fan; Wentao Wang; Gang Chen; Liqiang Zhang; Tianyang Wang",
        "status": 0,
        "relevancy": 0.23485695375499982,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18299",
        "date": "2024-05-28",
        "title": "Deep Learning Innovations for Underwater Waste Detection: An In-Depth\n  Analysis",
        "abstract": "  Addressing the issue of submerged underwater trash is crucial for\nsafeguarding aquatic ecosystems and preserving marine life. While identifying\ndebris present on the surface of water bodies is straightforward, assessing the\nunderwater submerged waste is a challenge due to the image distortions caused\nby factors such as light refraction, absorption, suspended particles, color\nshifts, and occlusion. This paper conducts a comprehensive review of\nstate-of-the-art architectures and on the existing datasets to establish a\nbaseline for submerged waste and trash detection. The primary goal remains to\nestablish the benchmark of the object localization techniques to be leveraged\nby advanced underwater sensors and autonomous underwater vehicles. The ultimate\nobjective is to explore the underwater environment, to identify, and remove\nunderwater debris. The absence of benchmarks (dataset or algorithm) in many\nresearches emphasizes the need for a more robust algorithmic solution. Through\nthis research, we aim to give performance comparative analysis of various\nunderwater trash detection algorithms.\n",
        "authors": "Jaskaran Singh Walia; Pavithra L K",
        "status": 0,
        "relevancy": 0.20318523813863398,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      },
      {
        "id": "2405.18383",
        "date": "2024-05-28",
        "title": "Brain Tumor Segmentation (BraTS) Challenge 2024: Meningioma Radiotherapy\n  Planning Automated Segmentation",
        "abstract": "  The 2024 Brain Tumor Segmentation Meningioma Radiotherapy (BraTS-MEN-RT)\nchallenge aims to advance automated segmentation algorithms using the largest\nknown multi-institutional dataset of radiotherapy planning brain MRIs with\nexpert-annotated target labels for patients with intact or post-operative\nmeningioma that underwent either conventional external beam radiotherapy or\nstereotactic radiosurgery. Each case includes a defaced 3D post-contrast\nT1-weighted radiotherapy planning MRI in its native acquisition space,\naccompanied by a single-label \"target volume\" representing the gross tumor\nvolume (GTV) and any at-risk post-operative site. Target volume annotations\nadhere to established radiotherapy planning protocols, ensuring consistency\nacross cases and institutions. For pre-operative meningiomas, the target volume\nencompasses the entire GTV and associated nodular dural tail, while for\npost-operative cases, it includes at-risk resection cavity margins as\ndetermined by the treating institution. Case annotations were reviewed and\napproved by expert neuroradiologists and radiation oncologists. Participating\nteams will develop, containerize, and evaluate automated segmentation models\nusing this comprehensive dataset. Model performance will be assessed using the\nlesion-wise Dice Similarity Coefficient and the 95% Hausdorff distance. The\ntop-performing teams will be recognized at the Medical Image Computing and\nComputer Assisted Intervention Conference in October 2024. BraTS-MEN-RT is\nexpected to significantly advance automated radiotherapy planning by enabling\nprecise tumor segmentation and facilitating tailored treatment, ultimately\nimproving patient outcomes.\n",
        "authors": "Dominic LaBella; Katherine Schumacher; Michael Mix; Kevin Leu; Shan McBurney-Lin; Pierre Nedelec; Javier Villanueva-Meyer; Jonathan Shapey; Tom Vercauteren; Kazumi Chia; Omar Al-Salihi; Justin Leu; Lia Halasz; Yury Velichko; Chunhao Wang; John Kirkpatrick; Scott Floyd; Zachary J. Reitman; Trey Mullikin; Ulas Bagci; Sean Sachdev; Jona A. Hattangadi-Gluth; Tyler Seibert; Nikdokht Farid; Connor Puett; Matthew W. Pease; Kevin Shiue; Syed Muhammad Anwar; Shahriar Faghani; Muhammad Ammar Haider; Pranav Warman; Jake Albrecht; András Jakab; Mana Moassefi; Verena Chung; Alejandro Aristizabal; Alexandros Karargyris; Hasan Kassem; Sarthak Pati; Micah Sheller; Christina Huang; Aaron Coley; Siddharth Ghanta; Alex Schneider; Conrad Sharp; Rachit Saluja; Florian Kofler; Philipp Lohmann; Phillipp Vollmuth; Louis Gagnon; Maruf Adewole; Hongwei Bran Li; Anahita Fathi Kazerooni; Nourel Hoda Tahon; Udunna Anazodo; Ahmed W. Moawad; Bjoern Menze; Marius George Linguraru; Mariam Aboian; Benedikt Wiestler; Ujjwal Baid; Gian-Marco Conte; Andreas M. T. Rauschecker; Ayman Nada; Aly H. Abayazeed; Raymond Huang; Maria Correia de Verdier; Jeffrey D. Rudie; Spyridon Bakas; Evan Calabrese",
        "status": 0,
        "relevancy": 0.20103659886064773,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:45.387Z",
        "updatedAt": "2024-05-31T04:51:45.387Z",
        "DatesTable": {
          "value": "2024-05-28",
          "status": "complete",
          "count": 161,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:45.389Z"
        }
      }
    ]
  },
  {
    "date": {
      "value": "2024-05-27",
      "status": "complete",
      "count": 126,
      "createdAt": "2024-05-31 00:09:48.114 +00:00",
      "updatedAt": "2024-05-31 04:51:34.031 +00:00"
    },
    "papers": [
      {
        "id": "2405.17249",
        "date": "2024-05-27",
        "title": "Assessing LLMs Suitability for Knowledge Graph Completion",
        "abstract": "  Recent work shown the capability of Large Language Models (LLMs) to solve\ntasks related to Knowledge Graphs, such as Knowledge Graph Completion, even in\nZero- or Few-Shot paradigms. However, they are known to hallucinate answers, or\noutput results in a non-deterministic manner, thus leading to wrongly reasoned\nresponses, even if they satisfy the user's demands. To highlight opportunities\nand challenges in knowledge graphs-related tasks, we experiment with two\ndistinguished LLMs, namely Mixtral-8x7B-Instruct-v0.1, and gpt-3.5-turbo-0125,\non Knowledge Graph Completion for static knowledge graphs, using prompts\nconstructed following the TELeR taxonomy, in Zero- and One-Shot contexts, on a\nTask-Oriented Dialogue system use case. When evaluated using both strict and\nflexible metrics measurement manners, our results show that LLMs could be fit\nfor such a task if prompts encapsulate sufficient information and relevant\nexamples.\n",
        "authors": "Vasile Ionut Remus Iga; Gheorghe Cosmin Silaghi",
        "status": 0,
        "relevancy": 0.6344067106470423,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16869",
        "date": "2024-05-27",
        "title": "Mixture of Modality Knowledge Experts for Robust Multi-modal Knowledge\n  Graph Completion",
        "abstract": "  Multi-modal knowledge graph completion (MMKGC) aims to automatically discover\nnew knowledge triples in the given multi-modal knowledge graphs (MMKGs), which\nis achieved by collaborative modeling the structural information concealed in\nmassive triples and the multi-modal features of the entities. Existing methods\ntend to focus on crafting elegant entity-wise multi-modal fusion strategies,\nyet they overlook the utilization of multi-perspective features concealed\nwithin the modalities under diverse relational contexts. To address this issue,\nwe introduce a novel MMKGC framework with Mixture of Modality Knowledge experts\n(MoMoK for short) to learn adaptive multi-modal embedding under intricate\nrelational contexts. We design relation-guided modality knowledge experts to\nacquire relation-aware modality embeddings and integrate the predictions from\nmulti-modalities to achieve comprehensive decisions. Additionally, we\ndisentangle the experts by minimizing their mutual information. Experiments on\nfour public MMKG benchmarks demonstrate the outstanding performance of MoMoK\nunder complex scenarios.\n",
        "authors": "Yichi Zhang; Zhuo Chen; Lingbing Guo; Yajing Xu; Binbin Hu; Ziqi Liu; Wen Zhang; Huajun Chen",
        "status": 0,
        "relevancy": 0.6146425764128003,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:52:11.665Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16929",
        "date": "2024-05-27",
        "title": "Uncertainty Management in the Construction of Knowledge Graphs: a Survey",
        "abstract": "  Knowledge Graphs (KGs) are a major asset for companies thanks to their great\nflexibility in data representation and their numerous applications, e.g.,\nvocabulary sharing, Q/A or recommendation systems. To build a KG it is a common\npractice to rely on automatic methods for extracting knowledge from various\nheterogeneous sources. But in a noisy and uncertain world, knowledge may not be\nreliable and conflicts between data sources may occur. Integrating unreliable\ndata would directly impact the use of the KG, therefore such conflicts must be\nresolved. This could be done manually by selecting the best data to integrate.\nThis first approach is highly accurate, but costly and time-consuming. That is\nwhy recent efforts focus on automatic approaches, which represents a\nchallenging task since it requires handling the uncertainty of extracted\nknowledge throughout its integration into the KG. We survey state-of-the-art\napproaches in this direction and present constructions of both open and\nenterprise KGs and how their quality is maintained. We then describe different\nknowledge extraction methods, introducing additional uncertainty. We also\ndiscuss downstream tasks after knowledge acquisition, including KG completion\nusing embedding models, knowledge alignment, and knowledge fusion in order to\naddress the problem of knowledge uncertainty in KG construction. We conclude\nwith a discussion on the remaining challenges and perspectives when\nconstructing a KG taking into account uncertainty.\n",
        "authors": "Lucas Jarnac; Yoan Chabot; Miguel Couceiro",
        "status": 0,
        "relevancy": 0.6016545632942065,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17243",
        "date": "2024-05-27",
        "title": "Surprise-Adaptive Intrinsic Motivation for Unsupervised Reinforcement\n  Learning",
        "abstract": "  Both entropy-minimizing and entropy-maximizing (curiosity) objectives for\nunsupervised reinforcement learning (RL) have been shown to be effective in\ndifferent environments, depending on the environment's level of natural\nentropy. However, neither method alone results in an agent that will\nconsistently learn intelligent behavior across environments. In an effort to\nfind a single entropy-based method that will encourage emergent behaviors in\nany environment, we propose an agent that can adapt its objective online,\ndepending on the entropy conditions by framing the choice as a multi-armed\nbandit problem. We devise a novel intrinsic feedback signal for the bandit,\nwhich captures the agent's ability to control the entropy in its environment.\nWe demonstrate that such agents can learn to control entropy and exhibit\nemergent behaviors in both high- and low-entropy regimes and can learn skillful\nbehaviors in benchmark tasks. Videos of the trained agents and summarized\nfindings can be found on our project page\nhttps://sites.google.com/view/surprise-adaptive-agents\n",
        "authors": "Adriana Hugessen; Roger Creus Castanyer; Faisal Mohamed; Glen Berseth",
        "status": 0,
        "relevancy": 0.5958386501330759,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17337",
        "date": "2024-05-27",
        "title": "Cost-efficient Knowledge-based Question Answering with Large Language\n  Models",
        "abstract": "  Knowledge-based question answering (KBQA) is widely used in many scenarios\nthat necessitate domain knowledge. Large language models (LLMs) bring\nopportunities to KBQA, while their costs are significantly higher and absence\nof domain-specific knowledge during pre-training. We are motivated to combine\nLLMs and prior small models on knowledge graphs (KGMs) for both inferential\naccuracy and cost saving. However, it remains challenging since accuracy and\ncost are not readily combined in the optimization as two distinct metrics. It\nis also laborious for model selection since different models excel in diverse\nknowledge. To this end, we propose Coke, a novel cost-efficient strategy for\nKBQA with LLMs, modeled as a tailored multi-armed bandit problem to minimize\ncalls to LLMs within limited budgets. We first formulate the accuracy\nexpectation with a cluster-level Thompson Sampling for either KGMs or LLMs. A\ncontext-aware policy is optimized to further distinguish the expert model\nsubject to the question semantics. The overall decision is bounded by the cost\nregret according to historical expenditure on failures. Extensive experiments\nshowcase the superior performance of Coke, which moves the Pareto frontier with\nup to 20.89% saving of GPT-4 fees while achieving a 2.74% higher accuracy on\nthe benchmark datasets.\n",
        "authors": "Junnan Dong; Qinggang Zhang; Chuang Zhou; Hao Chen; Daochen Zha; Xiao Huang",
        "status": 0,
        "relevancy": 0.5892430830592176,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17346",
        "date": "2024-05-27",
        "title": "Prompt Optimization with Human Feedback",
        "abstract": "  Large language models (LLMs) have demonstrated remarkable performances in\nvarious tasks. However, the performance of LLMs heavily depends on the input\nprompt, which has given rise to a number of recent works on prompt\noptimization. However, previous works often require the availability of a\nnumeric score to assess the quality of every prompt. Unfortunately, when a\nhuman user interacts with a black-box LLM, attaining such a score is often\ninfeasible and unreliable. Instead, it is usually significantly easier and more\nreliable to obtain preference feedback from a human user, i.e., showing the\nuser the responses generated from a pair of prompts and asking the user which\none is preferred. Therefore, in this paper, we study the problem of prompt\noptimization with human feedback (POHF), in which we aim to optimize the prompt\nfor a black-box LLM using only human preference feedback. Drawing inspiration\nfrom dueling bandits, we design a theoretically principled strategy to select a\npair of prompts to query for preference feedback in every iteration, and hence\nintroduce our algorithm named automated POHF (APOHF). We apply our APOHF\nalgorithm to various tasks, including optimizing user instructions, prompt\noptimization for text-to-image generative models, and response optimization\nwith human feedback (i.e., further refining the response using a variant of our\nAPOHF). The results demonstrate that our APOHF can efficiently find a good\nprompt using a small number of preference feedback instances. Our code can be\nfound at \\url{https://github.com/xqlin98/APOHF}.\n",
        "authors": "Xiaoqiang Lin; Zhongxiang Dai; Arun Verma; See-Kiong Ng; Patrick Jaillet; Bryan Kian Hsiang Low",
        "status": 0,
        "relevancy": 0.580458580367271,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17386",
        "date": "2024-05-27",
        "title": "MindMerger: Efficient Boosting LLM Reasoning in non-English Languages",
        "abstract": "  Reasoning capabilities are crucial for Large Language Models (LLMs), yet a\nnotable gap exists between English and non-English languages. To bridge this\ndisparity, some works fine-tune LLMs to relearn reasoning capabilities in\nnon-English languages, while others replace non-English inputs with an external\nmodel's outputs such as English translation text to circumvent the challenge of\nLLM understanding non-English. Unfortunately, these methods often underutilize\nthe built-in skilled reasoning and useful language understanding capabilities\nof LLMs. In order to better utilize the minds of reasoning and language\nunderstanding in LLMs, we propose a new method, namely MindMerger, which merges\nLLMs with the external language understanding capabilities from multilingual\nmodels to boost the multilingual reasoning performance. Furthermore, a two-step\ntraining scheme is introduced to first train to embeded the external\ncapabilities into LLMs and then train the collaborative utilization of the\nexternal capabilities and the built-in capabilities in LLMs. Experiments on\nthree multilingual reasoning datasets and a language understanding dataset\ndemonstrate that MindMerger consistently outperforms all baselines, especially\nin low-resource languages. Without updating the parameters of LLMs, the average\naccuracy improved by 6.7% and 8.0% across all languages and low-resource\nlanguages on the MGSM dataset, respectively.\n",
        "authors": "Zixian Huang; Wenhao Zhu; Gong Cheng; Lei Li; Fei Yuan",
        "status": 0,
        "relevancy": 0.5775147839163675,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16751",
        "date": "2024-05-27",
        "title": "LLM-Based Cooperative Agents using Information Relevance and Plan\n  Validation",
        "abstract": "  We address the challenge of multi-agent cooperation, where agents achieve a\ncommon goal by interacting with a 3D scene and cooperating with decentralized\nagents under complex partial observations. This involves managing communication\ncosts and optimizing interaction trajectories in dynamic environments. Our\nresearch focuses on three primary limitations of existing cooperative agent\nsystems. Firstly, current systems demonstrate inefficiency in managing acquired\ninformation through observation, resulting in declining planning performance as\nthe environment becomes more complex with additional objects or goals.\nSecondly, the neglect of false plans in partially observable settings leads to\nsuboptimal cooperative performance, as agents struggle to adapt to\nenvironmental changes influenced by the unseen actions of other agents. Lastly,\nthe failure to incorporate spatial data into decision-making processes\nrestricts the agent's ability to construct optimized trajectories. To overcome\nthese limitations, we propose the RElevance and Validation-Enhanced Cooperative\nLanguage Agent (REVECA), a novel cognitive architecture powered by GPT-3.5.\nREVECA leverages relevance assessment, plan validation, and spatial information\nto enhance the efficiency and robustness of agent cooperation in dynamic and\npartially observable environments while minimizing continuous communication\ncosts and effectively managing irrelevant dummy objects. Our extensive\nexperiments demonstrate the superiority of REVECA over previous approaches,\nincluding those driven by GPT-4.0. Additionally, a user study highlights\nREVECA's potential for achieving trustworthy human-AI cooperation. We expect\nthat REVECA will have significant applications in gaming, XR applications,\neducational tools, and humanoid robots, contributing to substantial economic,\ncommercial, and academic advancements.\n",
        "authors": "SeungWon Seo; Junhyeok Lee; SeongRae Noh; HyeongYeop Kang",
        "status": 0,
        "relevancy": 0.5720936333177186,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16919",
        "date": "2024-05-27",
        "title": "VoCoT: Unleashing Visually Grounded Multi-Step Reasoning in Large\n  Multi-Modal Models",
        "abstract": "  While large multi-modal models (LMMs) have exhibited impressive capabilities\nacross diverse tasks, their effectiveness in handling complex tasks has been\nlimited by the prevailing single-step reasoning paradigm. To this end, this\npaper proposes VoCoT, a multi-step Visually grounded object-centric\nChain-of-Thought reasoning framework tailored for inference with LMMs. VoCoT is\ncharacterized by two key features: (1) object-centric reasoning paths that\nrevolve around cross-modal shared object-level information, and (2) visually\ngrounded representation of object concepts in a multi-modal interleaved and\naligned manner, which effectively bridges the modality gap within LMMs during\nlong-term generation. Additionally, we construct an instruction dataset to\nfacilitate LMMs in adapting to reasoning with VoCoT. By introducing VoCoT into\nthe prevalent open-source LMM architecture, we introduce VolCano. With only 7B\nparameters and limited input resolution, VolCano demonstrates excellent\nperformance across various scenarios, surpassing SOTA models, including GPT-4V,\nin tasks requiring complex reasoning. Our code, data and model will be\navailable at https://github.com/RupertLuo/VoCoT.\n",
        "authors": "Zejun Li; Ruipu Luo; Jiwen Zhang; Minghui Qiu; Zhongyu Wei",
        "status": 0,
        "relevancy": 0.5701995442935639,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17009",
        "date": "2024-05-27",
        "title": "Position: Foundation Agents as the Paradigm Shift for Decision Making",
        "abstract": "  Decision making demands intricate interplay between perception, memory, and\nreasoning to discern optimal policies. Conventional approaches to decision\nmaking face challenges related to low sample efficiency and poor\ngeneralization. In contrast, foundation models in language and vision have\nshowcased rapid adaptation to diverse new tasks. Therefore, we advocate for the\nconstruction of foundation agents as a transformative shift in the learning\nparadigm of agents. This proposal is underpinned by the formulation of\nfoundation agents with their fundamental characteristics and challenges\nmotivated by the success of large language models (LLMs). Moreover, we specify\nthe roadmap of foundation agents from large interactive data collection or\ngeneration, to self-supervised pretraining and adaptation, and knowledge and\nvalue alignment with LLMs. Lastly, we pinpoint critical research questions\nderived from the formulation and delineate trends for foundation agents\nsupported by real-world use cases, addressing both technical and theoretical\naspects to propel the field towards a more comprehensive and impactful future.\n",
        "authors": "Xiaoqian Liu; Xingzhou Lou; Jianbin Jiao; Junge Zhang",
        "status": 0,
        "relevancy": 0.5700282258642639,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16806",
        "date": "2024-05-27",
        "title": "Entity Alignment with Noisy Annotations from Large Language Models",
        "abstract": "  Entity alignment (EA) aims to merge two knowledge graphs (KGs) by identifying\nequivalent entity pairs. While existing methods heavily rely on human-generated\nlabels, it is prohibitively expensive to incorporate cross-domain experts for\nannotation in real-world scenarios. The advent of Large Language Models (LLMs)\npresents new avenues for automating EA with annotations, inspired by their\ncomprehensive capability to process semantic information. However, it is\nnontrivial to directly apply LLMs for EA since the annotation space in\nreal-world KGs is large. LLMs could also generate noisy labels that may mislead\nthe alignment. To this end, we propose a unified framework, LLM4EA, to\neffectively leverage LLMs for EA. Specifically, we design a novel active\nlearning policy to significantly reduce the annotation space by prioritizing\nthe most valuable entities based on the entire inter-KG and intra-KG structure.\nMoreover, we introduce an unsupervised label refiner to continuously enhance\nlabel accuracy through in-depth probabilistic reasoning. We iteratively\noptimize the policy based on the feedback from a base EA model. Extensive\nexperiments demonstrate the advantages of LLM4EA on four benchmark datasets in\nterms of effectiveness, robustness, and efficiency. Codes are available via\nhttps://github.com/chensyCN/llm4ea_official.\n",
        "authors": "Shengyuan Chen; Qinggang Zhang; Junnan Dong; Wen Hua; Qing Li; Xiao Huang",
        "status": 0,
        "relevancy": 0.5614687806599702,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17428",
        "date": "2024-05-27",
        "title": "NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding\n  Models",
        "abstract": "  Decoder-only large language model (LLM)-based embedding models are beginning\nto outperform BERT or T5-based embedding models in general-purpose text\nembedding tasks, including dense vector-based retrieval. In this work, we\nintroduce the NV-Embed model with a variety of architectural designs and\ntraining procedures to significantly enhance the performance of LLM as a\nversatile embedding model, while maintaining its simplicity and\nreproducibility. For model architecture, we propose a latent attention layer to\nobtain pooled embeddings, which consistently improves retrieval and downstream\ntask accuracy compared to mean pooling or using the last <EOS> token embedding\nfrom LLMs. To enhance representation learning, we remove the causal attention\nmask of LLMs during contrastive training. For model training, we introduce a\ntwo-stage contrastive instruction-tuning method. It first applies contrastive\ntraining with instructions on retrieval datasets, utilizing in-batch negatives\nand curated hard negative examples. At stage-2, it blends various non-retrieval\ndatasets into instruction tuning, which not only enhances non-retrieval task\naccuracy but also improves retrieval performance. Combining these techniques,\nour NV-Embed model, using only publicly available data, has achieved a\nrecord-high score of 69.32, ranking No. 1 on the Massive Text Embedding\nBenchmark (MTEB) (as of May 24, 2024), with 56 tasks, encompassing retrieval,\nreranking, classification, clustering, and semantic textual similarity tasks.\nNotably, our model also attains the highest score of 59.36 on 15 retrieval\ntasks in the MTEB benchmark (also known as BEIR). We will open-source the model\nat: https://huggingface.co/nvidia/NV-Embed-v1.\n",
        "authors": "Chankyu Lee; Rajarshi Roy; Mengyao Xu; Jonathan Raiman; Mohammad Shoeybi; Bryan Catanzaro; Wei Ping",
        "status": 0,
        "relevancy": 0.5595641712884117,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17287",
        "date": "2024-05-27",
        "title": "Opinion-Guided Reinforcement Learning",
        "abstract": "  Human guidance is often desired in reinforcement learning to improve the\nperformance of the learning agent. However, human insights are often mere\nopinions and educated guesses rather than well-formulated arguments. While\nopinions are subject to uncertainty, e.g., due to partial informedness or\nignorance about a problem, they also emerge earlier than hard evidence could be\nproduced. Thus, guiding reinforcement learning agents through opinions offers\nthe potential for more performant learning processes, but comes with the\nchallenge of modeling and managing opinions in a formal way. In this article,\nwe present a method to guide reinforcement learning agents through opinions. To\nthis end, we provide an end-to-end method to model and manage advisors'\nopinions. To assess the utility of the approach, we evaluate it with synthetic\nand human advisors, at different levels of uncertainty, and under multiple\nadvise strategies. Our results indicate that opinions, even if uncertain,\nimprove the performance of reinforcement learning agents, resulting in higher\nrewards, more efficient exploration, and a better reinforced policy. Although\nwe demonstrate our approach in a simplified topological running example, our\napproach is applicable to complex problems with higher dimensions as well.\n",
        "authors": "Kyanna Dagenais; Istvan David",
        "status": 0,
        "relevancy": 0.5491430684706172,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17044",
        "date": "2024-05-27",
        "title": "Generation and human-expert evaluation of interesting research ideas\n  using knowledge graphs and large language models",
        "abstract": "  Advanced artificial intelligence (AI) systems with access to millions of\nresearch papers could inspire new research ideas that may not be conceived by\nhumans alone. However, how interesting are these AI-generated ideas, and how\ncan we improve their quality? Here, we introduce SciMuse, a system that uses an\nevolving knowledge graph built from more than 58 million scientific papers to\ngenerate personalized research ideas via an interface to GPT-4. We conducted a\nlarge-scale human evaluation with over 100 research group leaders from the Max\nPlanck Society, who ranked more than 4,000 personalized research ideas based on\ntheir level of interest. This evaluation allows us to understand the\nrelationships between scientific interest and the core properties of the\nknowledge graph. We find that data-efficient machine learning can predict\nresearch interest with high precision, allowing us to optimize the\ninterest-level of generated research ideas. This work represents a step towards\nan artificial scientific muse that could catalyze unforeseen collaborations and\nsuggest interesting avenues for scientists.\n",
        "authors": "Xuemei Gu; Mario Krenn",
        "status": 0,
        "relevancy": 0.5401620945253656,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17076",
        "date": "2024-05-27",
        "title": "Leveraging small language models for Text2SPARQL tasks to improve the\n  resilience of AI assistance",
        "abstract": "  In this work we will show that language models with less than one billion\nparameters can be used to translate natural language to SPARQL queries after\nfine-tuning. Using three different datasets ranging from academic to real\nworld, we identify prerequisites that the training data must fulfill in order\nfor the training to be successful. The goal is to empower users of semantic web\ntechnology to use AI assistance with affordable commodity hardware, making them\nmore resilient against external factors.\n",
        "authors": "Felix Brei; Johannes Frey; Lars-Peter Meyer",
        "status": 0,
        "relevancy": 0.5393790350799168,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17398",
        "date": "2024-05-27",
        "title": "Vista: A Generalizable Driving World Model with High Fidelity and\n  Versatile Controllability",
        "abstract": "  World models can foresee the outcomes of different actions, which is of\nparamount importance for autonomous driving. Nevertheless, existing driving\nworld models still have limitations in generalization to unseen environments,\nprediction fidelity of critical details, and action controllability for\nflexible application. In this paper, we present Vista, a generalizable driving\nworld model with high fidelity and versatile controllability. Based on a\nsystematic diagnosis of existing methods, we introduce several key ingredients\nto address these limitations. To accurately predict real-world dynamics at high\nresolution, we propose two novel losses to promote the learning of moving\ninstances and structural information. We also devise an effective latent\nreplacement approach to inject historical frames as priors for coherent\nlong-horizon rollouts. For action controllability, we incorporate a versatile\nset of controls from high-level intentions (command, goal point) to low-level\nmaneuvers (trajectory, angle, and speed) through an efficient learning\nstrategy. After large-scale training, the capabilities of Vista can seamlessly\ngeneralize to different scenarios. Extensive experiments on multiple datasets\nshow that Vista outperforms the most advanced general-purpose video generator\nin over 70% of comparisons and surpasses the best-performing driving world\nmodel by 55% in FID and 27% in FVD. Moreover, for the first time, we utilize\nthe capacity of Vista itself to establish a generalizable reward for real-world\naction evaluation without accessing the ground truth actions.\n",
        "authors": "Shenyuan Gao; Jiazhi Yang; Li Chen; Kashyap Chitta; Yihang Qiu; Andreas Geiger; Jun Zhang; Hongyang Li",
        "status": 0,
        "relevancy": 0.5358223377325635,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16907",
        "date": "2024-05-27",
        "title": "GTA: Generative Trajectory Augmentation with Guidance for Offline\n  Reinforcement Learning",
        "abstract": "  Offline Reinforcement Learning (Offline RL) presents challenges of learning\neffective decision-making policies from static datasets without any online\ninteractions. Data augmentation techniques, such as noise injection and data\nsynthesizing, aim to improve Q-function approximation by smoothing the learned\nstate-action region. However, these methods often fall short of directly\nimproving the quality of offline datasets, leading to suboptimal results. In\nresponse, we introduce \\textbf{GTA}, Generative Trajectory Augmentation, a\nnovel generative data augmentation approach designed to enrich offline data by\naugmenting trajectories to be both high-rewarding and dynamically plausible.\nGTA applies a diffusion model within the data augmentation framework. GTA\npartially noises original trajectories and then denoises them with\nclassifier-free guidance via conditioning on amplified return value. Our\nresults show that GTA, as a general data augmentation strategy, enhances the\nperformance of widely used offline RL algorithms in both dense and sparse\nreward settings. Furthermore, we conduct a quality analysis of data augmented\nby GTA and demonstrate that GTA improves the quality of the data. Our code is\navailable at https://github.com/Jaewoopudding/GTA\n",
        "authors": "Jaewoo Lee; Sujin Yun; Taeyoung Yun; Jinkyoo Park",
        "status": 0,
        "relevancy": 0.5272498199280046,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17430",
        "date": "2024-05-27",
        "title": "Matryoshka Multimodal Models",
        "abstract": "  Large Multimodal Models (LMMs) such as LLaVA have shown strong performance in\nvisual-linguistic reasoning. These models first embed images into a fixed large\nnumber of visual tokens and then feed them into a Large Language Model (LLM).\nHowever, this design causes an excessive number of tokens for dense visual\nscenarios such as high-resolution images and videos, leading to great\ninefficiency. While token pruning/merging methods do exist, they produce a\nsingle length output for each image and do not afford flexibility in trading\noff information density v.s. efficiency. Inspired by the concept of Matryoshka\nDolls, we propose M3: Matryoshka Multimodal Models, which learns to represent\nvisual content as nested sets of visual tokens that capture information across\nmultiple coarse-to-fine granularities. Our approach offers several unique\nbenefits for LMMs: (1) One can explicitly control the visual granularity per\ntest instance during inference, e.g. , adjusting the number of tokens used to\nrepresent an image based on the anticipated complexity or simplicity of the\ncontent; (2) M3 provides a framework for analyzing the granularity needed for\nexisting datasets, where we find that COCO-style benchmarks only need around ~9\nvisual tokens to obtain accuracy similar to that of using all 576 tokens; (3)\nOur approach provides a foundation to explore the best trade-off between\nperformance and visual token length at sample level, where our investigation\nreveals that a large gap exists between the oracle upper bound and current\nfixed-scale representations.\n",
        "authors": "Mu Cai; Jianwei Yang; Jianfeng Gao; Yong Jae Lee",
        "status": 0,
        "relevancy": 0.5244891003036051,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17067",
        "date": "2024-05-27",
        "title": "Tokenization Matters! Degrading Large Language Models through\n  Challenging Their Tokenization",
        "abstract": "  Large Language Models (LLMs) have shown remarkable capabilities in language\nunderstanding and generation. Nonetheless, it was also witnessed that LLMs tend\nto produce inaccurate responses to specific queries. This deficiency can be\ntraced to the tokenization step LLMs must undergo, which is an inevitable\nlimitation inherent to all LLMs. In fact, incorrect tokenization is the\ncritical point that hinders LLMs in understanding the input precisely, thus\nleading to unsatisfactory output. To demonstrate this flaw of LLMs, we\nconstruct an adversarial dataset, named as $\\textbf{ADT (Adversarial Dataset\nfor Tokenizer)}$, which draws upon the vocabularies of various open-source LLMs\nto challenge LLMs' tokenization. ADT consists of two subsets: the manually\nconstructed ADT-Human and the automatically generated ADT-Auto. Our empirical\nresults reveal that our ADT is highly effective on challenging the tokenization\nof leading LLMs, including GPT-4o, Llama-3, Qwen2.5-max and so on, thus\ndegrading these LLMs' capabilities. Moreover, our method of automatic data\ngeneration has been proven efficient and robust, which can be applied to any\nopen-source LLMs. To the best of our knowledge, our study is the first to\ninvestigating LLMs' vulnerability in terms of challenging their token\nsegmentation, which will shed light on the subsequent research of improving\nLLMs' capabilities through optimizing their tokenization process and\nalgorithms.\n",
        "authors": "Dixuan Wang; Yanda Li; Junyuan Jiang; Zepeng Ding; Guochao Jiang; Jiaqing Liang; Deqing Yang",
        "status": 0,
        "relevancy": 0.5234981328174072,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16755",
        "date": "2024-05-27",
        "title": "CHESS: Contextual Harnessing for Efficient SQL Synthesis",
        "abstract": "  Utilizing large language models (LLMs) for transforming natural language\nquestions into SQL queries (text-to-SQL) is a promising yet challenging\napproach, particularly when applied to real-world databases with complex and\nextensive schemas. In particular, effectively incorporating data catalogs and\ndatabase values for SQL generation remains an obstacle, leading to suboptimal\nsolutions. We address this problem by proposing a new pipeline that effectively\nretrieves relevant data and context, selects an efficient schema, and\nsynthesizes correct and efficient SQL queries. To increase retrieval precision,\nour pipeline introduces a hierarchical retrieval method leveraging\nmodel-generated keywords, locality-sensitive hashing indexing, and vector\ndatabases. Additionally, we have developed an adaptive schema pruning technique\nthat adjusts based on the complexity of the problem and the model's context\nsize. Our approach generalizes to both frontier proprietary models like GPT-4\nand open-source models such as Llama-3-70B. Through a series of ablation\nstudies, we demonstrate the effectiveness of each component of our pipeline and\nits impact on the end-to-end performance. Our method achieves new\nstate-of-the-art performance on the cross-domain challenging BIRD dataset.\n",
        "authors": "Shayan Talaei; Mohammadreza Pourreza; Yu-Chen Chang; Azalia Mirhoseini; Amin Saberi",
        "status": 0,
        "relevancy": 0.5210629928378254,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17129",
        "date": "2024-05-27",
        "title": "TEII: Think, Explain, Interact and Iterate with Large Language Models to\n  Solve Cross-lingual Emotion Detection",
        "abstract": "  Cross-lingual emotion detection allows us to analyze global trends, public\nopinion, and social phenomena at scale. We participated in the Explainability\nof Cross-lingual Emotion Detection (EXALT) shared task, achieving an F1-score\nof 0.6046 on the evaluation set for the emotion detection sub-task. Our system\noutperformed the baseline by more than 0.16 F1-score absolute, and ranked\nsecond amongst competing systems. We conducted experiments using fine-tuning,\nzero-shot learning, and few-shot learning for Large Language Model (LLM)-based\nmodels as well as embedding-based BiLSTM and KNN for non-LLM-based techniques.\nAdditionally, we introduced two novel methods: the Multi-Iteration Agentic\nWorkflow and the Multi-Binary-Classifier Agentic Workflow. We found that\nLLM-based approaches provided good performance on multilingual emotion\ndetection. Furthermore, ensembles combining all our experimented models yielded\nhigher F1-scores than any single approach alone.\n",
        "authors": "Long Cheng; Qihao Shao; Christine Zhao; Sheng Bi; Gina-Anne Levow",
        "status": 0,
        "relevancy": 0.5209382068261406,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17234",
        "date": "2024-05-27",
        "title": "Benchmarking General Purpose In-Context Learning",
        "abstract": "  In-context learning (ICL) capabilities are becoming increasingly appealing\nfor building general intelligence due to their sample efficiency and\nindependence from artificial optimization skills. To enhance generalization,\nbiological neural systems primarily inherit learning capabilities and\nsubsequently refine their memory, acquiring diverse skills and knowledge\nthrough extensive lifelong experiences. This process gives rise to the concept\nof general-purpose in-context learning (GPICL). Compared to standard ICL, GPICL\naddresses a broader range of tasks, extends learning horizons, and starts at a\nlower zero-shot baseline. We introduce two lightweight but insightful\nbenchmarks specifically crafted to train and evaluate GPICL functionalities.\nEach benchmark includes a vast number of tasks characterized by significant\ntask variance and minimal transferable knowledge among tasks, facilitating\nlifelong in-context learning through continuous generation and interaction.\nThese features pose significant challenges for models that rely on context or\ninteractions to improve their proficiency, including language models, decision\nmodels, and world models. Our experiments reveal that parameter scale alone may\nnot be crucial for ICL or GPICL, suggesting alternative approaches such as\nincreasing the scale of contexts and memory states.\n",
        "authors": "Fan Wang; Chuan Lin; Yang Cao; Yu Kang",
        "status": 0,
        "relevancy": 0.52039616867082,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16766",
        "date": "2024-05-27",
        "title": "Reframing the Relationship in Out-of-Distribution Detection",
        "abstract": "  The remarkable achievements of Large Language Models (LLMs) have captivated\nthe attention of both academia and industry, transcending their initial role in\ndialogue generation. The utilization of LLMs as intermediary agents in various\ntasks has yielded promising results, sparking a wave of innovation in\nartificial intelligence. Building on these breakthroughs, we introduce a novel\napproach that integrates the agent paradigm into the Out-of-distribution (OOD)\ndetection task, aiming to enhance its robustness and adaptability. Our proposed\nmethod, Concept Matching with Agent (CMA), employs neutral prompts as agents to\naugment the CLIP-based OOD detection process. These agents function as dynamic\nobservers and communication hubs, interacting with both In-distribution (ID)\nlabels and data inputs to form vector triangle relationships. This triangular\nframework offers a more nuanced approach than the traditional binary\nrelationship, allowing for better separation and identification of ID and OOD\ninputs. Our extensive experimental results showcase the superior performance of\nCMA over both zero-shot and training-required methods in a diverse array of\nreal-world scenarios.\n",
        "authors": "YuXiao Lee; Xiaofeng Cao",
        "status": 0,
        "relevancy": 0.5193883135881757,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17618",
        "date": "2024-05-27",
        "title": "Symmetric Reinforcement Learning Loss for Robust Learning on Diverse\n  Tasks and Model Scales",
        "abstract": "  Reinforcement learning (RL) training is inherently unstable due to factors\nsuch as moving targets and high gradient variance. Reinforcement Learning from\nHuman Feedback (RLHF) and Reinforcement Learning from AI Feedback (RLAIF) can\nintroduce additional difficulty. Differing preferences can complicate the\nalignment process, and prediction errors in a trained reward model can become\nmore severe as the LLM generates unseen outputs. To enhance training\nrobustness, RL has adopted techniques from supervised learning, such as\nensembles and layer normalization. In this work, we improve the stability of RL\ntraining by adapting the reverse cross entropy (RCE) from supervised learning\nfor noisy data to define a symmetric RL loss. We demonstrate performance\nimprovements across various tasks and scales. We conduct experiments in\ndiscrete action tasks (Atari games) and continuous action space tasks (MuJoCo\nbenchmark and Box2D) using Symmetric A2C (SA2C) and Symmetric PPO (SPPO), with\nand without added noise with especially notable performance in SPPO across\ndifferent hyperparameters. Furthermore, we validate the benefits of the\nsymmetric RL loss when using SPPO for large language models through improved\nperformance in RLHF tasks, such as IMDB positive sentiment sentiment and TL;DR\nsummarization tasks.\n",
        "authors": "Ju-Seung Byun; Andrew Perrault",
        "status": 0,
        "relevancy": 0.5161130411605034,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16994",
        "date": "2024-05-27",
        "title": "Vision-and-Language Navigation Generative Pretrained Transformer",
        "abstract": "  In the Vision-and-Language Navigation (VLN) field, agents are tasked with\nnavigating real-world scenes guided by linguistic instructions. Enabling the\nagent to adhere to instructions throughout the process of navigation represents\na significant challenge within the domain of VLN. To address this challenge,\ncommon approaches often rely on encoders to explicitly record past locations\nand actions, increasing model complexity and resource consumption. Our\nproposal, the Vision-and-Language Navigation Generative Pretrained Transformer\n(VLN-GPT), adopts a transformer decoder model (GPT2) to model trajectory\nsequence dependencies, bypassing the need for historical encoding modules. This\nmethod allows for direct historical information access through trajectory\nsequence, enhancing efficiency. Furthermore, our model separates the training\nprocess into offline pre-training with imitation learning and online\nfine-tuning with reinforcement learning. This distinction allows for more\nfocused training objectives and improved performance. Performance assessments\non the VLN dataset reveal that VLN-GPT surpasses complex state-of-the-art\nencoder-based models.\n",
        "authors": "Wen Hanlin",
        "status": 0,
        "relevancy": 0.5154482457814616,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17706",
        "date": "2024-05-27",
        "title": "Video Enriched Retrieval Augmented Generation Using Aligned Video\n  Captions",
        "abstract": "  In this work, we propose the use of \"aligned visual captions\" as a mechanism\nfor integrating information contained within videos into retrieval augmented\ngeneration (RAG) based chat assistant systems. These captions are able to\ndescribe the visual and audio content of videos in a large corpus while having\nthe advantage of being in a textual format that is both easy to reason about &\nincorporate into large language model (LLM) prompts, but also typically require\nless multimedia content to be inserted into the multimodal LLM context window,\nwhere typical configurations can aggressively fill up the context window by\nsampling video frames from the source video. Furthermore, visual captions can\nbe adapted to specific use cases by prompting the original foundational model /\ncaptioner for particular visual details or fine tuning. In hopes of helping\nadvancing progress in this area, we curate a dataset and describe automatic\nevaluation procedures on common RAG tasks.\n",
        "authors": "Kevin Dela Rosa",
        "status": 0,
        "relevancy": 0.515298130752256,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17631",
        "date": "2024-05-27",
        "title": "BioDiscoveryAgent: An AI Agent for Designing Genetic Perturbation\n  Experiments",
        "abstract": "  Agents based on large language models have shown great potential in\naccelerating scientific discovery by leveraging their rich background knowledge\nand reasoning capabilities. Here, we develop BioDiscoveryAgent, an agent that\ndesigns new experiments, reasons about their outcomes, and efficiently\nnavigates the hypothesis space to reach desired solutions. We demonstrate our\nagent on the problem of designing genetic perturbation experiments, where the\naim is to find a small subset out of many possible genes that, when perturbed,\nresult in a specific phenotype (e.g., cell growth). Utilizing its biological\nknowledge, BioDiscoveryAgent can uniquely design new experiments without the\nneed to train a machine learning model or explicitly design an acquisition\nfunction. Moreover, BioDiscoveryAgent achieves an average of 18% improvement in\ndetecting desired phenotypes across five datasets, compared to existing\nBayesian optimization baselines specifically trained for this task. Our\nevaluation includes one dataset that is unpublished, ensuring it is not part of\nthe language model's training data. Additionally, BioDiscoveryAgent predicts\ngene combinations to perturb twice as accurately as a random baseline, a task\nso far not explored in the context of closed-loop experiment design. The agent\nalso has access to tools for searching the biomedical literature, executing\ncode to analyze biological datasets, and prompting another agent to critically\nevaluate its predictions. Overall, BioDiscoveryAgent is interpretable at every\nstage, representing an accessible new paradigm in the computational design of\nbiological experiments with the potential to augment scientists' capabilities.\n",
        "authors": "Yusuf Roohani; Jian Vora; Qian Huang; Zachary Steinhart; Alexander Marson; Percy Liang; Jure Leskovec",
        "status": 0,
        "relevancy": 0.510634061615632,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17691",
        "date": "2024-05-27",
        "title": "Ontology-Enhanced Decision-Making for Autonomous Agents in Dynamic and\n  Partially Observable Environments",
        "abstract": "  Agents, whether software or hardware, perceive their environment through\nsensors and act using actuators, often operating in dynamic, partially\nobservable settings. They face challenges like incomplete and noisy data,\nunforeseen situations, and the need to adapt goals in real-time. Traditional\nreasoning and ML methods, including Reinforcement Learning (RL), help but are\nlimited by data needs, predefined goals, and extensive exploration periods.\nOntologies offer a solution by integrating diverse information sources,\nenhancing decision-making in complex environments. This thesis introduces an\nontology-enhanced decision-making model (OntoDeM) for autonomous agents.\nOntoDeM enriches agents' domain knowledge, allowing them to interpret\nunforeseen events, generate or adapt goals, and make better decisions. Key\ncontributions include: 1. An ontology-based method to improve agents' real-time\nobservations using prior knowledge. 2. The OntoDeM model for handling dynamic,\nunforeseen situations by evolving or generating new goals. 3. Implementation\nand evaluation in four real-world applications, demonstrating its\neffectiveness. Compared to traditional and advanced learning algorithms,\nOntoDeM shows superior performance in improving agents' observations and\ndecision-making in dynamic, partially observable environments.\n",
        "authors": "Saeedeh Ghanadbashi; Fatemeh Golpayegani",
        "status": 0,
        "relevancy": 0.5103616698161793,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16739",
        "date": "2024-05-27",
        "title": "Oracle-Efficient Reinforcement Learning for Max Value Ensembles",
        "abstract": "  Reinforcement learning (RL) in large or infinite state spaces is notoriously\nchallenging, both theoretically (where worst-case sample and computational\ncomplexities must scale with state space cardinality) and experimentally (where\nfunction approximation and policy gradient techniques often scale poorly and\nsuffer from instability and high variance). One line of research attempting to\naddress these difficulties makes the natural assumption that we are given a\ncollection of heuristic base or $\\textit{constituent}$ policies upon which we\nwould like to improve in a scalable manner. In this work we aim to compete with\nthe $\\textit{max-following policy}$, which at each state follows the action of\nwhichever constituent policy has the highest value. The max-following policy is\nalways at least as good as the best constituent policy, and may be considerably\nbetter. Our main result is an efficient algorithm that learns to compete with\nthe max-following policy, given only access to the constituent policies (but\nnot their value functions). In contrast to prior work in similar settings, our\ntheoretical results require only the minimal assumption of an ERM oracle for\nvalue function approximation for the constituent policies (and not the global\noptimal policy or the max-following policy itself) on samplable distributions.\nWe illustrate our algorithm's experimental effectiveness and behavior on\nseveral robotic simulation testbeds.\n",
        "authors": "Marcel Hussing; Michael Kearns; Aaron Roth; Sikata Bela Sengupta; Jessica Sorrell",
        "status": 0,
        "relevancy": 0.508665402744301,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17324",
        "date": "2024-05-27",
        "title": "Leveraging Offline Data in Linear Latent Bandits",
        "abstract": "  Sequential decision-making domains such as recommender systems, healthcare\nand education often have unobserved heterogeneity in the population that can be\nmodeled using latent bandits $-$ a framework where an unobserved latent state\ndetermines the model for a trajectory. While the latent bandit framework is\ncompelling, the extent of its generality is unclear. We first address this by\nestablishing a de Finetti theorem for decision processes, and show that\n$\\textit{every}$ exchangeable and coherent stateless decision process is a\nlatent bandit. The latent bandit framework lends itself particularly well to\nonline learning with offline datasets, a problem of growing interest in\nsequential decision-making. One can leverage offline latent bandit data to\nlearn a complex model for each latent state, so that an agent can simply learn\nthe latent state online to act optimally. We focus on a linear model for a\nlatent bandit with $d_A$-dimensional actions, where the latent states lie in an\nunknown $d_K$-dimensional subspace for $d_K \\ll d_A$. We present SOLD, a novel\nprincipled method to learn this subspace from short offline trajectories with\nguarantees. We then provide two methods to leverage this subspace online:\nLOCAL-UCB and ProBALL-UCB. We demonstrate that LOCAL-UCB enjoys $\\tilde\nO(\\min(d_A\\sqrt{T}, d_K\\sqrt{T}(1+\\sqrt{d_AT/d_KN})))$ regret guarantees, where\nthe effective dimension is lower when the size $N$ of the offline dataset is\nlarger. ProBALL-UCB enjoys a slightly weaker guarantee, but is more practical\nand computationally efficient. Finally, we establish the efficacy of our\nmethods using experiments on both synthetic data and real-life movie\nrecommendation data from MovieLens.\n",
        "authors": "Chinmaya Kausik; Kevin Tan; Ambuj Tewari",
        "status": 0,
        "relevancy": 0.5068921981905822,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16800",
        "date": "2024-05-27",
        "title": "TAGA: Text-Attributed Graph Self-Supervised Learning by Synergizing\n  Graph and Text Mutual Transformations",
        "abstract": "  Text-Attributed Graphs (TAGs) enhance graph structures with natural language\ndescriptions, enabling detailed representation of data and their relationships\nacross a broad spectrum of real-world scenarios. Despite the potential for\ndeeper insights, existing TAG representation learning primarily relies on\nsupervised methods, necessitating extensive labeled data and limiting\napplicability across diverse contexts. This paper introduces a new\nself-supervised learning framework, Text-And-Graph Multi-View Alignment (TAGA),\nwhich overcomes these constraints by integrating TAGs' structural and semantic\ndimensions. TAGA constructs two complementary views: Text-of-Graph view, which\norganizes node texts into structured documents based on graph topology, and the\nGraph-of-Text view, which converts textual nodes and connections into graph\ndata. By aligning representations from both views, TAGA captures joint textual\nand structural information. In addition, a novel structure-preserving random\nwalk algorithm is proposed for efficient training on large-sized TAGs. Our\nframework demonstrates strong performance in zero-shot and few-shot scenarios\nacross eight real-world datasets.\n",
        "authors": "Zheng Zhang; Yuntong Hu; Bo Pan; Chen Ling; Liang Zhao",
        "status": 0,
        "relevancy": 0.5066622232249672,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17626",
        "date": "2024-05-27",
        "title": "Matrix Low-Rank Approximation For Policy Gradient Methods",
        "abstract": "  Estimating a policy that maps states to actions is a central problem in\nreinforcement learning. Traditionally, policies are inferred from the so called\nvalue functions (VFs), but exact VF computation suffers from the curse of\ndimensionality. Policy gradient (PG) methods bypass this by learning directly a\nparametric stochastic policy. Typically, the parameters of the policy are\nestimated using neural networks (NNs) tuned via stochastic gradient descent.\nHowever, finding adequate NN architectures can be challenging, and convergence\nissues are common as well. In this paper, we put forth low-rank matrix-based\nmodels to estimate efficiently the parameters of PG algorithms. We collect the\nparameters of the stochastic policy into a matrix, and then, we leverage\nmatrix-completion techniques to promote (enforce) low rank. We demonstrate via\nnumerical studies how low-rank matrix-based policy models reduce the\ncomputational and sample complexities relative to NN models, while achieving a\nsimilar aggregated reward.\n",
        "authors": "Sergio Rozada; Antonio G. Marques",
        "status": 0,
        "relevancy": 0.5038693613310521,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16879",
        "date": "2024-05-27",
        "title": "Unsupervised Generative Feature Transformation via Graph Contrastive\n  Pre-training and Multi-objective Fine-tuning",
        "abstract": "  Feature transformation is to derive a new feature set from original features\nto augment the AI power of data. In many science domains such as material\nperformance screening, while feature transformation can model material formula\ninteractions and compositions and discover performance drivers, supervised\nlabels are collected from expensive and lengthy experiments. This issue\nmotivates an Unsupervised Feature Transformation Learning (UFTL) problem. Prior\nliterature, such as manual transformation, supervised feedback guided search,\nand PCA, either relies on domain knowledge or expensive supervised feedback, or\nsuffers from large search space, or overlooks non-linear feature-feature\ninteractions. UFTL imposes a major challenge on existing methods: how to design\na new unsupervised paradigm that captures complex feature interactions and\navoids large search space? To fill this gap, we connect graph, contrastive, and\ngenerative learning to develop a measurement-pretrain-finetune paradigm for\nUFTL. For unsupervised feature set utility measurement, we propose a feature\nvalue consistency preservation perspective and develop a mean discounted\ncumulative gain like unsupervised metric to evaluate feature set utility. For\nunsupervised feature set representation pretraining, we regard a feature set as\na feature-feature interaction graph, and develop an unsupervised graph\ncontrastive learning encoder to embed feature sets into vectors. For generative\ntransformation finetuning, we regard a feature set as a feature cross sequence\nand feature transformation as sequential generation. We develop a deep\ngenerative feature transformation model that coordinates the pretrained feature\nset encoder and the gradient information extracted from a feature set utility\nevaluator to optimize a transformed feature generator.\n",
        "authors": "Wangyang Ying; Dongjie Wang; Xuanming Hu; Yuanchun Zhou; Charu C. Aggarwal; Yanjie Fu",
        "status": 0,
        "relevancy": 0.5036297937191909,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17625",
        "date": "2024-05-27",
        "title": "Matrix Low-Rank Trust Region Policy Optimization",
        "abstract": "  Most methods in reinforcement learning use a Policy Gradient (PG) approach to\nlearn a parametric stochastic policy that maps states to actions. The standard\napproach is to implement such a mapping via a neural network (NN) whose\nparameters are optimized using stochastic gradient descent. However, PG methods\nare prone to large policy updates that can render learning inefficient. Trust\nregion algorithms, like Trust Region Policy Optimization (TRPO), constrain the\npolicy update step, ensuring monotonic improvements. This paper introduces\nlow-rank matrix-based models as an efficient alternative for estimating the\nparameters of TRPO algorithms. By gathering the stochastic policy's parameters\ninto a matrix and applying matrix-completion techniques, we promote and enforce\nlow rank. Our numerical studies demonstrate that low-rank matrix-based policy\nmodels effectively reduce both computational and sample complexities compared\nto NN models, while maintaining comparable aggregated rewards.\n",
        "authors": "Sergio Rozada; Antonio G. Marques",
        "status": 0,
        "relevancy": 0.5003660473501306,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17057",
        "date": "2024-05-27",
        "title": "ReflectionCoder: Learning from Reflection Sequence for Enhanced One-off\n  Code Generation",
        "abstract": "  Code generation plays a crucial role in various tasks, such as code\nauto-completion and mathematical reasoning. Previous work has proposed numerous\nmethods to enhance code generation performance, including integrating feedback\nfrom the compiler. Inspired by this, we present ReflectionCoder, a novel\napproach that effectively leverages reflection sequences constructed by\nintegrating compiler feedback to improve one-off code generation performance.\nFurthermore, we propose reflection self-distillation and dynamically masked\ndistillation to effectively utilize these reflection sequences. Extensive\nexperiments on three benchmarks, i.e., HumanEval (+), MBPP (+), and MultiPl-E,\ndemonstrate that models fine-tuned with our method achieve state-of-the-art\nperformance. Notably, ReflectionCoder-DeepSeek-Coder-33B reaches pass@1 of 82.9\n(76.8) on HumanEval (+) and 84.1 (72.0) on MBPP (+), on par with GPT-3.5-Turbo\nand Claude-3-opus, and surpasses early GPT-4. Beyond the code domain, we\nbelieve this approach can benefit other domains that focus on final results and\nrequire long reasoning paths. Code and data are available at\nhttps://github.com/SenseLLM/ReflectionCoder.\n",
        "authors": "Houxing Ren; Mingjie Zhan; Zhongyuan Wu; Aojun Zhou; Junting Pan; Hongsheng Li",
        "status": 0,
        "relevancy": 0.4977746859446158,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17640",
        "date": "2024-05-27",
        "title": "Probabilistically Plausible Counterfactual Explanations with Normalizing\n  Flows",
        "abstract": "  We present PPCEF, a novel method for generating probabilistically plausible\ncounterfactual explanations (CFs). PPCEF advances beyond existing methods by\ncombining a probabilistic formulation that leverages the data distribution with\nthe optimization of plausibility within a unified framework. Compared to\nreference approaches, our method enforces plausibility by directly optimizing\nthe explicit density function without assuming a particular family of\nparametrized distributions. This ensures CFs are not only valid (i.e., achieve\nclass change) but also align with the underlying data's probability density.\nFor that purpose, our approach leverages normalizing flows as powerful density\nestimators to capture the complex high-dimensional data distribution.\nFurthermore, we introduce a novel loss that balances the trade-off between\nachieving class change and maintaining closeness to the original instance while\nalso incorporating a probabilistic plausibility term. PPCEF's unconstrained\nformulation allows for efficient gradient-based optimization with batch\nprocessing, leading to orders of magnitude faster computation compared to prior\nmethods. Moreover, the unconstrained formulation of PPCEF allows for the\nseamless integration of future constraints tailored to specific counterfactual\nproperties. Finally, extensive evaluations demonstrate PPCEF's superiority in\ngenerating high-quality, probabilistically plausible counterfactual\nexplanations in high-dimensional tabular settings. This makes PPCEF a powerful\ntool for not only interpreting complex machine learning models but also for\nimproving fairness, accountability, and trust in AI systems.\n",
        "authors": "Patryk Wielopolski; Oleksii Furman; Jerzy Stefanowski; Maciej Zięba",
        "status": 0,
        "relevancy": 0.49564031505195183,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17103",
        "date": "2024-05-27",
        "title": "Empowering Character-level Text Infilling by Eliminating Sub-Tokens",
        "abstract": "  In infilling tasks, sub-tokens, representing instances where a complete token\nis segmented into two parts, often emerge at the boundaries of prefixes,\nmiddles, and suffixes. Traditional methods focused on training models at the\ntoken level, leading to sub-optimal performance in character-level infilling\ntasks during the inference stage. Alternately, some approaches considered\ncharacter-level infilling, but they relied on predicting sub-tokens in\ninference, yet this strategy diminished ability in character-level infilling\ntasks due to the large perplexity of the model on sub-tokens. In this paper, we\nintroduce FIM-SE, which stands for Fill-In-the-Middle with both Starting and\nEnding character constraints. The proposed method addresses character-level\ninfilling tasks by utilizing a line-level format to avoid predicting any\nsub-token in inference. In addition, we incorporate two special tokens to\nsignify the rest of the incomplete lines, thereby enhancing generation\nguidance. Extensive experiments demonstrate that our proposed approach\nsurpasses previous methods, offering a significant advantage. Code is available\nat https://github.com/SenseLLM/FIM-SE.\n",
        "authors": "Houxing Ren; Mingjie Zhan; Zhongyuan Wu; Hongsheng Li",
        "status": 0,
        "relevancy": 0.4952013521387346,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16899",
        "date": "2024-05-27",
        "title": "Partial Models for Building Adaptive Model-Based Reinforcement Learning\n  Agents",
        "abstract": "  In neuroscience, one of the key behavioral tests for determining whether a\nsubject of study exhibits model-based behavior is to study its adaptiveness to\nlocal changes in the environment. In reinforcement learning, however, recent\nstudies have shown that modern model-based agents display poor adaptivity to\nsuch changes. The main reason for this is that modern agents are typically\ndesigned to improve sample efficiency in single task settings and thus do not\ntake into account the challenges that can arise in other settings. In local\nadaptation settings, one particularly important challenge is in quickly\nbuilding and maintaining a sufficiently accurate model after a local change.\nThis is challenging for deep model-based agents as their models and replay\nbuffers are monolithic structures lacking distribution shift handling\ncapabilities. In this study, we show that the conceptually simple idea of\npartial models can allow deep model-based agents to overcome this challenge and\nthus allow for building locally adaptive model-based agents. By modeling the\ndifferent parts of the state space through different models, the agent can not\nonly maintain a model that is accurate across the state space, but it can also\nquickly adapt it in the presence of a local change in the environment. We\ndemonstrate this by showing that the use of partial models in agents such as\ndeep Dyna-Q, PlaNet and Dreamer can allow for them to effectively adapt to the\nlocal changes in their environments.\n",
        "authors": "Safa Alver; Ali Rahimi-Kalahroudi; Doina Precup",
        "status": 0,
        "relevancy": 0.49376953607242435,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17022",
        "date": "2024-05-27",
        "title": "Compositional Few-Shot Class-Incremental Learning",
        "abstract": "  Few-shot class-incremental learning (FSCIL) is proposed to continually learn\nfrom novel classes with only a few samples after the (pre-)training on base\nclasses with sufficient data. However, this remains a challenge. In contrast,\nhumans can easily recognize novel classes with a few samples. Cognitive science\ndemonstrates that an important component of such human capability is\ncompositional learning. This involves identifying visual primitives from\nlearned knowledge and then composing new concepts using these transferred\nprimitives, making incremental learning both effective and interpretable. To\nimitate human compositional learning, we propose a cognitive-inspired method\nfor the FSCIL task. We define and build a compositional model based on set\nsimilarities, and then equip it with a primitive composition module and a\nprimitive reuse module. In the primitive composition module, we propose to\nutilize the Centered Kernel Alignment (CKA) similarity to approximate the\nsimilarity between primitive sets, allowing the training and evaluation based\non primitive compositions. In the primitive reuse module, we enhance primitive\nreusability by classifying inputs based on primitives replaced with the closest\nprimitives from other classes. Experiments on three datasets validate our\nmethod, showing it outperforms current state-of-the-art methods with improved\ninterpretability. Our code is available at\nhttps://github.com/Zoilsen/Comp-FSCIL.\n",
        "authors": "Yixiong Zou; Shanghang Zhang; Haichen Zhou; Yuhua Li; Ruixuan Li",
        "status": 0,
        "relevancy": 0.49071128253474994,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17404",
        "date": "2024-05-27",
        "title": "Spectral Greedy Coresets for Graph Neural Networks",
        "abstract": "  The ubiquity of large-scale graphs in node-classification tasks significantly\nhinders the real-world applications of Graph Neural Networks (GNNs). Node\nsampling, graph coarsening, and dataset condensation are effective strategies\nfor enhancing data efficiency. However, owing to the interdependence of graph\nnodes, coreset selection, which selects subsets of the data examples, has not\nbeen successfully applied to speed up GNN training on large graphs, warranting\nspecial treatment. This paper studies graph coresets for GNNs and avoids the\ninterdependence issue by selecting ego-graphs (i.e., neighborhood subgraphs\naround a node) based on their spectral embeddings. We decompose the coreset\nselection problem for GNNs into two phases: a coarse selection of widely spread\nego graphs and a refined selection to diversify their topologies. We design a\ngreedy algorithm that approximately optimizes both objectives. Our spectral\ngreedy graph coreset (SGGC) scales to graphs with millions of nodes, obviates\nthe need for model pre-training, and applies to low-homophily graphs. Extensive\nexperiments on ten datasets demonstrate that SGGC outperforms other coreset\nmethods by a wide margin, generalizes well across GNN architectures, and is\nmuch faster than graph condensation.\n",
        "authors": "Mucong Ding; Yinhan He; Jundong Li; Furong Huang",
        "status": 0,
        "relevancy": 0.4900781490971424,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16860",
        "date": "2024-05-27",
        "title": "Think Before You Act: A Two-Stage Framework for Mitigating Gender Bias\n  Towards Vision-Language Tasks",
        "abstract": "  Gender bias in vision-language models (VLMs) can reinforce harmful\nstereotypes and discrimination. In this paper, we focus on mitigating gender\nbias towards vision-language tasks. We identify object hallucination as the\nessence of gender bias in VLMs. Existing VLMs tend to focus on salient or\nfamiliar attributes in images but ignore contextualized nuances. Moreover, most\nVLMs rely on the co-occurrence between specific objects and gender attributes\nto infer the ignored features, ultimately resulting in gender bias. We propose\nGAMA, a task-agnostic generation framework to mitigate gender bias. GAMA\nconsists of two stages: narrative generation and answer inference. During\nnarrative generation, GAMA yields all-sided but gender-obfuscated narratives,\nwhich prevents premature concentration on localized image features, especially\ngender attributes. During answer inference, GAMA integrates the image,\ngenerated narrative, and a task-specific question prompt to infer answers for\ndifferent vision-language tasks. This approach allows the model to rethink\ngender attributes and answers. We conduct extensive experiments on GAMA,\ndemonstrating its debiasing and generalization ability.\n",
        "authors": "Yunqi Zhang; Songda Li; Chunyuan Deng; Luyi Wang; Hui Zhao",
        "status": 0,
        "relevancy": 0.4872769760274511,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17104",
        "date": "2024-05-27",
        "title": "LLM-Optic: Unveiling the Capabilities of Large Language Models for\n  Universal Visual Grounding",
        "abstract": "  Visual grounding is an essential tool that links user-provided text queries\nwith query-specific regions within an image. Despite advancements in visual\ngrounding models, their ability to comprehend complex queries remains limited.\nTo overcome this limitation, we introduce LLM-Optic, an innovative method that\nutilizes Large Language Models (LLMs) as an optical lens to enhance existing\nvisual grounding models in comprehending complex text queries involving\nintricate text structures, multiple objects, or object spatial relationships,\nsituations that current models struggle with. LLM-Optic first employs an LLM as\na Text Grounder to interpret complex text queries and accurately identify\nobjects the user intends to locate. Then a pre-trained visual grounding model\nis used to generate candidate bounding boxes given the refined query by the\nText Grounder. After that, LLM-Optic annotates the candidate bounding boxes\nwith numerical marks to establish a connection between text and specific image\nregions, thereby linking two distinct modalities. Finally, it employs a Large\nMultimodal Model (LMM) as a Visual Grounder to select the marked candidate\nobjects that best correspond to the original text query. Through LLM-Optic, we\nhave achieved universal visual grounding, which allows for the detection of\narbitrary objects specified by arbitrary human language input. Importantly, our\nmethod achieves this enhancement without requiring additional training or\nfine-tuning. Extensive experiments across various challenging benchmarks\ndemonstrate that LLM-Optic achieves state-of-the-art zero-shot visual grounding\ncapabilities. Project Page: https://haoyu-zhao.github.io/LLM-Optic.github.io/.\n",
        "authors": "Haoyu Zhao; Wenhang Ge; Ying-cong Chen",
        "status": 0,
        "relevancy": 0.4836114182426331,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17512",
        "date": "2024-05-27",
        "title": "On Fairness of Low-Rank Adaptation of Large Models",
        "abstract": "  Low-rank adaptation of large models, particularly LoRA, has gained traction\ndue to its computational efficiency. This efficiency, contrasted with the\nprohibitive costs of full-model fine-tuning, means that practitioners often\nturn to LoRA and sometimes without a complete understanding of its\nramifications. In this study, we focus on fairness and ask whether LoRA has an\nunexamined impact on utility, calibration, and resistance to membership\ninference across different subgroups (e.g., genders, races, religions) compared\nto a full-model fine-tuning baseline. We present extensive experiments across\nvision and language domains and across classification and generation tasks\nusing ViT-Base, Swin-v2-Large, Llama-2 7B, and Mistral 7B. Intriguingly,\nexperiments suggest that while one can isolate cases where LoRA exacerbates\nmodel bias across subgroups, the pattern is inconsistent -- in many cases, LoRA\nhas equivalent or even improved fairness compared to the base model or its full\nfine-tuning baseline. We also examine the complications of evaluating\nfine-tuning fairness relating to task design and model token bias, calling for\nmore careful fairness evaluations in future work.\n",
        "authors": "Zhoujie Ding; Ken Ziyu Liu; Pura Peetathawatchai; Berivan Isik; Sanmi Koyejo",
        "status": 0,
        "relevancy": 0.4808035338972152,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17642",
        "date": "2024-05-27",
        "title": "Unifying Perspectives: Plausible Counterfactual Explanations on Global,\n  Group-wise, and Local Levels",
        "abstract": "  Growing regulatory and societal pressures demand increased transparency in\nAI, particularly in understanding the decisions made by complex machine\nlearning models. Counterfactual Explanations (CFs) have emerged as a promising\ntechnique within Explainable AI (xAI), offering insights into individual model\npredictions. However, to understand the systemic biases and disparate impacts\nof AI models, it is crucial to move beyond local CFs and embrace global\nexplanations, which offer a~holistic view across diverse scenarios and\npopulations. Unfortunately, generating Global Counterfactual Explanations\n(GCEs) faces challenges in computational complexity, defining the scope of\n\"global,\" and ensuring the explanations are both globally representative and\nlocally plausible. We introduce a novel unified approach for generating Local,\nGroup-wise, and Global Counterfactual Explanations for differentiable\nclassification models via gradient-based optimization to address these\nchallenges. This framework aims to bridge the gap between individual and\nsystemic insights, enabling a deeper understanding of model decisions and their\npotential impact on diverse populations. Our approach further innovates by\nincorporating a probabilistic plausibility criterion, enhancing actionability\nand trustworthiness. By offering a cohesive solution to the optimization and\nplausibility challenges in GCEs, our work significantly advances the\ninterpretability and accountability of AI models, marking a step forward in the\npursuit of transparent AI.\n",
        "authors": "Patryk Wielopolski; Oleksii Furman; Jerzy Stefanowski; Maciej Zięba",
        "status": 0,
        "relevancy": 0.47927225112713956,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16946",
        "date": "2024-05-27",
        "title": "Biological Neurons Compete with Deep Reinforcement Learning in Sample\n  Efficiency in a Simulated Gameworld",
        "abstract": "  How do biological systems and machine learning algorithms compare in the\nnumber of samples required to show significant improvements in completing a\ntask? We compared the learning efficiency of in vitro biological neural\nnetworks to the state-of-the-art deep reinforcement learning (RL) algorithms in\na simplified simulation of the game `Pong'. Using DishBrain, a system that\nembodies in vitro neural networks with in silico computation using a\nhigh-density multi-electrode array, we contrasted the learning rate and the\nperformance of these biological systems against time-matched learning from\nthree state-of-the-art deep RL algorithms (i.e., DQN, A2C, and PPO) in the same\ngame environment. This allowed a meaningful comparison between biological\nneural systems and deep RL. We find that when samples are limited to a\nreal-world time course, even these very simple biological cultures outperformed\ndeep RL algorithms across various game performance characteristics, implying a\nhigher sample efficiency. Ultimately, even when tested across multiple types of\ninformation input to assess the impact of higher dimensional data input,\nbiological neurons showcased faster learning than all deep reinforcement\nlearning agents.\n",
        "authors": "Moein Khajehnejad; Forough Habibollahi; Aswin Paul; Adeel Razi; Brett J. Kagan",
        "status": 0,
        "relevancy": 0.4771512731192644,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17678",
        "date": "2024-05-27",
        "title": "TIMA: Text-Image Mutual Awareness for Balancing Zero-Shot Adversarial\n  Robustness and Generalization Ability",
        "abstract": "  This work addresses the challenge of achieving zero-shot adversarial\nrobustness while preserving zero-shot generalization in large-scale foundation\nmodels, with a focus on the popular Contrastive Language-Image Pre-training\n(CLIP). Although foundation models were reported to have exceptional zero-shot\ngeneralization, they are highly vulnerable to adversarial perturbations.\nExisting methods achieve a comparable good tradeoff between zero-shot\nadversarial robustness and generalization under small adversarial\nperturbations. However, they fail to achieve a good tradeoff under large\nadversarial perturbations. To this end, we propose a novel Text-Image Mutual\nAwareness (TIMA) method that strikes a balance between zero-shot adversarial\nrobustness and generalization. More precisely, we propose an Image-Aware Text\n(IAT) tuning mechanism that increases the inter-class distance of text\nembeddings by incorporating the Minimum Hyperspherical Energy (MHE).\nSimultaneously, fixed pre-trained image embeddings are used as cross-modal\nauxiliary supervision to maintain the similarity between the MHE-tuned and\noriginal text embeddings by the knowledge distillation, preserving semantic\ninformation between different classes. Besides, we introduce a Text-Aware Image\n(TAI) tuning mechanism, which increases inter-class distance between image\nembeddings during the training stage by Text-distance based Adaptive Margin\n(TAM). Similarly, a knowledge distillation is utilized to retain the similarity\nbetween fine-tuned and pre-trained image embeddings. Extensive experimental\nresults demonstrate the effectiveness of our approach, showing impressive\nzero-shot performance against a wide range of adversarial perturbations while\npreserving the zero-shot generalization capabilities of the original CLIP\nmodel.\n",
        "authors": "Fengji Ma; Li Liu; Hei Victor Cheng",
        "status": 0,
        "relevancy": 0.4738095882720026,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17258",
        "date": "2024-05-27",
        "title": "$\\textit{Trans-LoRA}$: towards data-free Transferable Parameter\n  Efficient Finetuning",
        "abstract": "  Low-rank adapters (LoRA) and their variants are popular parameter-efficient\nfine-tuning (PEFT) techniques that closely match full model fine-tune\nperformance while requiring only a small number of additional parameters. These\nadditional LoRA parameters are specific to the base model being adapted. When\nthe base model needs to be deprecated and replaced with a new one, all the\nassociated LoRA modules need to be re-trained. Such re-training requires access\nto the data used to train the LoRA for the original base model. This is\nespecially problematic for commercial cloud applications where the LoRA modules\nand the base models are hosted by service providers who may not be allowed to\nhost proprietary client task data. To address this challenge, we propose\n$\\textit{Trans-LoRA}$ -- a novel method for lossless, nearly data-free transfer\nof LoRAs across base models. Our approach relies on synthetic data to transfer\nLoRA modules. Using large language models, we design a synthetic data generator\nto approximate the data-generating process of the $\\textit{observed}$ task data\nsubset. Training on the resulting synthetic dataset transfers LoRA modules to\nnew models. We show the effectiveness of our approach using both LLama and\nGemma model families. Our approach achieves lossless (mostly improved) LoRA\ntransfer between models within and across different base model families, and\neven between different PEFT methods, on a wide variety of tasks.\n",
        "authors": "Runqian Wang; Soumya Ghosh; David Cox; Diego Antognini; Aude Oliva; Rogerio Feris; Leonid Karlinsky",
        "status": 0,
        "relevancy": 0.47309652288824755,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16964",
        "date": "2024-05-27",
        "title": "Exploring the LLM Journey from Cognition to Expression with Linear\n  Representations",
        "abstract": "  This paper presents an in-depth examination of the evolution and interplay of\ncognitive and expressive capabilities in large language models (LLMs), with a\nspecific focus on Baichuan-7B and Baichuan-33B, an advanced bilingual (Chinese\nand English) LLM series. We define and explore the model's cognitive and\nexpressive capabilities through linear representations across three critical\nphases: Pretraining, Supervised Fine-Tuning (SFT), and Reinforcement Learning\nfrom Human Feedback (RLHF). Cognitive capability is defined as the quantity and\nquality of information conveyed by the neuron output vectors within the\nnetwork, similar to the neural signal processing in human cognition. Expressive\ncapability is defined as the model's capability to produce word-level output.\nOur findings unveil a sequential development pattern, where cognitive abilities\nare largely established during Pretraining, whereas expressive abilities\npredominantly advance during SFT and RLHF. Statistical analyses confirm a\nsignificant correlation between the two capabilities, suggesting that cognitive\ncapacity may limit expressive potential. The paper also explores the\ntheoretical underpinnings of these divergent developmental trajectories and\ntheir connection to the LLMs' architectural design. Moreover, we evaluate\nvarious optimization-independent strategies, such as few-shot learning and\nrepeated sampling, which bridge the gap between cognitive and expressive\ncapabilities. This research reveals the potential connection between the hidden\nspace and the output space, contributing valuable insights into the\ninterpretability and controllability of their training processes.\n",
        "authors": "Yuzi Yan; Jialian Li; Yipin Zhang; Dong Yan",
        "status": 0,
        "relevancy": 0.4689778665883011,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16851",
        "date": "2024-05-27",
        "title": "Temporal Spiking Neural Networks with Synaptic Delay for Graph Reasoning",
        "abstract": "  Spiking neural networks (SNNs) are investigated as biologically inspired\nmodels of neural computation, distinguished by their computational capability\nand energy efficiency due to precise spiking times and sparse spikes with\nevent-driven computation. A significant question is how SNNs can emulate\nhuman-like graph-based reasoning of concepts and relations, especially\nleveraging the temporal domain optimally. This paper reveals that SNNs, when\namalgamated with synaptic delay and temporal coding, are proficient in\nexecuting (knowledge) graph reasoning. It is elucidated that spiking time can\nfunction as an additional dimension to encode relation properties via a\nneural-generalized path formulation. Empirical results highlight the efficacy\nof temporal delay in relation processing and showcase exemplary performance in\ndiverse graph reasoning tasks. The spiking model is theoretically estimated to\nachieve $20\\times$ energy savings compared to non-spiking counterparts,\ndeepening insights into the capabilities and potential of biologically inspired\nSNNs for efficient reasoning. The code is available at\nhttps://github.com/pkuxmq/GRSNN.\n",
        "authors": "Mingqing Xiao; Yixin Zhu; Di He; Zhouchen Lin",
        "status": 0,
        "relevancy": 0.4680441503061067,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17372",
        "date": "2024-05-27",
        "title": "BehaviorGPT: Smart Agent Simulation for Autonomous Driving with\n  Next-Patch Prediction",
        "abstract": "  Simulating realistic interactions among traffic agents is crucial for\nefficiently validating the safety of autonomous driving systems. Existing\nleading simulators primarily use an encoder-decoder structure to encode the\nhistorical trajectories for future simulation. However, such a paradigm\ncomplicates the model architecture, and the manual separation of history and\nfuture trajectories leads to low data utilization. To address these challenges,\nwe propose Behavior Generative Pre-trained Transformers (BehaviorGPT), a\ndecoder-only, autoregressive architecture designed to simulate the sequential\nmotion of multiple agents. Crucially, our approach discards the traditional\nseparation between \"history\" and \"future,\" treating each time step as the\n\"current\" one, resulting in a simpler, more parameter- and data-efficient\ndesign that scales seamlessly with data and computation. Additionally, we\nintroduce the Next-Patch Prediction Paradigm (NP3), which enables models to\nreason at the patch level of trajectories and capture long-range\nspatial-temporal interactions. BehaviorGPT ranks first across several metrics\non the Waymo Sim Agents Benchmark, demonstrating its exceptional performance in\nmulti-agent and agent-map interactions. We outperformed state-of-the-art models\nwith a realism score of 0.741 and improved the minADE metric to 1.540, with an\napproximately 91.6% reduction in model parameters.\n",
        "authors": "Zikang Zhou; Haibo Hu; Xinhong Chen; Jianping Wang; Nan Guan; Kui Wu; Yung-Hui Li; Yu-Kai Huang; Chun Jason Xue",
        "status": 0,
        "relevancy": 0.46652290848841327,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17535",
        "date": "2024-05-27",
        "title": "Calibrated Dataset Condensation for Faster Hyperparameter Search",
        "abstract": "  Dataset condensation can be used to reduce the computational cost of training\nmultiple models on a large dataset by condensing the training dataset into a\nsmall synthetic set. State-of-the-art approaches rely on matching the model\ngradients between the real and synthetic data. However, there is no theoretical\nguarantee of the generalizability of the condensed data: data condensation\noften generalizes poorly across hyperparameters/architectures in practice. This\npaper considers a different condensation objective specifically geared toward\nhyperparameter search. We aim to generate a synthetic validation dataset so\nthat the validation-performance rankings of the models, with different\nhyperparameters, on the condensed and original datasets are comparable. We\npropose a novel hyperparameter-calibrated dataset condensation (HCDC)\nalgorithm, which obtains the synthetic validation dataset by matching the\nhyperparameter gradients computed via implicit differentiation and efficient\ninverse Hessian approximation. Experiments demonstrate that the proposed\nframework effectively maintains the validation-performance rankings of models\nand speeds up hyperparameter/architecture search for tasks on both images and\ngraphs.\n",
        "authors": "Mucong Ding; Yuancheng Xu; Tahseen Rabbani; Xiaoyu Liu; Brian Gravelle; Teresa Ranadive; Tai-Ching Tuan; Furong Huang",
        "status": 0,
        "relevancy": 0.46648243627871344,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17628",
        "date": "2024-05-27",
        "title": "Tensor Low-rank Approximation of Finite-horizon Value Functions",
        "abstract": "  The goal of reinforcement learning is estimating a policy that maps states to\nactions and maximizes the cumulative reward of a Markov Decision Process (MDP).\nThis is oftentimes achieved by estimating first the optimal (reward) value\nfunction (VF) associated with each state-action pair. When the MDP has an\ninfinite horizon, the optimal VFs and policies are stationary under mild\nconditions. However, in finite-horizon MDPs, the VFs (hence, the policies) vary\nwith time. This poses a challenge since the number of VFs to estimate grows not\nonly with the size of the state-action space but also with the time horizon.\nThis paper proposes a non-parametric low-rank stochastic algorithm to\napproximate the VFs of finite-horizon MDPs. First, we represent the (unknown)\nVFs as a multi-dimensional array, or tensor, where time is one of the\ndimensions. Then, we use rewards sampled from the MDP to estimate the optimal\nVFs. More precisely, we use the (truncated) PARAFAC decomposition to design an\nonline low-rank algorithm that recovers the entries of the tensor of VFs. The\nsize of the low-rank PARAFAC model grows additively with respect to each of its\ndimensions, rendering our approach efficient, as demonstrated via numerical\nexperiments.\n",
        "authors": "Sergio Rozada; Antonio G. Marques",
        "status": 0,
        "relevancy": 0.46178719348546093,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16830",
        "date": "2024-05-27",
        "title": "Structured Graph Network for Constrained Robot Crowd Navigation with Low\n  Fidelity Simulation",
        "abstract": "  We investigate the feasibility of deploying reinforcement learning (RL)\npolicies for constrained crowd navigation using a low-fidelity simulator. We\nintroduce a representation of the dynamic environment, separating human and\nobstacle representations. Humans are represented through detected states, while\nobstacles are represented as computed point clouds based on maps and robot\nlocalization. This representation enables RL policies trained in a low-fidelity\nsimulator to deploy in real world with a reduced sim2real gap. Additionally, we\npropose a spatio-temporal graph to model the interactions between agents and\nobstacles. Based on the graph, we use attention mechanisms to capture the\nrobot-human, human-human, and human-obstacle interactions. Our method\nsignificantly improves navigation performance in both simulated and real-world\nenvironments. Video demonstrations can be found at\nhttps://sites.google.com/view/constrained-crowdnav/home.\n",
        "authors": "Shuijing Liu; Kaiwen Hong; Neeloy Chakraborty; Katherine Driggs-Campbell",
        "status": 0,
        "relevancy": 0.45884806849533766,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16752",
        "date": "2024-05-27",
        "title": "Model Ensembling for Constrained Optimization",
        "abstract": "  There is a long history in machine learning of model ensembling, beginning\nwith boosting and bagging and continuing to the present day. Much of this\nhistory has focused on combining models for classification and regression, but\nrecently there is interest in more complex settings such as ensembling policies\nin reinforcement learning. Strong connections have also emerged between\nensembling and multicalibration techniques. In this work, we further\ninvestigate these themes by considering a setting in which we wish to ensemble\nmodels for multidimensional output predictions that are in turn used for\ndownstream optimization. More precisely, we imagine we are given a number of\nmodels mapping a state space to multidimensional real-valued predictions. These\npredictions form the coefficients of a linear objective that we would like to\noptimize under specified constraints. The fundamental question we address is\nhow to improve and combine such models in a way that outperforms the best of\nthem in the downstream optimization problem. We apply multicalibration\ntechniques that lead to two provably efficient and convergent algorithms. The\nfirst of these (the white box approach) requires being given models that map\nstates to output predictions, while the second (the \\emph{black box} approach)\nrequires only policies (mappings from states to solutions to the optimization\nproblem). For both, we provide convergence and utility guarantees. We conclude\nby investigating the performance and behavior of the two algorithms in a\ncontrolled experimental setting.\n",
        "authors": "Ira Globus-Harris; Varun Gupta; Michael Kearns; Aaron Roth",
        "status": 0,
        "relevancy": 0.4564235497196707,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17253",
        "date": "2024-05-27",
        "title": "Gaussian Embedding of Temporal Networks",
        "abstract": "  Representing the nodes of continuous-time temporal graphs in a\nlow-dimensional latent space has wide-ranging applications, from prediction to\nvisualization. Yet, analyzing continuous-time relational data with timestamped\ninteractions introduces unique challenges due to its sparsity. Merely embedding\nnodes as trajectories in the latent space overlooks this sparsity, emphasizing\nthe need to quantify uncertainty around the latent positions. In this paper, we\npropose TGNE (\\textbf{T}emporal \\textbf{G}aussian \\textbf{N}etwork\n\\textbf{E}mbedding), an innovative method that bridges two distinct strands of\nliterature: the statistical analysis of networks via Latent Space Models\n(LSM)\\cite{Hoff2002} and temporal graph machine learning. TGNE embeds nodes as\npiece-wise linear trajectories of Gaussian distributions in the latent space,\ncapturing both structural information and uncertainty around the trajectories.\nWe evaluate TGNE's effectiveness in reconstructing the original graph and\nmodelling uncertainty. The results demonstrate that TGNE generates competitive\ntime-varying embedding locations compared to common baselines for\nreconstructing unobserved edge interactions based on observed edges.\nFurthermore, the uncertainty estimates align with the time-varying degree\ndistribution in the network, providing valuable insights into the temporal\ndynamics of the graph. To facilitate reproducibility, we provide an open-source\nimplementation of TGNE at \\url{https://github.com/aida-ugent/tgne}.\n",
        "authors": "Raphaël Romero; Jefrey Lijffijt; Riccardo Rastelli; Marco Corneli; Tijl De Bie",
        "status": 0,
        "relevancy": 0.45577913674969794,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17053",
        "date": "2024-05-27",
        "title": "WirelessLLM: Empowering Large Language Models Towards Wireless\n  Intelligence",
        "abstract": "  The rapid evolution of wireless technologies and the growing complexity of\nnetwork infrastructures necessitate a paradigm shift in how communication\nnetworks are designed, configured, and managed. Recent advancements in Large\nLanguage Models (LLMs) have sparked interest in their potential to\nrevolutionize wireless communication systems. However, existing studies on LLMs\nfor wireless systems are limited to a direct application for telecom language\nunderstanding. To empower LLMs with knowledge and expertise in the wireless\ndomain, this paper proposes WirelessLLM, a comprehensive framework for adapting\nand enhancing LLMs to address the unique challenges and requirements of\nwireless communication networks. We first identify three foundational\nprinciples that underpin WirelessLLM: knowledge alignment, knowledge fusion,\nand knowledge evolution. Then, we investigate the enabling technologies to\nbuild WirelessLLM, including prompt engineering, retrieval augmented\ngeneration, tool usage, multi-modal pre-training, and domain-specific\nfine-tuning. Moreover, we present three case studies to demonstrate the\npractical applicability and benefits of WirelessLLM for solving typical\nproblems in wireless networks. Finally, we conclude this paper by highlighting\nkey challenges and outlining potential avenues for future research.\n",
        "authors": "Jiawei Shao; Jingwen Tong; Qiong Wu; Wei Guo; Zijian Li; Zehong Lin; Jun Zhang",
        "status": 0,
        "relevancy": 0.455027440264399,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17272",
        "date": "2024-05-27",
        "title": "DPN: Decoupling Partition and Navigation for Neural Solvers of Min-max\n  Vehicle Routing Problems",
        "abstract": "  The min-max vehicle routing problem (min-max VRP) traverses all given\ncustomers by assigning several routes and aims to minimize the length of the\nlongest route. Recently, reinforcement learning (RL)-based sequential planning\nmethods have exhibited advantages in solving efficiency and optimality.\nHowever, these methods fail to exploit the problem-specific properties in\nlearning representations, resulting in less effective features for decoding\noptimal routes. This paper considers the sequential planning process of min-max\nVRPs as two coupled optimization tasks: customer partition for different routes\nand customer navigation in each route (i.e., partition and navigation). To\neffectively process min-max VRP instances, we present a novel attention-based\nPartition-and-Navigation encoder (P&N Encoder) that learns distinct embeddings\nfor partition and navigation. Furthermore, we utilize an inherent symmetry in\ndecoding routes and develop an effective agent-permutation-symmetric (APS) loss\nfunction. Experimental results demonstrate that the proposed\nDecoupling-Partition-Navigation (DPN) method significantly surpasses existing\nlearning-based methods in both single-depot and multi-depot min-max VRPs. Our\ncode is available at\n",
        "authors": "Zhi Zheng; Shunyu Yao; Zhenkun Wang; Xialiang Tong; Mingxuan Yuan; Ke Tang",
        "status": 0,
        "relevancy": 0.453391192867578,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17523",
        "date": "2024-05-27",
        "title": "Locally Testing Model Detections for Semantic Global Concepts",
        "abstract": "  Ensuring the quality of black-box Deep Neural Networks (DNNs) has become ever\nmore significant, especially in safety-critical domains such as automated\ndriving. While global concept encodings generally enable a user to test a model\nfor a specific concept, linking global concept encodings to the local\nprocessing of single network inputs reveals their strengths and limitations.\nOur proposed framework global-to-local Concept Attribution (glCA) uses\napproaches from local (why a specific prediction originates) and global (how a\nmodel works generally) eXplainable Artificial Intelligence (xAI) to test DNNs\nfor a predefined semantical concept locally. The approach allows for\nconditioning local, post-hoc explanations on predefined semantic concepts\nencoded as linear directions in the model's latent space. Pixel-exact scoring\nconcerning the global concept usage assists the tester in further understanding\nthe model processing of single data points for the selected concept. Our\napproach has the advantage of fully covering the model-internal encoding of the\nsemantic concept and allowing the localization of relevant concept-related\ninformation. The results show major differences in the local perception and\nusage of individual global concept encodings and demand for further\ninvestigations regarding obtaining thorough semantic concept encodings.\n",
        "authors": "Franz Motzkus; Georgii Mikriukov; Christian Hellert; Ute Schmid",
        "status": 0,
        "relevancy": 0.4531931431896975,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17216",
        "date": "2024-05-27",
        "title": "Autoformalizing Euclidean Geometry",
        "abstract": "  Autoformalization involves automatically translating informal math into\nformal theorems and proofs that are machine-verifiable. Euclidean geometry\nprovides an interesting and controllable domain for studying autoformalization.\nIn this paper, we introduce a neuro-symbolic framework for autoformalizing\nEuclidean geometry, which combines domain knowledge, SMT solvers, and large\nlanguage models (LLMs). One challenge in Euclidean geometry is that informal\nproofs rely on diagrams, leaving gaps in texts that are hard to formalize. To\naddress this issue, we use theorem provers to fill in such diagrammatic\ninformation automatically, so that the LLM only needs to autoformalize the\nexplicit textual steps, making it easier for the model. We also provide\nautomatic semantic evaluation for autoformalized theorem statements. We\nconstruct LeanEuclid, an autoformalization benchmark consisting of problems\nfrom Euclid's Elements and the UniGeo dataset formalized in the Lean proof\nassistant. Experiments with GPT-4 and GPT-4V show the capability and\nlimitations of state-of-the-art LLMs on autoformalizing geometry problems. The\ndata and code are available at https://github.com/loganrjmurphy/LeanEuclid.\n",
        "authors": "Logan Murphy; Kaiyu Yang; Jialiang Sun; Zhaoyu Li; Anima Anandkumar; Xujie Si",
        "status": 0,
        "relevancy": 0.44660771314981684,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16792",
        "date": "2024-05-27",
        "title": "Laurel: Generating Dafny Assertions Using Large Language Models",
        "abstract": "  Dafny is a popular verification language, which automates proofs by\noutsourcing them to an SMT solver. This automation is not perfect, however, and\nthe solver often requires guidance in the form of helper assertions creating a\nburden for the proof engineer. In this paper, we propose Laurel, a tool that\nuses large language models (LLMs) to automatically generate helper assertions\nfor Dafny programs. To improve the success rate of LLMs in this task, we design\ntwo domain-specific prompting techniques. First, we help the LLM determine the\nlocation of the missing assertion by analyzing the verifier's error message and\ninserting an assertion placeholder at that location. Second, we provide the LLM\nwith example assertions from the same codebase, which we select based on a new\nlemma similarity metric. We evaluate our techniques on a dataset of helper\nassertions we extracted from three real-world Dafny codebases. Our evaluation\nshows that Laurel is able to generate over 50% of the required helper\nassertions given only a few attempts, making LLMs a usable and affordable tool\nto further automate practical program verification.\n",
        "authors": "Eric Mugnier; Emmanuel Anaya Gonzalez; Ranjit Jhala; Nadia Polikarpova; Yuanyuan Zhou",
        "status": 0,
        "relevancy": 0.44575798447962833,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16820",
        "date": "2024-05-27",
        "title": "Laboratory-Scale AI: Open-Weight Models are Competitive with ChatGPT\n  Even in Low-Resource Settings",
        "abstract": "  The rapid proliferation of generative AI has raised questions about the\ncompetitiveness of lower-parameter, locally tunable, open-weight models\nrelative to high-parameter, API-guarded, closed-weight models in terms of\nperformance, domain adaptation, cost, and generalization. Centering\nunder-resourced yet risk-intolerant settings in government, research, and\nhealthcare, we see for-profit closed-weight models as incompatible with\nrequirements for transparency, privacy, adaptability, and standards of\nevidence. Yet the performance penalty in using open-weight models, especially\nin low-data and low-resource settings, is unclear.\n  We assess the feasibility of using smaller, open-weight models to replace\nGPT-4-Turbo in zero-shot, few-shot, and fine-tuned regimes, assuming access to\nonly a single, low-cost GPU. We assess value-sensitive issues around bias,\nprivacy, and abstention on three additional tasks relevant to those topics. We\nfind that with relatively low effort, very low absolute monetary cost, and\nrelatively little data for fine-tuning, small open-weight models can achieve\ncompetitive performance in domain-adapted tasks without sacrificing generality.\nWe then run experiments considering practical issues in bias, privacy, and\nhallucination risk, finding that open models offer several benefits over closed\nmodels. We intend this work as a case study in understanding the opportunity\ncost of reproducibility and transparency over for-profit state-of-the-art zero\nshot performance, finding this cost to be marginal under realistic settings.\n",
        "authors": "Robert Wolfe; Isaac Slaughter; Bin Han; Bingbing Wen; Yiwei Yang; Lucas Rosenblatt; Bernease Herman; Eva Brown; Zening Qu; Nic Weber; Bill Howe",
        "status": 0,
        "relevancy": 0.44423645899245234,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17607",
        "date": "2024-05-27",
        "title": "Advancing Cultural Inclusivity: Optimizing Embedding Spaces for Balanced\n  Music Recommendations",
        "abstract": "  Popularity bias in music recommendation systems -- where artists and tracks\nwith the highest listen counts are recommended more often -- can also propagate\nbiases along demographic and cultural axes. In this work, we identify these\nbiases in recommendations for artists from underrepresented cultural groups in\nprototype-based matrix factorization methods. Unlike traditional matrix\nfactorization methods, prototype-based approaches are interpretable. This\nallows us to directly link the observed bias in recommendations for minority\nartists (the effect) to specific properties of the embedding space (the cause).\nWe mitigate popularity bias in music recommendation through capturing both\nusers' and songs' cultural nuances in the embedding space. To address these\nchallenges while maintaining recommendation quality, we propose two novel\nenhancements to the embedding space: i) we propose an approach to filter-out\nthe irrelevant prototypes used to represent each user and item to improve\ngeneralizability, and ii) we introduce regularization techniques to reinforce a\nmore uniform distribution of prototypes within the embedding space. Our results\ndemonstrate significant improvements in reducing popularity bias and enhancing\ndemographic and cultural fairness in music recommendations while achieving\ncompetitive -- if not better -- overall performance.\n",
        "authors": "Armin Moradi; Nicola Neophytou; Golnoosh Farnadi",
        "status": 0,
        "relevancy": 0.4365798993231671,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16847",
        "date": "2024-05-27",
        "title": "TokenUnify: Scalable Autoregressive Visual Pre-training with Mixture\n  Token Prediction",
        "abstract": "  Autoregressive next-token prediction is a standard pretraining method for\nlarge-scale language models, but its application to vision tasks is hindered by\nthe non-sequential nature of image data, leading to cumulative errors. Most\nvision models employ masked autoencoder (MAE) based pretraining, which faces\nscalability issues. To address these challenges, we introduce\n\\textbf{TokenUnify}, a novel pretraining method that integrates random token\nprediction, next-token prediction, and next-all token prediction. We provide\ntheoretical evidence demonstrating that TokenUnify mitigates cumulative errors\nin visual autoregression. Cooperated with TokenUnify, we have assembled a\nlarge-scale electron microscopy (EM) image dataset with ultra-high resolution,\nideal for creating spatially correlated long sequences. This dataset includes\nover 120 million annotated voxels, making it the largest neuron segmentation\ndataset to date and providing a unified benchmark for experimental validation.\nLeveraging the Mamba network inherently suited for long-sequence modeling on\nthis dataset, TokenUnify not only reduces the computational complexity but also\nleads to a significant 45\\% improvement in segmentation performance on\ndownstream EM neuron segmentation tasks compared to existing methods.\nFurthermore, TokenUnify demonstrates superior scalability over MAE and\ntraditional autoregressive methods, effectively bridging the gap between\npretraining strategies for language and vision models. Code is available at\n\\url{https://github.com/ydchen0806/TokenUnify}.\n",
        "authors": "Yinda Chen; Haoyuan Shi; Xiaoyu Liu; Te Shi; Ruobing Zhang; Dong Liu; Zhiwei Xiong; Feng Wu",
        "status": 0,
        "relevancy": 0.4312004611110959,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17610",
        "date": "2024-05-27",
        "title": "Explainable machine learning multi-label classification of Spanish legal\n  judgements",
        "abstract": "  Artificial Intelligence techniques such as Machine Learning (ML) have not\nbeen exploited to their maximum potential in the legal domain. This has been\npartially due to the insufficient explanations they provided about their\ndecisions. Automatic expert systems with explanatory capabilities can be\nspecially useful when legal practitioners search jurisprudence to gather\ncontextual knowledge for their cases. Therefore, we propose a hybrid system\nthat applies ML for multi-label classification of judgements (sentences) and\nvisual and natural language descriptions for explanation purposes, boosted by\nNatural Language Processing techniques and deep legal reasoning to identify the\nentities, such as the parties, involved. We are not aware of any prior work on\nautomatic multi-label classification of legal judgements also providing natural\nlanguage explanations to the end-users with comparable overall quality. Our\nsolution achieves over 85 % micro precision on a labelled data set annotated by\nlegal experts. This endorses its interest to relieve human experts from\nmonotonous labour-intensive legal classification tasks.\n",
        "authors": "Francisco de Arriba-Pérez; Silvia García-Méndez; Francisco J. González-Castaño; Jaime González-González",
        "status": 0,
        "relevancy": 0.43032799429604274,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17514",
        "date": "2024-05-27",
        "title": "AbstractBeam: Enhancing Bottom-Up Program Synthesis using Library\n  Learning",
        "abstract": "  LambdaBeam is a state-of-the-art execution-guided algorithm for program\nsynthesis that incorporates higher-order functions, lambda functions, and\niterative loops into the Domain-Specific Language (DSL). LambdaBeam generates\nevery program from the start. Yet, many program blocks or subprograms occur\nfrequently in a given domain, e.g., loops to traverse a list. Thus, repeating\nprograms can be used to enhance the synthesis algorithm. However, LambdaBeam\nfails to leverage this potential. For this purpose, we introduce AbstractBeam:\nA novel program synthesis framework that employs Library Learning to identify\nsuch program repetitions, integrates them into the DSL, and thus utilizes their\npotential to boost LambdaBeam's synthesis algorithm. Our experimental\nevaluations demonstrate that AbstractBeam significantly improves LambdaBeam's\nperformance in the LambdaBeam integer list manipulation domain. Additionally,\nAbstractBeam's program generation is more efficient compared to LambdaBeam's\nsynthesis. Finally, our findings indicate that Library Learning is effective in\ndomains not specifically crafted to highlight its benefits.\n",
        "authors": "Janis Zenkner; Lukas Dierkes; Tobias Sesterhenn; Chrisitan Bartelt",
        "status": 0,
        "relevancy": 0.42920826620517527,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17358",
        "date": "2024-05-27",
        "title": "Rethinking Transformers in Solving POMDPs",
        "abstract": "  Sequential decision-making algorithms such as reinforcement learning (RL) in\nreal-world scenarios inevitably face environments with partial observability.\nThis paper scrutinizes the effectiveness of a popular architecture, namely\nTransformers, in Partially Observable Markov Decision Processes (POMDPs) and\nreveals its theoretical limitations. We establish that regular languages, which\nTransformers struggle to model, are reducible to POMDPs. This poses a\nsignificant challenge for Transformers in learning POMDP-specific inductive\nbiases, due to their lack of inherent recurrence found in other models like\nRNNs. This paper casts doubt on the prevalent belief in Transformers as\nsequence models for RL and proposes to introduce a point-wise recurrent\nstructure. The Deep Linear Recurrent Unit (LRU) emerges as a well-suited\nalternative for Partially Observable RL, with empirical results highlighting\nthe sub-optimal performance of the Transformer and considerable strength of\nLRU.\n",
        "authors": "Chenhao Lu; Ruizhe Shi; Yuyao Liu; Kaizhe Hu; Simon S. Du; Huazhe Xu",
        "status": 0,
        "relevancy": 0.42899627156400677,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16883",
        "date": "2024-05-27",
        "title": "Scorch: A Library for Sparse Deep Learning",
        "abstract": "  The rapid growth in the size of deep learning models strains the capabilities\nof traditional dense computation paradigms. Leveraging sparse computation has\nbecome increasingly popular for training and deploying large-scale models, but\nexisting deep learning frameworks lack extensive support for sparse operations.\nTo bridge this gap, we introduce Scorch, a library that seamlessly integrates\nefficient sparse tensor computation into the PyTorch ecosystem, with an initial\nfocus on inference workloads on CPUs. Scorch provides a flexible and intuitive\ninterface for sparse tensors, supporting diverse sparse data structures. Scorch\nintroduces a compiler stack that automates key optimizations, including\nautomatic loop ordering, tiling, and format inference. Combined with a runtime\nthat adapts its execution to both dense and sparse data, Scorch delivers\nsubstantial speedups over hand-written PyTorch Sparse (torch.sparse) operations\nwithout sacrificing usability. More importantly, Scorch enables efficient\ncomputation of complex sparse operations that lack hand-optimized PyTorch\nimplementations. This flexibility is crucial for exploring novel sparse\narchitectures. We demonstrate Scorch's ease of use and performance gains on\ndiverse deep learning models across multiple domains. With only minimal code\nchanges, Scorch achieves 1.05-5.78x speedups over PyTorch Sparse on end-to-end\ntasks. Scorch's seamless integration and performance gains make it a valuable\naddition to the PyTorch ecosystem. We believe Scorch will enable wider\nexploration of sparsity as a tool for scaling deep learning and inform the\ndevelopment of other sparse libraries.\n",
        "authors": "Bobby Yan; Alexander J. Root; Trevor Gale; David Broman; Fredrik Kjolstad",
        "status": 0,
        "relevancy": 0.4249211758629958,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17638",
        "date": "2024-05-27",
        "title": "The surprising efficiency of temporal difference learning for rare event\n  prediction",
        "abstract": "  We quantify the efficiency of temporal difference (TD) learning over the\ndirect, or Monte Carlo (MC), estimator for policy evaluation in reinforcement\nlearning, with an emphasis on estimation of quantities related to rare events.\nPolicy evaluation is complicated in the rare event setting by the long\ntimescale of the event and by the need for \\emph{relative accuracy} in\nestimates of very small values. Specifically, we focus on least-squares TD\n(LSTD) prediction for finite state Markov chains, and show that LSTD can\nachieve relative accuracy far more efficiently than MC. We prove a central\nlimit theorem for the LSTD estimator and upper bound the \\emph{relative\nasymptotic variance} by simple quantities characterizing the connectivity of\nstates relative to the transition probabilities between them. Using this bound,\nwe show that, even when both the timescale of the rare event and the relative\naccuracy of the MC estimator are exponentially large in the number of states,\nLSTD maintains a fixed level of relative accuracy with a total number of\nobserved transitions of the Markov chain that is only \\emph{polynomially} large\nin the number of states.\n",
        "authors": "Xiaoou Cheng; Jonathan Weare",
        "status": 0,
        "relevancy": 0.42290361176635993,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16730",
        "date": "2024-05-27",
        "title": "Latent Energy-Based Odyssey: Black-Box Optimization via Expanded\n  Exploration in the Energy-Based Latent Space",
        "abstract": "  Offline Black-Box Optimization (BBO) aims at optimizing a black-box function\nusing the knowledge from a pre-collected offline dataset of function values and\ncorresponding input designs. However, the high-dimensional and\nhighly-multimodal input design space of black-box function pose inherent\nchallenges for most existing methods that model and operate directly upon input\ndesigns. These issues include but are not limited to high sample complexity,\nwhich relates to inaccurate approximation of black-box function; and\ninsufficient coverage and exploration of input design modes, which leads to\nsuboptimal proposal of new input designs. In this work, we consider finding a\nlatent space that serves as a compressed yet accurate representation of the\ndesign-value joint space, enabling effective latent exploration of high-value\ninput design modes. To this end, we formulate an learnable energy-based latent\nspace, and propose Noise-intensified Telescoping density-Ratio Estimation\n(NTRE) scheme for variational learning of an accurate latent space model\nwithout costly Markov Chain Monte Carlo. The optimization process is then\nexploration of high-value designs guided by the learned energy-based model in\nthe latent space, formulated as gradient-based sampling from a\nlatent-variable-parameterized inverse model. We show that our particular\nparameterization encourages expanded exploration around high-value design\nmodes, motivated by inversion thinking of a fundamental result of conditional\ncovariance matrix typically used for variance reduction. We observe that our\nmethod, backed by an accurately learned informative latent space and an\nexpanding-exploration model design, yields significant improvements over strong\nprevious methods on both synthetic and real world datasets such as the\ndesign-bench suite.\n",
        "authors": "Peiyu Yu; Dinghuai Zhang; Hengzhi He; Xiaojian Ma; Ruiyao Miao; Yifan Lu; Yasi Zhang; Deqian Kong; Ruiqi Gao; Jianwen Xie; Guang Cheng; Ying Nian Wu",
        "status": 0,
        "relevancy": 0.4210100742843319,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17279",
        "date": "2024-05-27",
        "title": "Socially-Aware Shared Control Navigation for Assistive Mobile Robots in\n  the Built Environment",
        "abstract": "  As the number of Persons with Disabilities (PWD), particularly those with one\nor more physical impairments, increases, there is an increasing demand for\nassistive robotic technologies that can support independent mobility in the\nbuilt environment and reduce the burden on caregivers. Current assistive\nmobility platforms (e.g., robotic wheelchairs) often fail to incorporate user\npreferences and control, leading to reduced trust and efficiency. Existing\nshared control algorithms do not allow the incorporation of the user control\npreferences inside the navigation framework or the path planning algorithm. In\naddition, existing dynamic local planner algorithms for robotic wheelchairs do\nnot take into account the social spaces of people, potentially leading such\nplatforms to infringe upon these areas and cause discomfort. To address these\nconcerns, this work introduces a novel socially-aware shared autonomy-based\nnavigation system for assistive mobile robotic platforms.\n  Our navigation framework comprises a Global Planner and a Local Planner. To\nimplement the Global Planner, the proposed approach introduces a novel User\nPreference Field (UPF) theory within its global planning framework, explicitly\nacknowledging user preferences to adeptly navigate away from congested areas.\nFor the Local Planner, we propose a Socially-aware Shared Control-based Model\nPredictive Control with Dynamic Control Barrier Function (SS-MPC-DCBF) to\nadjust movements in real-time, integrating user preferences for safer, more\nautonomous navigation. Evaluation results show that our Global Planner aligns\nclosely with user preferences compared to baselines, and our Local Planner\ndemonstrates enhanced safety and efficiency in dynamic and static scenarios.\nThis integrated approach fosters trust and autonomy, crucial for the acceptance\nof assistive mobility technologies in the built environment.\n",
        "authors": "Yifan Xu; Qianwei Wang; Vineet Kamat; Carol Menassa",
        "status": 0,
        "relevancy": 0.42095704544333123,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17708",
        "date": "2024-05-27",
        "title": "OPERA: Automatic Offline Policy Evaluation with Re-weighted Aggregates\n  of Multiple Estimators",
        "abstract": "  Offline policy evaluation (OPE) allows us to evaluate and estimate a new\nsequential decision-making policy's performance by leveraging historical\ninteraction data collected from other policies. Evaluating a new policy online\nwithout a confident estimate of its performance can lead to costly, unsafe, or\nhazardous outcomes, especially in education and healthcare. Several OPE\nestimators have been proposed in the last decade, many of which have\nhyperparameters and require training. Unfortunately, choosing the best OPE\nalgorithm for each task and domain is still unclear. In this paper, we propose\na new algorithm that adaptively blends a set of OPE estimators given a dataset\nwithout relying on an explicit selection using a statistical procedure. We\nprove that our estimator is consistent and satisfies several desirable\nproperties for policy evaluation. Additionally, we demonstrate that when\ncompared to alternative approaches, our estimator can be used to select\nhigher-performing policies in healthcare and robotics. Our work contributes to\nimproving ease of use for a general-purpose, estimator-agnostic, off-policy\nevaluation framework for offline RL.\n",
        "authors": "Allen Nie; Yash Chandak; Christina J. Yuan; Anirudhan Badrinath; Yannis Flet-Berliac; Emma Brunskil",
        "status": 0,
        "relevancy": 0.4208149681132872,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17182",
        "date": "2024-05-27",
        "title": "Exploring the Performance of Continuous-Time Dynamic Link Prediction\n  Algorithms",
        "abstract": "  Dynamic Link Prediction (DLP) addresses the prediction of future links in\nevolving networks. However, accurately portraying the performance of DLP\nalgorithms poses challenges that might impede progress in the field.\nImportantly, common evaluation pipelines usually calculate ranking or binary\nclassification metrics, where the scores of observed interactions (positives)\nare compared with those of randomly generated ones (negatives). However, a\nsingle metric is not sufficient to fully capture the differences between DLP\nalgorithms, and is prone to overly optimistic performance evaluation. Instead,\nan in-depth evaluation should reflect performance variations across different\nnodes, edges, and time segments. In this work, we contribute tools to perform\nsuch a comprehensive evaluation. (1) We propose Birth-Death diagrams, a simple\nbut powerful visualization technique that illustrates the effect of time-based\ntrain-test splitting on the difficulty of DLP on a given dataset. (2) We\ndescribe an exhaustive taxonomy of negative sampling methods that can be used\nat evaluation time. (3) We carry out an empirical study of the effect of the\ndifferent negative sampling strategies. Our comparison between heuristics and\nstate-of-the-art memory-based methods on various real-world datasets confirms a\nstrong effect of using different negative sampling strategies on the test Area\nUnder the Curve (AUC). Moreover, we conduct a visual exploration of the\nprediction, with additional insights on which different types of errors are\nprominent over time.\n",
        "authors": "Raphaël Romero; Maarten Buyl; Tijl De Bie; Jefrey Lijffijt",
        "status": 0,
        "relevancy": 0.4138786378625492,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17403",
        "date": "2024-05-27",
        "title": "A Closer Look at Time Steps is Worthy of Triple Speed-Up for Diffusion\n  Model Training",
        "abstract": "  Training diffusion models is always a computation-intensive task. In this\npaper, we introduce a novel speed-up method for diffusion model training,\ncalled, which is based on a closer look at time steps. Our key findings are: i)\nTime steps can be empirically divided into acceleration, deceleration, and\nconvergence areas based on the process increment. ii) These time steps are\nimbalanced, with many concentrated in the convergence area. iii) The\nconcentrated steps provide limited benefits for diffusion training. To address\nthis, we design an asymmetric sampling strategy that reduces the frequency of\nsteps from the convergence area while increasing the sampling probability for\nsteps from other areas. Additionally, we propose a weighting strategy to\nemphasize the importance of time steps with rapid-change process increments. As\na plug-and-play and architecture-agnostic approach, SpeeD consistently achieves\n3-times acceleration across various diffusion architectures, datasets, and\ntasks. Notably, due to its simple design, our approach significantly reduces\nthe cost of diffusion model training with minimal overhead. Our research\nenables more researchers to train diffusion models at a lower cost.\n",
        "authors": "Kai Wang; Yukun Zhou; Mingjia Shi; Zhihang Yuan; Yuzhang Shang; Xiaojiang Peng; Hanwang Zhang; Yang You",
        "status": 0,
        "relevancy": 0.41102471889139214,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16761",
        "date": "2024-05-27",
        "title": "Masked Face Recognition with Generative-to-Discriminative\n  Representations",
        "abstract": "  Masked face recognition is important for social good but challenged by\ndiverse occlusions that cause insufficient or inaccurate representations. In\nthis work, we propose a unified deep network to learn\ngenerative-to-discriminative representations for facilitating masked face\nrecognition. To this end, we split the network into three modules and learn\nthem on synthetic masked faces in a greedy module-wise pretraining manner.\nFirst, we leverage a generative encoder pretrained for face inpainting and\nfinetune it to represent masked faces into category-aware descriptors.\nAttribute to the generative encoder's ability in recovering context\ninformation, the resulting descriptors can provide occlusion-robust\nrepresentations for masked faces, mitigating the effect of diverse masks. Then,\nwe incorporate a multi-layer convolutional network as a discriminative reformer\nand learn it to convert the category-aware descriptors into identity-aware\nvectors, where the learning is effectively supervised by distilling relation\nknowledge from off-the-shelf face recognition model. In this way, the\ndiscriminative reformer together with the generative encoder serves as the\npretrained backbone, providing general and discriminative representations\ntowards masked faces. Finally, we cascade one fully-connected layer following\nby one softmax layer into a feature classifier and finetune it to identify the\nreformed identity-aware vectors. Extensive experiments on synthetic and\nrealistic datasets demonstrate the effectiveness of our approach in recognizing\nmasked faces.\n",
        "authors": "Shiming Ge; Weijia Guo; Chenyu Li; Junzheng Zhang; Yong Li; Dan Zeng",
        "status": 0,
        "relevancy": 0.40972512199191435,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17139",
        "date": "2024-05-27",
        "title": "Synergy and Diversity in CLIP: Enhancing Performance Through Adaptive\n  Backbone Ensembling",
        "abstract": "  Contrastive Language-Image Pretraining (CLIP) stands out as a prominent\nmethod for image representation learning. Various architectures, from vision\ntransformers (ViTs) to convolutional networks (ResNets) have been trained with\nCLIP to serve as general solutions to diverse vision tasks. This paper explores\nthe differences across various CLIP-trained vision backbones. Despite using the\nsame data and training objective, we find that these architectures have notably\ndifferent representations, different classification performance across\ndatasets, and different robustness properties to certain types of image\nperturbations. Our findings indicate a remarkable possible synergy across\nbackbones by leveraging their respective strengths. In principle,\nclassification accuracy could be improved by over 40 percentage with an\ninformed selection of the optimal backbone per test example.Using this insight,\nwe develop a straightforward yet powerful approach to adaptively ensemble\nmultiple backbones. The approach uses as few as one labeled example per class\nto tune the adaptive combination of backbones. On a large collection of\ndatasets, the method achieves a remarkable increase in accuracy of up to 39.1%\nover the best single backbone, well beyond traditional ensembles\n",
        "authors": "Cristian Rodriguez-Opazo; Ehsan Abbasnejad; Damien Teney; Edison Marrese-Taylor; Hamed Damirchi; Anton van den Hengel",
        "status": 0,
        "relevancy": 0.4096510192896936,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17604",
        "date": "2024-05-27",
        "title": "LoRA-XS: Low-Rank Adaptation with Extremely Small Number of Parameters",
        "abstract": "  The recent trend in scaling language models has led to a growing demand for\nparameter-efficient tuning (PEFT) methods such as LoRA (Low-Rank Adaptation).\nLoRA consistently matches or surpasses the full fine-tuning baseline with fewer\nparameters. However, handling numerous task-specific or user-specific LoRA\nmodules on top of a base model still presents significant storage challenges.\nTo address this, we introduce LoRA-XS (Low-Rank Adaptation with eXtremely Small\nnumber of parameters), a novel approach leveraging Singular Value Decomposition\n(SVD) for parameter-efficient fine-tuning. LoRA-XS introduces a small r x r\nweight matrix between frozen LoRA matrices, which are constructed by SVD of the\noriginal weight matrix. Training only r x r weight matrices ensures\nindependence from model dimensions, enabling more parameter-efficient\nfine-tuning, especially for larger models. LoRA-XS achieves a remarkable\nreduction of trainable parameters by over 100x in 7B models compared to LoRA.\nOur benchmarking across various scales, including GLUE, GSM8k, and MATH\nbenchmarks, shows that our approach outperforms LoRA and recent\nstate-of-the-art approaches like VeRA in terms of parameter efficiency while\nmaintaining competitive performance.\n",
        "authors": "Klaudia Bałazy; Mohammadreza Banaei; Karl Aberer; Jacek Tabor",
        "status": 0,
        "relevancy": 0.40911810903546764,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17187",
        "date": "2024-05-27",
        "title": "Memorize What Matters: Emergent Scene Decomposition from Multitraverse",
        "abstract": "  Humans naturally retain memories of permanent elements, while ephemeral\nmoments often slip through the cracks of memory. This selective retention is\ncrucial for robotic perception, localization, and mapping. To endow robots with\nthis capability, we introduce 3D Gaussian Mapping (3DGM), a self-supervised,\ncamera-only offline mapping framework grounded in 3D Gaussian Splatting. 3DGM\nconverts multitraverse RGB videos from the same region into a Gaussian-based\nenvironmental map while concurrently performing 2D ephemeral object\nsegmentation. Our key observation is that the environment remains consistent\nacross traversals, while objects frequently change. This allows us to exploit\nself-supervision from repeated traversals to achieve environment-object\ndecomposition. More specifically, 3DGM formulates multitraverse environmental\nmapping as a robust differentiable rendering problem, treating pixels of the\nenvironment and objects as inliers and outliers, respectively. Using robust\nfeature distillation, feature residuals mining, and robust optimization, 3DGM\njointly performs 2D segmentation and 3D mapping without human intervention. We\nbuild the Mapverse benchmark, sourced from the Ithaca365 and nuPlan datasets,\nto evaluate our method in unsupervised 2D segmentation, 3D reconstruction, and\nneural rendering. Extensive results verify the effectiveness and potential of\nour method for self-driving and robotics.\n",
        "authors": "Yiming Li; Zehong Wang; Yue Wang; Zhiding Yu; Zan Gojcic; Marco Pavone; Chen Feng; Jose M. Alvarez",
        "status": 0,
        "relevancy": 0.40309342238285495,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17202",
        "date": "2024-05-27",
        "title": "Efficient multi-prompt evaluation of LLMs",
        "abstract": "  Most popular benchmarks for comparing LLMs rely on a limited set of prompt\ntemplates, which may not fully capture the LLMs' abilities and can affect the\nreproducibility of results on leaderboards. Many recent works empirically\nverify prompt sensitivity and advocate for changes in LLM evaluation. In this\npaper, we consider the problem of estimating the performance distribution\nacross many prompt variants instead of finding a single prompt to evaluate\nwith. We introduce PromptEval, a method for estimating performance across a\nlarge set of prompts borrowing strength across prompts and examples to produce\naccurate estimates under practical evaluation budgets. The resulting\ndistribution can be used to obtain performance quantiles to construct various\nrobust performance metrics (e.g., top 95% quantile or median). We prove that\nPromptEval consistently estimates the performance distribution and demonstrate\nits efficacy empirically on three prominent LLM benchmarks: MMLU, BIG-bench\nHard, and LMentry. For example, PromptEval can accurately estimate performance\nquantiles across 100 prompt templates on MMLU with a budget equivalent to two\nsingle-prompt evaluations. Our code and data can be found at\nhttps://github.com/felipemaiapolo/prompt-eval.\n",
        "authors": "Felipe Maia Polo; Ronald Xu; Lucas Weber; Mírian Silva; Onkar Bhardwaj; Leshem Choshen; Allysson Flavio Melo de Oliveira; Yuekai Sun; Mikhail Yurochkin",
        "status": 0,
        "relevancy": 0.40162343599569783,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16783",
        "date": "2024-05-27",
        "title": "TrojFM: Resource-efficient Backdoor Attacks against Very Large\n  Foundation Models",
        "abstract": "  One key challenge in backdoor attacks against large foundation models is the\nresource limits. Backdoor attacks usually require retraining the target model,\nwhich is impractical for very large foundation models. Existing backdoor\nattacks are mainly designed for supervised classifiers or small foundation\nmodels (e.g., BERT). None of these attacks has successfully compromised a very\nlarge foundation model, such as Llama-3-70B, especially with limited\ncomputational resources. In this paper, we propose TrojFM, a novel backdoor\nattack tailored for very large foundation models. Our primary technical\ncontribution is the development of a novel backdoor injection method. This\nmethod forces a backdoored model to generate similar hidden representations for\npoisoned inputs regardless of their actual semantics. Our approach injects such\nbackdoors by fine-tuning only a very small proportion of model parameters. This\nenables TrojFM to efficiently launch downstream task-agnostic backdoor attacks\nagainst very large foundation models under limited computational resources.\nMoreover, we optimize the fine-tuning process with our customized QLoRA\ntechnique, enabling launching our attack via only~\\textit{one A100 GPU}.\nFurthermore, we design a new trigger injection method to ensure our attack\nstealthiness. Through extensive experiments, we first demonstrate that TrojFM\ncan launch effective backdoor attacks against widely used large GPT-style\nmodels without jeopardizing their normal functionalities (and outperforming\nexisting attacks on BERT-style models). Furthermore, we show that TrojFM is\nresilient to SOTA defenses and is insensitive to changes in key\nhyper-parameters. Finally, we conduct a resource analysis to quantify that our\nmethod can significantly save computational and memory costs compared to\nexisting backdoor attacks.\n",
        "authors": "Yuzhou. Nie; Yanting. Wang; Jinyuan. Jia; Michael J. De Lucia; Nathaniel D. Bastian; Wenbo. Guo; Dawn. Song",
        "status": 0,
        "relevancy": 0.40051467139857766,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17293",
        "date": "2024-05-27",
        "title": "Efficient Ensembles Improve Training Data Attribution",
        "abstract": "  Training data attribution (TDA) methods aim to quantify the influence of\nindividual training data points on the model predictions, with broad\napplications in data-centric AI, such as mislabel detection, data selection,\nand copyright compensation. However, existing methods in this field, which can\nbe categorized as retraining-based and gradient-based, have struggled with the\ntrade-off between computational efficiency and attribution efficacy.\nRetraining-based methods can accurately attribute complex non-convex models but\nare computationally prohibitive, while gradient-based methods are efficient but\noften fail for non-convex models. Recent research has shown that augmenting\ngradient-based methods with ensembles of multiple independently trained models\ncan achieve significantly better attribution efficacy. However, this approach\nremains impractical for very large-scale applications.\n  In this work, we discover that expensive, fully independent training is\nunnecessary for ensembling the gradient-based methods, and we propose two\nefficient ensemble strategies, DROPOUT ENSEMBLE and LORA ENSEMBLE, alternative\nto naive independent ensemble. These strategies significantly reduce training\ntime (up to 80%), serving time (up to 60%), and space cost (up to 80%) while\nmaintaining similar attribution efficacy to the naive independent ensemble. Our\nextensive experimental results demonstrate that the proposed strategies are\neffective across multiple TDA methods on diverse datasets and models, including\ngenerative settings, significantly advancing the Pareto frontier of TDA methods\nwith better computational efficiency and attribution efficacy.\n",
        "authors": "Junwei Deng; Ting-Wei Li; Shichang Zhang; Jiaqi Ma",
        "status": 0,
        "relevancy": 0.39765589259092715,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16887",
        "date": "2024-05-27",
        "title": "A Large Language Model-based multi-agent manufacturing system for\n  intelligent shopfloor",
        "abstract": "  As productivity advances, the demand of customers for multi-variety and\nsmall-batch production is increasing, thereby putting forward higher\nrequirements for manufacturing systems. When production tasks frequent changes\ndue to this demand, traditional manufacturing systems often cannot response\npromptly. The multi-agent manufacturing system is proposed to address this\nproblem. However, because of technical limitations, the negotiation among\nagents in this kind of system is realized through predefined heuristic rules,\nwhich is not intelligent enough to deal with the multi-variety and small batch\nproduction. To this end, a Large Language Model-based (LLM-based) multi-agent\nmanufacturing system for intelligent shopfloor is proposed in the present\nstudy. This system delineates the diverse agents and defines their\ncollaborative methods. The roles of the agents encompass Machine Server Agent\n(MSA), Bid Inviter Agent (BIA), Bidder Agent (BA), Thinking Agent (TA), and\nDecision Agent (DA). Due to the support of LLMs, TA and DA acquire the ability\nof analyzing the shopfloor condition and choosing the most suitable machine, as\nopposed to executing a predefined program artificially. The negotiation between\nBAs and BIA is the most crucial step in connecting manufacturing resources.\nWith the support of TA and DA, BIA will finalize the distribution of orders,\nrelying on the information of each machine returned by BA. MSAs bears the\nresponsibility for connecting the agents with the physical shopfloor. This\nsystem aims to distribute and transmit workpieces through the collaboration of\nthe agents with these distinct roles, distinguishing it from other scheduling\napproaches. Comparative experiments were also conducted to validate the\nperformance of this system.\n",
        "authors": "Zhen Zhao; Dunbing Tang; Haihua Zhu; Zequn Zhang; Kai Chen; Changchun Liu; Yuchen Ji",
        "status": 0,
        "relevancy": 0.39624565173825943,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17051",
        "date": "2024-05-27",
        "title": "BeamVQ: Aligning Space-Time Forecasting Model via Self-training on\n  Physics-aware Metrics",
        "abstract": "  Data-driven deep learning has emerged as the new paradigm to model complex\nphysical space-time systems. These data-driven methods learn patterns by\noptimizing statistical metrics and tend to overlook the adherence to physical\nlaws, unlike traditional model-driven numerical methods. Thus, they often\ngenerate predictions that are not physically realistic. On the other hand, by\nsampling a large amount of high quality predictions from a data-driven model,\nsome predictions will be more physically plausible than the others and closer\nto what will happen in the future. Based on this observation, we propose\n\\emph{Beam search by Vector Quantization} (BeamVQ) to enhance the physical\nalignment of data-driven space-time forecasting models. The key of BeamVQ is to\ntrain model on self-generated samples filtered with physics-aware metrics. To\nbe flexibly support different backbone architectures, BeamVQ leverages a code\nbank to transform any encoder-decoder model to the continuous state space into\ndiscrete codes. Afterwards, it iteratively employs beam search to sample\nhigh-quality sequences, retains those with the highest physics-aware scores,\nand trains model on the new dataset. Comprehensive experiments show that BeamVQ\nnot only gave an average statistical skill score boost for more than 32% for\nten backbones on five datasets, but also significantly enhances physics-aware\nmetrics.\n",
        "authors": "Hao Wu; Xingjian Shi; Ziyue Huang; Penghao Zhao; Wei Xiong; Jinbao Xue; Yangyu Tao; Xiaomeng Huang; Weiyan Wang",
        "status": 0,
        "relevancy": 0.39275063042312974,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17516",
        "date": "2024-05-27",
        "title": "Time Elastic Neural Networks",
        "abstract": "  We introduce and detail an atypical neural network architecture, called time\nelastic neural network (teNN), for multivariate time series classification. The\nnovelty compared to classical neural network architecture is that it explicitly\nincorporates time warping ability, as well as a new way of considering\nattention. In addition, this architecture is capable of learning a dropout\nstrategy, thus optimizing its own architecture.Behind the design of this\narchitecture, our overall objective is threefold: firstly, we are aiming at\nimproving the accuracy of instance based classification approaches that shows\nquite good performances as far as enough training data is available. Secondly\nwe seek to reduce the computational complexity inherent to these methods to\nimprove their scalability. Ideally, we seek to find an acceptable balance\nbetween these first two criteria. And finally, we seek to enhance the\nexplainability of the decision provided by this kind of neural architecture.The\nexperiment demonstrates that the stochastic gradient descent implemented to\ntrain a teNN is quite effective. To the extent that the selection of some\ncritical meta-parameters is correct, convergence is generally smooth and\nfast.While maintaining good accuracy, we get a drastic gain in scalability by\nfirst reducing the required number of reference time series, i.e. the number of\nteNN cells required. Secondly, we demonstrate that, during the training\nprocess, the teNN succeeds in reducing the number of neurons required within\neach cell. Finally, we show that the analysis of the activation and attention\nmatrices as well as the reference time series after training provides relevant\ninformation to interpret and explain the classification results.The comparative\nstudy that we have carried out and which concerns around thirty diverse and\nmultivariate datasets shows that the teNN obtains results comparable to those\nof the state of the art, in particular similar to those of a network mixing\nLSTM and CNN architectures for example.\n",
        "authors": "Pierre-François Marteau",
        "status": 0,
        "relevancy": 0.39145383705283754,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17097",
        "date": "2024-05-27",
        "title": "Evaluation of Multi-task Uncertainties in Joint Semantic Segmentation\n  and Monocular Depth Estimation",
        "abstract": "  While a number of promising uncertainty quantification methods have been\nproposed to address the prevailing shortcomings of deep neural networks like\noverconfidence and lack of explainability, quantifying predictive uncertainties\nin the context of joint semantic segmentation and monocular depth estimation\nhas not been explored yet. Since many real-world applications are multi-modal\nin nature and, hence, have the potential to benefit from multi-task learning,\nthis is a substantial gap in current literature. To this end, we conduct a\ncomprehensive series of experiments to study how multi-task learning influences\nthe quality of uncertainty estimates in comparison to solving both tasks\nseparately.\n",
        "authors": "Steven Landgraf; Markus Hillemann; Theodor Kapler; Markus Ulrich",
        "status": 0,
        "relevancy": 0.3913547533545545,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17399",
        "date": "2024-05-27",
        "title": "Transformers Can Do Arithmetic with the Right Embeddings",
        "abstract": "  The poor performance of transformers on arithmetic tasks seems to stem in\nlarge part from their inability to keep track of the exact position of each\ndigit inside of a large span of digits. We mend this problem by adding an\nembedding to each digit that encodes its position relative to the start of the\nnumber. In addition to the boost these embeddings provide on their own, we show\nthat this fix enables architectural modifications such as input injection and\nrecurrent layers to improve performance even further.\n  With positions resolved, we can study the logical extrapolation ability of\ntransformers. Can they solve arithmetic problems that are larger and more\ncomplex than those in their training data? We find that training on only 20\ndigit numbers with a single GPU for one day, we can reach state-of-the-art\nperformance, achieving up to 99% accuracy on 100 digit addition problems.\nFinally, we show that these gains in numeracy also unlock improvements on other\nmulti-step reasoning tasks including sorting and multiplication.\n",
        "authors": "Sean McLeish; Arpit Bansal; Alex Stein; Neel Jain; John Kirchenbauer; Brian R. Bartoldson; Bhavya Kailkhura; Abhinav Bhatele; Jonas Geiping; Avi Schwarzschild; Tom Goldstein",
        "status": 0,
        "relevancy": 0.3857384254624048,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17245",
        "date": "2024-05-27",
        "title": "Galaxy: A Resource-Efficient Collaborative Edge AI System for In-situ\n  Transformer Inference",
        "abstract": "  Transformer-based models have unlocked a plethora of powerful intelligent\napplications at the edge, such as voice assistant in smart home. Traditional\ndeployment approaches offload the inference workloads to the remote cloud\nserver, which would induce substantial pressure on the backbone network as well\nas raise users' privacy concerns. To address that, in-situ inference has been\nrecently recognized for edge intelligence, but it still confronts significant\nchallenges stemming from the conflict between intensive workloads and limited\non-device computing resources. In this paper, we leverage our observation that\nmany edge environments usually comprise a rich set of accompanying trusted edge\ndevices with idle resources and propose Galaxy, a collaborative edge AI system\nthat breaks the resource walls across heterogeneous edge devices for efficient\nTransformer inference acceleration. Galaxy introduces a novel hybrid model\nparallelism to orchestrate collaborative inference, along with a\nheterogeneity-aware parallelism planning for fully exploiting the resource\npotential. Furthermore, Galaxy devises a tile-based fine-grained overlapping of\ncommunication and computation to mitigate the impact of tensor synchronizations\non inference latency under bandwidth-constrained edge environments. Extensive\nevaluation based on prototype implementation demonstrates that Galaxy\nremarkably outperforms state-of-the-art approaches under various edge\nenvironment setups, achieving up to 2.5x end-to-end latency reduction.\n",
        "authors": "Shengyuan Ye; Jiangsu Du; Liekang Zeng; Wenzhong Ou; Xiaowen Chu; Yutong Lu; Xu Chen",
        "status": 0,
        "relevancy": 0.3832621662678949,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17345",
        "date": "2024-05-27",
        "title": "Exploring and steering the moral compass of Large Language Models",
        "abstract": "  Large Language Models (LLMs) have become central to advancing automation and\ndecision-making across various sectors, raising significant ethical questions.\nThis study proposes a comprehensive comparative analysis of the most advanced\nLLMs to assess their moral profiles. We subjected several state-of-the-art\nmodels to a selection of ethical dilemmas and found that all the proprietary\nones are mostly utilitarian and all of the open-weights ones align mostly with\nvalues-based ethics. Furthermore, when using the Moral Foundations\nQuestionnaire, all models we probed - except for Llama 2- displayed a strong\nliberal bias. Lastly, in order to causally intervene in one of the studied\nmodels, we propose a novel similarity-specific activation steering technique.\nUsing this method, we were able to reliably steer the model's moral compass to\ndifferent ethical schools. All of these results showcase that there is an\nethical dimension in already deployed LLMs, an aspect that is generally\noverlooked.\n",
        "authors": "Alejandro Tlaie",
        "status": 0,
        "relevancy": 0.38238329991701725,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17060",
        "date": "2024-05-27",
        "title": "Graph Neural Networks on Quantum Computers",
        "abstract": "  Graph Neural Networks (GNNs) are powerful machine learning models that excel\nat analyzing structured data represented as graphs, demonstrating remarkable\nperformance in applications like social network analysis and recommendation\nsystems. However, classical GNNs face scalability challenges when dealing with\nlarge-scale graphs. This paper proposes frameworks for implementing GNNs on\nquantum computers to potentially address the challenges. We devise quantum\nalgorithms corresponding to the three fundamental types of classical GNNs:\nGraph Convolutional Networks, Graph Attention Networks, and Message-Passing\nGNNs. A complexity analysis of our quantum implementation of the Simplified\nGraph Convolutional (SGC) Network shows potential quantum advantages over its\nclassical counterpart, with significant improvements in time and space\ncomplexities. Our complexities can have trade-offs between the two: when\noptimizing for minimal circuit depth, our quantum SGC achieves logarithmic time\ncomplexity in the input sizes (albeit at the cost of linear space complexity).\nWhen optimizing for minimal qubit usage, the quantum SGC exhibits space\ncomplexity logarithmic in the input sizes, offering an exponential reduction\ncompared to classical SGCs, while still maintaining better time complexity.\nThese results suggest our Quantum GNN frameworks could efficiently process\nlarge-scale graphs. This work paves the way for implementing more advanced\nGraph Neural Network models on quantum computers, opening new possibilities in\nquantum machine learning for analyzing graph-structured data.\n",
        "authors": "Yidong Liao; Xiao-Ming Zhang; Chris Ferrie",
        "status": 0,
        "relevancy": 0.38163586675496286,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17573",
        "date": "2024-05-27",
        "title": "Hamiltonian Mechanics of Feature Learning: Bottleneck Structure in Leaky\n  ResNets",
        "abstract": "  We study Leaky ResNets, which interpolate between ResNets ($\\tilde{L}=0$) and\nFully-Connected nets ($\\tilde{L}\\to\\infty$) depending on an 'effective depth'\nhyper-parameter $\\tilde{L}$. In the infinite depth limit, we study\n'representation geodesics' $A_{p}$: continuous paths in representation space\n(similar to NeuralODEs) from input $p=0$ to output $p=1$ that minimize the\nparameter norm of the network. We give a Lagrangian and Hamiltonian\nreformulation, which highlight the importance of two terms: a kinetic energy\nwhich favors small layer derivatives $\\partial_{p}A_{p}$ and a potential energy\nthat favors low-dimensional representations, as measured by the 'Cost of\nIdentity'. The balance between these two forces offers an intuitive\nunderstanding of feature learning in ResNets. We leverage this intuition to\nexplain the emergence of a bottleneck structure, as observed in previous work:\nfor large $\\tilde{L}$ the potential energy dominates and leads to a separation\nof timescales, where the representation jumps rapidly from the high dimensional\ninputs to a low-dimensional representation, move slowly inside the space of\nlow-dimensional representations, before jumping back to the potentially\nhigh-dimensional outputs. Inspired by this phenomenon, we train with an\nadaptive layer step-size to adapt to the separation of timescales.\n",
        "authors": "Arthur Jacot; Alexandre Kaiser",
        "status": 0,
        "relevancy": 0.3792870817675347,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16877",
        "date": "2024-05-27",
        "title": "Are Self-Attentions Effective for Time Series Forecasting?",
        "abstract": "  Time series forecasting is crucial for applications across multiple domains\nand various scenarios. Although Transformer models have dramatically shifted\nthe landscape of forecasting, their effectiveness remains debated. Recent\nfindings have indicated that simpler linear models might outperform complex\nTransformer-based approaches, highlighting the potential for more streamlined\narchitectures. In this paper, we shift focus from the overall architecture of\nthe Transformer to the effectiveness of self-attentions for time series\nforecasting. To this end, we introduce a new architecture, Cross-Attention-only\nTime Series transformer (CATS), that rethinks the traditional Transformer\nframework by eliminating self-attention and leveraging cross-attention\nmechanisms instead. By establishing future horizon-dependent parameters as\nqueries and enhanced parameter sharing, our model not only improves long-term\nforecasting accuracy but also reduces the number of parameters and memory\nusage. Extensive experiment across various datasets demonstrates that our model\nachieves superior performance with the lowest mean squared error and uses fewer\nparameters compared to existing models.\n",
        "authors": "Dongbin Kim; Jinseong Park; Jaewook Lee; Hoki Kim",
        "status": 0,
        "relevancy": 0.37927154051262324,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17419",
        "date": "2024-05-27",
        "title": "MultiOOD: Scaling Out-of-Distribution Detection for Multiple Modalities",
        "abstract": "  Detecting out-of-distribution (OOD) samples is important for deploying\nmachine learning models in safety-critical applications such as autonomous\ndriving and robot-assisted surgery. Existing research has mainly focused on\nunimodal scenarios on image data. However, real-world applications are\ninherently multimodal, which makes it essential to leverage information from\nmultiple modalities to enhance the efficacy of OOD detection. To establish a\nfoundation for more realistic Multimodal OOD Detection, we introduce the\nfirst-of-its-kind benchmark, MultiOOD, characterized by diverse dataset sizes\nand varying modality combinations. We first evaluate existing unimodal OOD\ndetection algorithms on MultiOOD, observing that the mere inclusion of\nadditional modalities yields substantial improvements. This underscores the\nimportance of utilizing multiple modalities for OOD detection. Based on the\nobservation of Modality Prediction Discrepancy between in-distribution (ID) and\nOOD data, and its strong correlation with OOD performance, we propose the\nAgree-to-Disagree (A2D) algorithm to encourage such discrepancy during\ntraining. Moreover, we introduce a novel outlier synthesis method, NP-Mix,\nwhich explores broader feature spaces by leveraging the information from\nnearest neighbor classes and complements A2D to strengthen OOD detection\nperformance. Extensive experiments on MultiOOD demonstrate that training with\nA2D and NP-Mix improves existing OOD detection algorithms by a large margin.\nOur source code and MultiOOD benchmark are available at\nhttps://github.com/donghao51/MultiOOD.\n",
        "authors": "Hao Dong; Yue Zhao; Eleni Chatzi; Olga Fink",
        "status": 0,
        "relevancy": 0.37847403289031745,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17429",
        "date": "2024-05-27",
        "title": "GaussianFormer: Scene as Gaussians for Vision-Based 3D Semantic\n  Occupancy Prediction",
        "abstract": "  3D semantic occupancy prediction aims to obtain 3D fine-grained geometry and\nsemantics of the surrounding scene and is an important task for the robustness\nof vision-centric autonomous driving. Most existing methods employ dense grids\nsuch as voxels as scene representations, which ignore the sparsity of occupancy\nand the diversity of object scales and thus lead to unbalanced allocation of\nresources. To address this, we propose an object-centric representation to\ndescribe 3D scenes with sparse 3D semantic Gaussians where each Gaussian\nrepresents a flexible region of interest and its semantic features. We\naggregate information from images through the attention mechanism and\niteratively refine the properties of 3D Gaussians including position,\ncovariance, and semantics. We then propose an efficient Gaussian-to-voxel\nsplatting method to generate 3D occupancy predictions, which only aggregates\nthe neighboring Gaussians for a certain position. We conduct extensive\nexperiments on the widely adopted nuScenes and KITTI-360 datasets. Experimental\nresults demonstrate that GaussianFormer achieves comparable performance with\nstate-of-the-art methods with only 17.8% - 24.8% of their memory consumption.\nCode is available at: https://github.com/huang-yh/GaussianFormer.\n",
        "authors": "Yuanhui Huang; Wenzhao Zheng; Yunpeng Zhang; Jie Zhou; Jiwen Lu",
        "status": 0,
        "relevancy": 0.3776902010456241,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17152",
        "date": "2024-05-27",
        "title": "CoSLight: Co-optimizing Collaborator Selection and Decision-making to\n  Enhance Traffic Signal Control",
        "abstract": "  Effective multi-intersection collaboration is pivotal for\nreinforcement-learning-based traffic signal control to alleviate congestion.\nExisting work mainly chooses neighboring intersections as collaborators.\nHowever, quite an amount of congestion, even some wide-range congestion, is\ncaused by non-neighbors failing to collaborate. To address these issues, we\npropose to separate the collaborator selection as a second policy to be\nlearned, concurrently being updated with the original signal-controlling\npolicy. Specifically, the selection policy in real-time adaptively selects the\nbest teammates according to phase- and intersection-level features. Empirical\nresults on both synthetic and real-world datasets provide robust validation for\nthe superiority of our approach, offering significant improvements over\nexisting state-of-the-art methods. The code is available at\nhttps://github.com/AnonymousAccountss/CoSLight.\n",
        "authors": "Jingqing Ruan; Ziyue Li; Hua Wei; Haoyuan Jiang; Jiaming Lu; Xuantang Xiong; Hangyu Mao; Rui Zhao",
        "status": 0,
        "relevancy": 0.3756238547396772,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16823",
        "date": "2024-05-27",
        "title": "Unified Editing of Panorama, 3D Scenes, and Videos Through Disentangled\n  Self-Attention Injection",
        "abstract": "  While text-to-image models have achieved impressive capabilities in image\ngeneration and editing, their application across various modalities often\nnecessitates training separate models. Inspired by existing method of single\nimage editing with self attention injection and video editing with shared\nattention, we propose a novel unified editing framework that combines the\nstrengths of both approaches by utilizing only a basic 2D image text-to-image\n(T2I) diffusion model. Specifically, we design a sampling method that\nfacilitates editing consecutive images while maintaining semantic consistency\nutilizing shared self-attention features during both reference and consecutive\nimage sampling processes. Experimental results confirm that our method enables\nediting across diverse modalities including 3D scenes, videos, and panorama\nimages.\n",
        "authors": "Gihyun Kwon; Jangho Park; Jong Chul Ye",
        "status": 0,
        "relevancy": 0.3709072341365782,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17072",
        "date": "2024-05-27",
        "title": "A novel framework for systematic propositional formula simplification\n  based on existential graphs",
        "abstract": "  This paper presents a novel simplification calculus for propositional logic\nderived from Peirce's existential graphs' rules of inference and implication\ngraphs. Our rules can be applied to propositional logic formulae in nested\nform, are equivalence-preserving, guarantee a monotonically decreasing number\nof variables, clauses and literals, and maximise the preservation of structural\nproblem information. Our techniques can also be seen as higher-level SAT\npreprocessing, and we show how one of our rules (TWSR) generalises and\nstreamlines most of the known equivalence-preserving SAT preprocessing methods.\nIn addition, we propose a simplification procedure based on the systematic\napplication of two of our rules (EPR and TWSR) which is solver-agnostic and can\nbe used to simplify large Boolean satisfiability problems and propositional\nformulae in arbitrary form, and we provide a formal analysis of its algorithmic\ncomplexity in terms of space and time. Finally, we show how our rules can be\nfurther extended with a novel n-ary implication graph to capture all known\nequivalence-preserving preprocessing procedures.\n",
        "authors": "Jordina Francès de Mas; Juliana Bowles",
        "status": 0,
        "relevancy": 0.37072588822425234,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17580",
        "date": "2024-05-27",
        "title": "Mixed Dynamics In Linear Networks: Unifying the Lazy and Active Regimes",
        "abstract": "  The training dynamics of linear networks are well studied in two distinct\nsetups: the lazy regime and balanced/active regime, depending on the\ninitialization and width of the network. We provide a surprisingly simple\nunyfing formula for the evolution of the learned matrix that contains as\nspecial cases both lazy and balanced regimes but also a mixed regime in between\nthe two. In the mixed regime, a part of the network is lazy while the other is\nbalanced. More precisely the network is lazy along singular values that are\nbelow a certain threshold and balanced along those that are above the same\nthreshold. At initialization, all singular values are lazy, allowing for the\nnetwork to align itself with the task, so that later in time, when some of the\nsingular value cross the threshold and become active they will converge rapidly\n(convergence in the balanced regime is notoriously difficult in the absence of\nalignment). The mixed regime is the `best of both worlds': it converges from\nany random initialization (in contrast to balanced dynamics which require\nspecial initialization), and has a low rank bias (absent in the lazy dynamics).\nThis allows us to prove an almost complete phase diagram of training behavior\nas a function of the variance at initialization and the width, for a MSE\ntraining task.\n",
        "authors": "Zhenfeng Tu; Santiago Aranguri; Arthur Jacot",
        "status": 0,
        "relevancy": 0.37054077698222954,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16852",
        "date": "2024-05-27",
        "title": "EM Distillation for One-step Diffusion Models",
        "abstract": "  While diffusion models can learn complex distributions, sampling requires a\ncomputationally expensive iterative process. Existing distillation methods\nenable efficient sampling, but have notable limitations, such as performance\ndegradation with very few sampling steps, reliance on training data access, or\nmode-seeking optimization that may fail to capture the full distribution. We\npropose EM Distillation (EMD), a maximum likelihood-based approach that\ndistills a diffusion model to a one-step generator model with minimal loss of\nperceptual quality. Our approach is derived through the lens of\nExpectation-Maximization (EM), where the generator parameters are updated using\nsamples from the joint distribution of the diffusion teacher prior and inferred\ngenerator latents. We develop a reparametrized sampling scheme and a noise\ncancellation technique that together stabilizes the distillation process. We\nfurther reveal an interesting connection of our method with existing methods\nthat minimize mode-seeking KL. EMD outperforms existing one-step generative\nmethods in terms of FID scores on ImageNet-64 and ImageNet-128, and compares\nfavorably with prior work on distilling text-to-image diffusion models.\n",
        "authors": "Sirui Xie; Zhisheng Xiao; Diederik P Kingma; Tingbo Hou; Ying Nian Wu; Kevin Patrick Murphy; Tim Salimans; Ben Poole; Ruiqi Gao",
        "status": 0,
        "relevancy": 0.36452710936895305,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16876",
        "date": "2024-05-27",
        "title": "Transfer Learning for Diffusion Models",
        "abstract": "  Diffusion models, a specific type of generative model, have achieved\nunprecedented performance in recent years and consistently produce high-quality\nsynthetic samples. A critical prerequisite for their notable success lies in\nthe presence of a substantial number of training samples, which can be\nimpractical in real-world applications due to high collection costs or\nassociated risks. Consequently, various finetuning and regularization\napproaches have been proposed to transfer knowledge from existing pre-trained\nmodels to specific target domains with limited data. This paper introduces the\nTransfer Guided Diffusion Process (TGDP), a novel approach distinct from\nconventional finetuning and regularization methods. We prove that the optimal\ndiffusion model for the target domain integrates pre-trained diffusion models\non the source domain with additional guidance from a domain classifier. We\nfurther extend TGDP to a conditional version for modeling the joint\ndistribution of data and its corresponding labels, together with two additional\nregularization terms to enhance the model performance. We validate the\neffectiveness of TGDP on Gaussian mixture simulations and on real\nelectrocardiogram (ECG) datasets.\n",
        "authors": "Yidong Ouyang; Liyan Xie; Hongyuan Zha; Guang Cheng",
        "status": 0,
        "relevancy": 0.35964317158352443,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17537",
        "date": "2024-05-27",
        "title": "BIOSCAN-CLIP: Bridging Vision and Genomics for Biodiversity Monitoring\n  at Scale",
        "abstract": "  Measuring biodiversity is crucial for understanding ecosystem health. While\nprior works have developed machine learning models for the taxonomic\nclassification of photographic images and DNA separately, in this work, we\nintroduce a multimodal approach combining both, using CLIP-style contrastive\nlearning to align images, DNA barcodes, and textual data in a unified embedding\nspace. This allows for accurate classification of both known and unknown insect\nspecies without task-specific fine-tuning, leveraging contrastive learning for\nthe first time to fuse DNA and image data. Our method surpasses previous\nsingle-modality approaches in accuracy by over 11% on zero-shot learning tasks,\nshowcasing its effectiveness in biodiversity studies.\n",
        "authors": "ZeMing Gong; Austin T. Wang; Joakim Bruslund Haurum; Scott C. Lowe; Graham W. Taylor; Angel X. Chang",
        "status": 0,
        "relevancy": 0.35020639554003075,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17533",
        "date": "2024-05-27",
        "title": "PAE: LLM-based Product Attribute Extraction for E-Commerce Fashion\n  Trends",
        "abstract": "  Product attribute extraction is an growing field in e-commerce business, with\nseveral applications including product ranking, product recommendation, future\nassortment planning and improving online shopping customer experiences.\nUnderstanding the customer needs is critical part of online business,\nspecifically fashion products. Retailers uses assortment planning to determine\nthe mix of products to offer in each store and channel, stay responsive to\nmarket dynamics and to manage inventory and catalogs. The goal is to offer the\nright styles, in the right sizes and colors, through the right channels. When\nshoppers find products that meet their needs and desires, they are more likely\nto return for future purchases, fostering customer loyalty. Product attributes\nare a key factor in assortment planning. In this paper we present PAE, a\nproduct attribute extraction algorithm for future trend reports consisting text\nand images in PDF format. Most existing methods focus on attribute extraction\nfrom titles or product descriptions or utilize visual information from existing\nproduct images. Compared to the prior works, our work focuses on attribute\nextraction from PDF files where upcoming fashion trends are explained. This\nwork proposes a more comprehensive framework that fully utilizes the different\nmodalities for attribute extraction and help retailers to plan the assortment\nin advance. Our contributions are three-fold: (a) We develop PAE, an efficient\nframework to extract attributes from unstructured data (text and images); (b)\nWe provide catalog matching methodology based on BERT representations to\ndiscover the existing attributes using upcoming attribute values; (c) We\nconduct extensive experiments with several baselines and show that PAE is an\neffective, flexible and on par or superior (avg 92.5% F1-Score) framework to\nexisting state-of-the-art for attribute value extraction task.\n",
        "authors": "Apurva Sinha; Ekta Gujral",
        "status": 0,
        "relevancy": 0.3497941600497627,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17284",
        "date": "2024-05-27",
        "title": "An NLP Crosswalk Between the Common Core State Standards and NAEP Item\n  Specifications",
        "abstract": "  Natural language processing (NLP) is rapidly developing for applications in\neducational assessment. In this paper, I describe an NLP-based procedure that\ncan be used to support subject matter experts in establishing a crosswalk\nbetween item specifications and content standards. This paper extends recent\nwork by proposing and demonstrating the use of multivariate similarity based on\nembedding vectors for sentences or texts. In particular, a hybrid regression\nprocedure is demonstrated for establishing the match of each content standard\nto multiple item specifications. The procedure is used to evaluate the match of\nthe Common Core State Standards (CCSS) for mathematics at grade 4 to the\ncorresponding item specifications for the 2026 National Assessment of\nEducational Progress (NAEP).\n",
        "authors": "Gregory Camilli",
        "status": 0,
        "relevancy": 0.34863222355677714,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17034",
        "date": "2024-05-27",
        "title": "FUGNN: Harmonizing Fairness and Utility in Graph Neural Networks",
        "abstract": "  Fairness-aware Graph Neural Networks (GNNs) often face a challenging\ntrade-off, where prioritizing fairness may require compromising utility. In\nthis work, we re-examine fairness through the lens of spectral graph theory,\naiming to reconcile fairness and utility within the framework of spectral graph\nlearning. We explore the correlation between sensitive features and spectrum in\nGNNs, using theoretical analysis to delineate the similarity between original\nsensitive features and those after convolution under different spectrum. Our\nanalysis reveals a reduction in the impact of similarity when the eigenvectors\nassociated with the largest magnitude eigenvalue exhibit directional\nsimilarity. Based on these theoretical insights, we propose FUGNN, a novel\nspectral graph learning approach that harmonizes the conflict between fairness\nand utility. FUGNN ensures algorithmic fairness and utility by truncating the\nspectrum and optimizing eigenvector distribution during the encoding process.\nThe fairness-aware eigenvector selection reduces the impact of convolution on\nsensitive features while concurrently minimizing the sacrifice of utility.\nFUGNN further optimizes the distribution of eigenvectors through a transformer\narchitecture. By incorporating the optimized spectrum into the graph\nconvolution network, FUGNN effectively learns node representations. Experiments\non six real-world datasets demonstrate the superiority of FUGNN over baseline\nmethods. The codes are available at https://github.com/yushuowiki/FUGNN.\n",
        "authors": "Renqiang Luo; Huafei Huang; Shuo Yu; Zhuoyang Han; Estrid He; Xiuzhen Zhang; Feng Xia",
        "status": 0,
        "relevancy": 0.34688222616025866,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16922",
        "date": "2024-05-27",
        "title": "Theories of synaptic memory consolidation and intelligent plasticity for\n  continual learning",
        "abstract": "  Humans and animals learn throughout life. Such continual learning is crucial\nfor intelligence. In this chapter, we examine the pivotal role plasticity\nmechanisms with complex internal synaptic dynamics could play in enabling this\nability in neural networks. By surveying theoretical research, we highlight two\nfundamental enablers for continual learning. First, synaptic plasticity\nmechanisms must maintain and evolve an internal state over several behaviorally\nrelevant timescales. Second, plasticity algorithms must leverage the internal\nstate to intelligently regulate plasticity at individual synapses to facilitate\nthe seamless integration of new memories while avoiding detrimental\ninterference with existing ones. Our chapter covers successful applications of\nthese principles to deep neural networks and underscores the significance of\nsynaptic metaplasticity in sustaining continual learning capabilities. Finally,\nwe outline avenues for further research to understand the brain's superb\ncontinual learning abilities and harness similar mechanisms for artificial\nintelligence systems.\n",
        "authors": "Friedemann Zenke; Axel Laborieux",
        "status": 0,
        "relevancy": 0.34419065660735604,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17088",
        "date": "2024-05-27",
        "title": "Phase Transitions in the Output Distribution of Large Language Models",
        "abstract": "  In a physical system, changing parameters such as temperature can induce a\nphase transition: an abrupt change from one state of matter to another.\nAnalogous phenomena have recently been observed in large language models.\nTypically, the task of identifying phase transitions requires human analysis\nand some prior understanding of the system to narrow down which low-dimensional\nproperties to monitor and analyze. Statistical methods for the automated\ndetection of phase transitions from data have recently been proposed within the\nphysics community. These methods are largely system agnostic and, as shown\nhere, can be adapted to study the behavior of large language models. In\nparticular, we quantify distributional changes in the generated output via\nstatistical distances, which can be efficiently estimated with access to the\nprobability distribution over next-tokens. This versatile approach is capable\nof discovering new phases of behavior and unexplored transitions -- an ability\nthat is particularly exciting in light of the rapid development of language\nmodels and their emergent capabilities.\n",
        "authors": "Julian Arnold; Flemming Holtorf; Frank Schäfer; Niels Lörch",
        "status": 0,
        "relevancy": 0.33974698551099825,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17110",
        "date": "2024-05-27",
        "title": "Superpixelwise Low-rank Approximation based Partial Label Learning for\n  Hyperspectral Image Classification",
        "abstract": "  Insufficient prior knowledge of a captured hyperspectral image (HSI) scene\nmay lead the experts or the automatic labeling systems to offer incorrect\nlabels or ambiguous labels (i.e., assigning each training sample to a group of\ncandidate labels, among which only one of them is valid; this is also known as\npartial label learning) during the labeling process. Accordingly, how to learn\nfrom such data with ambiguous labels is a problem of great practical\nimportance. In this paper, we propose a novel superpixelwise low-rank\napproximation (LRA)-based partial label learning method, namely SLAP, which is\nthe first to take into account partial label learning in HSI classification.\nSLAP is mainly composed of two phases: disambiguating the training labels and\nacquiring the predictive model. Specifically, in the first phase, we propose a\nsuperpixelwise LRA-based model, preparing the affinity graph for the subsequent\nlabel propagation process while extracting the discriminative representation to\nenhance the following classification task of the second phase. Then to\ndisambiguate the training labels, label propagation propagates the labeling\ninformation via the affinity graph of training pixels. In the second phase, we\ntake advantage of the resulting disambiguated training labels and the\ndiscriminative representations to enhance the classification performance. The\nextensive experiments validate the advantage of the proposed SLAP method over\nstate-of-the-art methods.\n",
        "authors": "Shujun Yang; Yu Zhang; Yao Ding; Danfeng Hong",
        "status": 0,
        "relevancy": 0.33528598412051314,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17527",
        "date": "2024-05-27",
        "title": "Unisolver: PDE-Conditional Transformers Are Universal PDE Solvers",
        "abstract": "  Deep models have recently emerged as a promising tool to solve partial\ndifferential equations (PDEs), known as neural PDE solvers. While neural\nsolvers trained from either simulation data or physics-informed loss can solve\nthe PDEs reasonably well, they are mainly restricted to a specific set of PDEs,\ne.g. a certain equation or a finite set of coefficients. This bottleneck limits\nthe generalizability of neural solvers, which is widely recognized as its major\nadvantage over numerical solvers. In this paper, we present the Universal PDE\nsolver (Unisolver) capable of solving a wide scope of PDEs by leveraging a\nTransformer pre-trained on diverse data and conditioned on diverse PDEs.\nInstead of simply scaling up data and parameters, Unisolver stems from the\ntheoretical analysis of the PDE-solving process. Our key finding is that a PDE\nsolution is fundamentally under the control of a series of PDE components, e.g.\nequation symbols, coefficients, and initial and boundary conditions. Inspired\nby the mathematical structure of PDEs, we define a complete set of PDE\ncomponents and correspondingly embed them as domain-wise (e.g. equation\nsymbols) and point-wise (e.g. boundaries) conditions for Transformer PDE\nsolvers. Integrating physical insights with recent Transformer advances,\nUnisolver achieves consistent state-of-the-art results on three challenging\nlarge-scale benchmarks, showing impressive gains and endowing favorable\ngeneralizability and scalability.\n",
        "authors": "Zhou Hang; Yuezhou Ma; Haixu Wu; Haowen Wang; Mingsheng Long",
        "status": 0,
        "relevancy": 0.33298675729878147,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17556",
        "date": "2024-05-27",
        "title": "Probabilistic Verification of Neural Networks using Branch and Bound",
        "abstract": "  Probabilistic verification of neural networks is concerned with formally\nanalysing the output distribution of a neural network under a probability\ndistribution of the inputs. Examples of probabilistic verification include\nverifying the demographic parity fairness notion or quantifying the safety of a\nneural network. We present a new algorithm for the probabilistic verification\nof neural networks based on an algorithm for computing and iteratively refining\nlower and upper bounds on probabilities over the outputs of a neural network.\nBy applying state-of-the-art bound propagation and branch and bound techniques\nfrom non-probabilistic neural network verification, our algorithm significantly\noutpaces existing probabilistic verification algorithms, reducing solving times\nfor various benchmarks from the literature from tens of minutes to tens of\nseconds. Furthermore, our algorithm compares favourably even to dedicated\nalgorithms for restricted subsets of probabilistic verification. We complement\nour empirical evaluation with a theoretical analysis, proving that our\nalgorithm is sound and, under mildly restrictive conditions, also complete when\nusing a suitable set of heuristics.\n",
        "authors": "David Boetius; Stefan Leue; Tobias Sutter",
        "status": 0,
        "relevancy": 0.3321800163674924,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17422",
        "date": "2024-05-27",
        "title": "Hardness-Aware Scene Synthesis for Semi-Supervised 3D Object Detection",
        "abstract": "  3D object detection aims to recover the 3D information of concerning objects\nand serves as the fundamental task of autonomous driving perception. Its\nperformance greatly depends on the scale of labeled training data, yet it is\ncostly to obtain high-quality annotations for point cloud data. While\nconventional methods focus on generating pseudo-labels for unlabeled samples as\nsupplements for training, the structural nature of 3D point cloud data\nfacilitates the composition of objects and backgrounds to synthesize realistic\nscenes. Motivated by this, we propose a hardness-aware scene synthesis (HASS)\nmethod to generate adaptive synthetic scenes to improve the generalization of\nthe detection models. We obtain pseudo-labels for unlabeled objects and\ngenerate diverse scenes with different compositions of objects and backgrounds.\nAs the scene synthesis is sensitive to the quality of pseudo-labels, we further\npropose a hardness-aware strategy to reduce the effect of low-quality\npseudo-labels and maintain a dynamic pseudo-database to ensure the diversity\nand quality of synthetic scenes. Extensive experimental results on the widely\nused KITTI and Waymo datasets demonstrate the superiority of the proposed HASS\nmethod, which outperforms existing semi-supervised learning methods on 3D\nobject detection. Code: https://github.com/wzzheng/HASS.\n",
        "authors": "Shuai Zeng; Wenzhao Zheng; Jiwen Lu; Haibin Yan",
        "status": 0,
        "relevancy": 0.32968740132693775,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16797",
        "date": "2024-05-27",
        "title": "A Real-Time Voice Activity Detection Based On Lightweight Neural",
        "abstract": "  Voice activity detection (VAD) is the task of detecting speech in an audio\nstream, which is challenging due to numerous unseen noises and low\nsignal-to-noise ratios in real environments. Recently, neural network-based\nVADs have alleviated the degradation of performance to some extent. However,\nthe majority of existing studies have employed excessively large models and\nincorporated future context, while neglecting to evaluate the operational\nefficiency and latency of the models. In this paper, we propose a lightweight\nand real-time neural network called MagicNet, which utilizes casual and depth\nseparable 1-D convolutions and GRU. Without relying on future features as\ninput, our proposed model is compared with two state-of-the-art algorithms on\nsynthesized in-domain and out-domain test datasets. The evaluation results\ndemonstrate that MagicNet can achieve improved performance and robustness with\nfewer parameter costs.\n",
        "authors": "Jidong Jia; Pei Zhao; Di Wang",
        "status": 0,
        "relevancy": 0.3168383313386973,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17569",
        "date": "2024-05-27",
        "title": "Discriminant audio properties in deep learning based respiratory\n  insufficiency detection in Brazilian Portuguese",
        "abstract": "  This work investigates Artificial Intelligence (AI) systems that detect\nrespiratory insufficiency (RI) by analyzing speech audios, thus treating speech\nas a RI biomarker. Previous works collected RI data (P1) from COVID-19 patients\nduring the first phase of the pandemic and trained modern AI models, such as\nCNNs and Transformers, which achieved $96.5\\%$ accuracy, showing the\nfeasibility of RI detection via AI. Here, we collect RI patient data (P2) with\nseveral causes besides COVID-19, aiming at extending AI-based RI detection. We\nalso collected control data from hospital patients without RI. We show that the\nconsidered models, when trained on P1, do not generalize to P2, indicating that\nCOVID-19 RI has features that may not be found in all RI types.\n",
        "authors": "Marcelo Matheus Gauy; Larissa Cristina Berti; Arnaldo Cândido Jr; Augusto Camargo Neto; Alfredo Goldman; Anna Sara Shafferman Levin; Marcus Martins; Beatriz Raposo de Medeiros; Marcelo Queiroz; Ester Cerdeira Sabino; Flaviane Romani Fernandes Svartman; Marcelo Finger",
        "status": 0,
        "relevancy": 0.3138868821358264,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16836",
        "date": "2024-05-27",
        "title": "Enhancing Fast Feed Forward Networks with Load Balancing and a Master\n  Leaf Node",
        "abstract": "  Fast feedforward networks (FFFs) are a class of neural networks that exploit\nthe observation that different regions of the input space activate distinct\nsubsets of neurons in wide networks. FFFs partition the input space into\nseparate sections using a differentiable binary tree of neurons and during\ninference descend the binary tree in order to improve computational efficiency.\nInspired by Mixture of Experts (MoE) research, we propose the incorporation of\nload balancing and Master Leaf techniques into the FFF architecture to improve\nperformance and simplify the training process. We reproduce experiments found\nin literature and present results on FFF models enhanced using these\ntechniques. The proposed architecture and training recipe achieves up to 16.3%\nand 3% absolute classification accuracy increase in training and test accuracy,\nrespectively, compared to the original FFF architecture. Additionally, we\nobserve a smaller variance in the results compared to those reported in prior\nresearch. These findings demonstrate the potential of integrating MoE-inspired\ntechniques into FFFs for developing more accurate and efficient models.\n",
        "authors": "Andreas Charalampopoulos; Nikolas Chatzis; Foivos Ntoulas-Panagiotopoulos; Charilaos Papaioannou; Alexandros Potamianos",
        "status": 0,
        "relevancy": 0.3118953246492042,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17653",
        "date": "2024-05-27",
        "title": "InversionView: A General-Purpose Method for Reading Information from\n  Neural Activations",
        "abstract": "  The inner workings of neural networks can be better understood if we can\nfully decipher the information encoded in neural activations. In this paper, we\nargue that this information is embodied by the subset of inputs that give rise\nto similar activations. Computing such subsets is nontrivial as the input space\nis exponentially large. We propose InversionView, which allows us to\npractically inspect this subset by sampling from a trained decoder model\nconditioned on activations. This helps uncover the information content of\nactivation vectors, and facilitates understanding of the algorithms implemented\nby transformer models. We present three case studies where we investigate\nmodels ranging from small transformers to GPT-2. In these studies, we\ndemonstrate the characteristics of our method, show the distinctive advantages\nit offers, and provide causally verified circuits.\n",
        "authors": "Xinting Huang; Madhur Panwar; Navin Goyal; Michael Hahn",
        "status": 0,
        "relevancy": 0.3087470043038405,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17025",
        "date": "2024-05-27",
        "title": "SWAT: Scalable and Efficient Window Attention-based Transformers\n  Acceleration on FPGAs",
        "abstract": "  Efficiently supporting long context length is crucial for Transformer models.\nThe quadratic complexity of the self-attention computation plagues traditional\nTransformers. Sliding window-based static sparse attention mitigates the\nproblem by limiting the attention scope of the input tokens, reducing the\ntheoretical complexity from quadratic to linear. Although the sparsity induced\nby window attention is highly structured, it does not align perfectly with the\nmicroarchitecture of the conventional accelerators, leading to suboptimal\nimplementation. In response, we propose a dataflow-aware FPGA-based accelerator\ndesign, SWAT, that efficiently leverages the sparsity to achieve scalable\nperformance for long input. The proposed microarchitecture is based on a design\nthat maximizes data reuse by using a combination of row-wise dataflow, kernel\nfusion optimization, and an input-stationary design considering the distributed\nmemory and computation resources of FPGA. Consequently, it achieves up to\n22$\\times$ and 5.7$\\times$ improvement in latency and energy efficiency\ncompared to the baseline FPGA-based accelerator and 15$\\times$ energy\nefficiency compared to GPU-based solution.\n",
        "authors": "Zhenyu Bai; Pranav Dangi; Huize Li; Tulika Mitra",
        "status": 0,
        "relevancy": 0.30787864208193405,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16961",
        "date": "2024-05-27",
        "title": "Blind Data Adaptation to tackle Covariate Shift in Operational\n  Steganalysis",
        "abstract": "  The proliferation of image manipulation for unethical purposes poses\nsignificant challenges in social networks. One particularly concerning method\nis Image Steganography, allowing individuals to hide illegal information in\ndigital images without arousing suspicions. Such a technique pose severe\nsecurity risks, making it crucial to develop effective steganalysis methods\nenabling to detect manipulated images for clandestine communications. Although\nsignificant advancements have been achieved with machine learning models, a\ncritical issue remains: the disparity between the controlled datasets used to\ntrain steganalysis models against real-world datasets of forensic\npractitioners, undermining severely the practical effectiveness of standardized\nsteganalysis models. In this paper, we address this issue focusing on a\nrealistic scenario where practitioners lack crucial information about the\nlimited target set of images under analysis, including details about their\ndevelopment process and even whereas it contains manipulated images or not. By\nleveraging geometric alignment and distribution matching of source and target\nresiduals, we develop TADA (Target Alignment through Data Adaptation), a novel\nmethodology enabling to emulate sources aligned with specific targets in\nsteganalysis, which is also relevant for highly unbalanced targets. The\nemulator is represented by a light convolutional network trained to align\ndistributions of image residuals. Experimental validation demonstrates the\npotential of our strategy over traditional methods fighting covariate shift in\nsteganalysis.\n",
        "authors": "Rony Abecidan; Vincent Itier; Jérémie Boulanger; Patrick Bas; Tomáš Pevný",
        "status": 0,
        "relevancy": 0.3063693757652065,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17412",
        "date": "2024-05-27",
        "title": "Towards One Model for Classical Dimensionality Reduction: A\n  Probabilistic Perspective on UMAP and t-SNE",
        "abstract": "  This paper shows that the dimensionality reduction methods, UMAP and t-SNE,\ncan be approximately recast as MAP inference methods corresponding to a\ngeneralized Wishart-based model introduced in ProbDR. This interpretation\noffers deeper theoretical insights into these algorithms, while introducing\ntools with which similar dimensionality reduction methods can be studied.\n",
        "authors": "Aditya Ravuri; Neil D. Lawrence",
        "status": 0,
        "relevancy": 0.3054431804955444,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16867",
        "date": "2024-05-27",
        "title": "Clustering-based Learning for UAV Tracking and Pose Estimation",
        "abstract": "  UAV tracking and pose estimation plays an imperative role in various\nUAV-related missions, such as formation control and anti-UAV measures.\nAccurately detecting and tracking UAVs in a 3D space remains a particularly\nchallenging problem, as it requires extracting sparse features of micro UAVs\nfrom different flight environments and continuously matching correspondences,\nespecially during agile flight. Generally, cameras and LiDARs are the two main\ntypes of sensors used to capture UAV trajectories in flight. However, both\nsensors have limitations in UAV classification and pose estimation. This\ntechnical report briefly introduces the method proposed by our team \"NTU-ICG\"\nfor the CVPR 2024 UG2+ Challenge Track 5. This work develops a clustering-based\nlearning detection approach, CL-Det, for UAV tracking and pose estimation using\ntwo types of LiDARs, namely Livox Avia and LiDAR 360. We combine the\ninformation from the two data sources to locate drones in 3D. We first align\nthe timestamps of Livox Avia data and LiDAR 360 data and then separate the\npoint cloud of objects of interest (OOIs) from the environment. The point cloud\nof OOIs is clustered using the DBSCAN method, with the midpoint of the largest\ncluster assumed to be the UAV position. Furthermore, we utilize historical\nestimations to fill in missing data. The proposed method shows competitive pose\nestimation performance and ranks 5th on the final leaderboard of the CVPR 2024\nUG2+ Challenge.\n",
        "authors": "Jiaping Xiao; Phumrapee Pisutsin; Cheng Wen Tsao; Mir Feroskhan",
        "status": 0,
        "relevancy": 0.30175949012852477,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17637",
        "date": "2024-05-27",
        "title": "The Economic Implications of Large Language Model Selection on Earnings\n  and Return on Investment: A Decision Theoretic Model",
        "abstract": "  Selecting language models in business contexts requires a careful analysis of\nthe final financial benefits of the investment. However, the emphasis of\nacademia and industry analysis of LLM is solely on performance. This work\nintroduces a framework to evaluate LLMs, focusing on the earnings and return on\ninvestment aspects that should be taken into account in business decision\nmaking. We use a decision-theoretic approach to compare the financial impact of\ndifferent LLMs, considering variables such as the cost per token, the\nprobability of success in the specific task, and the gain and losses associated\nwith LLMs use. The study reveals how the superior accuracy of more expensive\nmodels can, under certain conditions, justify a greater investment through more\nsignificant earnings but not necessarily a larger RoI. This article provides a\nframework for companies looking to optimize their technology choices, ensuring\nthat investment in cutting-edge technology aligns with strategic financial\nobjectives. In addition, we discuss how changes in operational variables\ninfluence the economics of using LLMs, offering practical insights for\nenterprise settings, finding that the predicted gain and loss and the different\nprobabilities of success and failure are the variables that most impact the\nsensitivity of the models.\n",
        "authors": "Geraldo Xexéo; Filipe Braida; Marcus Parreiras; Paulo Xavier",
        "status": 0,
        "relevancy": 0.3003379031232045,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17672",
        "date": "2024-05-27",
        "title": "Exploring Loss Design Techniques For Decision Tree Robustness To Label\n  Noise",
        "abstract": "  In the real world, data is often noisy, affecting not only the quality of\nfeatures but also the accuracy of labels. Current research on mitigating label\nerrors stems primarily from advances in deep learning, and a gap exists in\nexploring interpretable models, particularly those rooted in decision trees. In\nthis study, we investigate whether ideas from deep learning loss design can be\napplied to improve the robustness of decision trees. In particular, we show\nthat loss correction and symmetric losses, both standard approaches, are not\neffective. We argue that other directions need to be explored to improve the\nrobustness of decision trees to label noise.\n",
        "authors": "Lukasz Sztukiewicz; Jack Henry Good; Artur Dubrawski",
        "status": 0,
        "relevancy": 0.28276645161404157,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16807",
        "date": "2024-05-27",
        "title": "Extreme Compression of Adaptive Neural Images",
        "abstract": "  Implicit Neural Representations (INRs) and Neural Fields are a novel paradigm\nfor signal representation, from images and audio to 3D scenes and videos. The\nfundamental idea is to represent a signal as a continuous and differentiable\nneural network. This idea offers unprecedented benefits such as continuous\nresolution and memory efficiency, enabling new compression techniques. However,\nrepresenting data as neural networks poses new challenges. For instance, given\na 2D image as a neural network, how can we further compress such a neural\nimage?. In this work, we present a novel analysis on compressing neural fields,\nwith the focus on images. We also introduce Adaptive Neural Images (ANI), an\nefficient neural representation that enables adaptation to different inference\nor transmission requirements. Our proposed method allows to reduce the\nbits-per-pixel (bpp) of the neural image by 4x, without losing sensitive\ndetails or harming fidelity. We achieve this thanks to our successful\nimplementation of 4-bit neural representations. Our work offers a new framework\nfor developing compressed neural fields.\n",
        "authors": "Leo Hoshikawa; Marcos V. Conde; Takeshi Ohashi; Atsushi Irie",
        "status": 0,
        "relevancy": 0.27942434519936177,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.16956",
        "date": "2024-05-27",
        "title": "Functional Programming Paradigm of Python for Scientific Computation\n  Pipeline Integration",
        "abstract": "  The advent of modern data processing has led to an increasing tendency\ntowards interdisciplinarity, which frequently involves the importation of\ndifferent technical approaches. Consequently, there is an urgent need for a\nunified data control system to facilitate the integration of varying libraries.\nThis integration is of profound significance in accelerating prototype\nverification, optimising algorithm performance and minimising maintenance\ncosts. This paper presents a novel functional programming (FP) paradigm based\non the Python architecture and associated suites in programming practice,\ndesigned for the integration of pipelines of different data mapping operations.\nIn particular, the solution is intended for the integration of scientific\ncomputation flows, which affords a robust yet flexible solution for the\naforementioned challenges.\n",
        "authors": "Chen Zhang; Lecheng Jia; Wei Zhang; Ning Wen",
        "status": 0,
        "relevancy": 0.26921365042337875,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17176",
        "date": "2024-05-27",
        "title": "DreamMat: High-quality PBR Material Generation with Geometry- and\n  Light-aware Diffusion Models",
        "abstract": "  2D diffusion model, which often contains unwanted baked-in shading effects\nand results in unrealistic rendering effects in the downstream applications.\nGenerating Physically Based Rendering (PBR) materials instead of just RGB\ntextures would be a promising solution. However, directly distilling the PBR\nmaterial parameters from 2D diffusion models still suffers from incorrect\nmaterial decomposition, such as baked-in shading effects in albedo. We\nintroduce DreamMat, an innovative approach to resolve the aforementioned\nproblem, to generate high-quality PBR materials from text descriptions. We find\nout that the main reason for the incorrect material distillation is that\nlarge-scale 2D diffusion models are only trained to generate final shading\ncolors, resulting in insufficient constraints on material decomposition during\ndistillation. To tackle this problem, we first finetune a new light-aware 2D\ndiffusion model to condition on a given lighting environment and generate the\nshading results on this specific lighting condition. Then, by applying the same\nenvironment lights in the material distillation, DreamMat can generate\nhigh-quality PBR materials that are not only consistent with the given geometry\nbut also free from any baked-in shading effects in albedo. Extensive\nexperiments demonstrate that the materials produced through our methods exhibit\ngreater visual appeal to users and achieve significantly superior rendering\nquality compared to baseline methods, which are preferable for downstream tasks\nsuch as game and film production.\n",
        "authors": "Yuqing Zhang; Yuan Liu; Zhiyu Xie; Lei Yang; Zhongyuan Liu; Mengzhou Yang; Runze Zhang; Qilong Kou; Cheng Lin; Wenping Wang; Xiaogang Jin",
        "status": 0,
        "relevancy": 0.25740473378688034,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17413",
        "date": "2024-05-27",
        "title": "Enhancing Music Genre Classification through Multi-Algorithm Analysis\n  and User-Friendly Visualization",
        "abstract": "  The aim of this study is to teach an algorithm how to recognize different\ntypes of music. Users will submit songs for analysis. Since the algorithm\nhasn't heard these songs before, it needs to figure out what makes each song\nunique. It does this by breaking down the songs into different parts and\nstudying things like rhythm, melody, and tone via supervised learning because\nthe program learns from examples that are already labelled. One important thing\nto consider when classifying music is its genre, which can be quite complex. To\nensure accuracy, we use five different algorithms, each working independently,\nto analyze the songs. This helps us get a more complete understanding of each\nsong's characteristics. Therefore, our goal is to correctly identify the genre\nof each submitted song. Once the analysis is done, the results are presented\nusing a graphing tool, making it easy for users to understand and provide\nfeedback.\n",
        "authors": "Navin Kamuni; Dheerendra Panwar",
        "status": 0,
        "relevancy": 0.2500404254243823,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17116",
        "date": "2024-05-27",
        "title": "Mixtures of Unsupervised Lexicon Classification",
        "abstract": "  This paper presents a mixture version of the method-of-moment unsupervised\nlexicon classification by an incorporation of a Dirichlet process.\n",
        "authors": "Peratham Wiriyathammabhum",
        "status": 0,
        "relevancy": 0.23446744584451407,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17576",
        "date": "2024-05-27",
        "title": "Container pre-marshalling problem minimizing CV@R under uncertainty of\n  ship arrival times",
        "abstract": "  This paper is concerned with the container pre-marshalling problem, which\ninvolves relocating containers in the storage area so that they can be\nefficiently loaded onto ships without reshuffles. In reality, however, ship\narrival times are affected by various external factors, which can cause the\norder of container retrieval to be different from the initial plan. To\nrepresent such uncertainty, we generate multiple scenarios from a multivariate\nprobability distribution of ship arrival times. We derive a mixed-integer\nlinear optimization model to find an optimal container layout such that the\nconditional value-at-risk is minimized for the number of misplaced containers\nresponsible for reshuffles. Moreover, we devise an exact algorithm based on the\ncutting-plane method to handle large-scale problems. Numerical experiments\nusing synthetic datasets demonstrate that our method can produce high-quality\ncontainer layouts compared with the conventional robust optimization model.\nAdditionally, our algorithm can speed up the computation of solving large-scale\nproblems.\n",
        "authors": "Daiki Ikuma; Shunnosuke Ikeda; Noriyoshi Sukegawa; Yuichi Takano",
        "status": 0,
        "relevancy": 0.2171130374575132,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17038",
        "date": "2024-05-27",
        "title": "Advancements in Tactile Hand Gesture Recognition for Enhanced\n  Human-Machine Interaction",
        "abstract": "  Motivated by the growing interest in enhancing intuitive physical\nHuman-Machine Interaction (HRI/HVI), this study aims to propose a robust\ntactile hand gesture recognition system. We performed a comprehensive\nevaluation of different hand gesture recognition approaches for a large area\ntactile sensing interface (touch interface) constructed from conductive\ntextiles. Our evaluation encompassed traditional feature engineering methods,\nas well as contemporary deep learning techniques capable of real-time\ninterpretation of a range of hand gestures, accommodating variations in hand\nsizes, movement velocities, applied pressure levels, and interaction points.\nOur extensive analysis of the various methods makes a significant contribution\nto tactile-based gesture recognition in the field of human-machine interaction.\n",
        "authors": "Chiara Fumelli; Anirvan Dutta; Mohsen Kaboli",
        "status": 0,
        "relevancy": 0.19371136395567634,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      },
      {
        "id": "2405.17676",
        "date": "2024-05-27",
        "title": "Utilising a Quantum Hybrid Solver for Bi-objective Quadratic Assignment\n  Problems",
        "abstract": "  The intersection between quantum computing and optimisation has been an area\nof interest in recent years. There have been numerous studies exploring the\napplication of quantum and quantum-hybrid solvers to various optimisation\nproblems. This work explores scalarisation methods within the context of\nsolving the bi-objective quadratic assignment problem using a quantum-hybrid\nsolver. We show results that are consistent with previous research on a\ndifferent Ising machine.\n",
        "authors": "Mayowa Ayodele",
        "status": 0,
        "relevancy": 0.18695488808112448,
        "isStarred": false,
        "keywords": null,
        "createdAt": "2024-05-31T04:51:34.029Z",
        "updatedAt": "2024-05-31T04:51:34.029Z",
        "DatesTable": {
          "value": "2024-05-27",
          "status": "complete",
          "count": 126,
          "createdAt": "2024-05-31T00:09:48.114Z",
          "updatedAt": "2024-05-31T04:51:34.031Z"
        }
      }
    ]
  }
]